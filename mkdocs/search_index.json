{
    "docs": [
        {
            "location": "/",
            "text": "0. Foreword\n\u00b6\n\n\nThe ABINIT project is a group effort of dozens of people worldwide, whose\ncentral outcome is the main ABINIT application, delivered with many other\nfiles in the ABINIT package. The ABINIT project includes also resources\nprovided on the \nABINIT Web site\n and the \n\nABINIT Github repository\n.\n\n\n\n\nWarning\n\n\nBefore reading the present file, and get some grasp about the main ABINIT\napplication, you should get some theoretical background. In case you have\nalready used another electronic structure code, or a quantum chemistry code,\nit might be sufficient to read the introduction of the paper ``Iterative\nminimization techniques for ab initio total-energy calculations: molecular\ndynamics and conjugate gradients\u2019\u2018 M. C. Payne, M. P. Teter, D. C. Allan, T.\nA. Arias, and J. D. Joannopoulos, Rev. Mod. Phys. 64, 1045-1097 (1992).\nIf you have never used another electronic structure code or a Quantum\nChemistry package, you should complete such reading by going (at your own\npace) through the Chaps. 1 to 13 , and appendices L and M of the book\nElectronic Structure. Basic Theory and Practical Methods. R. M. Martin.\nCambridge University Press (2004) ISBN 0 521 78285 6.\n\n\n\n\nAfter having gone through the present New User\u2019s Guide, you should follow the\nABINIT tutorial (\nlesson_welcome\n).\n\n\n\n\n1. Introduction\n\u00b6\n\n\nABINIT is a package whose main program allows to find the total energy, charge\ndensity and electronic structure of systems made of electrons and nuclei\n(molecules and periodic solids) within Density Functional Theory, using\npseudopotentials and a planewave basis, or augmented plane waves, or even\nwavelets. Some possibilities of ABINIT go beyond Density Functional Theory,\ni.e. the many-body perturbation theory (GW approximation the Bethe-Salpether\nequation), Time-Dependent Density Functional Theory, Dynamical Mean-Field\nTheory, the Allen-Heine-Cardona theory to find temperature-dependent\nelectronic structure. ABINIT also includes options to optimize the geometry\naccording to the DFT forces and stresses, or to perform molecular dynamics\nsimulation using these forces, or to generate dynamical (vibrations - phonons)\nproperties, dielectric properties, mechanical properties, thermodynamical\nproperties, etc . In addition to the main ABINIT code, different utility\nprograms are provided.\n\n\nWe suppose that you have downloaded the ABINIT package from the Web site,\nunpacked it and installed it. If not, you might nevertheless continue reading\nthe present Web page, just to get an overview, but it might prove more\nfruitful to have first downloaded the ABINIT package and at least unpacked it,\nsee the \ninstallation notes\n.\n\n\nWe will use the name \u201c~abinit\u201d to refer to the directory that contains the\nABINIT package after download. In practice, a version number is appended to\nthis name, to give for example : abinit-8.4.0 . The ABINIT package versioning\nscheme is explained later in this file.\n\n\n~abinit contains different subdirectories. For example, the present file, as\nwell as other descriptive files, should be found in ~abinit/doc/users . Other\nsubdirectories will be described later.\n\n\n\n\n2. The ABINIT executable : abinit. \n\u00b6\n\n\nAfter compilation, the main code will be present in the package as\n~abinit/src/98_main/abinit (or perhaps at another place, depending on your\ninstallation).\n\n\nTo run abinit you need four things:\n\n\n\n\nAccess to the executable, abinit. \n\n\nAn input file. \n\n\nA files file (list of file names in a file). \n\n\nA pseudopotential input file for each kind of element in the unit cell. \n\n\n\n\nWith these items a job can be run.\n\n\nThe full list of input variables, all of which are provided in the single\ninput file, is given in the ABINIT \nallvariables\n.\n\nThe detailed description of input variables is given in many \u201cVAR*\u201d files,\nincluding:\n\n\n\n\nBasic variables, \nvarbas\n\n\nGround-state calculation variables, \nvargs\n\n\nGW variables, \nvargw\n\n\nFiles handling variables, \nvarfil\n\n\nParallelisation variables, \nvarpar\n\n\nResponse Function variables, \nvarrf\n\n\n\u2026 \n\n\n\n\nA set of examples aimed at guiding the beginner is available in the tutorial\n(\nlesson_welcome\n).\n\n\nOther test cases (more than 800 input files) can be found in the ~abinit/test\nsubdirectories, e.g. \u201cfast\u201d, the \u201cvX\u201d series (v1, v2, \u2026 v67mbpt, v7, v8),\n\u201clibxc\u201d, \u201cparal\u201d, the \u201ctutoX\u201d series \u2026\n\n\nMany different sorts of pseudopotentials can be used with ABINIT. Most of them\ncan be found on the \natomic data\nfiles\n page of the ABINIT\nweb site. There are official recommended pseudopotentials tables (the PAW JTH\ntable, and the norm-conserving table from ONCVPSP), and also some older sets\nof pseudopotentials. A subset of existing pseudopotentials are used for test\ncases, and are located in the ~abinit/tests/Psps_for_tests directory, but they\nare not recommended for production. Information on pseudopotential files can\nbe found in the \nABINIT help file\n and the ~abinit/doc/psp_infos directory.\n\n\n\n\n3. Other programs in the ABINIT package.\n\u00b6\n\n\nIn addition to abinit, there are utility programs provided in the ABINIT\npackage.\n\n\nSome utility programs are written in F90 (like the main abinit program), and\ntheir sources is also in ~abinit/src/98_main .\n\nThese include : \nmrgddb\n, \nanaddb\n, \naim\n, \nconducti\n, \noptics\n,\n\nmrgscr\n, \ncut3d\n, and \nfold2Bloch\n.\n\n\nmrgddb\n and \nanaddb\n allow to post-process responses to atomic displacements and/or to homogeneous electric field, and/or to strain perturbation, as generated by abinit, to produce full phonon band structures, thermodynamical functions, piezoelectric properties, superconducting properties, to name a few. \u201cmrgddb\u201d is for \u201cMerge of Derivative DataBases\u201d, while \u201canaddb\u201d is for \u201cAnalysis of Derivative DataBases\u201d. \n\n\ncut3d\n can be used to post-process the three-dimensional density (or potential) files generated by abinit. It allows one to deduce charge density in selected planes (for isodensity plots), along selected lines, or at selected points. It allows one also to make the Hirshfeld decomposition of the charge density in \u201catomic\u201d contributions. \n\n\nfold2Bloch\n is used for unfolding of first-principle electronic band structure obtained with ABINIT code. \n\n\naim\n is also a post-processor of the three-dimensional density files generated by abinit. It performs the Bader Atom-In-Molecule decomposition of the charge density in \u201catomic\u201d contributions. \n\n\nconducti\n allows one to compute the frequency-dependent optical conductivity. \n\n\nSome utility programs are not written in F90, but in Python. They are\ncontained in ~abinit/scripts, where post-processing (numerous tools) and pre-\nprocessing scripts are distinguished. Some allows one to visualize ABINIT\noutputs, like abinit_eignc_to_bandstructure.py .\n\n\n\n\n4. Other resources outside the ABINIT package.\n\u00b6\n\n\nIn addition to the ABINIT package, other resources can be obtained from the\n\nABINIT GitHub site\n. The sources of the latest\nversion of the ABINIT package are actually mirrored on this site, but for\nother resources (not in the package) this is the only download point.\n\n\nabipy\n is an open-source library for analyzing the results produced by ABINIT (including visualisation), and for preparing input files and workflows to automate ab-initio calculations (so-called high-throughput calculations). It provides interface with pymatgen, developed by the Materials Project. Links for AbiPy : \nhttps://github.com/abinit/abipy\n, and \nhttp://abinit.github.io/abipy\n. \n\n\nThe \npseudo-dojo\n is a Python framework for generating and validating\npseudopotentials (or PAW atomic data files). Normal ABINIT users benefit a lot\nfrom this project, since the ABINIT recommended table of norm-conserving\npseudopotentials has been generated thanks to it, while the PAW recommended\ntable is under control of it. Albeit, only specialized ABINIT experts use it.\n\n\nabiconfig\n is a holding area for configuration files used to configure/compile Abinit on clusters. You might benefit from it if you have indeed to install Abinit on a cluster. \n\n\nabiconda\n contains conda recipes to build Abinit-related packages (like AbiPy). You might benefit from it if you install Abipy on your machine. \n\n\nabiflows\n provides flows for high-throughput calculations with ABINIT. \n\n\nIn addition to the resources that the ABINIT developer provide to the\ncommunity through the ABINIT packages, portal and Github, many ABINIT-\nindependent commercial or free applications can be used to visualize ABINIT\noutputs or interact with ABINIT. We provide a (not very well maintained) list\nof links in \nhttp://www.abinit.org/community/links\n. Of course, you might get\nmore by browsing the Web\u2026\n\n\n\n\n5. Input variables to abinit.\n\u00b6\n\n\nAs an overview, the most important input variables, to be provided in the\ninput file, are listed below:\n\n\nSpecification of the geometry of the problem, and types of atoms :\n\n\n\n\nnatom\n\n\ntotal number of atoms in unit cell\n\n\nntypat\n\n\nnumber of types of atoms\n\n\n\n\n\n\nNote\n\n\nthe atomic coordinates (\nxangst\n, \nxcart\n or \nxred\n)\nmust be specified in the same order\n\n\n\n\n\n\nrprim\n (3,3)\n\n\nunscaled primitive translations of periodic cell;\n  each COLUMN of this array is one primitive translation\n\n\nxangst\n (3,\nnatom\n)\n\n\ncartesian coordinates (Angstrom) of atoms in unit cell\n  NOTE: only used when \nxred\n and \nxcart\n are absent\n\n\nxcart\n (3,\nnatom\n)\n\n\ncartesian coordinates (Bohr) of atoms in unit cell\n  NOTE: only used when \nxred\n and \nxangst\n are absent\n\n\nxred\n (3,\nnatom\n)\n\n\nfractional coordinates for atomic locations;\n  NOTE: leave out if \nxangst\n or \nxcart\n is used\n\n\nznucl\n (\nntypat\n)\n\n\nNuclear charge of each type of element; must agree with\n  nuclear charge found in psp file.\n\n\n\n\nSpecification of the planewave basis set, Brillouin zone wavevector sampling, and occupation of the bands:\n\n\n\n\necut\n\n\nplanewave kinetic energy cutoff in Hartree\n\n\nkptopt\n\n\noption for specifying the k-point grid\n  if \nkptopt\n=1, automatic generation, using ngkpt and shiftk.\n  (for the latter, see the \nhelp_abinit\n file)\n\n\nngkpt\n (3)\n\n\ndimensions of the three-dimensional grid of k-points\n\n\noccopt\n\n\nset the occupation of electronic levels:\n=1 for semiconductors\n=3 \u2026 7  for metals\n\n\n\n\nSpecification of the type of calculation to be done:\n\n\n\n\nionmov\n\n\nwhen \nionmov\n = 0 : the ions and cell shape are fixed\n              = 2 : search for the equilibrium geometry\n              = 6 : molecular dynamics\n\n\niscf\n\n\neither a positive number for defining self-consistent\n  algorithm (usual), or -2 for band structure in fixed potential\n\n\noptdriver\n\n\nwhen == 3 and 4 : will do GW calculations (many-body perturbation theory)\n\n\nrfelfd\n\n\nwhen /= 0 : will do response calculation to electric field\n\n\nrfphon\n\n\nwhen = 1 : will do response calculation to atomic displacements\n\n\n\n\nSpecification of the numerical convergency of the calculation:\n\n\n\n\nnstep\n\n\nmaximal number of self-consistent cycles (on the order of 20)\n\n\ntolvrs\n\n\ntolerance on self-consistent convergence\n\n\nntime\n\n\nnumber of molecular dynamics or relaxation steps\n\n\ntolmxf\n\n\nforce tolerance for structural relaxation in Hartree/Bohr\n\n\n\n\n\n\n 6. Output files.\n\u00b6\n\n\nOutput from an abinit run shows up in several files and in the standard\noutput. Usually one runs the command with a pipe of standard output to a log\nfile, which can be inspected for warnings or error messages if anything goes\nwrong or otherwise can be discarded at the end of a run. The more easily\nreadable formatted output goes to the output file whose name is given in the\n\u201cfiles\u201d file, i.e. you provide the name of the formatted output file. No error\nmessage is reported in the latter file. On the other hand, this is the file\nthat is usually kept for archival purposes.\n\n\nIn addition, wavefunctions can be input (starting point) or output (result of\nthe calculation), and possibly, charge density and/or electrostatic potential,\nif they have been asked for. These three sets of data are stored in\nunformatted files.\n\nThe Density Of States (DOS) can also be an output as a formatted (readable)\nfile.\n\nAn analysis of geometry can also be provided (GEO file)\n\nThe name of these files is constructed from a \u201croot\u201d name, that must be\ndifferent for input files and output files, and that is provided by the user,\nto which the code will append a descriptor, like WFK for wavefunctions, DEN\nfor the density, POT for the potential, DOS for the density of states \u2026\n\n\nThere are also different temporary files. A \u201croot\u201d name should be provided by\nthe user, from which the code generates a full name. Amongst these files,\nthere is a \u201cstatus\u201d file, summarizing the current status of advancement of the\ncode, in long jobs. The \nABINIT help file\n contains more details.\n\n\n\n\n 7. What does the code do?\n\u00b6\n\n\nThe simplest sort of job computes an electronic structure for a fixed set of\natomic positions within a periodic unit cell. By electronic structure, we mean\na set of eigenvalues and wavefunctions which achieve the lowest (DFT) energy\npossible for that basis set (that number of planewaves). The code takes the\ndescription of the unit cell and atomic positions and assembles a crystal\npotential from the input atomic pseudopotentials, then uses either an input\nwavefunction or simple gaussians to generate the initial charge density and\nscreening potential, then uses a self-consistent algorithm to iteratively\nadjust the planewave coefficients until a sufficient convergence is reached in\nthe energy.\n\n\nAnalytic derivatives of the energy with respect to atomic positions and unit\ncell primitive translations yield atomic forces and the stress tensor. The\ncode can optionally adjust atomic positions to move the forces toward zero and\nadjust unit cell parameters to move toward zero stress. It can performs\nmolecular dynamics. It can also be used to find responses to atomic\ndisplacements and homogeneous electric field, so that the full phonon band\nstructure can be constructed\u2026\n\n\n\n\n 8. Versioning logic.\n\u00b6\n\n\nWe finish this \u201cnew user guide\u201d with a brief explanation of the logic of\nABINIT version releases.\n\n\nThe full name of a version has three digits (for example, 8.4.0). The first\ndigit is the slowly varying one (in average, it is changed after two or three\nyears). It indicates the major efforts and trends in that version. At the\nlevel of 1.x.y ABINIT (before 2000 !), the major effort was placed on the\n\u201cground-state\u201d properties (total energy, forces, geometry optimisation,\nmolecular dynamics \u2026). With version 2.x.y , response-function features\n(phonons, dielectric response, effective charges, interatomic force constants\n\u2026) were included. The main additional characteristics of version 3.x.y were\nthe distribution under the GNU General Public Licence, the set-up of the\ndocumentation and help to the user through the Web site in html format, and\nthe availability of GW capabilities. The version 4.x.y put a lot of effort in\nthe speed of ABINIT (e.g. PAW), and its parallelisation. These historical\ndevelopments explain why the tests are gathered in directories \u201cv1\u201d, \u201cv2\u201d,\n\u201cv3\u201d, etc. Every 4 to 8 months, we release a \u201cproduction version\u201d of ABINIT in\nwhich the second digit, an even number, is incremented, which usually goes\nwith additional features. A release notes document is issued, with the list of\nadditional capabilities, and other information with respect to modifications\nwith the previous release. The odd second digits are used for internal\nmanagement only, so-called \u201cdevelopment versions\u201d of ABINIT (for example\n8.5.0). Two versions differing by the last (third) digit have the same\ncapabilities, but the one with the largest last digit is more debugged than\nthe other : version 8.4.1 is more debugged than 8.4.0, but no new features has\nbeen added (so likely, no additional bug!).\n\n\n\n\nIn order to start using ABINIT, please follow the tutorial\n(\nlesson_welcome\n)",
            "title": "Introduction"
        },
        {
            "location": "/#046-foreword",
            "text": "The ABINIT project is a group effort of dozens of people worldwide, whose\ncentral outcome is the main ABINIT application, delivered with many other\nfiles in the ABINIT package. The ABINIT project includes also resources\nprovided on the  ABINIT Web site  and the  ABINIT Github repository .   Warning  Before reading the present file, and get some grasp about the main ABINIT\napplication, you should get some theoretical background. In case you have\nalready used another electronic structure code, or a quantum chemistry code,\nit might be sufficient to read the introduction of the paper ``Iterative\nminimization techniques for ab initio total-energy calculations: molecular\ndynamics and conjugate gradients\u2019\u2018 M. C. Payne, M. P. Teter, D. C. Allan, T.\nA. Arias, and J. D. Joannopoulos, Rev. Mod. Phys. 64, 1045-1097 (1992).\nIf you have never used another electronic structure code or a Quantum\nChemistry package, you should complete such reading by going (at your own\npace) through the Chaps. 1 to 13 , and appendices L and M of the book\nElectronic Structure. Basic Theory and Practical Methods. R. M. Martin.\nCambridge University Press (2004) ISBN 0 521 78285 6.   After having gone through the present New User\u2019s Guide, you should follow the\nABINIT tutorial ( lesson_welcome ).",
            "title": "0. Foreword"
        },
        {
            "location": "/#146-introduction",
            "text": "ABINIT is a package whose main program allows to find the total energy, charge\ndensity and electronic structure of systems made of electrons and nuclei\n(molecules and periodic solids) within Density Functional Theory, using\npseudopotentials and a planewave basis, or augmented plane waves, or even\nwavelets. Some possibilities of ABINIT go beyond Density Functional Theory,\ni.e. the many-body perturbation theory (GW approximation the Bethe-Salpether\nequation), Time-Dependent Density Functional Theory, Dynamical Mean-Field\nTheory, the Allen-Heine-Cardona theory to find temperature-dependent\nelectronic structure. ABINIT also includes options to optimize the geometry\naccording to the DFT forces and stresses, or to perform molecular dynamics\nsimulation using these forces, or to generate dynamical (vibrations - phonons)\nproperties, dielectric properties, mechanical properties, thermodynamical\nproperties, etc . In addition to the main ABINIT code, different utility\nprograms are provided.  We suppose that you have downloaded the ABINIT package from the Web site,\nunpacked it and installed it. If not, you might nevertheless continue reading\nthe present Web page, just to get an overview, but it might prove more\nfruitful to have first downloaded the ABINIT package and at least unpacked it,\nsee the  installation notes .  We will use the name \u201c~abinit\u201d to refer to the directory that contains the\nABINIT package after download. In practice, a version number is appended to\nthis name, to give for example : abinit-8.4.0 . The ABINIT package versioning\nscheme is explained later in this file.  ~abinit contains different subdirectories. For example, the present file, as\nwell as other descriptive files, should be found in ~abinit/doc/users . Other\nsubdirectories will be described later.",
            "title": "1. Introduction"
        },
        {
            "location": "/#246-the-abinit-executable-abinit",
            "text": "After compilation, the main code will be present in the package as\n~abinit/src/98_main/abinit (or perhaps at another place, depending on your\ninstallation).  To run abinit you need four things:   Access to the executable, abinit.   An input file.   A files file (list of file names in a file).   A pseudopotential input file for each kind of element in the unit cell.    With these items a job can be run.  The full list of input variables, all of which are provided in the single\ninput file, is given in the ABINIT  allvariables . \nThe detailed description of input variables is given in many \u201cVAR*\u201d files,\nincluding:   Basic variables,  varbas  Ground-state calculation variables,  vargs  GW variables,  vargw  Files handling variables,  varfil  Parallelisation variables,  varpar  Response Function variables,  varrf  \u2026    A set of examples aimed at guiding the beginner is available in the tutorial\n( lesson_welcome ).  Other test cases (more than 800 input files) can be found in the ~abinit/test\nsubdirectories, e.g. \u201cfast\u201d, the \u201cvX\u201d series (v1, v2, \u2026 v67mbpt, v7, v8),\n\u201clibxc\u201d, \u201cparal\u201d, the \u201ctutoX\u201d series \u2026  Many different sorts of pseudopotentials can be used with ABINIT. Most of them\ncan be found on the  atomic data\nfiles  page of the ABINIT\nweb site. There are official recommended pseudopotentials tables (the PAW JTH\ntable, and the norm-conserving table from ONCVPSP), and also some older sets\nof pseudopotentials. A subset of existing pseudopotentials are used for test\ncases, and are located in the ~abinit/tests/Psps_for_tests directory, but they\nare not recommended for production. Information on pseudopotential files can\nbe found in the  ABINIT help file  and the ~abinit/doc/psp_infos directory.",
            "title": "2. The ABINIT executable : abinit."
        },
        {
            "location": "/#346-other-programs-in-the-abinit-package",
            "text": "In addition to abinit, there are utility programs provided in the ABINIT\npackage.  Some utility programs are written in F90 (like the main abinit program), and\ntheir sources is also in ~abinit/src/98_main . \nThese include :  mrgddb ,  anaddb ,  aim ,  conducti ,  optics , mrgscr ,  cut3d , and  fold2Bloch .  mrgddb  and  anaddb  allow to post-process responses to atomic displacements and/or to homogeneous electric field, and/or to strain perturbation, as generated by abinit, to produce full phonon band structures, thermodynamical functions, piezoelectric properties, superconducting properties, to name a few. \u201cmrgddb\u201d is for \u201cMerge of Derivative DataBases\u201d, while \u201canaddb\u201d is for \u201cAnalysis of Derivative DataBases\u201d.   cut3d  can be used to post-process the three-dimensional density (or potential) files generated by abinit. It allows one to deduce charge density in selected planes (for isodensity plots), along selected lines, or at selected points. It allows one also to make the Hirshfeld decomposition of the charge density in \u201catomic\u201d contributions.   fold2Bloch  is used for unfolding of first-principle electronic band structure obtained with ABINIT code.   aim  is also a post-processor of the three-dimensional density files generated by abinit. It performs the Bader Atom-In-Molecule decomposition of the charge density in \u201catomic\u201d contributions.   conducti  allows one to compute the frequency-dependent optical conductivity.   Some utility programs are not written in F90, but in Python. They are\ncontained in ~abinit/scripts, where post-processing (numerous tools) and pre-\nprocessing scripts are distinguished. Some allows one to visualize ABINIT\noutputs, like abinit_eignc_to_bandstructure.py .",
            "title": "3. Other programs in the ABINIT package."
        },
        {
            "location": "/#446-other-resources-outside-the-abinit-package",
            "text": "In addition to the ABINIT package, other resources can be obtained from the ABINIT GitHub site . The sources of the latest\nversion of the ABINIT package are actually mirrored on this site, but for\nother resources (not in the package) this is the only download point.  abipy  is an open-source library for analyzing the results produced by ABINIT (including visualisation), and for preparing input files and workflows to automate ab-initio calculations (so-called high-throughput calculations). It provides interface with pymatgen, developed by the Materials Project. Links for AbiPy :  https://github.com/abinit/abipy , and  http://abinit.github.io/abipy .   The  pseudo-dojo  is a Python framework for generating and validating\npseudopotentials (or PAW atomic data files). Normal ABINIT users benefit a lot\nfrom this project, since the ABINIT recommended table of norm-conserving\npseudopotentials has been generated thanks to it, while the PAW recommended\ntable is under control of it. Albeit, only specialized ABINIT experts use it.  abiconfig  is a holding area for configuration files used to configure/compile Abinit on clusters. You might benefit from it if you have indeed to install Abinit on a cluster.   abiconda  contains conda recipes to build Abinit-related packages (like AbiPy). You might benefit from it if you install Abipy on your machine.   abiflows  provides flows for high-throughput calculations with ABINIT.   In addition to the resources that the ABINIT developer provide to the\ncommunity through the ABINIT packages, portal and Github, many ABINIT-\nindependent commercial or free applications can be used to visualize ABINIT\noutputs or interact with ABINIT. We provide a (not very well maintained) list\nof links in  http://www.abinit.org/community/links . Of course, you might get\nmore by browsing the Web\u2026",
            "title": "4. Other resources outside the ABINIT package."
        },
        {
            "location": "/#546-input-variables-to-abinit",
            "text": "As an overview, the most important input variables, to be provided in the\ninput file, are listed below:  Specification of the geometry of the problem, and types of atoms :   natom  total number of atoms in unit cell  ntypat  number of types of atoms    Note  the atomic coordinates ( xangst ,  xcart  or  xred )\nmust be specified in the same order    rprim  (3,3)  unscaled primitive translations of periodic cell;\n  each COLUMN of this array is one primitive translation  xangst  (3, natom )  cartesian coordinates (Angstrom) of atoms in unit cell\n  NOTE: only used when  xred  and  xcart  are absent  xcart  (3, natom )  cartesian coordinates (Bohr) of atoms in unit cell\n  NOTE: only used when  xred  and  xangst  are absent  xred  (3, natom )  fractional coordinates for atomic locations;\n  NOTE: leave out if  xangst  or  xcart  is used  znucl  ( ntypat )  Nuclear charge of each type of element; must agree with\n  nuclear charge found in psp file.   Specification of the planewave basis set, Brillouin zone wavevector sampling, and occupation of the bands:   ecut  planewave kinetic energy cutoff in Hartree  kptopt  option for specifying the k-point grid\n  if  kptopt =1, automatic generation, using ngkpt and shiftk.\n  (for the latter, see the  help_abinit  file)  ngkpt  (3)  dimensions of the three-dimensional grid of k-points  occopt  set the occupation of electronic levels:\n=1 for semiconductors\n=3 \u2026 7  for metals   Specification of the type of calculation to be done:   ionmov  when  ionmov  = 0 : the ions and cell shape are fixed\n              = 2 : search for the equilibrium geometry\n              = 6 : molecular dynamics  iscf  either a positive number for defining self-consistent\n  algorithm (usual), or -2 for band structure in fixed potential  optdriver  when == 3 and 4 : will do GW calculations (many-body perturbation theory)  rfelfd  when /= 0 : will do response calculation to electric field  rfphon  when = 1 : will do response calculation to atomic displacements   Specification of the numerical convergency of the calculation:   nstep  maximal number of self-consistent cycles (on the order of 20)  tolvrs  tolerance on self-consistent convergence  ntime  number of molecular dynamics or relaxation steps  tolmxf  force tolerance for structural relaxation in Hartree/Bohr",
            "title": "5. Input variables to abinit."
        },
        {
            "location": "/#646-output-files",
            "text": "Output from an abinit run shows up in several files and in the standard\noutput. Usually one runs the command with a pipe of standard output to a log\nfile, which can be inspected for warnings or error messages if anything goes\nwrong or otherwise can be discarded at the end of a run. The more easily\nreadable formatted output goes to the output file whose name is given in the\n\u201cfiles\u201d file, i.e. you provide the name of the formatted output file. No error\nmessage is reported in the latter file. On the other hand, this is the file\nthat is usually kept for archival purposes.  In addition, wavefunctions can be input (starting point) or output (result of\nthe calculation), and possibly, charge density and/or electrostatic potential,\nif they have been asked for. These three sets of data are stored in\nunformatted files. \nThe Density Of States (DOS) can also be an output as a formatted (readable)\nfile. \nAn analysis of geometry can also be provided (GEO file) \nThe name of these files is constructed from a \u201croot\u201d name, that must be\ndifferent for input files and output files, and that is provided by the user,\nto which the code will append a descriptor, like WFK for wavefunctions, DEN\nfor the density, POT for the potential, DOS for the density of states \u2026  There are also different temporary files. A \u201croot\u201d name should be provided by\nthe user, from which the code generates a full name. Amongst these files,\nthere is a \u201cstatus\u201d file, summarizing the current status of advancement of the\ncode, in long jobs. The  ABINIT help file  contains more details.",
            "title": "6. Output files."
        },
        {
            "location": "/#746-what-does-the-code-do",
            "text": "The simplest sort of job computes an electronic structure for a fixed set of\natomic positions within a periodic unit cell. By electronic structure, we mean\na set of eigenvalues and wavefunctions which achieve the lowest (DFT) energy\npossible for that basis set (that number of planewaves). The code takes the\ndescription of the unit cell and atomic positions and assembles a crystal\npotential from the input atomic pseudopotentials, then uses either an input\nwavefunction or simple gaussians to generate the initial charge density and\nscreening potential, then uses a self-consistent algorithm to iteratively\nadjust the planewave coefficients until a sufficient convergence is reached in\nthe energy.  Analytic derivatives of the energy with respect to atomic positions and unit\ncell primitive translations yield atomic forces and the stress tensor. The\ncode can optionally adjust atomic positions to move the forces toward zero and\nadjust unit cell parameters to move toward zero stress. It can performs\nmolecular dynamics. It can also be used to find responses to atomic\ndisplacements and homogeneous electric field, so that the full phonon band\nstructure can be constructed\u2026",
            "title": "7. What does the code do?"
        },
        {
            "location": "/#846-versioning-logic",
            "text": "We finish this \u201cnew user guide\u201d with a brief explanation of the logic of\nABINIT version releases.  The full name of a version has three digits (for example, 8.4.0). The first\ndigit is the slowly varying one (in average, it is changed after two or three\nyears). It indicates the major efforts and trends in that version. At the\nlevel of 1.x.y ABINIT (before 2000 !), the major effort was placed on the\n\u201cground-state\u201d properties (total energy, forces, geometry optimisation,\nmolecular dynamics \u2026). With version 2.x.y , response-function features\n(phonons, dielectric response, effective charges, interatomic force constants\n\u2026) were included. The main additional characteristics of version 3.x.y were\nthe distribution under the GNU General Public Licence, the set-up of the\ndocumentation and help to the user through the Web site in html format, and\nthe availability of GW capabilities. The version 4.x.y put a lot of effort in\nthe speed of ABINIT (e.g. PAW), and its parallelisation. These historical\ndevelopments explain why the tests are gathered in directories \u201cv1\u201d, \u201cv2\u201d,\n\u201cv3\u201d, etc. Every 4 to 8 months, we release a \u201cproduction version\u201d of ABINIT in\nwhich the second digit, an even number, is incremented, which usually goes\nwith additional features. A release notes document is issued, with the list of\nadditional capabilities, and other information with respect to modifications\nwith the previous release. The odd second digits are used for internal\nmanagement only, so-called \u201cdevelopment versions\u201d of ABINIT (for example\n8.5.0). Two versions differing by the last (third) digit have the same\ncapabilities, but the one with the largest last digit is more debugged than\nthe other : version 8.4.1 is more debugged than 8.4.0, but no new features has\nbeen added (so likely, no additional bug!).   In order to start using ABINIT, please follow the tutorial\n( lesson_welcome )",
            "title": "8. Versioning logic."
        },
        {
            "location": "/installation/",
            "text": "Installation notes for ABINIT v8.4\n\u00b6\n\n\n\n\nThis file provides a description of the operations needed to install the\nABINIT package, to generate the executable and to make the tests. It provides\nalso the description of simple modifications of the package, for developers.\n\n\nSee a recent version of the \nnew user\u2019s guide\n,\nfor an introduction to the abinit package. See a recent version of the \nabinit\nhelp\n file for learning how to use the code. Both\nof them can be found either on the Web, or in the doc subdirectory of the\npackage.\n\n\nAny comment or suggestion to improve the procedure will be welcome! Simply\ncontact the ABINIT group (http://forum.abinit.org/).\n\n\n\n\n\n\nInstallation notes for ABINIT v8.4\n\n\n0. Short how to \u2026\n\n\n1. How to get a version of ABINIT?\n\n\n1.A. Expert user of developer\n\n\n1.B. Normal user\n\n\n\n\n\n\n2. How to make the executables? (=How to compile the executables?)\n\n\n3. How to make the internal tests?\n\n\n5. How to make the other tests?\n\n\n6. Things that are NOT in the installation packages.\n\n\n7. For developers: how to modify the code?\n\n\n7.1. To modify a file (arguments unchanged).\n\n\n7.2. To modify a file (arguments changed).\n\n\n7.3. To add a Fortran file.\n\n\n7.4. To generate the source package.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0. Short how to \u2026\n\u00b6\n\n\nFor the vast majority of people willing to use ABINIT (Unix/Linux, not developers, but users), \nhere follows a short list of instructions needed to install it:\n\n\n\n\nDownload, gunzip and untar the \nlatest version of the ABINIT package\n (abinit-x.y.z.tar.gz) from the abinit Web site, then change the current directory to the top of the directory that was created. If you do not know what all this means, go to \n1. How to get a version of ABINIT? (Section 1B Normal users)\n\n\nIssue configure or ./configure (or first create a tmp directory, then cd tmp, then ../configure)\n\n\nIssue make (or make mj4 , or make multi multi_nprocs=n for using \u201cn\u201d processors on a SMP machine where you have to replace \u201cn\u201d by its value) \n\n\nIssue (optionally) \u201cmake install\u201d\n\n\n\n\nWell, it might also be that information on the Fortran compiler is needed, in\nwhich case something like:\n\n\n     $ ./configure \nFC\n=\nyour_F90_compiler \n\n\n\n\n\ninstead of the bare \u201cconfigure\u201d, might work, where \u201cyour_F90_compiler\u201d has to\nbe replaced by the location of your F90 compiler, such as\n/usr/local/gcc472/bin/gfortran.\n\n\nIf you succeeded to download, gunzip and untar the ABINIT package, but failed\nwith the next steps, please go to \n2. How to make the executables?\n\n\nIf you succeeded to make the executables, but would like to check whether\nABINIT has been installed correctly, please go to \n3. How to make the\ninternal tests?\n and the following sections.\n\n\nIf you want to have a much better handling on ABINIT than normal users, or if\nyou download ABINIT from Gitlab or GitHub, then go to \n1. How to get a\nversion of ABINIT? (Section 1A Expert users of developer)\n.\n\n\nTo build the executables you will need at least 400 MBytes of free disk space.\nRunning all tests will require more than 2.5 GBytes.\n\n\n\n\n1. How to get a version of ABINIT?\n\u00b6\n\n\nWe will distinguish two cases:\n\n\n\n\n1.A. Expert user or developer. You have a F90 compiler under UNIX/Linux or MacOS X, as well as (free) \nsoftware applications like git, automake, autoconf, libtool, perl, python, and you want to have a full handle\n on the package (compilation, modification of files, writing of scripts \u2026 this is the preferred case for developers). This is also needed if you download ABINIT from the primary ABINIT GitLab repository or its GitHub mirror. We will sometimes refer to this case as the \u201cautotools working mode\u201d.\n\n\n1.B. Normal user. You have a F90 compiler under UNIX/Linux or MacOS X and you want \nsimply to compile the source code\n, and, from time to time, \nmodify and/or add a new file\n (this is the case of most users, system managers, and also occasional developers). We will sometimes refer to this case as being \u201cwithout autotools\u201d.\n\n\n\n\nYou should read only the appropriate section (you can safely ignore the other\none \u2026).\n\n\n1.A. Expert user of developer\n\u00b6\n\n\nYou have a F90 compiler under UNIX/Linux or MacOS X, as well as (free)\nsoftware like git, automake, autoconf, libtool, perl, python, and you want to\nhave a full handle on the package (compilation, modification of files, writing\nof scripts). This is the preferred case for developers\u2026 We will sometimes\nrefer to this case as the \u201cautotools development mode\u201d.\n\n\nIf you do not have these tools, and would like to have them, please consult\nyour local computer guru, and the following pages:\n\n\n\n\nAn overview of ABINIT development\n\n\n10 steps to hike ABINIT\n\n\nABINIT environment\n\n\n\n\nIf you want to develop on a regular basis, please have a Git(lab) access\ncreated for you by contacting Jean-Michel Beuken, as described in these pages.\nIf it is only very occasional, you might as well rely on the \nABINIT Github Web site\n.\n\n\nIt is strongly advised to subscribe to the \nABINIT\nforum\n if you want to be able to get the latest\ninformation concerning the autotools development mode.\n\n\n\n\nAfter having installed git, and obtained a branch on the ABINIT worldwide\n\n\nrepository, create an automomous copy of the source code, on top of which you\n\n\nhave to make your development. This is explained in the ABINIT wiki [git(lab)\n\n\nABINIT\nspecificities](https://wiki.abinit.org/doku.php?id=developers:specificities_git_abinit)\n\n\n\n\nFor your branches on the ABINIT worldwide repository, you will have the\npermission not only to clone/fetch/pull, but also to commit/push your\nmodifications. You might alternatively download other branches of the\narchives, but you will not be able to commit in these branches. So, do not\nstart to modify these, you will not be able to include them afterwards in the\narchive.\n\n\nWorking with \ngit clone\n creates a local archive for your daily work, this\narchive being linked to the main ABINIT archive. This very efficient technique\nis recommended, as it makes you more independent for the management of your\nwork (you will be able to create new branches). One big advantage of this\ntechnique is that people working with a laptop can develop and commit safely\nwithout a network connection.\n\n\nNow, cd to the newly created abinit directory, and issue :\n\n\n    $ ./config/scripts/makemake\n\n\n\n\n\nThis command initializes a whole set of files and scripts, needed for the\nautotools, as well as for the global work on ABINIT sources. This\ninitialization might take up to two minutes.\n\n\nAfter this initialisation, you can proceed to the generation of the\nexecutables, as described in section 2.\n\n\n1.B. Normal user\n\u00b6\n\n\nYou have a F90 compiler under UNIX/Linux or MacOS X and you want simply to\n\ncompile the source files\n, and, from time to time, \nmodify and/or add a\nnew file\n. This is the case of most users, system managers, and also many\ndevelopers. If you want to modify and/or add a new file, please consult the\nsection 7. For developers : how to modify the code? after reading the present\nsection. In what follows, \nx.y.z\n represents the ABINIT version.\n\n\nIn order to get the ABINIT package, you have first to download the file\n\nabinit-\nx.y.z\n.tar.gz\n from the ABINIT Web site, see \nthe following\npage\n then issue :\n\n\n    gunzip **abinit-_x.y.z_.tar.gz** \n|\n tar -xvf -\n\n\n\n\n\nThat\u2019s it.\n\n\nThe \nabinit-\nx.y.z\n.tar.gz\n gzipped tar file contains all the needed files, including:\n\n\n\n\nthe sources of the abinit code (also, the files needed for generating the blas and lapack libraries), in the directories \u201csrc\u201d and \u201clib\u201d;\n\n\nthe documentation, in the directory \u201cdoc\u201d;\n\n\nthe complete set of tests, and the pseudopotentials needed for the tests, in the directory \u201ctests\u201d;\n\n\nall the scripts and information needed to produce makefiles, in other directories, especially \u201cconfig\u201d.\n\n\n\n\nThe package does not contain the object files and the binary executable files.\n\n\nYou can go to the next section, to generate the executable files, if this\nworked.\n\n\nIf this did not work, here are more detailed explanations \u2026\n\n\nSo, execute the following actions:\n\n\n\n\nunder mac os x, open a terminal session, so you can work as if it were a unix platform.\n\n\n\n\ntransfer the above-mentioned file(s) to your machine, in a directory suitable for the installation of the present version of abinit, and subsequent ones.\n\nyou should have about 250 mb of disk space to install the code, maybe more,\ndepending on the version, and the number of tests that you will do.\n\n\n\n\n\n\ngunzip (on some machine you need gzip -d) and untar the file \u2018\nabinit-\nx.y.z\n.tar.gz\n\u2019:\n\ngunzip \nabinit-\nx.y.z\n.tar.gz\n | tar -xvf -\n\n\n\n\n\n\nIf correctly done, a main directory, denoted ~abinit in the present document\n(usually, its real name will be \nabinit-\nx.y.z\n) and a whole set of\nsubdirectories should have been created. One of them is called \u2018doc/\u2019. It\ncontains many important informations. many of the files it contains are .html\nfiles, that are placed on the web site. However, many other files are not\navailable in .html format, and are not found on the web site. In the future,\nkeep in mind that the information that you are looking for (but that you\ncannot find on the web site) might be in the subdirectories of doc/, esp.\ndoc/theory/, doc/users/, doc/psp_infos/.\n\n\nYou might now go to the section 2.\n\n\nDo not forget: if you want to modify and/or add a new file, please consult the\nsection 7. for developers: how to modify the code? after reading the present\nsection.\n\n\n\n\n2. How to make the executables? (=How to compile the executables?)\n\u00b6\n\n\nWe now suppose that you have a F90 compiler and you want to compile the source\nfiles.\n\n\nIn most cases, you will have to provide to the \u2018make\u2019 utility some\ninformation: the location of the F90 compiler (and sometimes even the C\ncompiler) on your machine, the adequate compiler options, and, if you want to\nproduce the parallel binaries, the location of the MPI library on your\nmachine.\n\n\nAlthough the presently implemented building tools should be powerful enough to\nsucceed to make the binaries without you giving such information, it has been\nseen that on a significant number of platforms, it is still better to give\nthem. Indeed, you might generate a clearly suboptimal executable, executing\nslowly, or with downgraded capabilities.\n\n\nSupposing that you are in the lucky case where the build system is able to\nfind all the information, then the build of ABINIT is very simple. Issue:\n\n\n\n\nconfigure or ./configure (or first create a tmp directory, then cd tmp, then ../configure)\n\n\nmake (or make mj4 , or make multi multi_nprocs=n for using \u201cn\u201d processors on a SMP machine where you have to replace \u201cn\u201d by its value) \n\n\n(optionally) make install\n\n\n\n\nWell, it might also be that only one additional information is needed, in\nwhich case something like:\n\n\n\n\nconfigure FC=gcc\n\n\nmake \n\n\n\n\nmight work. In both cases, let\u2019s explain a bit what is done, and the further\npossibilities.\n\n\nThe \u2018configure\u2019 step produces the set of Makefile files (among other things),\ntaking into account information about your machine and the hostname.ac file.\nIt takes three minute long, or less. The \u2018make\u2019 step compiles everything,\naccording to the Makefile files produced in the prior step. The time to make\neverything is highly dependent on the compiler and platform. On a 2.8 GHz\nquad-proc machine (using make mj4), the whole compilation is about 5 minutes.\nOn some other platforms, with only one processor, it might be more than one\nhour.\n\n\nThe executables will be located in the subdirectory ~abinit/src/98_main, if\nyou have chosen to issue ./configure in the ~abinit directory. If you have\nissued ./configure in another directory, it will be placed accordingly.\n\n\nThe \u2018make\u2019 command can also be used in many different ways, by mentioning one\nor more targets. A (partial) list of targets for users can be obtained by\ntyping:\n\n\n    make \nhelp\n\n\n\n\n\n\nAdditional targets, for developers, can be obtained by typing:\n\n\n    make help_dev\n\n\n\n\n\nIt is possible to compile only one of the executable, just after the configure\nstep by typing:\n\n\n    make name_of_the_binary\n\n\n\n\n\n(where name_of_the_binary can be abinit, cut3d, anaddb, \u2026).\n\n\nThese are only a tiny fraction of the things that you can realize thanks to\n\u2018make\u2019. Moreover, there are also \u2018Makefile\u2019 files in most of the\nsubdirectories of ABINIT, with often their own (partial) list of targets for\nusers (and also sometimes for developers). To obtain these lists, go to the\ndirectory, and type:\n\n\n    make \nhelp\n\n\n\n\n\n\nor\n\n\nmake help_dev\n\n\n\n\n\nFinally,\n\n\nmake install\n\n\n\n\n\nwill install abinit in the /usr/local directory.\n\n\nIn case you want to go further, please consult files in ~abinit/doc/build .\n\n\nLet\u2019s come back to the case where the build system needs some more\ninformation. This information should be stored in a file named hostname.ac,\nwhere \u201chostname\u201d is the result of executing the command \nhostname\n on your\nmachine, e.g. abiref.pcpm.ucl.ac.be or my_machine \u2026 , and taking the first\nword of the returned chain of character, e.g. abiref or my_machine \u2026\n\n\nThere is a template for such a file, located in ~abinit/doc/config/. Its name\nis config-template.ac. Examples of such files, that have been used for testing\nthe package, can be found in ~abinit/doc/build/config-examples/. By the way,\nthe known problems observed for these different tests are mentioned in the\n~abinit/KNOWN_PROBLEMS file, and the hostname.ac files are correspondingly\nindicated at the beginning of this file.\n\n\nMost of the examples provided in the ~abinit/doc/build/config-examples/\ndirectory contain about five definitions: F90 and C locations, F90 and C\noptions, MPI library location (or the indication that MPI is not enabled). On\nthe other hand, there are many other possible control flags (\u201cwith_XYZ\u201d),\nneeded for advanced use. In case you have trouble with some library (LibXC,\nWANNIER90, ETSF_IO \u2026), you may disable its build.\n\n\nYour hostname.ac file might be placed in your home directory in a new\ndirectory that you will name ~/.abinit/build/. At that location, everytime you\ninstall a new version of ABINIT, the needed information will be found by\nABINIT, so you do not have to care anymore about this file after the first\ninstallation.\n\n\nOn the other hand, if you need to play with several computers, you can place\nthe hostname.ac file directory in the ~abinit directory, where such a\nhostname.ac file will be also seen by the build system (and preferred over the\none located in ~/.abinit/build/) or in your build directory (like\n~abinit/tmp/). As mentioned above, you might even type at the terminal the\ndefinitions contained in the hostname.ac file.\n\n\nNote the order of precedence for the location of the hostname.ac file (or\ncommand-line information), in case more than one possibility is used,\n(decreasing order of precedence):\n\n\n\n\nCommand line (overcome all other information)\n\n\nYour build directory (~abinit/tmp/)\n\n\nThe ABINIT top source directory (~abinit/)\n\n\n~/.abinit/build/\n\n\n/etc/abinit/build/\n\n\n\n\nWhen the hostname.ac file is ready, you have to issue, in the ~abinit\ndirectory:\n\n\n\n\nconfigure or ./configure (or first create a tmp directory, then cd tmp, create a hostname.ac file, then ../configure)\n\n\nmake or make mj4 (or make multi for using several processors on a SMP machine)\n\n\n(optionally) make install\n\n\n\n\n\n\n3. How to make the internal tests?\n\u00b6\n\n\nIn case you are running under Unix (Linux or another flavour), the abinit code\nhas several small internal tests (three basic ones, called \u201cfast\u201d, \u201cv1\u201d and\n\u201cv5\u201d, and then one for each of the libraries \u201cbigdft\u201d, \u201cetsf_io\u201d, \u201clibxc\u201d,\n\u201cwannier90\u201d), that can be issued automatically, and that check themselves\nwhether the results that have been obtained are right or wrong. These tests\nare available whether you have got the package from the Web or from the ABINIT\narchive. Of course, you need to have compiled abinit in order to run the\ninternal tests. Moreover, the simple implementation procedure assumes that the\nexecutable is located in ~abinit/src/98_main (the standard location after\nissuing \u201cmake\u201d).\n\n\nYou can begin with the test \u201cfast\u201d. Simply issue the command:\n\n\n**make test_fast**\n\n\n\n\n\nIt will run during a few seconds. It should print:\n\n\nStatus file, reporting on built-in test fast\n\n==> The run finished cleanly.\n    Moreover, comparison of the total energy, and other (few) relevant quantities with reference values has been successful.\n    This does not mean that no problem is present, however.\n    Please run the complete set of ABINIT tests to gain a better confidence in your installation.\n\n\n\n\n\nThis means that the internal test \u201cfast\u201d ran successfully. If you do not get\nthis message, then the executables were not properly generated, or there is a\nproblem with the makefile that drives the internal test. In this case, after\nhaving tried to solve the problem by yourself, you should contact somebody in\nthe ABINIT group.\n\n\nIn addition to this small message, you can have access to all generated files,\nthat are located inside the tests/built-in/Input subdirectory.\n\n\nSupposing test \u201cfast\u201d was OK, then you might issue the command:\n\n\n**make tests_in**\n\n\n\n\n\nThe test \u201cfast\u201d will be done once more, followed by the other internal tests.\nAgain, we hope that you will get the positive diagnostics for the other tests.\nOf course, the \u201cbigdft\u201d, \u201cetsf_io\u201d, \u201clibxc\u201d, and \u201cwannier90\u201d needs the\nappropriate library to be installed in order to work properly.\n\n\nFor further information on these internal tests, see the ~abinit/tests/built-\nin/README file.\n\n\nYou might now read the \nnew user\u2019s guide\n, in\norder to learn how to use the code, and then to follow the four basic\ntutorials, see the \nentry page for the tutorials\n.\nThis is useful if you consider that the installation has been successful. Or\nyou might continue to read the present Web page, and try to perform the speed\ntests, as well as the other tests.\n\n\n\n\n5. How to make the other tests?\n\u00b6\n\n\nAlthough it is possible to make the other tests without knowing really how to\nuse the code (since all steps involved - the run and subsequent analysis - are\ndone automatically), for the other tests, it is recommended to read the \nnew\nuser\u2019s guide\n, and then to follow the four basic\ntutorials, see the \nentry page for the tutorials\n.\n\n\nLet us pursue with the testing procedure. Go to the ~abinit/tests directory,\nand issue:\n\n\n**make help**\n\n\n\n\n\nThe workhorse script to run the tests is called runtests.py . It is very\nflexible. A reasonable set of tests (those contained in the fast and v\u201dx\u201d\ndirectories), can be run automatically by:\n\n\n**./runtests.py **\n\n\n\n\n\nor e.g.\n\n\n**./runtests.py -j4**\n\n\n\n\n\n(if you have 4 cores on your computer)\n\n\nThis is the recommended procedure for developers. In order to execute these\ntests, you will need a larger disk space than for the simple installation of\nthe code (the total additional disk space required is on the order of 1GB).\n\n\nThe video below gives an overwiew of the command line options of \nruntests.py\n\n\n\n\nLet us now examine the different subdirectories.\n\n\n~ABINIT/tests/fast/ is the simplest, and its content will be described in some\ndetail below. For tests of the parallel version see the directory\ntests/paral/, as well as the ~abinit/doc/users/paral_use text file. For tests\nof the response function features of abinit, and for tests of mrgddb and\nanaddb, see the subdirectories tests/v2. The other directories tests/v3,\ntests/v4, \u2026 presents further tests of recently implemented features of\nABINIT.\n\n\n1) tests/fast/\n (for the sequential version only)\n\n\nThis subdirectory contains a basic set of tests of the code, aimed at testing\nwhether the code is coherent in time (successive versions), and exercising\nseveral parts of the code. However, they do not examine its accuracy on\nphysical problems, mainly because the number of plane waves used is too small,\nand some tests are not run to self-consistent convergence. 32 MB of memory\nshould be enough for these tests.\n\n\nThe input files for each of the tests can be found in the\n~abinit/tests/fast/Input directory. At the bottom of the each of the input\nfile, some metadata is present. Such metadata mentions the executable to be\nused (automatically), possibly the other input files (like pseudopotentials),\nthe output files to be analyzed, the admitted tolerances with respect to\nreference output files, the author of the test, and a brief description of the\ntest.\n\n\nTo run only the tests in this directory, simply issue, in the ~abinit/tests/\ndirectory:\n\n\n**./runtests.py fast**\n\n\n\n\n\nIt will create a directory named Test_suite. All the results will be in that\ndirectory. The output files will be automatically compared, thanks to a \u2018diff\u2019\ncommand, to a set of reference files (in ~abinit/tests/fast/Refs/). The\ncorresponding difference files are prefixed by \u2018diff.\u2019.\n\n\nIn addition to \u2018diff\u2019, there are two other levels of automatic analysis: one\nbased on a comparing tool called \u2018fldiff\u2019, producing \u2018fldiff.report\u2019 files,\nand another where the output of \u2018fldiff\u2019 is further analyzed, and produce a\nbrief report called \u2018report\u2019. The latter step is only performed in case all\nthe tests cases of one directory are performed (including the case where tests\nof different directories are performed)\n\n\nThe one-line summaries produced by fldiff (see later) are compared with the\ntolerances indicated in the input file (metadata added at the end of the input\nfile). This procedure produces a file called \u201creport\u201d, in which there is a one\nline assessment of the behaviour of each test: succeeded (everything is OK),\npassed (the test is OK for users in production), passed marginally (the test\nis within 1.5 of the usually accepted deviation, which is likely OK for most\napplications - still to be improved by the development team, though), failed\n(there is a problem, the deviation is usually not accepted). This is by far\nthe most convenient tool to analyze the automatic tests of abinit.\n\n\nThe vast majority of tests cases succeed or pass on all platforms that are\nused by the developer team in Louvain-la-neuve. Some problems are mentioned in\nthe file ~abinit/KNOWN_PROBLEMS , Additionally, there might be specific\nproblems for some test case for some platforms, also mentioned in\n~abinit/KNOWN_PROBLEMS. So, apart of the known problems, mentioned in this\nfile, the \u201creport\u201d file should mention, for each test case, only \u201csucceeded\u201d\nor \u201cpassed\u201d.\n\n\nThe comparing tool \u2018fldiff\u2019 -for \u2018floating diff\u2019- performs in a more detailed\nway the comparison of floating numbers between the output files and the\nreference files than in the case of a \u2018diff\u2019 command. As used presently, for\neach run inside one directory, one single file, called \u2018fldiff.report\u2019, will\nbe produced, and gather the analysis for all tests in that directory.\n\n\nIf for one test case, the two files differ by the number of lines, the\n\u2018fldiff.report\u2019 file will report that it cannot compare the two files. Usually\nthis problem will be seen at the level of \u2018command signs\u2019 appearing sometimes\nin the first column of the output files, so a typical error message\n(announcing something went wrong) will be:\n\n\nCase_1\n22\nThe diff analysis cannot be pursued: the command sign differ.\n\n\n\n\n\nBy contrast, it will identify the floating numbers and ignore their\ndifferences if they are within some prescribed tolerance, or if the difference\nis not relevant. For example, it is able to ignore the differences in timings.\nIf everything goes fine for a test, fldiff should identify only the\ndifferences in:\n\n\n\n\nthe dates of execution (possibly);\n\n\nthe version numbers (possibly);\n\n\nthe platform description (possibly);\n\n\nthe overall execution time (this is ALWAYS printed, even without differences).\n\n\n\n\nSo, a successful execution of one test case may be announced as follows in the\nfldiff.report file:\n\n\nCase_1\n2\n<  Version 8.0.6  of ABINIT\n>  Version 8.0.3  of ABINIT\n5\n<  Starting date: Mon 23 May 2016.\n>  Starting date: Mon  4 Apr 2016\n202\n< +overall time at end (sec): cpu=          7.1  wall=          8.0\n> +Overall time at end (sec): cpu=          7.3  wall=          8.0\nSummary Case_1: no significant difference has been found\n\n\n\n\n\nThe fldiff.report file will have one such section for each test_case that was\nrun. It begins with the number of the test case, then includes a few blocks of\nthree lines: the number of the line where something is happening, followed by\nthe content of the two lines. Finally, there is a one-line summary for each\ntest case.\n\n\nMore information on the fldiff script can be found in the\n~abinit/tests/Scripts/fldiff.pl file.\n\n\n2) tests/v1\n\n\nThis directory contains tests built in the same spirit as those in the\ntest/fast directory, but that exercise other basic features, like the\ntreatment of metals, the GGA, the new pseudopotentials, the multi-dataset\nmode, the cell parameters optimization, and the spatial symmetry groups\ndatabase. These were developed during the development time of the version 1 of\nABINIT. Of course, the automatic difference procedure only compares to recent\nruns of the ABINIT code. As for the \u2018fast\u2019 test cases, the fldiff.report and\nreport files are also available. 64 MB of memory should be enough for these\ntests.\n\n\n3) tests/v2\n\n\nThis directory contains tests built in the same spirit as those in the\ntests/fast/ or tests/v1 directory, but that exercise features not present in\nversion 1 of the ABINIT package, mainly the response function features, and\nthe use of the mrgddb and anaddb codes. Again, the automatic difference\nprocedure only compares to recent runs of the ABINIT code. As for the \u2018fast\u2019\ntest cases, the fldiff.report and report files are also available. 64 MB of\nmemory should be enough for these tests.\n\n\n4) tests/v3, tests/v4, tests/v5, tests/v6, tests/v67mbpt, tests/v7, tests/v8, tests/bigdft, tests/etsf_io, tests/libxc, tests/wannier90\n\n\nThese directories contain tests built in the same spirit as those in the\ntests/fast/ directory, but that exercise features not present in the\nPlane_Wave code, nor in version 1 or 2 of the ABINIT package, noticeably the\nuse of the GW code, the utilities Cut3d, AIM, .., the PAW \u2026 . Or the\ninterfacing with fallbacks. Again, the automatic difference procedure only\ncompares to recent runs of the ABINIT code. As for the \u2018fast\u2019 test cases, the\nfldiff.report and report files are also available. 64 MB of memory should be\nenough for these tests.\n\n\n5) tests/paral/ and tests/mpiio/\n (need MPI support)\n\n\nThis directory contains tests built in the same spirit as those in the\ntest/fast/ directory, but that exercise the parallel version of the ABINIT\ncode.\n\n\nThe script runtests.py considers one of the different input files, and for\nthis file, it will use the parallel code with one processing node, then\nperform different parallel runs with an increasing number of processing nodes,\nas specified in the metadata contained in the input file. As for the other\nseries of test, the diff and the fldiff utilities are used automatically, and\nfldiff.report and report files are produced automatically.\n\n\n6) tests/cpu \n (for the sequential version only)\n\n\nThis subdirectory contains the scripts, and input files needed for testing the\ncpu time, either on progressively finer real space grids, or on progressively\nbigger unit cells. Please read the README file of this directory. Also for\nthis suite of tests is activated with:\n\n\n**make tests_cpu**\n\n\n\n\n\nUnlike in the previous case, many directories will be created (more than 10 in\nthe present version). Their name begins with the test name (A1, A2, A3, A4,\nB1, B2, B3, B4, C3, D3), and is followed by the machine name and the date.\nInside these directories, many runs are done. There is a \u2018report\u2019 file that\nsummarizes the timing of the different runs, and there is a \u2018diff\u2019 file, that\ncompares these timings with the reference (output files from a PIV at 2.8 MHz,\nusually).\n\n\nThe structure of these tests is more complex than that of the test/fast/ and\ntest/v1/ directories. The tools used are the \u2018serie\u2019 scripts (serieA,serieB,\nserieC and serieD) as well as the \u2018getrep\u2019 script. For an explanation, contact\nthe ABINIT group. For the largest tests (B and D series), up to 200MB of\ncentral memory are required.\n\n\n\n\n6. Things that are NOT in the installation packages.\n\u00b6\n\n\n\n\n\n\nMany pseudopotentials are not in the installation package:\n\nThe package contain several dozen pseudopotentials, for testing purposes, see\n~abinit/tests/Psps_for_tests/. However, the largest set of pseudopotentials\nand PAW atomic datafiles can be found on the \nAtomic data files ABINIT Web\npage\n. Other\npseudopotentials have been generated by many different users, and might be\nshared, but you might have to contact them.\n\n\n\n\n\n\nThe \u201cfallbacks\u201d are \nnot\n in the installation package. They are downloaded from the Web automatically at configure time. If you do not have the command \u201cwget\u201d install on your machine, or if you do not have an access to the internet, you should disable all the fallbacks. \n\n\n\n\nThe Web site \nhttp://www.abinit.org\n contains many other things, including links to the forum, the mailing list, the ABINIT events, \u2026  \n\n\n\n\n\n\n7. For developers: how to modify the code?\n\u00b6\n\n\n7.1. To modify a file (arguments unchanged).\n\u00b6\n\n\nIf you want simply to modify the content of an existing file (e.g. one of the\nFortran files, located in one of the src/* directories), without changing its\nlist of arguments, and recompile the code, the procedure is quite simple.\nModify that file, and reissue:\n\n\n**make**\n\n\n\n\n\nin ~abinit.\n\n\n7.2. To modify a file (arguments changed).\n\u00b6\n\n\nIf you want to modify the content of an existing Fortran file as well as the\nlist of arguments, and recompile the code, the procedure is to modify that\nfile, and then issue, in the ~abinit directory:\n\n\n***/abilint . .**  \n**make**\n\n\n\n\n\nDo not forget the two dots in the abilint command.\n\n\n7.3. To add a Fortran file.\n\u00b6\n\n\nIf you want to add a new Fortran file, there is a difference whether you work\nwith or without the autotools.\n\n\nIn both cases, you must \nadd the file name in the abinit.src file of the\ncorresponding directory\n. As an example, suppose that you want to add a new\nroutine named \nblork.F90\n in the directory ~abinit/src/65_nonlocal/. Then,\nyou must also declare it in the ~abinit/src/65_nonlocal/abinit.src file.\n\n\nNote that the choice of directory is important. You should choose to put your\nnew routine in a directory that has a prefix number (e.g. 42 for 42_nlstrain)\nhigher than all the directories that contain routines you will use (except if\nthe called routines are in the same directory), and smaller than all the\ndirectories that call your routine (except for routines that are in the same\ndirectory as yours).\n\n\nIf you work with the autotools, you have now to reissue:\n\n\n***/*/makemake**\n**./configure**\n**make**\n\n\n\n\n\n(see the section 2).\n\n\nIf you work without the autotools, \nyou must also modify by hand\n (i.e. find\nthe places where the Fortran files are listed, and complete the list) the\nMakefile.in of the directory where the new file has been added (e.g.\n~abinit/src/65_nonlocal/Makefile.in).\n\n\nThen issue:\n\n\n***/abilint . . **\n**make**\n\n\n\n\n\nin ~abinit/.\n\n\n7.4. To generate the source package.\n\u00b6\n\n\nIf you want to produce the source package abinit-\nx.y.z\n.tar.gz, type:\n\n\n**make dist**\n\n\n\n\n\nin ~abinit/.\n\n\nDo not forget to change its name (e.g. add your name after \nx.y.z\n, to\nidentify that this is a modified version of ABINIT).",
            "title": "Installation"
        },
        {
            "location": "/installation/#installation-notes-for-abinit-v84",
            "text": "This file provides a description of the operations needed to install the\nABINIT package, to generate the executable and to make the tests. It provides\nalso the description of simple modifications of the package, for developers.  See a recent version of the  new user\u2019s guide ,\nfor an introduction to the abinit package. See a recent version of the  abinit\nhelp  file for learning how to use the code. Both\nof them can be found either on the Web, or in the doc subdirectory of the\npackage.  Any comment or suggestion to improve the procedure will be welcome! Simply\ncontact the ABINIT group (http://forum.abinit.org/).    Installation notes for ABINIT v8.4  0. Short how to \u2026  1. How to get a version of ABINIT?  1.A. Expert user of developer  1.B. Normal user    2. How to make the executables? (=How to compile the executables?)  3. How to make the internal tests?  5. How to make the other tests?  6. Things that are NOT in the installation packages.  7. For developers: how to modify the code?  7.1. To modify a file (arguments unchanged).  7.2. To modify a file (arguments changed).  7.3. To add a Fortran file.  7.4. To generate the source package.",
            "title": "Installation notes for ABINIT v8.4"
        },
        {
            "location": "/installation/#046-short-how-to",
            "text": "For the vast majority of people willing to use ABINIT (Unix/Linux, not developers, but users), \nhere follows a short list of instructions needed to install it:   Download, gunzip and untar the  latest version of the ABINIT package  (abinit-x.y.z.tar.gz) from the abinit Web site, then change the current directory to the top of the directory that was created. If you do not know what all this means, go to  1. How to get a version of ABINIT? (Section 1B Normal users)  Issue configure or ./configure (or first create a tmp directory, then cd tmp, then ../configure)  Issue make (or make mj4 , or make multi multi_nprocs=n for using \u201cn\u201d processors on a SMP machine where you have to replace \u201cn\u201d by its value)   Issue (optionally) \u201cmake install\u201d   Well, it might also be that information on the Fortran compiler is needed, in\nwhich case something like:       $ ./configure  FC = your_F90_compiler   instead of the bare \u201cconfigure\u201d, might work, where \u201cyour_F90_compiler\u201d has to\nbe replaced by the location of your F90 compiler, such as\n/usr/local/gcc472/bin/gfortran.  If you succeeded to download, gunzip and untar the ABINIT package, but failed\nwith the next steps, please go to  2. How to make the executables?  If you succeeded to make the executables, but would like to check whether\nABINIT has been installed correctly, please go to  3. How to make the\ninternal tests?  and the following sections.  If you want to have a much better handling on ABINIT than normal users, or if\nyou download ABINIT from Gitlab or GitHub, then go to  1. How to get a\nversion of ABINIT? (Section 1A Expert users of developer) .  To build the executables you will need at least 400 MBytes of free disk space.\nRunning all tests will require more than 2.5 GBytes.",
            "title": "0. Short how to ..."
        },
        {
            "location": "/installation/#146-how-to-get-a-version-of-abinit",
            "text": "We will distinguish two cases:   1.A. Expert user or developer. You have a F90 compiler under UNIX/Linux or MacOS X, as well as (free)  software applications like git, automake, autoconf, libtool, perl, python, and you want to have a full handle  on the package (compilation, modification of files, writing of scripts \u2026 this is the preferred case for developers). This is also needed if you download ABINIT from the primary ABINIT GitLab repository or its GitHub mirror. We will sometimes refer to this case as the \u201cautotools working mode\u201d.  1.B. Normal user. You have a F90 compiler under UNIX/Linux or MacOS X and you want  simply to compile the source code , and, from time to time,  modify and/or add a new file  (this is the case of most users, system managers, and also occasional developers). We will sometimes refer to this case as being \u201cwithout autotools\u201d.   You should read only the appropriate section (you can safely ignore the other\none \u2026).",
            "title": "1. How to get a version of ABINIT?"
        },
        {
            "location": "/installation/#1a-expert-user-of-developer",
            "text": "You have a F90 compiler under UNIX/Linux or MacOS X, as well as (free)\nsoftware like git, automake, autoconf, libtool, perl, python, and you want to\nhave a full handle on the package (compilation, modification of files, writing\nof scripts). This is the preferred case for developers\u2026 We will sometimes\nrefer to this case as the \u201cautotools development mode\u201d.  If you do not have these tools, and would like to have them, please consult\nyour local computer guru, and the following pages:   An overview of ABINIT development  10 steps to hike ABINIT  ABINIT environment   If you want to develop on a regular basis, please have a Git(lab) access\ncreated for you by contacting Jean-Michel Beuken, as described in these pages.\nIf it is only very occasional, you might as well rely on the  ABINIT Github Web site .  It is strongly advised to subscribe to the  ABINIT\nforum  if you want to be able to get the latest\ninformation concerning the autotools development mode.   After having installed git, and obtained a branch on the ABINIT worldwide  repository, create an automomous copy of the source code, on top of which you  have to make your development. This is explained in the ABINIT wiki [git(lab)  ABINIT\nspecificities](https://wiki.abinit.org/doku.php?id=developers:specificities_git_abinit)   For your branches on the ABINIT worldwide repository, you will have the\npermission not only to clone/fetch/pull, but also to commit/push your\nmodifications. You might alternatively download other branches of the\narchives, but you will not be able to commit in these branches. So, do not\nstart to modify these, you will not be able to include them afterwards in the\narchive.  Working with  git clone  creates a local archive for your daily work, this\narchive being linked to the main ABINIT archive. This very efficient technique\nis recommended, as it makes you more independent for the management of your\nwork (you will be able to create new branches). One big advantage of this\ntechnique is that people working with a laptop can develop and commit safely\nwithout a network connection.  Now, cd to the newly created abinit directory, and issue :      $ ./config/scripts/makemake  This command initializes a whole set of files and scripts, needed for the\nautotools, as well as for the global work on ABINIT sources. This\ninitialization might take up to two minutes.  After this initialisation, you can proceed to the generation of the\nexecutables, as described in section 2.",
            "title": "1.A. Expert user of developer"
        },
        {
            "location": "/installation/#1b-normal-user",
            "text": "You have a F90 compiler under UNIX/Linux or MacOS X and you want simply to compile the source files , and, from time to time,  modify and/or add a\nnew file . This is the case of most users, system managers, and also many\ndevelopers. If you want to modify and/or add a new file, please consult the\nsection 7. For developers : how to modify the code? after reading the present\nsection. In what follows,  x.y.z  represents the ABINIT version.  In order to get the ABINIT package, you have first to download the file abinit- x.y.z .tar.gz  from the ABINIT Web site, see  the following\npage  then issue :      gunzip **abinit-_x.y.z_.tar.gz**  |  tar -xvf -  That\u2019s it.  The  abinit- x.y.z .tar.gz  gzipped tar file contains all the needed files, including:   the sources of the abinit code (also, the files needed for generating the blas and lapack libraries), in the directories \u201csrc\u201d and \u201clib\u201d;  the documentation, in the directory \u201cdoc\u201d;  the complete set of tests, and the pseudopotentials needed for the tests, in the directory \u201ctests\u201d;  all the scripts and information needed to produce makefiles, in other directories, especially \u201cconfig\u201d.   The package does not contain the object files and the binary executable files.  You can go to the next section, to generate the executable files, if this\nworked.  If this did not work, here are more detailed explanations \u2026  So, execute the following actions:   under mac os x, open a terminal session, so you can work as if it were a unix platform.   transfer the above-mentioned file(s) to your machine, in a directory suitable for the installation of the present version of abinit, and subsequent ones. \nyou should have about 250 mb of disk space to install the code, maybe more,\ndepending on the version, and the number of tests that you will do.    gunzip (on some machine you need gzip -d) and untar the file \u2018 abinit- x.y.z .tar.gz \u2019: \ngunzip  abinit- x.y.z .tar.gz  | tar -xvf -    If correctly done, a main directory, denoted ~abinit in the present document\n(usually, its real name will be  abinit- x.y.z ) and a whole set of\nsubdirectories should have been created. One of them is called \u2018doc/\u2019. It\ncontains many important informations. many of the files it contains are .html\nfiles, that are placed on the web site. However, many other files are not\navailable in .html format, and are not found on the web site. In the future,\nkeep in mind that the information that you are looking for (but that you\ncannot find on the web site) might be in the subdirectories of doc/, esp.\ndoc/theory/, doc/users/, doc/psp_infos/.  You might now go to the section 2.  Do not forget: if you want to modify and/or add a new file, please consult the\nsection 7. for developers: how to modify the code? after reading the present\nsection.",
            "title": "1.B. Normal user"
        },
        {
            "location": "/installation/#246-how-to-make-the-executables-how-to-compile-the-executables",
            "text": "We now suppose that you have a F90 compiler and you want to compile the source\nfiles.  In most cases, you will have to provide to the \u2018make\u2019 utility some\ninformation: the location of the F90 compiler (and sometimes even the C\ncompiler) on your machine, the adequate compiler options, and, if you want to\nproduce the parallel binaries, the location of the MPI library on your\nmachine.  Although the presently implemented building tools should be powerful enough to\nsucceed to make the binaries without you giving such information, it has been\nseen that on a significant number of platforms, it is still better to give\nthem. Indeed, you might generate a clearly suboptimal executable, executing\nslowly, or with downgraded capabilities.  Supposing that you are in the lucky case where the build system is able to\nfind all the information, then the build of ABINIT is very simple. Issue:   configure or ./configure (or first create a tmp directory, then cd tmp, then ../configure)  make (or make mj4 , or make multi multi_nprocs=n for using \u201cn\u201d processors on a SMP machine where you have to replace \u201cn\u201d by its value)   (optionally) make install   Well, it might also be that only one additional information is needed, in\nwhich case something like:   configure FC=gcc  make    might work. In both cases, let\u2019s explain a bit what is done, and the further\npossibilities.  The \u2018configure\u2019 step produces the set of Makefile files (among other things),\ntaking into account information about your machine and the hostname.ac file.\nIt takes three minute long, or less. The \u2018make\u2019 step compiles everything,\naccording to the Makefile files produced in the prior step. The time to make\neverything is highly dependent on the compiler and platform. On a 2.8 GHz\nquad-proc machine (using make mj4), the whole compilation is about 5 minutes.\nOn some other platforms, with only one processor, it might be more than one\nhour.  The executables will be located in the subdirectory ~abinit/src/98_main, if\nyou have chosen to issue ./configure in the ~abinit directory. If you have\nissued ./configure in another directory, it will be placed accordingly.  The \u2018make\u2019 command can also be used in many different ways, by mentioning one\nor more targets. A (partial) list of targets for users can be obtained by\ntyping:      make  help   Additional targets, for developers, can be obtained by typing:      make help_dev  It is possible to compile only one of the executable, just after the configure\nstep by typing:      make name_of_the_binary  (where name_of_the_binary can be abinit, cut3d, anaddb, \u2026).  These are only a tiny fraction of the things that you can realize thanks to\n\u2018make\u2019. Moreover, there are also \u2018Makefile\u2019 files in most of the\nsubdirectories of ABINIT, with often their own (partial) list of targets for\nusers (and also sometimes for developers). To obtain these lists, go to the\ndirectory, and type:      make  help   or  make help_dev  Finally,  make install  will install abinit in the /usr/local directory.  In case you want to go further, please consult files in ~abinit/doc/build .  Let\u2019s come back to the case where the build system needs some more\ninformation. This information should be stored in a file named hostname.ac,\nwhere \u201chostname\u201d is the result of executing the command  hostname  on your\nmachine, e.g. abiref.pcpm.ucl.ac.be or my_machine \u2026 , and taking the first\nword of the returned chain of character, e.g. abiref or my_machine \u2026  There is a template for such a file, located in ~abinit/doc/config/. Its name\nis config-template.ac. Examples of such files, that have been used for testing\nthe package, can be found in ~abinit/doc/build/config-examples/. By the way,\nthe known problems observed for these different tests are mentioned in the\n~abinit/KNOWN_PROBLEMS file, and the hostname.ac files are correspondingly\nindicated at the beginning of this file.  Most of the examples provided in the ~abinit/doc/build/config-examples/\ndirectory contain about five definitions: F90 and C locations, F90 and C\noptions, MPI library location (or the indication that MPI is not enabled). On\nthe other hand, there are many other possible control flags (\u201cwith_XYZ\u201d),\nneeded for advanced use. In case you have trouble with some library (LibXC,\nWANNIER90, ETSF_IO \u2026), you may disable its build.  Your hostname.ac file might be placed in your home directory in a new\ndirectory that you will name ~/.abinit/build/. At that location, everytime you\ninstall a new version of ABINIT, the needed information will be found by\nABINIT, so you do not have to care anymore about this file after the first\ninstallation.  On the other hand, if you need to play with several computers, you can place\nthe hostname.ac file directory in the ~abinit directory, where such a\nhostname.ac file will be also seen by the build system (and preferred over the\none located in ~/.abinit/build/) or in your build directory (like\n~abinit/tmp/). As mentioned above, you might even type at the terminal the\ndefinitions contained in the hostname.ac file.  Note the order of precedence for the location of the hostname.ac file (or\ncommand-line information), in case more than one possibility is used,\n(decreasing order of precedence):   Command line (overcome all other information)  Your build directory (~abinit/tmp/)  The ABINIT top source directory (~abinit/)  ~/.abinit/build/  /etc/abinit/build/   When the hostname.ac file is ready, you have to issue, in the ~abinit\ndirectory:   configure or ./configure (or first create a tmp directory, then cd tmp, create a hostname.ac file, then ../configure)  make or make mj4 (or make multi for using several processors on a SMP machine)  (optionally) make install",
            "title": "2. How to make the executables? (=How to compile the executables?)"
        },
        {
            "location": "/installation/#346-how-to-make-the-internal-tests",
            "text": "In case you are running under Unix (Linux or another flavour), the abinit code\nhas several small internal tests (three basic ones, called \u201cfast\u201d, \u201cv1\u201d and\n\u201cv5\u201d, and then one for each of the libraries \u201cbigdft\u201d, \u201cetsf_io\u201d, \u201clibxc\u201d,\n\u201cwannier90\u201d), that can be issued automatically, and that check themselves\nwhether the results that have been obtained are right or wrong. These tests\nare available whether you have got the package from the Web or from the ABINIT\narchive. Of course, you need to have compiled abinit in order to run the\ninternal tests. Moreover, the simple implementation procedure assumes that the\nexecutable is located in ~abinit/src/98_main (the standard location after\nissuing \u201cmake\u201d).  You can begin with the test \u201cfast\u201d. Simply issue the command:  **make test_fast**  It will run during a few seconds. It should print:  Status file, reporting on built-in test fast\n\n==> The run finished cleanly.\n    Moreover, comparison of the total energy, and other (few) relevant quantities with reference values has been successful.\n    This does not mean that no problem is present, however.\n    Please run the complete set of ABINIT tests to gain a better confidence in your installation.  This means that the internal test \u201cfast\u201d ran successfully. If you do not get\nthis message, then the executables were not properly generated, or there is a\nproblem with the makefile that drives the internal test. In this case, after\nhaving tried to solve the problem by yourself, you should contact somebody in\nthe ABINIT group.  In addition to this small message, you can have access to all generated files,\nthat are located inside the tests/built-in/Input subdirectory.  Supposing test \u201cfast\u201d was OK, then you might issue the command:  **make tests_in**  The test \u201cfast\u201d will be done once more, followed by the other internal tests.\nAgain, we hope that you will get the positive diagnostics for the other tests.\nOf course, the \u201cbigdft\u201d, \u201cetsf_io\u201d, \u201clibxc\u201d, and \u201cwannier90\u201d needs the\nappropriate library to be installed in order to work properly.  For further information on these internal tests, see the ~abinit/tests/built-\nin/README file.  You might now read the  new user\u2019s guide , in\norder to learn how to use the code, and then to follow the four basic\ntutorials, see the  entry page for the tutorials .\nThis is useful if you consider that the installation has been successful. Or\nyou might continue to read the present Web page, and try to perform the speed\ntests, as well as the other tests.",
            "title": "3. How to make the internal tests?"
        },
        {
            "location": "/installation/#546-how-to-make-the-other-tests",
            "text": "Although it is possible to make the other tests without knowing really how to\nuse the code (since all steps involved - the run and subsequent analysis - are\ndone automatically), for the other tests, it is recommended to read the  new\nuser\u2019s guide , and then to follow the four basic\ntutorials, see the  entry page for the tutorials .  Let us pursue with the testing procedure. Go to the ~abinit/tests directory,\nand issue:  **make help**  The workhorse script to run the tests is called runtests.py . It is very\nflexible. A reasonable set of tests (those contained in the fast and v\u201dx\u201d\ndirectories), can be run automatically by:  **./runtests.py **  or e.g.  **./runtests.py -j4**  (if you have 4 cores on your computer)  This is the recommended procedure for developers. In order to execute these\ntests, you will need a larger disk space than for the simple installation of\nthe code (the total additional disk space required is on the order of 1GB).  The video below gives an overwiew of the command line options of  runtests.py   Let us now examine the different subdirectories.  ~ABINIT/tests/fast/ is the simplest, and its content will be described in some\ndetail below. For tests of the parallel version see the directory\ntests/paral/, as well as the ~abinit/doc/users/paral_use text file. For tests\nof the response function features of abinit, and for tests of mrgddb and\nanaddb, see the subdirectories tests/v2. The other directories tests/v3,\ntests/v4, \u2026 presents further tests of recently implemented features of\nABINIT.  1) tests/fast/  (for the sequential version only)  This subdirectory contains a basic set of tests of the code, aimed at testing\nwhether the code is coherent in time (successive versions), and exercising\nseveral parts of the code. However, they do not examine its accuracy on\nphysical problems, mainly because the number of plane waves used is too small,\nand some tests are not run to self-consistent convergence. 32 MB of memory\nshould be enough for these tests.  The input files for each of the tests can be found in the\n~abinit/tests/fast/Input directory. At the bottom of the each of the input\nfile, some metadata is present. Such metadata mentions the executable to be\nused (automatically), possibly the other input files (like pseudopotentials),\nthe output files to be analyzed, the admitted tolerances with respect to\nreference output files, the author of the test, and a brief description of the\ntest.  To run only the tests in this directory, simply issue, in the ~abinit/tests/\ndirectory:  **./runtests.py fast**  It will create a directory named Test_suite. All the results will be in that\ndirectory. The output files will be automatically compared, thanks to a \u2018diff\u2019\ncommand, to a set of reference files (in ~abinit/tests/fast/Refs/). The\ncorresponding difference files are prefixed by \u2018diff.\u2019.  In addition to \u2018diff\u2019, there are two other levels of automatic analysis: one\nbased on a comparing tool called \u2018fldiff\u2019, producing \u2018fldiff.report\u2019 files,\nand another where the output of \u2018fldiff\u2019 is further analyzed, and produce a\nbrief report called \u2018report\u2019. The latter step is only performed in case all\nthe tests cases of one directory are performed (including the case where tests\nof different directories are performed)  The one-line summaries produced by fldiff (see later) are compared with the\ntolerances indicated in the input file (metadata added at the end of the input\nfile). This procedure produces a file called \u201creport\u201d, in which there is a one\nline assessment of the behaviour of each test: succeeded (everything is OK),\npassed (the test is OK for users in production), passed marginally (the test\nis within 1.5 of the usually accepted deviation, which is likely OK for most\napplications - still to be improved by the development team, though), failed\n(there is a problem, the deviation is usually not accepted). This is by far\nthe most convenient tool to analyze the automatic tests of abinit.  The vast majority of tests cases succeed or pass on all platforms that are\nused by the developer team in Louvain-la-neuve. Some problems are mentioned in\nthe file ~abinit/KNOWN_PROBLEMS , Additionally, there might be specific\nproblems for some test case for some platforms, also mentioned in\n~abinit/KNOWN_PROBLEMS. So, apart of the known problems, mentioned in this\nfile, the \u201creport\u201d file should mention, for each test case, only \u201csucceeded\u201d\nor \u201cpassed\u201d.  The comparing tool \u2018fldiff\u2019 -for \u2018floating diff\u2019- performs in a more detailed\nway the comparison of floating numbers between the output files and the\nreference files than in the case of a \u2018diff\u2019 command. As used presently, for\neach run inside one directory, one single file, called \u2018fldiff.report\u2019, will\nbe produced, and gather the analysis for all tests in that directory.  If for one test case, the two files differ by the number of lines, the\n\u2018fldiff.report\u2019 file will report that it cannot compare the two files. Usually\nthis problem will be seen at the level of \u2018command signs\u2019 appearing sometimes\nin the first column of the output files, so a typical error message\n(announcing something went wrong) will be:  Case_1\n22\nThe diff analysis cannot be pursued: the command sign differ.  By contrast, it will identify the floating numbers and ignore their\ndifferences if they are within some prescribed tolerance, or if the difference\nis not relevant. For example, it is able to ignore the differences in timings.\nIf everything goes fine for a test, fldiff should identify only the\ndifferences in:   the dates of execution (possibly);  the version numbers (possibly);  the platform description (possibly);  the overall execution time (this is ALWAYS printed, even without differences).   So, a successful execution of one test case may be announced as follows in the\nfldiff.report file:  Case_1\n2\n<  Version 8.0.6  of ABINIT\n>  Version 8.0.3  of ABINIT\n5\n<  Starting date: Mon 23 May 2016.\n>  Starting date: Mon  4 Apr 2016\n202\n< +overall time at end (sec): cpu=          7.1  wall=          8.0\n> +Overall time at end (sec): cpu=          7.3  wall=          8.0\nSummary Case_1: no significant difference has been found  The fldiff.report file will have one such section for each test_case that was\nrun. It begins with the number of the test case, then includes a few blocks of\nthree lines: the number of the line where something is happening, followed by\nthe content of the two lines. Finally, there is a one-line summary for each\ntest case.  More information on the fldiff script can be found in the\n~abinit/tests/Scripts/fldiff.pl file.  2) tests/v1  This directory contains tests built in the same spirit as those in the\ntest/fast directory, but that exercise other basic features, like the\ntreatment of metals, the GGA, the new pseudopotentials, the multi-dataset\nmode, the cell parameters optimization, and the spatial symmetry groups\ndatabase. These were developed during the development time of the version 1 of\nABINIT. Of course, the automatic difference procedure only compares to recent\nruns of the ABINIT code. As for the \u2018fast\u2019 test cases, the fldiff.report and\nreport files are also available. 64 MB of memory should be enough for these\ntests.  3) tests/v2  This directory contains tests built in the same spirit as those in the\ntests/fast/ or tests/v1 directory, but that exercise features not present in\nversion 1 of the ABINIT package, mainly the response function features, and\nthe use of the mrgddb and anaddb codes. Again, the automatic difference\nprocedure only compares to recent runs of the ABINIT code. As for the \u2018fast\u2019\ntest cases, the fldiff.report and report files are also available. 64 MB of\nmemory should be enough for these tests.  4) tests/v3, tests/v4, tests/v5, tests/v6, tests/v67mbpt, tests/v7, tests/v8, tests/bigdft, tests/etsf_io, tests/libxc, tests/wannier90  These directories contain tests built in the same spirit as those in the\ntests/fast/ directory, but that exercise features not present in the\nPlane_Wave code, nor in version 1 or 2 of the ABINIT package, noticeably the\nuse of the GW code, the utilities Cut3d, AIM, .., the PAW \u2026 . Or the\ninterfacing with fallbacks. Again, the automatic difference procedure only\ncompares to recent runs of the ABINIT code. As for the \u2018fast\u2019 test cases, the\nfldiff.report and report files are also available. 64 MB of memory should be\nenough for these tests.  5) tests/paral/ and tests/mpiio/  (need MPI support)  This directory contains tests built in the same spirit as those in the\ntest/fast/ directory, but that exercise the parallel version of the ABINIT\ncode.  The script runtests.py considers one of the different input files, and for\nthis file, it will use the parallel code with one processing node, then\nperform different parallel runs with an increasing number of processing nodes,\nas specified in the metadata contained in the input file. As for the other\nseries of test, the diff and the fldiff utilities are used automatically, and\nfldiff.report and report files are produced automatically.  6) tests/cpu   (for the sequential version only)  This subdirectory contains the scripts, and input files needed for testing the\ncpu time, either on progressively finer real space grids, or on progressively\nbigger unit cells. Please read the README file of this directory. Also for\nthis suite of tests is activated with:  **make tests_cpu**  Unlike in the previous case, many directories will be created (more than 10 in\nthe present version). Their name begins with the test name (A1, A2, A3, A4,\nB1, B2, B3, B4, C3, D3), and is followed by the machine name and the date.\nInside these directories, many runs are done. There is a \u2018report\u2019 file that\nsummarizes the timing of the different runs, and there is a \u2018diff\u2019 file, that\ncompares these timings with the reference (output files from a PIV at 2.8 MHz,\nusually).  The structure of these tests is more complex than that of the test/fast/ and\ntest/v1/ directories. The tools used are the \u2018serie\u2019 scripts (serieA,serieB,\nserieC and serieD) as well as the \u2018getrep\u2019 script. For an explanation, contact\nthe ABINIT group. For the largest tests (B and D series), up to 200MB of\ncentral memory are required.",
            "title": "5. How to make the other tests?"
        },
        {
            "location": "/installation/#646-things-that-are-not-in-the-installation-packages",
            "text": "Many pseudopotentials are not in the installation package: \nThe package contain several dozen pseudopotentials, for testing purposes, see\n~abinit/tests/Psps_for_tests/. However, the largest set of pseudopotentials\nand PAW atomic datafiles can be found on the  Atomic data files ABINIT Web\npage . Other\npseudopotentials have been generated by many different users, and might be\nshared, but you might have to contact them.    The \u201cfallbacks\u201d are  not  in the installation package. They are downloaded from the Web automatically at configure time. If you do not have the command \u201cwget\u201d install on your machine, or if you do not have an access to the internet, you should disable all the fallbacks.    The Web site  http://www.abinit.org  contains many other things, including links to the forum, the mailing list, the ABINIT events, \u2026",
            "title": "6. Things that are NOT in the installation packages."
        },
        {
            "location": "/installation/#746-for-developers-how-to-modify-the-code",
            "text": "",
            "title": "7. For developers: how to modify the code?"
        },
        {
            "location": "/installation/#71-to-modify-a-file-arguments-unchanged",
            "text": "If you want simply to modify the content of an existing file (e.g. one of the\nFortran files, located in one of the src/* directories), without changing its\nlist of arguments, and recompile the code, the procedure is quite simple.\nModify that file, and reissue:  **make**  in ~abinit.",
            "title": "7.1. To modify a file (arguments unchanged)."
        },
        {
            "location": "/installation/#72-to-modify-a-file-arguments-changed",
            "text": "If you want to modify the content of an existing Fortran file as well as the\nlist of arguments, and recompile the code, the procedure is to modify that\nfile, and then issue, in the ~abinit directory:  ***/abilint . .**  \n**make**  Do not forget the two dots in the abilint command.",
            "title": "7.2. To modify a file (arguments changed)."
        },
        {
            "location": "/installation/#73-to-add-a-fortran-file",
            "text": "If you want to add a new Fortran file, there is a difference whether you work\nwith or without the autotools.  In both cases, you must  add the file name in the abinit.src file of the\ncorresponding directory . As an example, suppose that you want to add a new\nroutine named  blork.F90  in the directory ~abinit/src/65_nonlocal/. Then,\nyou must also declare it in the ~abinit/src/65_nonlocal/abinit.src file.  Note that the choice of directory is important. You should choose to put your\nnew routine in a directory that has a prefix number (e.g. 42 for 42_nlstrain)\nhigher than all the directories that contain routines you will use (except if\nthe called routines are in the same directory), and smaller than all the\ndirectories that call your routine (except for routines that are in the same\ndirectory as yours).  If you work with the autotools, you have now to reissue:  ***/*/makemake**\n**./configure**\n**make**  (see the section 2).  If you work without the autotools,  you must also modify by hand  (i.e. find\nthe places where the Fortran files are listed, and complete the list) the\nMakefile.in of the directory where the new file has been added (e.g.\n~abinit/src/65_nonlocal/Makefile.in).  Then issue:  ***/abilint . . **\n**make**  in ~abinit/.",
            "title": "7.3. To add a Fortran file."
        },
        {
            "location": "/installation/#74-to-generate-the-source-package",
            "text": "If you want to produce the source package abinit- x.y.z .tar.gz, type:  **make dist**  in ~abinit/.  Do not forget to change its name (e.g. add your name after  x.y.z , to\nidentify that this is a modified version of ABINIT).",
            "title": "7.4. To generate the source package."
        },
        {
            "location": "/topics/crystal/",
            "text": "This file gives hints on how to specify a crystal with the ABINIT package.\n\n\n\n\n\n\n1. Introduction.\n\n\n2. Related lesson(s) of the tutorial.\n\n\n3. Related input variables.\n\n\n4. Selected input files.\n\n\n\n\n\n\n1. Introduction.\n\u00b6\n\n\nThe cell may be orthogonal or non-orthogonal. Any kind of symmetries and\ncorresponding sets of k-point can be input, and taken into account in the\ncomputation. The crystal structure and the position of the atoms in the unit\ncell must be specified. Details about the way the crystal structure is defined\nin ABINIT can be found \nhere\n.\n\nThe code can automatically generate symmetries from the primitive cell and the\nposition of atoms. In this case, it identifies automatically the Bravais\nlattice, point group and space group. Alternatively, it can start from the\nsymmetries and generate the atomic positions from the irreducible set. Also, a\ndatabase of the 230 spatial groups of symmetry is built inside ABINIT.  \n\n\n\n\n2. Related lesson(s) of the tutorial.\n\u00b6\n\n\n\n\nThe lesson 1\n deals with the H2 molecule : get the total energy, the electronic energies, the charge density, the bond length, the atomisation energy \n\n\nThe lesson 2\n deals again with the H2 molecule: convergence studies, LDA versus GGA \n\n\nThe lesson 3\n deals with crystalline silicon (an insulator): the definition of a k-point grid, the smearing of the cut-off energy, the computation of a band structure, and again, convergence studies \u2026\n\n\nThe lesson 4\n deals with crystalline aluminum (a metal), and its surface: occupation numbers, smearing the Fermi-Dirac distribution, the surface energy, and again, convergence studies \u2026\n\n\n\n\n\n\n3. Related input variables.\n\u00b6\n\n\nCompulsory input variables:\n\n\n\u2026 \nacell\n [CELL\nlattice vector scaling]\n\n\u2026 \nrprim\n [Real\nspace PRIMitive translations]\n\n\u2026 \nxangst\n\n[vectors (X) of atom positions in cartesian coordinates -length in ANGSTrom-]\n\n\u2026 \nxcart\n [vectors\n(X) of atom positions in CARTesian coordinates]\n\n\u2026 \nxred\n [vectors\n(X) of atom positions in REDuced coordinates]  \n\n\nUseful input variables:\n\n\n\u2026 \nangdeg\n [ANGles\nin DEGrees]\n\n\u2026 \nchkprim\n [CHecK\nwhether the cell is PRIMitive]\n\n\u2026 \nnsym\n [Number of\nSYMmetry operations]\n\n\u2026 \nscalecart\n\n[SCALE CARTesian coordinates]\n\n\u2026 \nsymrel\n\n[SYMmetry in REaL space]\n\n\u2026 \ntnons\n\n[Translation NON-Symmorphic vectors]  \n\n\nInput variables for experts:\n\n\n\n\n\u2026 \nbrvltt\n\n\n[BRaVais LaTTice type]\n\n\n\u2026 \nmaxnsym\n\n\n[MAXimum Number of SYMetries]\n\n\n\u2026 \nnatrd\n [Number\n\n\nof AToms ReaD]\n\n\n\u2026 \nnobj\n [Number of\n\n\nOBJects]\n\n\n\u2026 \nobjaat\n [OBJect\n\n\nA : list of AToms]\n\n\n\u2026 \nobjaax\n [OBJect\n\n\nA : AXis]\n\n\n\u2026 \nobjan\n [OBJect A\n\n\n\n\n\n\nNumber of atoms]\n\n\n\u2026 \nobjarf\n [OBJect\n\n\nA : Repetition Factors]\n\n\n\u2026 \nobjaro\n [OBJect\n\n\nA : ROtations]\n\n\n\u2026 \nobjatr\n [OBJect\n\n\nA : TRanslations]\n\n\n\u2026 \nobjbat\n [OBJect\n\n\nB : list of AToms]\n\n\n\u2026 \nobjbax\n [OBJect\n\n\nB : AXis]\n\n\n\u2026 \nobjbn\n [OBJect B\n\n\nNumber of atoms]\n\n\u2026 \nobjbrf\n [OBJect\nB : Repetition Factors]\n\n\u2026 \nobjbro\n [OBJect\nB : ROtations]\n\n\u2026 \nobjbtr\n [OBJect\nB : TRanslations]\n\n\u2026 \nspgaxor\n\n[SPace Group : AXes ORientation]\n\n\u2026 \nspgorig\n\n[SPace Group : ORIGin]\n\n\u2026 \nspgroup\n\n[SPace GROUP number]\n\n\u2026 \nsymmorphi\n\n[SYMMORPHIc symmetry operation selection]\n\n\u2026 \nvaclst\n\n[VACancies LiST]\n\n\u2026 \nvacnum\n\n[VACancies NUMber]\n\n\u2026 \nxyzfile\n [XYZ\nFILE input for geometry]  \n\n\n\n\n\n\n\n\n\n\n4. Selected input files.\n\u00b6\n\n\nThe user can find some related example input files in the ABINIT package in\nthe directory /tests, or on the Web:\n\n\ntests/v1/Input: \nt40.in\n\n\nt42.in\n \nt43.in\n\n\ntests/v3/Input: \nt21.in\n\n\nt23.in\n \nt24.in\n\n\nt25.in\n \nt26.in\n\n\nt27.in\n \nt28.in\n\n\nt29.in\n \nt32.in\n\n\nt33.in\n \nt34.in\n\n\nt35.in\n \nt36.in\n\n\ntests/v5/Input: \nt14.in",
            "title": "Crystalline Structure"
        },
        {
            "location": "/topics/crystal/#146-introduction",
            "text": "The cell may be orthogonal or non-orthogonal. Any kind of symmetries and\ncorresponding sets of k-point can be input, and taken into account in the\ncomputation. The crystal structure and the position of the atoms in the unit\ncell must be specified. Details about the way the crystal structure is defined\nin ABINIT can be found  here . \nThe code can automatically generate symmetries from the primitive cell and the\nposition of atoms. In this case, it identifies automatically the Bravais\nlattice, point group and space group. Alternatively, it can start from the\nsymmetries and generate the atomic positions from the irreducible set. Also, a\ndatabase of the 230 spatial groups of symmetry is built inside ABINIT.",
            "title": "1. Introduction."
        },
        {
            "location": "/topics/crystal/#246-related-lessons-of-the-tutorial",
            "text": "The lesson 1  deals with the H2 molecule : get the total energy, the electronic energies, the charge density, the bond length, the atomisation energy   The lesson 2  deals again with the H2 molecule: convergence studies, LDA versus GGA   The lesson 3  deals with crystalline silicon (an insulator): the definition of a k-point grid, the smearing of the cut-off energy, the computation of a band structure, and again, convergence studies \u2026  The lesson 4  deals with crystalline aluminum (a metal), and its surface: occupation numbers, smearing the Fermi-Dirac distribution, the surface energy, and again, convergence studies \u2026",
            "title": "2. Related lesson(s) of the tutorial."
        },
        {
            "location": "/topics/crystal/#346-related-input-variables",
            "text": "Compulsory input variables:  \u2026  acell  [CELL\nlattice vector scaling] \n\u2026  rprim  [Real\nspace PRIMitive translations] \n\u2026  xangst \n[vectors (X) of atom positions in cartesian coordinates -length in ANGSTrom-] \n\u2026  xcart  [vectors\n(X) of atom positions in CARTesian coordinates] \n\u2026  xred  [vectors\n(X) of atom positions in REDuced coordinates]    Useful input variables:  \u2026  angdeg  [ANGles\nin DEGrees] \n\u2026  chkprim  [CHecK\nwhether the cell is PRIMitive] \n\u2026  nsym  [Number of\nSYMmetry operations] \n\u2026  scalecart \n[SCALE CARTesian coordinates] \n\u2026  symrel \n[SYMmetry in REaL space] \n\u2026  tnons \n[Translation NON-Symmorphic vectors]    Input variables for experts:   \u2026  brvltt  [BRaVais LaTTice type]  \u2026  maxnsym  [MAXimum Number of SYMetries]  \u2026  natrd  [Number  of AToms ReaD]  \u2026  nobj  [Number of  OBJects]  \u2026  objaat  [OBJect  A : list of AToms]  \u2026  objaax  [OBJect  A : AXis]  \u2026  objan  [OBJect A    Number of atoms]  \u2026  objarf  [OBJect  A : Repetition Factors]  \u2026  objaro  [OBJect  A : ROtations]  \u2026  objatr  [OBJect  A : TRanslations]  \u2026  objbat  [OBJect  B : list of AToms]  \u2026  objbax  [OBJect  B : AXis]  \u2026  objbn  [OBJect B  Number of atoms] \n\u2026  objbrf  [OBJect\nB : Repetition Factors] \n\u2026  objbro  [OBJect\nB : ROtations] \n\u2026  objbtr  [OBJect\nB : TRanslations] \n\u2026  spgaxor \n[SPace Group : AXes ORientation] \n\u2026  spgorig \n[SPace Group : ORIGin] \n\u2026  spgroup \n[SPace GROUP number] \n\u2026  symmorphi \n[SYMMORPHIc symmetry operation selection] \n\u2026  vaclst \n[VACancies LiST] \n\u2026  vacnum \n[VACancies NUMber] \n\u2026  xyzfile  [XYZ\nFILE input for geometry]",
            "title": "3. Related input variables."
        },
        {
            "location": "/topics/crystal/#446-selected-input-files",
            "text": "The user can find some related example input files in the ABINIT package in\nthe directory /tests, or on the Web:  tests/v1/Input:  t40.in  t42.in   t43.in  tests/v3/Input:  t21.in  t23.in   t24.in  t25.in   t26.in  t27.in   t28.in  t29.in   t32.in  t33.in   t34.in  t35.in   t36.in  tests/v5/Input:  t14.in",
            "title": "4. Selected input files."
        },
        {
            "location": "/topics/kpoints/",
            "text": "This file gives hints on how to set parameters related to the k-points\n\u00b6\n\n\nwith the ABINIT package.\n\n\n\n\n\n\n\n\nThis file gives hints on how to set parameters related to the k-points\n\n\n1. Introduction.\n\n\n2. Related lesson(s) of the tutorial.\n\n\n3. Related input variables.\n\n\n4. Selected input files.\n\n\n\n\n\n\n1. Introduction.\n\u00b6\n\n\nAny kind of symmetries and corresponding sets of k-point can be input, and\ntaken into account in the computation.\n\nSince ABINIT is based on periodic boundary conditions, the Brillouin zone must\nbe sampled adequately. The number of k-points to be used for this sampling, in\nthe full Brillouin zone, is inversely proportional to ucvol, but may also vary\na lot from system to system. As a rule of thumb, a system with a large band\ngap will need few k-points, while metals will need lot of k-points to produce\nconverged results. For large systems, the inverse scale with respect to ucvol\nis unfortunately stopped because at least one k-point must be used. The\neffective number of k-points to be used will be strongly influenced by the\nsymmetries of the system, since only the irreducible part of the Brillouin\nzone must be sampled. Moreover the time-reversal symmetry (k equivalent to -k)\ncan be used for ground-state calculations, to reduce sometimes even further\nthe portion of the brillouin zone to be sampled. The number of k points to be\nused in a calculation is named nkpt. There is another way to take advantage of\nthe time-reversal symmetry, in the specific case of k-points that are\ninvariant under k => -k , or are sent to another vector distant of the\noriginal one by some vector of the reciprocal lattice. See below for more\nexplanation about the advantages of using these k-points.\n\nAs a rule of thumb, for homogeneous systems, a reasonable accuracy may be\nreached when the product of the number of atoms by the number of k-points in\nthe full Brillouin zone is on the order of 50 or larger, for wide gap\ninsulators, on the order of 250 for small gap semiconductors like Si, and\nbeyond 500 for metals, depending on the value of the input variable tsmear. As\nsoon as there is some vacuum in the system, the product natom * nkpt can be\nmuch smaller than this (for an isolated molecule in a sufficiently large\nsupercell, one k-point is enough).\n\nThe generation of special k point sets (Monkhorst-Pack sets) and band\nstructure k points can be done directly inside ABINIT. A list of interesting k\npoint sets, can be generated automatically, including a measure of their\naccuracy in term of integration within the Brillouin Zone.  \n\n\n\n\n2. Related lesson(s) of the tutorial.\n\u00b6\n\n\n\n\nThe lesson 3\n deals with crystalline silicon (an insulator): the definition of a k-point grid, the smearing of the cut-off energy, the computation of a band structure, and again, convergence studies \u2026\n\n\n\n\n\n\n3. Related input variables.\n\u00b6\n\n\nBasic input variables:\n\n\n\u2026\n\nchksymbreak\n\n[CHecK SYMmetry BREAKing]\n\n\u2026 \nkptopt\n\n[KPoinTs OPTion]\n\n\u2026 \nngkpt\n [Number\nof Grid points for K PoinTs generation]  \n\n\nUseful input variables:\n\n\n\u2026 \nistwfk\n\n[Integer for choice of STorage of WaveFunction at each k point]\n\n\u2026 \nkpt\n [K - PoinTs]\n\n\u2026 \nkptnrm\n [K -\nPoinTs NoRMalization]\n\n\u2026 \nkptrlatt\n [K -\nPoinTs grid : Real space LATTice]\n\n\u2026 \nkptrlen\n [K -\nPoinTs grid : Real space LENgth]\n\n\u2026 \nnkpt\n [Number of\nK - Points]\n\n\u2026 \nnshiftk\n\n[Number of SHIFTs for K point grids]\n\n\u2026 \nshiftk\n [SHIFT\nfor K points]\n\n\u2026 \nwtk\n [WeighTs for\nK points]  \n\n\nRelevant internal variables:\n\n\n\u2026 \n%kptns\n\n[K-PoinTs re-Normalized and Shifted]  \n\n\nInput variables for experts:\n\n\n\u2026 \nkptbounds\n [K\nPoinT BOUNDarieS]\n\n\u2026 \nndivk\n [Number of\nDIVisions of K lines]\n\n\u2026 \nndivsm\n [Number\nof DIVisions for the SMallest segment]\n\n\u2026 \nvacuum\n [VACUUM\nidentification]\n\n\u2026 \nvacwidth\n\n[VACuum WIDTH]  \n\n\n\n\n4. Selected input files.\n\u00b6\n\n\nThe user can find some related example input files in the ABINIT package in\nthe directory /tests, or on the Web:\n\n\ntests/v2/Input: \nt43.in\n\n\nt44.in\n \nt61.in\n\n\nt62.in\n \nt63.in\n\n\nt64.in",
            "title": "K-points"
        },
        {
            "location": "/topics/kpoints/#this-file-gives-hints-on-how-to-set-parameters-related-to-the-k-points",
            "text": "with the ABINIT package.     This file gives hints on how to set parameters related to the k-points  1. Introduction.  2. Related lesson(s) of the tutorial.  3. Related input variables.  4. Selected input files.",
            "title": "This file gives hints on how to set parameters related to the k-points"
        },
        {
            "location": "/topics/kpoints/#146-introduction",
            "text": "Any kind of symmetries and corresponding sets of k-point can be input, and\ntaken into account in the computation. \nSince ABINIT is based on periodic boundary conditions, the Brillouin zone must\nbe sampled adequately. The number of k-points to be used for this sampling, in\nthe full Brillouin zone, is inversely proportional to ucvol, but may also vary\na lot from system to system. As a rule of thumb, a system with a large band\ngap will need few k-points, while metals will need lot of k-points to produce\nconverged results. For large systems, the inverse scale with respect to ucvol\nis unfortunately stopped because at least one k-point must be used. The\neffective number of k-points to be used will be strongly influenced by the\nsymmetries of the system, since only the irreducible part of the Brillouin\nzone must be sampled. Moreover the time-reversal symmetry (k equivalent to -k)\ncan be used for ground-state calculations, to reduce sometimes even further\nthe portion of the brillouin zone to be sampled. The number of k points to be\nused in a calculation is named nkpt. There is another way to take advantage of\nthe time-reversal symmetry, in the specific case of k-points that are\ninvariant under k => -k , or are sent to another vector distant of the\noriginal one by some vector of the reciprocal lattice. See below for more\nexplanation about the advantages of using these k-points. \nAs a rule of thumb, for homogeneous systems, a reasonable accuracy may be\nreached when the product of the number of atoms by the number of k-points in\nthe full Brillouin zone is on the order of 50 or larger, for wide gap\ninsulators, on the order of 250 for small gap semiconductors like Si, and\nbeyond 500 for metals, depending on the value of the input variable tsmear. As\nsoon as there is some vacuum in the system, the product natom * nkpt can be\nmuch smaller than this (for an isolated molecule in a sufficiently large\nsupercell, one k-point is enough). \nThe generation of special k point sets (Monkhorst-Pack sets) and band\nstructure k points can be done directly inside ABINIT. A list of interesting k\npoint sets, can be generated automatically, including a measure of their\naccuracy in term of integration within the Brillouin Zone.",
            "title": "1. Introduction."
        },
        {
            "location": "/topics/kpoints/#246-related-lessons-of-the-tutorial",
            "text": "The lesson 3  deals with crystalline silicon (an insulator): the definition of a k-point grid, the smearing of the cut-off energy, the computation of a band structure, and again, convergence studies \u2026",
            "title": "2. Related lesson(s) of the tutorial."
        },
        {
            "location": "/topics/kpoints/#346-related-input-variables",
            "text": "Basic input variables:  \u2026 chksymbreak \n[CHecK SYMmetry BREAKing] \n\u2026  kptopt \n[KPoinTs OPTion] \n\u2026  ngkpt  [Number\nof Grid points for K PoinTs generation]    Useful input variables:  \u2026  istwfk \n[Integer for choice of STorage of WaveFunction at each k point] \n\u2026  kpt  [K - PoinTs] \n\u2026  kptnrm  [K -\nPoinTs NoRMalization] \n\u2026  kptrlatt  [K -\nPoinTs grid : Real space LATTice] \n\u2026  kptrlen  [K -\nPoinTs grid : Real space LENgth] \n\u2026  nkpt  [Number of\nK - Points] \n\u2026  nshiftk \n[Number of SHIFTs for K point grids] \n\u2026  shiftk  [SHIFT\nfor K points] \n\u2026  wtk  [WeighTs for\nK points]    Relevant internal variables:  \u2026  %kptns \n[K-PoinTs re-Normalized and Shifted]    Input variables for experts:  \u2026  kptbounds  [K\nPoinT BOUNDarieS] \n\u2026  ndivk  [Number of\nDIVisions of K lines] \n\u2026  ndivsm  [Number\nof DIVisions for the SMallest segment] \n\u2026  vacuum  [VACUUM\nidentification] \n\u2026  vacwidth \n[VACuum WIDTH]",
            "title": "3. Related input variables."
        },
        {
            "location": "/topics/kpoints/#446-selected-input-files",
            "text": "The user can find some related example input files in the ABINIT package in\nthe directory /tests, or on the Web:  tests/v2/Input:  t43.in  t44.in   t61.in  t62.in   t63.in  t64.in",
            "title": "4. Selected input files."
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/",
            "text": "This file gives for the beginner an overview of the features implemented in\nthe ABINIT package, grouped in different topics, also answering the question\n\u201cHow to \u2026 with ABINIT ?\u201d\n\n\n\n\n\n\n1. Introduction\n\n\n2. Ground state static calculations.\n\n\n3. Molecular dynamics, geometry optimization, transition paths.\n\n\n4. Correlated electrons.\n\n\n5.Response functions.\n\n\n6.Excited state calculations.\n\n\n7. Practical settings.\n\n\n8. Others.\n\n\n\n\n\n\n\n\n1. Introduction\n\u00b6\n\n\nABINIT is a package whose main program allows to find the total energy, charge\ndensity and electronic structure of systems made of electrons and nuclei\n(molecules and periodic solids) within Density Functional Theory, using\npseudopotentials and a planewave basis, or augmented plane waves, or even\nwavelets. Some possibilities of ABINIT go beyond Density Functional Theory,\ni.e. the many-body perturbation theory (GW approximation) and Time-Dependent\nDensity Functional Theory. ABINIT also includes options to optimize the\ngeometry according to the DFT forces and stresses, or to perform molecular\ndynamics simulation using these forces, or to generate dynamical (vibrations -\nphonons) properties, dielectric properties, mechanical properties,\nthermodynamical properties, etc . In addition to the main ABINIT code,\ndifferent utility programs are provided.\n\n\nThe simplest sort of job computes an electronic structure for a fixed set of\natomic positions within a periodic unit cell. By electronic structure , we\nmean a set of eigenvalues and wavefunctions which achieve the lowest (DFT)\nenergy possible for that basis set (that number of planewaves). The code takes\nthe description of the unit cell and atomic positions and assembles a crystal\npotential from the input atomic pseudopotentials, then uses either an input\nwavefunction or simple gaussians to generate the initial charge density and\nscreening potential, then uses a self-consistent algorithm to iteratively\nadjust the planewave coefficients until a sufficient convergence is reached in\nthe energy.\n\n\nAnalytic derivatives of the energy with respect to atomic positions and unit\ncell primitive translations yield atomic forces and the stress tensor. The\ncode can optionally adjust atomic positions to move the forces toward zero and\nadjust unit cell parameters to move toward zero stress. It can performs\nmolecular dynamics. It can also be used to find responses to atomic\ndisplacements and homogeneous electric field, so that the full phonon band\nstructure can be constructed\u2026\n\n\n\n\n2. Ground state static calculations. \n\u00b6\n\n\n\n\n1.\n Building an input file. \n\n\n2.\n General settings. \n\n\n3.\n Crystalline structure and symmetries. \n\n\n4.\n k-points. \n\n\n5.\n Exchange and correlation functionals. \n\n\n6.\n Convergency settings. \n\n\n7.\n PAW special settings. \n\n\n8.\n Spin-polarised systems and spin-orbit coupling \n\n\n9.\n Other settings. \n\n\n\n\n\n\n3. Molecular dynamics, geometry optimization, transition paths.\n\u00b6\n\n\n\n\n1.\n Molecular dynamics calculations. \n\n\n2.\n Geometry optimization calculations. \n\n\n3.\n Transition path calculations: NEB and string method. \n\n\n4.\n PIMD calculations. \n\n\n\n\n\n\n4. Correlated electrons.\n\u00b6\n\n\nWhen correlated electrons are to be considered, it is necessary to go beyond\nthe DFT framework. ABINIT enables the following possibilities:\n\n\n\n\n1.\n The use of hybrid functionals. \n\n\n2.\n Calculation of the effective Coulomb interaction. \n\n\n3.\n The use of the DFT+U approximation. \n\n\n4.\n The use of the DMFT framework. \n\n\n\n\n\n\n 5.Response functions. \n\u00b6\n\n\n\n\n1.\n DFPT: phonon modes, elastic tensors, effective charges, dielectric tensors,\u2026 \n\n\n2.\n Raman intensities and electro-optic properties. \n\n\n3.\n Electron-phonon calculations. \n\n\n4.\n Effective mass calculations. \n\n\n\n\n\n\n 6.Excited state calculations. \n\u00b6\n\n\n\n\n\n\n\n\nGW calculations. \n\n\n\n\n\n\n\n\n\n\nBethe-Salpeter calculations. \n\n\n\n\n\n\n3.\n GW- Lanczos-Sternheimer method. \n\n\n4.\n TDDFT calculations. \n\n\n\n\n\n\n 7. Practical settings.\n\u00b6\n\n\n\n\n1.\n Multi-dataset calculations. \n\n\n2.\n Parallelism and ABINIT. \n\n\n3.\n Printing options. \n\n\n\n\n\n\n 8. Others.\n\u00b6\n\n\n\n\n1.\n Positron calculations. \n\n\n2.\n Wavelets in ABINIT. \n\n\n3.\n Wannier functions in ABINIT. \n\n\n4.\n Recursion methods and orbital free calculations.",
            "title": "Overview"
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/#146-introduction",
            "text": "ABINIT is a package whose main program allows to find the total energy, charge\ndensity and electronic structure of systems made of electrons and nuclei\n(molecules and periodic solids) within Density Functional Theory, using\npseudopotentials and a planewave basis, or augmented plane waves, or even\nwavelets. Some possibilities of ABINIT go beyond Density Functional Theory,\ni.e. the many-body perturbation theory (GW approximation) and Time-Dependent\nDensity Functional Theory. ABINIT also includes options to optimize the\ngeometry according to the DFT forces and stresses, or to perform molecular\ndynamics simulation using these forces, or to generate dynamical (vibrations -\nphonons) properties, dielectric properties, mechanical properties,\nthermodynamical properties, etc . In addition to the main ABINIT code,\ndifferent utility programs are provided.  The simplest sort of job computes an electronic structure for a fixed set of\natomic positions within a periodic unit cell. By electronic structure , we\nmean a set of eigenvalues and wavefunctions which achieve the lowest (DFT)\nenergy possible for that basis set (that number of planewaves). The code takes\nthe description of the unit cell and atomic positions and assembles a crystal\npotential from the input atomic pseudopotentials, then uses either an input\nwavefunction or simple gaussians to generate the initial charge density and\nscreening potential, then uses a self-consistent algorithm to iteratively\nadjust the planewave coefficients until a sufficient convergence is reached in\nthe energy.  Analytic derivatives of the energy with respect to atomic positions and unit\ncell primitive translations yield atomic forces and the stress tensor. The\ncode can optionally adjust atomic positions to move the forces toward zero and\nadjust unit cell parameters to move toward zero stress. It can performs\nmolecular dynamics. It can also be used to find responses to atomic\ndisplacements and homogeneous electric field, so that the full phonon band\nstructure can be constructed\u2026",
            "title": "1. Introduction"
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/#246-ground-state-static-calculations",
            "text": "1.  Building an input file.   2.  General settings.   3.  Crystalline structure and symmetries.   4.  k-points.   5.  Exchange and correlation functionals.   6.  Convergency settings.   7.  PAW special settings.   8.  Spin-polarised systems and spin-orbit coupling   9.  Other settings.",
            "title": "2. Ground state static calculations."
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/#346-molecular-dynamics-geometry-optimization-transition-paths",
            "text": "1.  Molecular dynamics calculations.   2.  Geometry optimization calculations.   3.  Transition path calculations: NEB and string method.   4.  PIMD calculations.",
            "title": "3. Molecular dynamics, geometry optimization, transition paths."
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/#446-correlated-electrons",
            "text": "When correlated electrons are to be considered, it is necessary to go beyond\nthe DFT framework. ABINIT enables the following possibilities:   1.  The use of hybrid functionals.   2.  Calculation of the effective Coulomb interaction.   3.  The use of the DFT+U approximation.   4.  The use of the DMFT framework.",
            "title": "4. Correlated electrons."
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/#5response-functions",
            "text": "1.  DFPT: phonon modes, elastic tensors, effective charges, dielectric tensors,\u2026   2.  Raman intensities and electro-optic properties.   3.  Electron-phonon calculations.   4.  Effective mass calculations.",
            "title": "5.Response functions."
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/#6excited-state-calculations",
            "text": "GW calculations.       Bethe-Salpeter calculations.     3.  GW- Lanczos-Sternheimer method.   4.  TDDFT calculations.",
            "title": "6.Excited state calculations."
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/#746-practical-settings",
            "text": "1.  Multi-dataset calculations.   2.  Parallelism and ABINIT.   3.  Printing options.",
            "title": "7. Practical settings."
        },
        {
            "location": "/user-guide/help_what_ABINIT_does/#846-others",
            "text": "1.  Positron calculations.   2.  Wavelets in ABINIT.   3.  Wannier functions in ABINIT.   4.  Recursion methods and orbital free calculations.",
            "title": "8. Others."
        },
        {
            "location": "/user-guide/help_abinit/",
            "text": "The new user is advised to read first the \nhelp_new_user\n, before reading\nthe present file. It will be easier to discover the present file with the help\nof the \nlesson_welcome\n file.\n\n\nIt is worthwhile to print this help file, for ease of reading.\n\n\nWhen the user will be sufficiently familiarized with ABINIT, reading the\n~abinit/doc/users/tuning.txt file might be useful (this file, as many\nadditional documentation files, is not available on the Web, but is available\nin the package). For response-function calculations using abinit, the\ncomplementary \nhelp_respfn\n is needed.\n\n\n\n\n\n\n  Open tests/v1/Input/t01.in\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n        \n\u00d7\n\n        \ntests/v1/Input/t01.in\n\n      \n\n      \n\n        \n#   FCC Al; 2 special points\n\n#nband 8\n#nspinor 2\n\n acell 3*7.60\n ecut 10\n enunit 2\n intxc 1\n kptopt 0\n kpt   1 1 1     1 2 2   kptnrm 4\n natom  1\n nband 4\n nkpt  2\n nline 3\n nstep 8\n nsym  24 ntypat  1\n occopt  4  prtvol 10\n rprim   0 .5 .5  .5 0 .5  .5 .5 0\n symrel\n       1  0  0    0  1  0    0  0  1\n       0  1 -1    1  0 -1    0  0 -1\n      -1  0  0   -1  0  1   -1  1  0\n       0 -1  1    0 -1  0    1 -1  0\n      -1  0  1   -1  0  0   -1  1  0\n       0 -1  0    0 -1  1    1 -1  0\n       0 -1  1    1 -1  0    0 -1  0\n       0  1 -1    0  0 -1    1  0 -1\n       0  0 -1    1  0 -1    0  1 -1\n      -1  1  0   -1  0  1   -1  0  0\n       1  0 -1    0  1 -1    0  0 -1\n       1 -1  0    0 -1  0    0 -1  1\n      -1  0  0   -1  1  0   -1  0  1\n       0  1  0    1  0  0    0  0  1\n       0  0  1    0  1  0    1  0  0\n       1  0  0    0  0  1    0  1  0\n       0  0  1    1  0  0    0  1  0\n       0  1  0    0  0  1    1  0  0\n      -1  0  1   -1  1  0   -1  0  0\n       0  0 -1    0  1 -1    1  0 -1\n       1  0 -1    0  0 -1    0  1 -1\n       1 -1  0    0 -1  1    0 -1  0\n       0 -1  0    1 -1  0    0 -1  1\n      -1  1  0   -1  0  0   -1  0  1\n tnons   72*0.0d0\n tolwfr 1.0d-16\n tsmear 0.05\n typat  1\n wtk   1 3\n xred  0.0 0.0 0.0\n znucl 13.0\n\n\n## After modifying the following section, one might need to regenerate the pickle database with runtests.py -r\n#%%\n\n#%% [setup]\n#%% executable = abinit\n#%% [files]\n#%% files_to_test = t01.out, tolnlines=0, tolabs=0.0, tolrel=0.0\n#%% psp_files=13al.pspgth\n#%% [paral_info]\n#%% max_nprocs = 2\n#%% [extra_info]\n#%% keywords = NC\n#%% description = \n#%%  Bulk Aluminium, FCC, with 2 special points, occopt=4 and tsmear=0.05 .\n#%%  Designed to test the treatment of metals, using the \"cold smearing\"\n#%%  of N. Marzari , with a=-.5634 (minimization of the bump).   \n#%%\n\n\n\n      \n\n      \n\n        \nClose\n\n        \nSave changes\n\n      \n\n    \n\n  \n\n\n\n\n\n1. How to run the code\n\u00b6\n\n\n1.1 Introducing the files file.\n\u00b6\n\n\nGiven an input file (parameters described below) and the required\npseudopotential files, the user must create a \u201cfiles\u201d file which lists names\nfor the files the job will require, including the main input file, the main\noutput file, root names for other input, output, or temporary files, and\ndifferent pseudopotential file names.\n\n\nThe files file (called for example ab.files) could look like:\n\n\n    ab_in\n    ab_out\n    abi\n    abo\n    tmp\n    14si.psp\n\n\n\n\n\nIn this example:  \n\n\n- The main input file is called \u201cab_in\u201d.\n\n- The main output will be put into the file called \u201cab_out\u201d.\n\n- The name of input wavefunctions (if any) will be built from the root \u201cabi\u201d\n(namely abi_WFK, see later).\n\n- The output wavefunctions will be written to abo_WFK. Other output files\nmight be build from this root.\n\n- The temporary files will have a name that use the root \u201ctmp\u201d. (for example\ntmp_STATUS).\n\n- The pseudopotential needed for this job is \u201c14si.psp\u201d.  \n\n\nOther examples are given in the subdirectories of the ~abinit/tests directory.\nThe maximal length of names for the main input or output files is presently\n132 characters. It is 112 characters for the root strings, since they will be\nsupplemented by different character strings.\n\n\nIf you follow the tutorial, you should go back to the tutorial window now.\n\n\n1.2. Running the code\n\u00b6\n\n\nThe main executable file is called abinit. Supposing that the \u201cfiles\u201d file is\ncalled ab.files, and that the executable is placed in your working directory,\nabinit is run interactively (in Unix) with the command\n\n\n    $ abinit < ab.files >\n&\n log\n\n\n\n\n\nor, in the background, with the command\n\n\n    $ abinit < ab.files >\n&\n log \n&\n\n\n\n\n\n\nwhere standard out and standard error are piped to the log file called \u201clog\u201d\n(piping the standard error, thanks to the \u2018&\u2019 sign placed after \u2018>\u2019 is\n\nreally important\n for the analysis of eventual failures, when not due to\nABINIT, but to other sources, like disk full problem \u2026). The user can\nspecify any names he/she wishes for any of these files. Variations of the\nabove commands could be needed, depending on the flavor of UNIX that is used\non the platform that is considered for running the code.  \n\n\nIf you follow the tutorial, you should go back to the tutorial window now.\n\n\n\n\n2. The underlying theoretical framework and algorithms\n\u00b6\n\n\nSee the \u201c\nbibliography\n\u201d\nfile.\n\n\nThe methods employed in this computer code to solve the electronic structure\nproblem are described in part in different review papers as well as research\npapers. The code is an implementation of the Local Density Approximation to\nthe Density Functional Theory, based upon a plane wave basis set and separable\npseudopotentials. The iterative minimization algorithm is a combination of\nfixed potential preconditioned conjugate gradient optimization of wavefunction\nand a choice of different algorithms for the update of the potential, one of\nwhich is a potential-based conjugate gradient algorithm.\n\n\nThe representation of potential, density and wavefunctions in real space will\nbe done on a regular 3D grid of points. Its spacing will be determined by the\ncut-off energy (see the input variable \necut\n) of the planewave basis in\nreciprocal space. This grid of points will also be the starting point of Fast\nFourier Transforms between real and reciprocal space. The number of such\npoints, called \nngfft\n, should be sufficiently large for adequate\nrepresentation of the functions, but not too large, for reasons of\ncomputational efficiency. The trade-off between accuracy and computational\nefficiency is present in many places of the code, and addressed briefly at the\nend of the present help file.\n\n\nWe recommend a good introduction to many different concepts valid for this\ncode, available in a Reviews of Modern Physics article, ``Iterative\nminimization techniques for ab initio total-energy calculations: molecular\ndynamics and conjugate gradients\u2019\u2018, M. C. Payne, M. P. Teter, D. C. Allan, T.\nA. Arias, and J. D. Joannopoulos, Rev. Mod. Phys. 64, 1045-1097 (1992).\n\nThis paper does NOT reflect the present status of the code. ABINIT is closer\nin spirit to the paper of of Kresse and Furthmuller, see the\n\nbibliography\n list.\n\n\nIf you have never used another electronic structure code or a Quantum\nChemistry package, you should browse through the Chaps. 1 to 13 , and\nappendices L and M of the book Electronic Structure. Basic Theory and\nPractical Methods. R. M. Martin. Cambridge University Press (2004) ISBN 0 521\n78285 6.\n\n\n\n\n3. The input file\n\u00b6\n\n\n3.1. Format of the input file.\n\u00b6\n\n\nNote that this input file was called ab_in in the example of  section 1.1 .\n\nWe first explain the content of the input file without use of the \u201cmulti-\ndataset\u201d possibility (that will be explained in section 3.3).\n\n\nThe parameters are input to the code from a single input file. Each parameter\nvalue is provided by giving the name of the input variable and then placing\nthe numerical value(s) beside the name, separated by one or more spaces, or\neven an equal sign (equal signs are replaced by blanks by the parser).\nDepending on the input variable, the numerical value may be an integer or a\nreal number (internal representation as double precision number), and may\nactually represent an array of values. If it represents an array, the next set\nof numbers separated by spaces are taken as the values for the array.\n\n\n\n\nDo NOT separate a minus sign from the number to which it applies. \n\n\nDo NOT use tabs. \n\n\nNOTE THAT NO LINE OF THE INPUT FILE MAY EXCEED 132 CHARACTERS. That is, only the first 132 characters of each line of the input file will be read and parsed for input variables and their values. \n\n\n\n\nThe names of all the parameters can be found in the \nallvariables\n. The list\nof input variables present in the latter file links them to their definitions,\ncontained in different files, of which some are listed here:\n\n\n\n\nBasic variables, \nvarbas\n\n\nFiles handling variables, \nvarfil\n\n\nGround-state calculation variables, \nvargs\n\n\nGW variables, \nvargw\n\n\nParallelisation variables, \nvarpar\n\n\nResponse Function variables, \nvarrf\n\n\n\n\nIn the actual input file, these parameters may be given in any desired order,\nand more than one may be given per line. Spaces are used to separate values\nand additional spaces are ignored.\n\nAn as example of input, the parameter for length scales is called \nacell\n\nand is an array \n[acell]\n for the lengths of the primitive translations in\nBohr atomic units. To input a typical Si diamond lattice one would have the\nline\n\n\nacell 10.25311 10.25311 10.25311\n\n\nin the input file. This may equivalently be written\n\n\nacell 3*10.25311\n\n\nand will still be parsed correctly : it is equivalent to the above line. Even\n\n\nacell *10.25311\n\n\nwill work. In the latter case the \u2018*\u2019 sign means that the parser should use\nthe given value to fill the array, by repeating it as many time as needed.\n\nMultiple spaces are ignored, as is any text which does not contain the\ncharacter strings which correspond to some input parameters. In case of\narrays, only the needed numbers will be considered, and the eventual numbers\nafter those needed will also be ignored. For example,\n\n\n[[natom]] 3 # This gives the number of atoms  \n[[typat]] 1 1 2 2 3 # typat(1:natom) gives the type of each atom : only  \n               # the first three data are read, since [[natom]]=3\n  \n\n\nA given variable is identified by the parser by having at least one blank\nbefore it and after it (again, multiple blanks are irrelevant).\n\nABINIT has also some (very limited) interpretor capabilities :\n\n\n\n\nIt can identify one slash sign (/) being placed between two numbers (without a separating blank) as being the definition of a fraction (e.g. 1/3 will be interpreted as 0.33333333333333d0) ; \n\n\nIt can identify sqrt(\u2026) or -sqrt(\u2026) as being the definition of a square root, when applied to one valid number - also without a separating blank - (e.g. -sqrt(0.75) will be interpreted as -0.8660254038d0) ; \n\n\nNote, however, that these capabilities are NOT recursive. At most, a sqrt identifier can contain an expression that uses a fraction (e.g. sqrt(3/4) is OK), but two fractions (or two sqrt) cannot be used in one expression, and a sqrt cannot be present in the numerator or denominator of a fraction. \n\n\n\n\nComments should be placed to the right of the comment characters # or ! ;\nanything to the right of a \u201c#\u201d or a \u201c!\u201d on any line is simply ignored by the\nparser. Additional text, not preceded by a \u201c#\u201d or a \u201c!\u201d would not otherwise\ncause trouble unless the text inadvertently contained character strings which\nwere the same as variable names (e.g. \nacell\n). The characters \u201c#\u201d or \u201c!\u201d\ncan also be used to \u201cstore\u201d old values of variables or place anything else of\nconvenience into the file in such a way as to be ignored by the parser when\nthe data is read.\n\nCase is irrelevant as the entire input string is mapped to upper case before\nparsing, to remove case sensitivity.\n\nMore than one parameter per line may be given. If a given parameter name is\ngiven more than once in the input file, an error message is printed, and the\ncode stops.\n\n\n_If you follow the tutorial, you should go back to the tutorial window now. _\n\n\n3.2. More about ABINIT input variables.\n\u00b6\n\n\nIn each section of the ABINIT input variables files, a generic information on\nthe input variable is given : a mnemonics, some \u201ccharacteristics\u201d, the\nvariable type, and the default. Then, follows the description of the variable.\n\n\nThe \nmnemonics\n is indicated when available.\n\n\nThe \u201ccharacteristics\u201d can be of different types : \nDEVELOP\n, \nRESPFN\n,\n\nNONLINEAR\n, \nGW\n, \nBETHE_SALPETER\n, \nTDDFT\n, \nGEOMETRY_BUILDER\n,\n\nSYMMETRISER\n, \nSYMMETRY_FINDER\n, \nNO MULTI\n, \nINTERNAL_ONLY\n,\n\nINPUT_ONLY\n, \nEVOLVING\n, \nENERGY\n, \nLENGTH\n, \nMAGNETIC FIELD\n. We\nnow explain each of these classes.\n\n\n\u2018\nDEVELOP\n\u2018 refers to input variables that are not used in production runs,\nbut only during development time. For non developers, it is strongly advised\nto skip them.\n\n\nSome input variables are related to response function features, or non-linear\nfeatures, and are indicated \u2018\nRESPFN\n\u2018 and \u2018\nNONLINEAR\n\u2019. Detailed\nexplanations related to response function and non linear features are to be\nfound in the complementary \nhelp_respfn\n. The initials RF are used for\n\u2018response function\u2019, and non-response-function are often referred to as GS\n(for ground-state), although this latter designation is not really\nsatisfactory.\n\n\nSome input variables are related to excited state calculations, and are\nindicated \u2018\nGW\n\u2019, \u2018\nBETHE_SALPETER\n\u2019, or \u2018\nTDDFT\n\u2019. No complementary\nhelp file is yet provided for such calculations. Please refer to the tutorial\n(\nlesson_gw1\n, \nlesson_gw2\n, \nlesson_tddft\n, and \nlesson_bse\n).\n\n\nThere are also parameters related to the geometry builder, a preprocessor of\nthe input file, aimed at easing the work of the user when there are molecules\nto be manipulated (rotation and translation), or group of atoms to be\nrepeated. The indication \u2018\nGEOMETRY_BUILDER\n\u2018 is given for them. These can\nalso be skipped for the first few steps in the use of the code.\n\nIndeed, it should be \neasy to set up the geometry of systems with less than\n20-40 atoms without this geometry builder\n. Even for larger systems, its\nfunctionalities could eventually be of no help. For a step-to-step description\nof this geometry builder, look at the variable \u2018\nnobj\n\u2019. The related input\nvariables being used for preprocessing of the input file, they are not echoed\nin the output file.\n\n\nAlternatively to the geometry builder, there is also a symmetriser. It allows\nto generate the full set of atoms in the primitive cell from the knowledge of\nthe symmetry operations and the atoms in the asymmetric cell. It also allows\nto generate the symmetry operations from the knowledge of the number of the\nspace group according to the international crystallographic tables. The\nindication \u2018\nSYMMETRISER\n\u2018 is given for the variables related to its use.\nLook at the variable \u2018\nspgroup\n\u2019.\n\nYou may find in the space group \nhelp file\n the\ncrystallographic equivalence of the parameters belonging to the symmetriser.\nThe related input variables being used for preprocessing of the input file,\nthey are not echoed in the output file.\n\n\nStill as an alternative to the geometry builder and the symmetriser, if all\nthe coordinates of the atoms are given, the code is able to deduce all\nsymmetry operations leaving the lattice and atomic sublattices invariant, see\n\u2018\nSYMMETRY_FINDER\n\u2019. Note that the default tolerance on the coordinates that\nare provided by the user, for a symmetry to be recognized, is on the order of\n1.e-8 . If the provided coordinates are rather inaccurate, ABINIT will not\nrecognize the symmetry, unless the input variable \ntolsym\n is changed.\n\n\nMost of the variables can be used in the multi-dataset mode (see section 3.3),\nbut those that must have a unique value throughout all the datasets are\nsignaled with the indication \u2018\nNO_MULTI\n\u2018\n\n\nSome of the input variables, with characteristics \u2018\nINPUT_ONLY\n\u2018 are only\nused by the parser, to initialize other input variables, but are not\ntransmitted inside the code, beyond the parser. In particular, they are not\nechoed in the output file.\n\n\nAt variance, some internal variables, with characteristics \u2018\nINTERNAL_ONLY\n\u2018\nare documented in the help files, but are not accessible as input variables.\nThe documentation is provided because such variables are sometimes mentioned\nin the output file.\n\n\nMost of the input variables do not change while a run is performed. Some of\nthem, by contrast, may evolve, like the atomic positions, the atomic\nvelocities, the cell shape, and the occupation numbers. Their echo, after the\nrun has proceeded, will of course differ from their input value. They are\nsignaled by the indication \u2018\nEVOLVING\n\u2019.\n\n\nThe use of the atomic unit system (e.g. the Hartree for energy, about 27.211\neV, and the Bohr for lengths about 0.529 Angstroms) is strictly enforced\nwithin the code. However, the dimension of some input variables can be\nspecified and read correctly. At present, this applies to three types of\nvariables : those that have the dimension of an energy, those that have a\ndimension of length, and those that have a dimension of magnetic field. The\nfirst class of variables have the characteristics \u2018\nENERGY\n\u2019, and can be\nspecified in atomic units (Hartree), or electron-volts, or Rydbergs, or even\nKelvin. The second class of variables have the characteristics \u2018\nLENGTH\n\u2019,\nand can be specified in atomic units (Bohr) and angstrom. The third class of\nvariables have the characteristics \u2018\nMAGNETIC FIELD\n\u2019, and can be specified\nin atomic units and Tesla. The abinit parser recognize a dimension if it is\nspecified after the list of numbers following the input variable keyword, in\nthe input file. The specification can be upper or lower case, or a mix\nthereof. Here is the list of recognized chains of characters :\n\n\n\n\n\u2018Ry \u2018 => Rydberg (for energies) \n\n\n\u2018eV \u2018 => electron-volts (for energies) \n\n\n\u2018K \u2018 => Kelvin (for energies) \n\n\n\u2018Angstr\u2026\u2019 => Angstrom (for lengths) \n\n\n\n\nExcept in the case of \u2018Angstr\u2019, the abbreviation must be used (i.e. \u2018Rydberg\u2019\nwill not be recognized presently). Other character chains, like \u201cau\u201d (for\natomic units) or \u201cHartree\u201d, or \u201cBohr\u201d are not recognized, but make the parser\nchoose (by default) atomic units, which is the correct behaviour. Example :\n\n\n     acell 8 8 8 angstrom\n     ecut 8 Ry\n     tsmear 1000 K\n\n\n\n\n\nor\n\n\n      acell 3*10 Bohr  ecut 270 eV  tsmear 0.01\n\n\n\n\n\nThe use of the atomic units is mandatory for other dimensioned input\nvariables, like the tolerance on forces (\ntoldff\n), parameters that define\nan \u2018object\u2019 (\nobjaax, objbax\n, \n\nobjatr, objbtr\n), and the\ninitial velocity of atoms (\nvel\n - if needed).\n\n\nThe initial atomic positions can be input in Bohr or Angstrom through\n\u2018\nxcart\n\u2019, but also, independently, in Angstrom through \u2018\nxangst\n\u2019, or\neven in reduced coordinates, through \u2018\nxred\n\u2019. Reduced cartesian coordinates\nmust be used for the eventual translations accompanying symmetry operations\n(\ntnons\n).\n\n\nIn addition to giving the input variables, the input file can be useful for\nanother purpose : placing the word \u201c\nexit\n\u201d on the top line will cause the\njob to end smoothly on the very next iteration, if the \nchkexit\n input\nvariable is non-zero. This functions because the program closes and reopens\nthe input file on every iteration and checks the top line for the keyword\n\u201cexit\u201d. THE WORD MUST BE PLACED WITH SPACES (BLANKS) ON BOTH SIDES. Thus\nplacing exit on the top line of the input file WHILE THE JOB IS ALREADY\nRUNNING will force the job to end smoothly on the very next iteration. On some\nmachines, this does not work always (we do not know why\u2026). Another\npossibility is offered : one can create a file named \u201cabinit.exit\u201d in the\ndirectory where the job was started. The code should also smoothly end. In\nboth cases, the stop is not immediate. It can take a significant fraction\n(about 20% at most) of one SCF step to execute properly the instruction still\nneeded.\n\n\nIf you follow the tutorial, you should go back to the tutorial window now.\n\n\n3.3. The multi-dataset mode.\n\u00b6\n\n\nUntil now, we have assumed that the user wants to make computations\ncorresponding to one set of data : for example, determination of the total\nenergy for some geometry, with some set of plane waves and some set of\nk-points.\n\n\nIt is often needed to redo the calculations for different values of some\nparameter, letting all the other things equal. As typical examples, we have\nconvergence studies needed to determine which cut-off energy gives the needed\naccuracy. In other cases, one makes chains of calculations in order to compute\nthe band structure : first a self-consistent calculation of the density and\npotential, then the eigenenergy computation along different lines.\n\n\nFor that purpose, the \nmulti-dataset mode\n has been implemented.\n\n\nIt allows the code to treat, in one run, different sets of data, and to chain\nthem. The number of datasets to be treated is specified by the variable\n\nndtset\n, while the indices of the datasets (by default 1, 2, 3, and so on)\ncan be eventually provided by the array \njdtset\n.\n\n\nFor each dataset to be treated, characterized by some index, each input\nvariable will determined by the following \nrules\n (actually, it is easier to\nunderstand when one looks at examples, see below) :\n\n\n\n\n(1) ABINIT looks whether the variable name (e.g. \necut\n ), appended with the index of the dataset (e.g. \njdtset\n=2), exists (e.g. \u201cecut2\u201d ) . It will take the data that follows this keyword, if it exists.\n\n\n(2) If this modified variable name does not exist, it will look whether a metacharacter, a series or a double-loop data set has been defined, see sections 3.4 or 3.5.\n\n\n(3) If the variable name appended with the index of the dataset does not exist, and if there is no series nor double-loop dataset for this keyword, it looks for an occurrence of the variable name without any index appended, and take the corresponding data. (This corresponds to the single dataset mode)\n\n\n(4) If such occurrences do not exist, it takes the default value. (Also, similar to the single dataset mode)\n ---------------\n\n 1st example.\n\n ndtset   2\n  acell   8 8 8\n   ecut1  10\n   ecut2  15\n\n\n\n\n\n\n\n\n\nmeans that there are 2 datasets : a first in which\n\n\n     acell 8 8 8  ecut 10\n\n\n\n\n\nhas to be used, and a second in which\n\n\n     acell 8 8 8  ecut 15\n\n\n\n\n\nhas to be used.\n\n\n     ------------------\n\n     2nd example\n\n     ndtset 2     jdtset 4 5\n\n     acell   8 8 8\n     acell5 10 10 10\n     ecut1  10\n     ecut2  15\n     ecut3  20\n     ecut4  25\n     ecut5  30\n\n\n\n\n\nthis means that there are still two datasets, but now characterized by the\nindices 4 and 5, so that the first run will use the generic \u201cacell\u201d, and\n\u201cecut4\u201d :\n\n\n     acell 8 8 8 ecut 25\n\n\n\n\n\nand the second run will use \u201cacell5\u201d and \u201cecut5\u201d :\n\n\n     acell 10 10 10 ecut 30\n\n\n\n\n\nNote that ecut1, ecut2 and ecut3 are not used.\n\n\n3.4. Defining a series.\n\u00b6\n\n\nRule (2) is split in three parts : (2a), (2b) and (2c).\n\nSeries relate with (2b):\n\n\n(2b) If the variable name appended with the index of the dataset does not\nexist, the code looks whether a series has been defined for this keyword.\n\n\nThere are two kinds of series :\n\n\n\n\narithmetic series (constant \nincrement\n between terms of the series) \n\n\ngeometric series (constant \nratio\n between terms of the series) \n\n\n\n\nThe first term of the series is defined by the keyword appended with a colon\n(e.g. \necut:\n ), while the increment of an arithmetic series is defined by\nthe keyword appended with a plus (e.g. \necut+\n ), and the factor of a\ngeometric series is defined by the keyword appended with a times (e.g.\n\necut\n* ).\n\n\nIf the index of the dataset is 1, the first term of the series is used, while\nfor index N , the appropriate input data is obtained by considering the Nth\nterm of the series.\n\n\n  ------------------\n\n  3rd example\n\n    ndtset 6\n    ecut1 10\n    ecut2 15\n    ecut3 20\n    ecut4 25\n    ecut5 30\n    ecut6 35\n\n\n\n\n\nis equivalent to\n\n\n    ndtset 6 ecut: 10 ecut+ 5\n\n\n\n\n\nIn both cases, there are six datasets, with increasing values of \necut\n.\n\n\n3.5. Defining a double loop dataset\n\u00b6\n\n\nTo define a double loop dataset, one has first to define the upper limit of\ntwo loop counters, thanks to the variable \nudtset\n. The inner loop will\nexecute from 1 to \n[udtset]\n, and the outer loop will execute from 1 to\n\n[udtset]\n. Note that the largest value for \n[udtset]\n is presently 999,\nwhile it is 9 for \n[udtset]\n (so, only the last digit for the inner loop).\n\n\nThe value of \nndtset\n must be coherent with \nudtset\n (it must equal the\nproduct \nudtset(1)*udtset(2)\n ).\n\n\nA dataset index is created by the concatenation of the outer loop index and\nthe inner loop index.\n\nFor example, if \n[udtset]\n is 2 and \n[udtset]\n is 4, the index will\nassume the following values : \n11, 12, 13, 14, 21, 22, 23, and 24\n.\n\n\nIndependently of the use of \nudtset\n, rules (2a) and (2c) will be used to\ndefine the value of an input variable:\n\n\n(2a) The question mark \u201c\n?\n\u201d can be used as a metacharacter, replacing any\ndigit from 1 to 9, to define an index of a dataset.\n\nFor example, \necut?\n1 means that the input value that follows it can be used\nfor \necut\n for the datasets \n01, 11, 21, 31, 41, 51, 61, 71, 81, and 91\n.\n\n\n(2c) If the variable name appended with the index of the dataset does not\nexist, the code looks whether a double-loop series has been defined for this\nkeyword. Series can be defined for the inner loop index or the outer loop\nindex. Two signs will be appended to the variable name (instead of one in the\nsimple series case). One of these signs must be a question mark \u201c\n?\n\u201d, again\nused as a metacharacter able to assume the values 1 to 9.\n\nIf it is found in the first of the two positions, it means that the series\ndoes not care about the outer loop index (so the values generated are equal\nfor all outer loop index values). If it is found in the second of the two\npositions, the series does not care about the inner loop index. The other sign\ncan be a colon, a plus or a times, as in the case of the series defined in\n(2a), with the same meaning.\n\n\nRule (1) has precedence over them, they have precedence over rules (3) or (4),\nrule (2a) has precedence over rules (2b) or (2c) and the two latter cannot be\nused simultaneously for the same variable.\n\n\n     ------------------\n\n     4th example\n     ndtset 6    udtset 2 3\n     acell1?  10 10 10\n     acell2?  15 15 15\n     ecut?: 5    ecut?+ 1\n\n\n\n\n\nis equivalent to\n\n\n     ndtset 6     jdtset 11 12 13  21 22 23\n     acell11  10 10 10     ecut11 5\n     acell12  10 10 10     ecut12 6\n     acell13  10 10 10     ecut13 7\n     acell21  15 15 15     ecut21 5\n     acell22  15 15 15     ecut22 6\n     acell23  15 15 15     ecut23 7\n\n\n\n\n\nMore examples can be found in the directory ~abinit/tests/v1, cases 59 and\nlater.\n\n\n3.6. File names in the multi-dataset mode.\n\u00b6\n\n\nThe root names for input and output files (potential, density, wavefunctions\nand so on) will receive an appendix : \u2018\n_DS\n\u2018 followed by the index of the\ndataset. See section 4.\n\n\nThe \u2018\nget\n\u2018 variables can be used to chain the calculations.\n\n\nUntil now, there are eight of them : \ngetwfk\n, \ngetwfq\n, \ngetddk\n,\n\nget1wf\n, \ngetden\n, \ngetcell\n, \ngetxred\n and \ngetxcart\n.\n\n\n\n\ngetwfk\n allows to take the output wavefunctions of a previous dataset and use them as input wavefunctions \n\n\ngetwfq\n, \ngetddk\n and \nget1wf\n do similar things for response function calculations \n\n\ngetden\n does the same for the density ; \ngetcell\n does the same for \nacell\n and \nrprim\n \n\n\ngetxred\n and \ngetxcart\n do the same for the atomic positions, either in reduced coordinates, or in cartesian coordinates. \n\n\n\n\nThe different variables corresponding to each dataset are echoed using the\nsame indexing convention as for the input step. For the last echo of the code\nvariables, some output variables are also summarized, using the same\nconventions :\n\n\n\n\netotal\n (total energy) \n\n\nfcart\n (cartesian forces) \n\n\nstrten\n (the stress tensor). \n\n\n\n\nIf you follow the tutorial, you should go back to the tutorial window now.\n\n\n\n\n4. The \u201cfiles\u201d file\n\u00b6\n\n\nNote: \nThis \u201cfiles\u201d file is called ab.files in section 1.1 .\n\n\nContains the file names or root names needed to build file names. These are\nlisted below : there are 5 names or root names for input, output and\ntemporaries, and then a list of pseudopotentials. These names may be provided\nfrom unit 05 interactively during the run but are more typically provided by\npiping from a file in Unix (the \u201cfiles\u201d file).\n\n\nab_in\n \n\nFilename of file containing the input data, described in the preceding\nsections.\n\n\nab_out\n\nFilename of the main file in which formatted output will be placed (the main\noutput file). Error messages and other diagnostics will NOT be placed in this\nfile, but sent to unit 06 (terminal or log file); the unit 06 output can be\nignored unless something goes wrong. The code repeats a lot of information to\nboth unit 06 and to the main output file. The unit 06 output is intended to be\ndiscarded if the run completes successfully, with the main output file keeping\nthe record of the run in a nicer looking format.\n\n\nabi\n \n\nThe other files READ by the code will have a name that is constructed from the\nroot \u201cabi\u201d. This apply to optionally read wavefunction, density or potential\nfiles. In the multi-dataset mode, this root will be complemented by \u2018\n_DS\n\u2018\nand the dataset index. The list of possible input files, with their name\ncreated from the root \u2018abi\u2019, is the following (a similar list exist when\n\u2018\n_DS\n\u2018 and the dataset index are appended to \u2018abi\u2019):\n\n\n\n\n\n\nabi_WFK\n \n\nfilename of file containing input wavefunction coefficients created from an\nearlier run (with \nnqpt\n=0). Will be opened and read if \nirdwfk\n is 1 .\nThe wavefunction file is unformatted and can be very large. \nWarning\n : in\nthe multi dataset mode, if getwfk is non-zero, a wavefunction file build from\n\nabo\n will be read.\n\n\n\n\n\n\nabi_WFQ\n \n\nfilename of file containing input wavefunction coefficients created from an\nearlier run (with \nnqpt\n=1), as needed for response function calculations.\nThe wavefunction file is unformatted and can be very large. \nWarning\n : in\nthe multi dataset mode, if getwfk is non-zero, a wavefunction file build from\n\nabo\n will be read.\n\n\n\n\n\n\nabi_1WFxx\n \n\nfilename of file containing input first-order wavefunctions created from an\nearlier RF run. xx is the index of the perturbation\n\n\n\n\n\n\nabi_DEN\n \n\nfilename of file containing density created from an earlier run. See\nexplanations related to negative values of \niscf\n. This file is also\nunformatted. \nWarning\n : in the multi dataset mode, if getwfk is non-zero, a\ndensity file build from \nabo\n will be read.\n\n\n\n\n\n\nabi_HES\n \n\nfilename of file containing an approximate hessian, for eventual\n(re)initialisation of Broyden minimisation. See brdmin.F90 routine. The use of\n\nrestartxf\n is preferred.\n\n\n\n\n\n\nabo\n \n\nExcept \u201cab_out\u201d and \u201clog\u201d, the other files WRITTEN by the code will have a\nname that is constructed from the root \u201cabo\u201d. This apply to optionally written\nwavefunction, density, potential, or density of states files. In the multi-\ndataset mode, this root will be complemented by \u2018\n_DS\n\u2018 and the dataset\nindex. Also in the multi-dataset mode, the root \u201cabo\u201d can be used to build the\nname of \ninput\n files, thanks to the \u2018get\u2019 variables. The list of possible\noutput files, with their name created from the root \u2018abo\u2019 is the following (a\nsimilar list exists when \u2018\n_DS\n\u2018 and the dataset index are appended to\n\u2018abo\u2019) :\n\n\n\n\n\n\nabo_WFK\n \n\nFilename of file containing output wavefunction coefficients, if \nnqpt\n=0.\nThe wavefunction file is unformatted and can be very large.\n\n\n\n\n\n\nabo_WFQ\n \n\nSame as \nabo_WFK\n, but for the case \nnqpt\n=1. The wavefunctions are always\noutput, either with the name \nabo_WFK\n, or with the name \nabo_WFQ\n.\n\n\n\n\n\n\nabo_1WFxx\n \n\nSame as \nabo_WFK\n, but for first-order wavefunctions, xx is the index of the\nperturbation, see the section \n6.3\n of the\n\nhelp_respfn\n.\n\n\n\n\n\n\nabo_DDB\n \n\nThe derivative database, produced by a response-function dataset, see the\nsection \n6.5\n of the \nhelp_respfn\n\n\n\n\n\n\nabo_DEN\n \n\nfilename of file containing density, in the case \nionmov\n=0. See the keyword\n\nprtden\n. This file is unformatted, but can be read by cut3d.\n\n\n\n\n\n\nabo_TIMx_DEN\n \n\nfilenames of files containing density, in the case \nionmov\n/=0. The value of\n\u201cx\u201d after \u201c\nTIM\n\u201d is described hereafter. See the keyword \nprtden\n. This\nfile is unformatted, but can be read by cut3d.\n\n\n\n\n\n\nabo_POT\n \n\nfilename of file containing Kohn-Sham potential See the keyword \nprtpot\n.\nThis file is unformatted, but can be read by cut3d.\n\n\n\n\n\n\nabo_TIMx_POT\n \n\nfilenames of files containing Kohn-Sham potential in the case \nionmov\n/=0.\nThe value of \u201cx\u201d after \u201cTIM\u201d is described hereafter. See the keyword\n\nprtpot\n. This file is unformatted, but can be read by cut3d.\n\n\n\n\n\n\nabo_DOS\n \n\nfilename of file containing density of states. See the keyword \nprtdos\n.\nThis file is formatted.\n\n\n\n\n\n\nabo_TIMx_DOS\n \n\nfilenames of files containing the density of states in the case \nprtdos\n=2\nand \nionmov\n=1 or 2. The value of \u201cx\u201d after \u201cTIM\u201d is described hereafter.\nSee also the keyword \nprtdos\n. This file is formatted.\n\n\n\n\n\n\nabo_GEO\n \n\nfilename of file containing the geometrical analysis (bond lengths and bond\nangles) in the case \nionmov\n=0. See the keyword \nprtgeo\n. This file is\nformatted.\n\n\n\n\n\n\nabo_TIMx_GEO\n \n\nfilenames of files containing the geometrical analysis (bond lengths and bond\nangles) in the case \nionmov\n=1 or 2. The value of \u201cx\u201d after \u201cTIM\u201d is\ndescribed hereafter. See also the keyword \nprtgeo\n. This file is formatted.\n\n\n\n\n\n\nabo_KSS\n \n\nfilename of file containing output wavefunction coefficients, if\n\nnbandkss\n/=0. This wavefunction file is unformatted and can be very large.\nIts purpose is to start a GW calculation using M.Torrent\u2019s code. A different\nformat than for \nabo_WFK\n is used, see the file\n~abinit/doc/developers/format_KSS.txt .\n\n\n\n\n\n\nabo_EIG\n \n\nA file containing the electronic eigenvalues, for subsequent plotting of band\nstructure.\n\n\n\n\n\n\nWhen \nionmov\n/=0, the \nPOT\n, \nDEN\n, or \nGEO\n files are output each\ntime that a SCF cycle is finished. The \u201c\nx\n\u201d of \nTIMx\n aims at giving each\nof these files a different name. It is attributed as follows:\n\n- case ionmov==1 : there is an initialization phase, that takes 4 calls to\nthe SCF calculation. The value of x will be A, B, C, and D. Then, x will be 1,\n2, 3 \u2026 , actually in agreement with the value of itime (see the keyword\n\nntime\n)\n\n- other ionmov cases : the initialisation phase take only one SCF call. The\nvalue of x will be 0 for that call. Then, the value of x is 1, 2, 3 \u2026 in\nagreement with the value of itime (see the keyword \nntime\n)\n\n\ntmp\n \n\nThe temporary files created by the codes will have a name that is constructed\nfrom the root \u201c\ntmp\n\u201d. tmp should usually be chosen such as to give access\nto a disk of the machine that is running the job, not a remote (NFS) disk.\nUnder Unix, the name might be something like \n/tmp/user_name/temp\n. As an\nexample, \ntmp_STATUS\n\ngives the status of advancement of the calculation, and is updated very\nfrequently\n\n\npsp1\n \n\nfilename of first pseudopotential input file. The pseudopotential data files\nare formatted. There must be as many filenames provided sequentially here as\nthere are types of atoms in the system, and the order in which the names are\ngiven establishes the identity of the atoms in the unit cell. (psp2, psp3, \u2026\n)\n\n\n_If you follow the tutorial, you should go back to the tutorial window now. _\n\n\n\n\n5. The pseudopotential files\n\u00b6\n\n\nActually, no real understanding of these files is needed to run the code, but\nfor different other reasons, it might be useful to be able to understand the\nfile structures. Different format are possible (labelled 1 to 7 presently) The\nassociated internal variable is called pspcod. Examples of use are found in\n~abinit/test/v1 . Information on the file structure can be found in the\n~abinit/doc/psp_infos directory.\n\n\n\n\npspcod=1 : Troullier-Martins pseudopotentials, generated by DC Allan and A Khein, see ~abinit/doc/psp_infos/psp1_info.txt ; \n\n\npspcod=2 : Goedecker-Teter-Hutter (GTH) pseudopotentials. See Phys. Rev. B 54, 1703 (1996) if needed ; \n\n\npspcod=3 : Hartwigsen-Goedecker-Hutter pseudopotentials. See Phys. Rev. B 58, 3641 (1998) if needed, and the file ~abinit/doc/psp_infos/psp3_info.txt ; \n\n\npspcod=4 or 5 : old format pseudopotentials, see ~abinit/doc/psp_infos/psp45_info.txt ; \n\n\npspcod=6 : pseudopotentials from the fhi98pp code, see ~abinit/doc/psp_infos/psp6_info.txt ; \n\n\npspcod=7 : pseudo atomic data for PAW ; \n\n\npspcod=8 : pseudopotential file format from Don Hamann, providing additional flexibility. \n\n\n\n\n\n\n6. The different output files\n\u00b6\n\n\nExplanation of the output from the code\n\n\nOutput from the code goes to several places listed below.\n\n\n6.1. The log file\n\u00b6\n\n\nThe \u201clog\u201d file (this is the standard UNIX output file, and corresponds to\nFortran unit number 06) : a file which echoes the values of the input\nparameters and describes various steps of the calculation, typically in much\nmore detail than is desired as a permanent record of the run. This log file is\nintended to be informative in case of an error or for a fuller description of\nthe run. For a successful run the user will generally delete the log file\nafterwards. There are four types of exception messages : \nERROR\n, \nBUG\n,\n\nWARNING\n and \nCOMMENT\n messages.\n\n\nERROR\n and \nBUG\n messages cause the code to stop, immediately, or after a very small delay. An \nERROR\n is attributed to the user, while a \nBUG\n is attributed to the developer. \n\n\nA \nWARNING\n message indicates that something happened that is not as\nexpected, but this something is not so important as to make the code stop. A\n\nCOMMENT\n message gives some information to the user, concerning something\nunusual. None of them should appear when the run is completely normal.\n\n\nAfter a run is completed, always have a look at the end of the log file, to\nsee whether an \nERROR\n or a \nBUG\n occurred.  \n\n\nAlso, the code gives the number of \nWARNING\n or \nCOMMENT\n it issued. It is\nadvised to read at least the \nWARNING\n messages, during the first month of\nABINIT use.\n\n\nIf you follow the tutorial, you should go back to the tutorial window now.\n\n\n6.2. The main output file \n\u00b6\n\n\nThe \nmain output file\n is a formatted output file to be kept as the\npermanent record of the run.\n\n\nNote that it is expected \nnot\n to exist at the beginning of the run:\n\nIf a file with the name specified in the \u201cfiles\u201d file already exists, the code\nwill generate, from the given one, another name, appended with \n.A\n . If\nthis new name already exists, it will try to append \n.B\n , and so on, until\n\n.Z\n .\n\nThen, the code stops, and asks you to clean the directory.\n\n\nThe \nmain output file\n starts with a heading:\n\n\n\n\nversion number and specified platform \n\n\ncopyright notice and distribution licence \n\n\ndate \n\n\necho of \u201cfiles\u201d file (except pseudopotential name) \n\n\n\n\nThen, for each dataset, it reports the point symmetry group and Bravais\nlattice, and the expected memory needs. It echoes the input data, and report\non checks of data consistency for each dataset.\n\n\nIf you follow the tutorial, you should go back to the tutorial window now.\n\n\n6.3. More on the main output file \n\u00b6\n\n\nThen, for each dataset, the real computation is done, and the code will report\non some initialisations, the SCF convergence, and the final analysis of\nresults for this dataset. Each of these phases is now described in more\ndetails.\n\n\nThe code reports:\n\n\n\n\nthe real and reciprocal space translation vectors (\nNote\n: the definition of the reciprocal vector is such that Ri.Gj= deltaij)\n\n\nthe volume of the unit cell\n\n\n\n\nthe ratio between linear dimension of the FFT box and the sphere of plane waves, called \u201c\nboxcut\n\u201d. \n\nIt must be above 2 for exact treatment of convolutions by FFT. \nngfft\n has\nbeen automatically chosen to give a boxcut value larger than 2, but not much\nlarger, since more CPU time is needed for larger FFT grids;\n\n\n\n\n\n\nthe code also mention that for the same FFT grid you might treat (slightly) larger \necut\n (so, with a rather small increase of CPU time) \n\n\n\n\nthe heading for each pseudopotential which has been input \n\n\nfrom the inwffil subroutine, a description of the wavefunction initialization (random number initialization or input from a disk file), that is, a report of the number of planewaves (npw) in the basis at each k point\n\n\nfrom the setup2 subroutine, the average number of planewaves over all k points is reported in two forms, arithmetic average and geometric average. \n\n\n\n\nUntil here, the output of a ground-state computation is identical to the one\nof a response-function calculation. See the \nhelp_respfn\n for the latter,\nespecially section \n6.2\n.\n\n\nNext the code reports information for each SCF iteration:\n\n\n\n\nthe iteration number \n\n\nthe (pseudo) total energy (Etot) in Hartree [This is not the total energy of the system, since the pseudopotential approximation has been made : a constant energy (in the frozen-core approximation) should be added to the present pseudo total energy in order to obtain a total energy, that includes the contributions from the core electrons. Since only differences of total energy matter (except is extremely rare cases), one can work with this pseudo energy like if it were the true total energy, except that the missing constant depends on the pseudopotential that has been used. Thus one has to perform differences of pseudo energies between simulations that use the same pseudopotentials]. \n\n\nthe change in Etot since last iteration (deltaE) \n\n\nthe maximum squared residual residm over all bands and k points (residm - the residual measures the quality of the wavefunction convergence) \n\n\nthe squared residual of the potential in the SCF procedure (vres2) \n\n\nthe maximum change in the gradients of Etot with respect to fractional coordinates (diffor, in Hartree) \n\n\n\n\nthe rms value of the gradients of Etot with respect to fractional coordinates (maxfor, in Hartree).\n\n\nThe latter two are directly related to forces on each atom.\n\n\n\n\n\n\nThen comes an assessment of the SCF convergence : the criterion for fulfillment of the SCF criterion (defined by \ntoldfe\n, \ntoldff\n, \ntolwfr\n or \ntolvrs\n) might be satisfied or not \u2026 \n\n\n\n\nThen the stresses are reported. \n\n\n\n\nThis ends the content of a fixed atomic position calculation.\n\n\nMany such blocks can follow.\n\n\nWhen the atomic positions have been eventually relaxed, according to the value\nof \nntime\n, the code output more information:\n\n\n\n\nThe squared residuals for each band are reported, k point by k point. \n\n\nThen the fractional or reduced coordinates are given, \n\n\nfollowed by the energy gradients, \n\n\nfollowed by the cartesian coordinates in Angstroms, \n\n\nfollowed by the cartesian forces in Hartree/Bohr and eV/Angstrom. \n\n\nAlso are given the rms force (\nfrms\n) and the maximum absolute value of any force component (\nmax\n). \n\n\nNext are the length scales of the unit cell in Bohr and in Angstroms. \n\n\nNext are the eigenvalues of each band for each k point, in eV or Hartree or both depending on the choice of \nenunit\n.   \n\n\n\n\nNOTE that the average electrostatic potential of a periodically repeated cell is UNDEFINED.\n\nIn the present implementation, the average Hartree potential and local\npotential are imposed to be zero, but not the average exchange-correlation\npotential. This definition gives some meaning to the absolute values of\neigenenergies, thanks to Janak\u2019s theorem: they are derivatives of the total\nenergy with respect to occupation number. Indeed, the G=0 contributions of the\nHartree, local potential and ion-ion to the total energy is independent of the\noccupation number in the present implementation. With this noticeable\nexception, one should always work with \ndifferences\n in eigenenergies, as\nwell as \ndifferences\n between eigenenergies and the potential. For example,\nthe absolute eigenenergies of a bulk cell should not be used to try to predict\na work function. The latter quantity should be obtained in a supercell\ngeometry, by comparing the Fermi energy in a slab and the potential in the\nvacuum in the same supercell.\n\n\n\n\nNext are the minimum and maximum values for charge density, and next smaller or larger values (in order to see degeneracies). \n\n\nNext are the total energy (Ha and eV) and its components: \n\n\nkinetic, \n\n\nHartree, \n\n\nexchange and correlation (xc), \n\n\nEwald (ion-ion energy), \n\n\n\u201c\ncore correction\n\u201d to the local pseudopotential, \n\n\nlocal pseudopotential, and \n\n\nnonlocal pseudopotential.  The sum of the Kohn-Sham energies (termed \u201cband energy\u201d) is also given. \n\n\n\n\n\n\nNext is the stress tensor, \n\n(1/ucvol) d(Etot)/d(strain(a,b))\n\nfor Etot=total energy per unit cell and\n\n\na\n,\nb\n are \nx\n, \ny\n, or \nz\n components of strain. \n\nThe stress tensor is given in cartesian coordinates in Hartree/Bohr3 and GPa.\n\nThe basics of the stress tensor are described in O. H. Nielsen and Richard M.\nMartin, see the\n\nbibliography\n file.\n\n\n\n\nHaving finished all the calculations for the different datasets, the code\nechoes the parameters listed in the input file, using the latest values e.g.\nfor \nxred\n, \nvel\n, and \nxcart\n, and supplement them with the values\nobtained for the total energy, the forces and stresses, as well as occupation\nnumbers.\n\nThe latter echoes are very convenient for a quick look at the result of\ncalculation !\n\n\nThis is followed finally by the timing output: both \u201ccpu\u201d time and \u201cwall\nclock\u201d time as provided by calls within the code.\n\nThe total cpu and wall clock times are reported first, in seconds, minutes,\nand hours for convenient checking at a glance.\n\nNext are the cpu and wall times for the principal time-consuming subroutine\ncalls, each of which is independent of the others. The sum of these times\nusually accounts for about 90% of the run time.\n\nThe main subroutines, for BIG jobs, are\n\n\n\n\n(1) fourwf: the subroutine which performs the fast Fourier transform for the wavefunctions: \n\n\n(2) fourdp: the subroutine which performs the fast Fourier transform related to density and potential \n\n\n(3) rhohxc: computes the Hartree and exchange-correlation energy and potential and sometimes derivative of potential; only the XC timing is reported, excluding time connected to the FFTs : \nxc:pot/=fourdp.\n\n\n(4) nonlop: computes \n< G | Vnon-local | C >\n\n\n\n\n\n\n\n\n\nthe matrix elements of the nonlocal pseudopotential;\n\n\n\n\n(5) projbd: Gram-Schmidt orthogonalisation \n\n\n\n\nIn case of small jobs, other (initialisation) routines may take a larger\nshare, and the sum of the times for the principal time-consuming subroutine\ncalls will not make 90% of the run time..\n\n\nIf the long printing option has been selected (\nprtvol\n=1), the code gives\nmuch more information in the whole output file. These should be rather self-\nexplanatory, usually. Some need more explanation.\n\nIn particular the cpu and wall times for major subroutines which are NOT\nindependent of each other; for example vtorho conducts the loop over k points\nand calls practically everything else. In case of a ground state calculation,\nat fixed atomic positions, these subroutines are\n\n\n\n\n(1) \nabinit\n: the main routine \n\n\n(2) \ndriver\n : select ground state or response calculations \n\n\n(3) \ngstate\n : the driver of the ground state calculations \n\n\n(4) \nscfcv\n : the SCF cycle driver \n\n\n(5) \nvtorho\n : compute the density from the potential (it includes a loop over spins and k-points) \n\n\n(6) \nvtowfk\n : compute the wavefunctions at one particular k-point (includes a non self consistent loop, and a loop over bands) \n\n\n(7) \ncgwf\n : optimize one wavefunction in a fixed potential \n\n\n(8) \ngetghc\n: computes < G | H | C >, that is, applies the Hamiltonian operator to an input vector. \n\n\n\n\nIf you follow the tutorial, you should go back to the tutorial window now.\n\n\n6.4. The header\n\u00b6\n\n\nThe \nwavefunction files\n, \ndensity files\n, and \npotential files\n all\nbegin with the same records, called the \u201cheader\u201d.\n\nThis header is treated using a hdr_type datastructure inside ABINIT. There are\ndedicated routines inside ABINIT for initializing a header, updating it,\nreading the header of an unformatted disk file, writing a header to an\nunformatted disk file, echoing a header to a formatted disk file, cleaning a\nheader datastructure.\n\n\nThe header is made of 4+\nntypat\n unformatted records, obtained by the\nfollowing Fortran90 instructions (format 5.7):\n\n\n \nwrite\n(\nunit\n=\nheader\n)\n \ncodvsn\n,\nheadform\n,\nfform\n\n \nwrite\n(\nunit\n=\nheader\n)\n \nbantot\n,\ndate\n,\nintxc\n,\nixc\n,\nnatom\n,\nngfft\n(\n1\n:\n3\n),&\n\n    \nnkpt\n,\nnspden\n,\nnspinor\n,\nnsppol\n,\nnsym\n,\nnpsp\n,\nntypat\n,\noccopt\n,\npertcase\n,\nusepaw\n,&\n\n    \necut\n,\necutdg\n,\necutsm\n,\necut_eff\n,\nqptn\n(\n1\n:\n3\n),\nrprimd\n(\n1\n:\n3\n,\n1\n:\n3\n),\nstmbias\n,\ntphysel\n,\ntsmear\n,\nusewvl\n\n\n \nwrite\n(\nunit\n=\nheader\n)\n \nistwfk\n(\n1\n:\nnkpt\n),\nnband\n(\n1\n:\nnkpt\n*\nnsppol\n),&\n\n    \nnpwarr\n(\n1\n:\nnkpt\n),\nso_psp\n(\n1\n:\nnpsp\n),\nsymafm\n(\n1\n:\nnsym\n),\nsymrel\n(\n1\n:\n3\n,\n1\n:\n3\n,\n1\n:\nnsym\n),\ntypat\n(\n1\n:\nnatom\n),&\n\n    \nkpt\n(\n1\n:\n3\n,\n1\n:\nnkpt\n),\nocc\n(\n1\n:\nbantot\n),\ntnons\n(\n1\n:\n3\n,\n1\n:\nnsym\n),\nznucltypat\n(\n1\n:\nntypat\n),\nwtk\n(\n1\n:\nnkpt\n)\n\n \ndo \nipsp\n=\n1\n,\nnpsp\n\n\n! (npsp lines, 1 for each pseudopotential ; npsp=ntypat, except if alchemical pseudo-atoms)\n\n  \nwrite\n(\nunit\n=\nunit\n)\n \ntitle\n,\nznuclpsp\n,\nzionpsp\n,\npspso\n,\npspdat\n,\npspcod\n,\npspxc\n,\nlmn_size\n\n \nenddo\n\n\n!(in case of usepaw==0, final record: residm, coordinates, total energy, Fermi energy)\n\n \nwrite\n(\nunit\n=\nunit\n)\n \nresidm\n,\nxred\n(\n1\n:\n3\n,\n1\n:\nnatom\n),\netotal\n,\nfermie\n\n\n!(in case of usepaw==1, there are some additional records)\n\n \nif\n \n(\nusepaw\n==\n1\n)\nthen\n\n\n  write\n(\nunit\n=\nunit\n)(\n \npawrhoij\n(\niatom\n)%\nnrhoijsel\n(\n1\n:\nnspden\n),\niatom\n=\n1\n,\nnatom\n),\n \ncplex\n,\n \nnspden\n\n  \nwrite\n(\nunit\n=\nunit\n)((\npawrhoij\n(\niatom\n)%\nrhoijselect\n(\n1\n:\n      \nnrhoijsel\n(\nispden\n),\nispden\n),\nispden\n=\n1\n,\nnspden\n),\niatom\n=\n1\n,\nnatom\n),&\n\n                  \n((\npawrhoij\n(\niatom\n)%\nrhoijp\n     \n(\n1\n:\ncplex\n*\nnrhoijsel\n(\nispden\n),\nispden\n),\nispden\n=\n1\n,\nnspden\n),\niatom\n=\n1\n,\nnatom\n)\n\n \nendif\n\n\n\n\n\n\nwhere the type of the different variables is :\n\n\ncharacter\n*\n6\n \n::\n \ncodvsn\n\n\ninteger\n \n::\n \nheadform\n,\nfform\n\n\ninteger\n \n::\n \nbantot\n,\ndate\n,\nintxc\n,\nixc\n,\nnatom\n,\nngfft\n(\n3\n),\nnkpt\n,\nnpsp\n,\n\n\nnspden\n,\nnspinor\n,\nnsppol\n,\nnsym\n,\nntypat\n,\noccopt\n,\npertcase\n,\nusepaw\n\n\ninteger\n \n::\n \nusewvl\n,\n \ncplex\n,\n \nnspden\n\n\ndouble precision\n \n::\n \nacell\n(\n3\n),\necut\n,\necutdg\n,\necutsm\n,\necut_eff\n,\nqptn\n(\n3\n),\nrprimd\n(\n3\n,\n3\n),\nstmbias\n,\ntphysel\n,\ntsmear\n\n\ninteger\n \n::\n \nistwfk\n(\nnkpt\n),\nnband\n(\nnkpt\n*\nnsppol\n),\nnpwarr\n(\nnkpt\n),\nso_psp\n(\nnpsp\n),&\n\n\n&\n \nsymafm\n(\nnsym\n),\nsymrel\n(\n3\n,\n3\n,\nnsym\n),\ntypat\n(\nnatom\n),\nnrhoijsel\n(\nnspden\n),\nrhoijselect\n(\n*\n,\nnspden\n)\n\n\ndouble precision\n \n::\n \nkpt\n(\n3\n,\nnkpt\n),\nocc\n(\nbantot\n),\ntnons\n(\n3\n,\nnsym\n),\nznucltypat\n(\nntypat\n),\nwtk\n(\nnkpt\n)\n\n\ncharacter\n*\n132\n \n::\n \ntitle\n\n\ndouble precision\n \n::\n \nznuclpsp\n,\nzionpsp\n\n\ninteger\n \n::\n \npspso\n,\npspdat\n,\npspcod\n,\npspxc\n,\nlmax\n,\nlloc\n,\nmmax\n=\nintegers\n\n\ndouble precision\n \n::\n \nresidm\n,\nxred\n(\n3\n,\nnatom\n),\netotal\n,\nfermie\n,\nrhoij\n(\n*\n,\nnspden\n)\n\n\n\n\n\n\nNOTE : \netotal is set to its true value only for density and potential files.\nFor other files, it is set to 1.0d20\n\nNOTE : \necut_eff=\n\necut\n*\n\ndilatmx\n2\n\nNOTE : \nFor all cases where occupation numbers are defined (that is, positive\niscf, and iscf=-3), and for non-metallic occupation numbers, the Fermi energy\nis set to the highest occupied eigenenergy. This might not correspond to the\nexpected Fermi energy for a later non-self-consistent calculation (e.g. the\nband structure)\n\n\nThe header might differ for different versions of ABINIT. One pre-v5.3 format\nis described below. Note however, that the current version of ABINIT should be\nable to read all the previous formats (not to write them), with the exception\nof wavefunction files for which the\n\necutsm\n value was\nnon-zero (there has been a change of definition of the smearing function in\nv4.4).\n\n\nThe format for version 4.4, 4.5, 4.6, 5.0, 5.1 and 5.2 was :\n\n\n \nwrite\n(\nunit\n=\nheader\n)\n \ncodvsn\n,\nheadform\n,\nfform\n\n \nwrite\n(\nunit\n=\nheader\n)\n \nbantot\n,\ndate\n,\nintxc\n,\nixc\n,\nnatom\n,\nngfft\n(\n1\n:\n3\n),&\n\n\n&\n \nnkpt\n,\nnspden\n,\nnspinor\n,\nnsppol\n,\nnsym\n,\nnpsp\n,\nntypat\n,\noccopt\n,\npertcase\n,\nusepaw\n,&\n\n\n&\n \necut\n,\necutdg\n,\necutsm\n,\necut_eff\n,\nqptn\n(\n1\n:\n3\n),\nrprimd\n(\n1\n:\n3\n,\n1\n:\n3\n),\nstmbias\n,\ntphysel\n,\ntsmear\n\n \nwrite\n(\nunit\n=\nheader\n)\n \nistwfk\n(\n1\n:\nnkpt\n),\nnband\n(\n1\n:\nnkpt\n*\nnsppol\n),&\n\n\n&\n \nnpwarr\n(\n1\n:\nnkpt\n),\nso_typat\n(\n1\n:\nntypat\n),\nsymafm\n(\n1\n:\nnsym\n),\nsymrel\n(\n1\n:\n3\n,\n1\n:\n3\n,\n1\n:\nnsym\n),\ntypat\n(\n1\n:\nnatom\n),&\n\n\n&\n \nkpt\n(\n1\n:\n3\n,\n1\n:\nnkpt\n),\nocc\n(\n1\n:\nbantot\n),\ntnons\n(\n1\n:\n3\n,\n1\n:\nnsym\n),\nznucltypat\n(\n1\n:\nntypat\n)\n\n \ndo \nipsp\n=\n1\n,\nnpsp\n\n\n! (npsp lines, 1 for each pseudopotential ; npsp=ntypat, except if alchemical pseudo-atoms)\n\n  \nwrite\n(\nunit\n=\nunit\n)\n \ntitle\n,\nznuclpsp\n,\nzionpsp\n,\npspso\n,\npspdat\n,\npspcod\n,\npspxc\n,\nlmn_size\n\n \nenddo\n\n\n!(in case of usepaw==0, final record: residm, coordinates, total energy, Fermi energy)\n\n \nwrite\n(\nunit\n=\nunit\n)\n \nresidm\n,\nxred\n(\n1\n:\n3\n,\n1\n:\nnatom\n),\netotal\n,\nfermie\n\n\n!(in case of usepaw==1, there are some additional records)\n\n \nif\n \n(\nusepaw\n==\n1\n)\nthen\n\n\n  write\n(\nunit\n=\nunit\n)(\npawrhoij\n(\niatom\n)%\nnrhoijsel\n(\n1\n:\nnspden\n),\niatom\n=\n1\n,\nnatom\n)\n\n  \nwrite\n(\nunit\n=\nunit\n)((\npawrhoij\n(\niatom\n)%\nrhoijselect\n(\n1\n:\nnrhoijsel\n(\nispden\n),\nispden\n),\nispden\n=\n1\n,\nnspden\n),\niatom\n=\n1\n,\nnatom\n),&\n\n\n&\n                 \n((\npawrhoij\n(\niatom\n)%\nrhoijp\n     \n(\n1\n:\nnrhoijsel\n(\nispden\n),\nispden\n),\nispden\n=\n1\n,\nnspden\n),\niatom\n=\n1\n,\nnatom\n)\n\n \nendif\n\n\n\n\n\n\n6.5. The density output file\n\u00b6\n\n\nThis is an unformatted data file containing the electron density on the real\nspace FFT grid. It consists of the header records followed by\n\n\ndo \nispden\n=\n1\n,\nnspden\n\n \nwrite\n(\nunit\n)\n \n(\nrhor\n(\nir\n),\nir\n=\n1\n,\ncplex\n*\nngfft\n(\n1\n)\n*\nngfft\n(\n2\n)\n*\nngfft\n(\n3\n))\n\n\nenddo\n\n\n\n\n\n\nwhere \nrhor\n is the electron density in electrons/Bohr^3, and cplex is the\nnumber of complex components of the density (cplex=1 for GS calculations -the\ndensity is real-, and cplex=1 or 2 for RF). The input variable \nnspden\n\ndescribes the number of components of the density. The first component (the\nonly one present when \nnspden\n=1) is always the total charge density. When\n\nnspden\n=2, the second component is the density associated with spin-up\nelectrons. When \nnspden\n=4, the second, third and fourth components\ncorrespond to the x, y and z projections of the local magnetization, in units\nof hbar/2 . Note that the meaning of the different components of the density\ndiffers for the density array (rhor) and for the different potential arrays\n(vxc \u2026), see section  6.6 .\n\n\nTo identify the points in real space which correspond with the index \u201cir\u201d\nabove, consider the following.\n\nThe first array value (ir=1) corresponds with the first grid point which is at\nthe origin of the unit cell, (x=0, y=0, z=0).\n\nThe next grid point (ir=2) lies along the first primitive translation at the\nnext fft grid point, which is (1/\n[ngfft]\n)\n[acell]\n[rprim]\n.\nThis is 1/\n[ngfft]\n of the way along the first primitive translation.\n\nThe rest of the values up to ir=\n[ngfft]\n lie along this vector, at\n(ir-1)/\n[ngfft]\n of the way along the first primitive translation. The\npoint at ir=\n[ngfft]\n+1 lies at 1/\n[ngfft]\n along the second primitive\ntranslation.\n\nThe next points up to ir=\n[ngfft]\n+\n[ngfft]\n are displaced in the\ndirection of the second primitive translation by 1/\n[ngfft]\n and in the\nfirst translation by (ir-\n[ngfft]\n-1)/\n[ngfft]\n.\n\nThis pattern continues until ir=\n[ngfft]\n[ngfft]\n.\n\nThe next point after that is displaced along the third primitive translation\nby 1/ngfft(3), and so forth until ir varies all the way from 1 to\n\n[ngfft]\n[ngfft]\n*\n[ngfft]\n. This last point is in the corner\ndiagonally opposite from the origin, or right alongside the origin if the\nwhole grid is viewed as being periodically repeated.\n\n\n 6.6. The potential files \n\u00b6\n\n\nAlso unformatted files consisting of the header records and\n\n\ndo \nispden\n=\n1\n,\nnspden\n\n \nwrite\n(\nunit\n)\n \n(\npotential\n(\nir\n),\nir\n=\n1\n,\ncplex\n*\nngfft\n(\n1\n)\n*\nngfft\n(\n2\n)\n*\nngfft\n(\n3\n))\n\n\nenddo\n\n\n\n\n\n\nwhere \npotential\n can be either the sum of the Hartree potential, exchange-\ncorrelation and local pseudopotential (see \nprtpot\n), the Hartree potential\n(see \nprtvha\n), the Hartree+XC potential (see \nprtvhxc\n), the local\npseudopotential (see \nprtvpsp\n) or the XC potential (see \nprtvxc\n), These\nare defined on the real space grid in Hartree energy units. The underlying\ngrid is as described above. If \nnspden\n=2, the different components are the\nspin-up potential and the spin-down potential. In the case \nnspden\n=4, the\ncomponents correspond to the up-up potential, the down-down potential, the\nreal part of the up-down potential, and the imaginary part of the up-down\npotential. Note that the Hartree potential is NOT spin-dependent, but in order\nto use the same format as for the other potential files, the spin-independent\narray is written twice, once for spin-up and one for spin-down.\n\n\n6.7. The wavefunction output file \n\u00b6\n\n\nThis is an unformatted data file containing the planewaves coefficients of all\nthe wavefunctions, and different supplementary data.\n\n\nThe \nground-state\n wf file consists of the header records, and data written\nwith the following lines of FORTRAN (version 4.0 and more recent versions):\n\n\nbantot\n=\n0\n                                    \n<--\n \ncounts\n \nover\n \nall \nbands\n\n\nindex\n=\n0\n                                     \n<--\n \nindex \nfor\n \nthe\n \nwavefunction\n \nlocation\n\n\ndo \nisppol\n=\n1\n,\nnsppol\n\n \ndo \nikpt\n=\n1\n,\nnkpt\n\n  \nwrite\n(\nunit\n)\n \nnpw\n,\nnspinor\n,\nnband\n                    \n<--\n \nfor\n \neach\n \nk\n \npoint\n\n  \nwrite\n(\nunit\n)\n \nkg\n(\n1\n:\n3\n,\n1\n:\nnpw\n)\n                        \n<--\n \nplane\n \nwave\n \nreduced\n \ncoordinates\n\n  \nwrite\n(\nunit\n)\n \neigen\n(\n1\n+\nbantot\n:\nnband\n+\nbantot\n),\n        \n<--\n \neigenvalues\n \nfor\n \nthis\n \nk\n \npoint\n\n              \nocc\n(\n1\n+\nbantot\n:\nnband\n+\nbantot\n)\n           \n<--\n \noccupation\n \nnumbers\n \nfor\n \nthis\n \nk\n \npoint\n\n  \ndo \niband\n=\n1\n,\nnband\n\n   \nwrite\n(\nunit\n)\n \n(\ncg\n(\nii\n+\nindex\n),\nii\n=\n1\n,\n2\n*\nnpw\n*\nnspinor\n)\n   \n<--\n \nwavefunction\n \ncoefficients\n\n  \nenddo\n                                            \nfor\n \na\n \nsingle\n \nband\n \nand \nk\n \npoint\n\n  \nbantot\n=\nbantot\n+\nnband\n\n  \nindex\n=\nindex\n+\n2\n*\nnpw\n*\nnspinor\n*\nnband\n\n \nenddo\n\n\nenddo\n\n\n\n\n\n\nIf the job ended without problem, a few supplementary lines are added, in\norder to give the history of atomic positions and corresponding forces. The\ninteger nxfh gives the number of pairs (x,f) of positions and forces in\nreduced coordinates :\n\n\n \nwrite\n(\nunit\n)\nnxfh\n\n \ndo \nixfh\n=\n1\n,\nnxfh\n\n  \nwrite\n(\nunit\n)\n \nxred\n(\n1\n:\n3\n,\n1\n:\nnatom\n,\nixfh\n),\ndummy\n(\n1\n:\n3\n,\n1\n:\n4\n),&\n\n\n&\n             \nfred\n(\n1\n:\n3\n,\n1\n:\nnatom\n,\nixfh\n),\ndummy\n(\n1\n:\n3\n,\n1\n:\n4\n)\n\n \nenddo\n\n\n\n\n\n\nThe dummy variables might contain, in the future, the description of the unit\ncell, and the stresses. The type of the different variables is :\n\n\ninteger\n \n::\n \nkg\n,\nnband\n,\nnpw\n,\nnspinor\n,\nnxfh\n\n\ndouble precision\n \n::\n \ncg\n,\ndummy\n,\neigen\n,\nfred\n,\nocc\n,\nxred\n\n\n\n\n\n\nThe \nresponse-function\n wf file consists of the header records, and data\nwritten with the following lines of FORTRAN (version 4.0 and more recent\nversions):\n\n\nbantot\n=\n0\n                                    \n<--\n \ncounts\n \nover\n \nall \nbands\n\n\ndo \nisppol\n=\n1\n,\nnsppol\n\n \ndo \nikpt\n=\n1\n,\nnkpt\n\n  \nwrite\n(\nunit\n)\n \nnpw\n,\nnspinor\n,\nnband\n                    \n<--\n \nfor\n \neach\n \nk\n \npoint\n\n  \nwrite\n(\nunit\n)\n \nkg\n(\n1\n:\n3\n,\n1\n:\nnpw\n)\n                        \n<--\n \nplane\n \nwave\n \nreduced\n \ncoordinates\n\n  \ndo \niband\n=\n1\n,\nnband\n\n   \nwrite\n(\nunit\n)\n \n(\neigen\n(\njband\n+\n(\niband\n-\n1\n)\n*\nnband\n+\nbantot\n),\njband\n=\n1\n,\n2\n*\nnband\n)\n  \n<--\n \ncolumn\n \nof\n \neigenvalue\n \nmatrix\n\n   \nwrite\n(\nunit\n)\n \n(\ncg\n(\nii\n+\nindex\n),\nii\n=\n1\n,\n2\n*\nnpw\n*\nnspinor\n)\n     \n<--\n \nwavefunction\n \ncoefficients\n\n  \nenddo\n                                            \nfor\n \na\n \nsingle\n \nband\n \nand \nk\n \npoint\n\n  \nbantot\n=\nbantot\n+\nnband\n\n \nenddo\n\n\nenddo\n\n\n\n\n\n\nIn version previous to 4.0 , npw and nspinor were combined :\n\n\nwrite\n(\nunit\n)\n \nnpw\n*\nnspinor\n,\nnband\n\n\n\n\n\n\nwhile the planewave coordinate record was not present (in both GS and RF\ncases).\n\n\nNote that there is an alternative format (_KSS) for the output of the\nwavefunction coefficients, activated by a non-zero value of \nnbandkss\n.\n\n\n6.8. Other output files.\n\u00b6\n\n\nThere are many other output files, optionally written, all formatted files at\npresent. Their use is usually governed by a specific input variable. Please\nconsult the description of this input variable, in order to have more\ninformation on such files :\n\n\n\n\nprtdos\n to print a file with the electronic Density-Of-States\n\n\nprteig\n to print a file with the list of k points and eigenenergies\n\n\nprtgeo\n to print a file with a geometrical analysis (bond lengths and bond angles), that also contains an XMOL section\n\n\nprt1dm\n to print a one-dimensional projection of potential and density, for the three axes.\n\n\n\n\n_If you follow the tutorial, you should go back to the tutorial window now. _\n\n\n6.9. Control of output in the parallel case.\n\u00b6\n\n\nFor massively parallel runs, one cannot afford to have some of the output\nfiles that are usually created. Explicitly, the log file and also the status\nfile become problematic. By default, with less than N processors, they are\ncreated, but beyond N processors, they are deactivated except for the main log\nfile (master processor).\n\n\nThis default behaviour can be changed as follows. If a file named \u201c_NOLOG\u201d\nexists in the current directory, then no log file and no status file will be\ncreated, even with less than N processors. By contrast, if a file \u201c_LOG\u201d\nexists in the current directory, then a log file and the status files will be\ncreated, even with more than N processors. Alternatively, if a file named\n\u201c_MAINLOG\u201d exists and there are less than N processors, only the master\nprocessor writes the log and status files (this mimic the default behavior\nwhen using more than N processors but with less than N processors)\n\n\nIn ABINITv7, N was set at N=100. However, with ABINITv8, N has been switched\nto 2. It can be changed \u201cby hand\u201d, though : modify NPROC_NO_EXTRA_LOG in\nsrc/10_defs/defs_basis.F90 and recompile. See src/95_drive/iofn1.F90 for more\nexplanation.\n\n\n\n\n7. Numerical quality of the calculations\n\u00b6\n\n\nThe following section describes various parameters which affect convergence\nand the numerical quality of calculations.\n\n\nThe list of these input parameters is\n\n\n\n\n(1) \necut\n \n\n\n(2) \ntoldfe\n, \ntoldff\n, \ntolwfr\n, and \ntolvrs\n, as well as \nnstep\n \n\n\n(3) \nnkpt\n \n\n\n(4) \nngfft\n \n\n\n(5) \ntolmxf\n, as well as \namu\n, \ndtion\n, \nvis\n, \nntime\n \n\n\n(6) \nacell\n and \nrprim\n \n\n\n\n\nThe technical design of the pseudopotential also affects the quality of the\nresults.\n\n\n(1) The first issue regarding convergence is the number of planewaves in the\nbasis for a given set of atoms. Some atoms (notably those in the first row or\nfirst transition series row) have relatively deep pseudopotentials which\nrequire many planewaves for convergence. In contrast are atoms like Si for\nwhich fewer planewaves are needed. A typical value of \necut\n for silicon\nmight be 5-10 Hartree for quite good convergence, while the value for oxygen\nmight be 25-35 Hartree or more depending on the convergence desired and the\ndesign of the pseudo- potential.\n\n\nNOTE: It is necessary in every new problem to \nTEST\n the convergence by\n\nRAISING\n \necut\n for a given calculation until the results being computed\nare constant to within some tolerance. This is up to the user and is very\nimportant. For a given \nacell\n and \nrprim\n, \necut\n is the parameter\nwhich controls the number of planewaves. Of course if \nrprim\n or \nacell\n\nis varied then the number of planewaves will also change.\n\n\nLet us reiterate that extremely careful pseudopotential design can optimize\nthe convergence of \ne.g.\n the total energy within some range of planewave\nnumber or \necut\n. It is appropriate to attempt to optimize this convergence,\nespecially for difficult atoms like oxygen or copper, as long as one does not\nsignificantly compromise the quality or transferability of the\npseudopotential. There are many people working on new techniques for\noptimizing convergence.\n\n\nFor information on extended norm conservation, see E. L. Shirley, D. C. Allan,\nR. M. Martin, and J. D. Joannopoulos, Phys. Rev. B 40, 3652 (1989).\n\n\nFor information on optimizing the convergence of pseudopotentials, see A. M.\nRappe, K. M. Rabe, E. Kaxiras, and J. D. Joannopoulos, Phys. Rev. B 41, 1227\n(1990).\n\n\n(2) In addition to achieving convergence in the number of planewaves in the\nbasis, one must ensure that the SCF iterations which solve the electronic\nstructure for a given set of atomic coordinates are also converged. This\nconvergence is controlled by the parameters \ntoldfe\n, \ntoldff\n,\n\ntolwfr\n, and \ntolvrs\n, as well as the parameter \nnstep\n. One of the\n\u201ctolerance\u201d parameters must be chosen, and, when the required level of\ntolerance is fulfilled, the SCF cycles will stop. The \nnstep\n variable also\ncontrols convergence in preconditioned conjugate gradient iterations by\nforcing the calculation to stop whenever the number of such iterations exceeds\nnstep. Usually one wants nstep to be set larger than needed to reach a given\ntolerance, or else one wants to restart insufficiently converged calculations\nuntil the required tolerance is reached.\n\n\nNote that, if the gap in the system closes (e.g. due to defect formation or if\nthe system is metallic in the first place), the presently coded algorithm will\nbe slower to converge than for insulating materials. Convergence trouble\nduring iterations usually signals closure of the gap. The code will suggest to\ntreat at least one unoccupied state (or band) in order to be able to monitor\nsuch a closure.\n\n\n(3) For self consistent calculations (\niscf\n positive) it is important to\ntest the adequacy of the k point integration. If symmetry is used then one\nusually tests a set of \u201cspecial point\u201d grids. Otherwise one tests the addition\nof more and more k points, presumably on uniform grids, to ensure that a\nsufficient number has been included for good k point integration. The\nparameter nkpt indicates how many k points are being used, and their\ncoordinates are given by kpt and kptnrm, described above. The weight given to\neach k point is provided by input variable \nwtk\n. Systematic tests of k\npoint integration are much more difficult than tests of the adequacy of the\nnumber of planewaves. The difficulty I refer to is simply the lack of a very\nsystematic method for generating k point grids for tests.\n\n\n(4) It is possible to run calculations for which the fft box is not quite\nlarge enough to avoid aliasing error in fft convolutions. An aliasing error,\nor a Fourier filter approximation, is occurring when the output variable\n\u201c\nboxcut\n\u201d is less than 2. boxcut is the smallest ratio of the fft box side\nto the planewave basis sphere diameter. If this ratio is 2 or larger then e.g.\nthe calculation of the Hartree potential from the charge density is done\nwithout approximation.\n\nNOTE : the values of \n[ngfft]\n are chosen automatically by the code to\ngive boxcut > 2, if \nngfft\n has not been set by hand. At ratios smaller than\n2, certain of the highest Fourier components are corrupted in the convolution.\nIf the basis is nearly complete, this Fourier filter can be an excellent\napproximation. In this case values of boxcut can be as small as about 1.5\nwithout incurring significant error. For a given \necut\n, \nacell\n, and\n\nrprim\n, one should run tests for which \nngfft\n is large enough to give\nboxcut >= 2, and then one may try smaller values of \nngfft\n if the results\nare not significantly altered. See the descriptions of these variables above.\n\n\n(5) If you are running calculations to relax or equilibrate structures, i.e.\nwith \nionmov\n=1 and possibly \nvis\n>0, then the quality of your molecular\ndynamics or relaxation will be affected by the parameters \namu\n, \ndtion\n,\n\nvis\n, \nntime\n, \ntolmxf\n. Clearly if you want a relaxed structure you\nmust either run long enough or make repeated runs until the largest force in\nthe problem (output as fmax) is smaller than what you will tolerate (see\n\ntolmxf\n).\n\nIf \ndtion\n is too large for the given values of masses (\namu\n) and\nviscosity (\nvis\n) then the molecular dynamics will be unstable. If \ndtion\n\nis too small, then the molecular dynamics will move inefficiently slowly. A\nconsensus exists in the community that forces larger than about 0.1\neV/Angstrom are really too large to consider the relaxation to be converged.\nIt is best for the user to get experience with this in his/her own\napplication.\n\nThe option \nionmov\n=2, 3 or 7 are also available This uses the Broyden\n(BFGS) scheme for structural optimization and is much more efficient than\nviscous damping for structural relaxation.\n\n\n(6) If you are running supercell calculations (i.e. an isolated atom or\nmolecule in a big box, or a defect in a solid, or a slab calculation) you must\ncheck the convergence of your calculation with respect to the supercell and\nsystem size.\n\n\n\n\nFor an isolated molecule in a big box : increase concurrently the three dimensions of your supercell (\nacell\n), and check the convergence of your physical property. \n\n\nFor a defect in a solid : your supercell must be a multiple of the primitive cell of the bulk solid, so you have less freedom. Still, be sure that your supercell is large enough for your properties of interest to be accurate at the level you want it to be. \n\n\nFor a slab calculation : you must increase the vacuum in the cell, but also the thickness of your slab systematically\u2026 \n\n\n\n\n_If you follow the tutorial, you should go back to the tutorial window now. _\n\n\n\n\n8. Final remarks\n\u00b6\n\n\nThe ABINIT package is developed by the ABINIT group. The status of this\npackage and the ABINIT group are explained in the file\n~abinit/doc/users/context.txt and ~abinit/doc/developers/planning.txt , or\nsome recent version of them.",
            "title": "Abinit"
        },
        {
            "location": "/user-guide/help_abinit/#1-how-to-run-the-code",
            "text": "",
            "title": "1. How to run the code"
        },
        {
            "location": "/user-guide/help_abinit/#11-introducing-the-files-file",
            "text": "Given an input file (parameters described below) and the required\npseudopotential files, the user must create a \u201cfiles\u201d file which lists names\nfor the files the job will require, including the main input file, the main\noutput file, root names for other input, output, or temporary files, and\ndifferent pseudopotential file names.  The files file (called for example ab.files) could look like:      ab_in\n    ab_out\n    abi\n    abo\n    tmp\n    14si.psp  In this example:    - The main input file is called \u201cab_in\u201d. \n- The main output will be put into the file called \u201cab_out\u201d. \n- The name of input wavefunctions (if any) will be built from the root \u201cabi\u201d\n(namely abi_WFK, see later). \n- The output wavefunctions will be written to abo_WFK. Other output files\nmight be build from this root. \n- The temporary files will have a name that use the root \u201ctmp\u201d. (for example\ntmp_STATUS). \n- The pseudopotential needed for this job is \u201c14si.psp\u201d.    Other examples are given in the subdirectories of the ~abinit/tests directory.\nThe maximal length of names for the main input or output files is presently\n132 characters. It is 112 characters for the root strings, since they will be\nsupplemented by different character strings.  If you follow the tutorial, you should go back to the tutorial window now.",
            "title": "1.1 Introducing the files file."
        },
        {
            "location": "/user-guide/help_abinit/#12-running-the-code",
            "text": "The main executable file is called abinit. Supposing that the \u201cfiles\u201d file is\ncalled ab.files, and that the executable is placed in your working directory,\nabinit is run interactively (in Unix) with the command      $ abinit < ab.files > &  log  or, in the background, with the command      $ abinit < ab.files > &  log  &   where standard out and standard error are piped to the log file called \u201clog\u201d\n(piping the standard error, thanks to the \u2018&\u2019 sign placed after \u2018>\u2019 is really important  for the analysis of eventual failures, when not due to\nABINIT, but to other sources, like disk full problem \u2026). The user can\nspecify any names he/she wishes for any of these files. Variations of the\nabove commands could be needed, depending on the flavor of UNIX that is used\non the platform that is considered for running the code.    If you follow the tutorial, you should go back to the tutorial window now.",
            "title": "1.2. Running the code"
        },
        {
            "location": "/user-guide/help_abinit/#246-the-underlying-theoretical-framework-and-algorithms",
            "text": "See the \u201c bibliography \u201d\nfile.  The methods employed in this computer code to solve the electronic structure\nproblem are described in part in different review papers as well as research\npapers. The code is an implementation of the Local Density Approximation to\nthe Density Functional Theory, based upon a plane wave basis set and separable\npseudopotentials. The iterative minimization algorithm is a combination of\nfixed potential preconditioned conjugate gradient optimization of wavefunction\nand a choice of different algorithms for the update of the potential, one of\nwhich is a potential-based conjugate gradient algorithm.  The representation of potential, density and wavefunctions in real space will\nbe done on a regular 3D grid of points. Its spacing will be determined by the\ncut-off energy (see the input variable  ecut ) of the planewave basis in\nreciprocal space. This grid of points will also be the starting point of Fast\nFourier Transforms between real and reciprocal space. The number of such\npoints, called  ngfft , should be sufficiently large for adequate\nrepresentation of the functions, but not too large, for reasons of\ncomputational efficiency. The trade-off between accuracy and computational\nefficiency is present in many places of the code, and addressed briefly at the\nend of the present help file.  We recommend a good introduction to many different concepts valid for this\ncode, available in a Reviews of Modern Physics article, ``Iterative\nminimization techniques for ab initio total-energy calculations: molecular\ndynamics and conjugate gradients\u2019\u2018, M. C. Payne, M. P. Teter, D. C. Allan, T.\nA. Arias, and J. D. Joannopoulos, Rev. Mod. Phys. 64, 1045-1097 (1992). \nThis paper does NOT reflect the present status of the code. ABINIT is closer\nin spirit to the paper of of Kresse and Furthmuller, see the bibliography  list.  If you have never used another electronic structure code or a Quantum\nChemistry package, you should browse through the Chaps. 1 to 13 , and\nappendices L and M of the book Electronic Structure. Basic Theory and\nPractical Methods. R. M. Martin. Cambridge University Press (2004) ISBN 0 521\n78285 6.",
            "title": "2. The underlying theoretical framework and algorithms"
        },
        {
            "location": "/user-guide/help_abinit/#346-the-input-file",
            "text": "",
            "title": "3. The input file"
        },
        {
            "location": "/user-guide/help_abinit/#31-format-of-the-input-file",
            "text": "Note that this input file was called ab_in in the example of  section 1.1 . \nWe first explain the content of the input file without use of the \u201cmulti-\ndataset\u201d possibility (that will be explained in section 3.3).  The parameters are input to the code from a single input file. Each parameter\nvalue is provided by giving the name of the input variable and then placing\nthe numerical value(s) beside the name, separated by one or more spaces, or\neven an equal sign (equal signs are replaced by blanks by the parser).\nDepending on the input variable, the numerical value may be an integer or a\nreal number (internal representation as double precision number), and may\nactually represent an array of values. If it represents an array, the next set\nof numbers separated by spaces are taken as the values for the array.   Do NOT separate a minus sign from the number to which it applies.   Do NOT use tabs.   NOTE THAT NO LINE OF THE INPUT FILE MAY EXCEED 132 CHARACTERS. That is, only the first 132 characters of each line of the input file will be read and parsed for input variables and their values.    The names of all the parameters can be found in the  allvariables . The list\nof input variables present in the latter file links them to their definitions,\ncontained in different files, of which some are listed here:   Basic variables,  varbas  Files handling variables,  varfil  Ground-state calculation variables,  vargs  GW variables,  vargw  Parallelisation variables,  varpar  Response Function variables,  varrf   In the actual input file, these parameters may be given in any desired order,\nand more than one may be given per line. Spaces are used to separate values\nand additional spaces are ignored. \nAn as example of input, the parameter for length scales is called  acell \nand is an array  [acell]  for the lengths of the primitive translations in\nBohr atomic units. To input a typical Si diamond lattice one would have the\nline  acell 10.25311 10.25311 10.25311  in the input file. This may equivalently be written  acell 3*10.25311  and will still be parsed correctly : it is equivalent to the above line. Even  acell *10.25311  will work. In the latter case the \u2018*\u2019 sign means that the parser should use\nthe given value to fill the array, by repeating it as many time as needed. \nMultiple spaces are ignored, as is any text which does not contain the\ncharacter strings which correspond to some input parameters. In case of\narrays, only the needed numbers will be considered, and the eventual numbers\nafter those needed will also be ignored. For example,  [[natom]] 3 # This gives the number of atoms  \n[[typat]] 1 1 2 2 3 # typat(1:natom) gives the type of each atom : only  \n               # the first three data are read, since [[natom]]=3     A given variable is identified by the parser by having at least one blank\nbefore it and after it (again, multiple blanks are irrelevant). \nABINIT has also some (very limited) interpretor capabilities :   It can identify one slash sign (/) being placed between two numbers (without a separating blank) as being the definition of a fraction (e.g. 1/3 will be interpreted as 0.33333333333333d0) ;   It can identify sqrt(\u2026) or -sqrt(\u2026) as being the definition of a square root, when applied to one valid number - also without a separating blank - (e.g. -sqrt(0.75) will be interpreted as -0.8660254038d0) ;   Note, however, that these capabilities are NOT recursive. At most, a sqrt identifier can contain an expression that uses a fraction (e.g. sqrt(3/4) is OK), but two fractions (or two sqrt) cannot be used in one expression, and a sqrt cannot be present in the numerator or denominator of a fraction.    Comments should be placed to the right of the comment characters # or ! ;\nanything to the right of a \u201c#\u201d or a \u201c!\u201d on any line is simply ignored by the\nparser. Additional text, not preceded by a \u201c#\u201d or a \u201c!\u201d would not otherwise\ncause trouble unless the text inadvertently contained character strings which\nwere the same as variable names (e.g.  acell ). The characters \u201c#\u201d or \u201c!\u201d\ncan also be used to \u201cstore\u201d old values of variables or place anything else of\nconvenience into the file in such a way as to be ignored by the parser when\nthe data is read. \nCase is irrelevant as the entire input string is mapped to upper case before\nparsing, to remove case sensitivity. \nMore than one parameter per line may be given. If a given parameter name is\ngiven more than once in the input file, an error message is printed, and the\ncode stops.  _If you follow the tutorial, you should go back to the tutorial window now. _",
            "title": "3.1. Format of the input file."
        },
        {
            "location": "/user-guide/help_abinit/#32-more-about-abinit-input-variables",
            "text": "In each section of the ABINIT input variables files, a generic information on\nthe input variable is given : a mnemonics, some \u201ccharacteristics\u201d, the\nvariable type, and the default. Then, follows the description of the variable.  The  mnemonics  is indicated when available.  The \u201ccharacteristics\u201d can be of different types :  DEVELOP ,  RESPFN , NONLINEAR ,  GW ,  BETHE_SALPETER ,  TDDFT ,  GEOMETRY_BUILDER , SYMMETRISER ,  SYMMETRY_FINDER ,  NO MULTI ,  INTERNAL_ONLY , INPUT_ONLY ,  EVOLVING ,  ENERGY ,  LENGTH ,  MAGNETIC FIELD . We\nnow explain each of these classes.  \u2018 DEVELOP \u2018 refers to input variables that are not used in production runs,\nbut only during development time. For non developers, it is strongly advised\nto skip them.  Some input variables are related to response function features, or non-linear\nfeatures, and are indicated \u2018 RESPFN \u2018 and \u2018 NONLINEAR \u2019. Detailed\nexplanations related to response function and non linear features are to be\nfound in the complementary  help_respfn . The initials RF are used for\n\u2018response function\u2019, and non-response-function are often referred to as GS\n(for ground-state), although this latter designation is not really\nsatisfactory.  Some input variables are related to excited state calculations, and are\nindicated \u2018 GW \u2019, \u2018 BETHE_SALPETER \u2019, or \u2018 TDDFT \u2019. No complementary\nhelp file is yet provided for such calculations. Please refer to the tutorial\n( lesson_gw1 ,  lesson_gw2 ,  lesson_tddft , and  lesson_bse ).  There are also parameters related to the geometry builder, a preprocessor of\nthe input file, aimed at easing the work of the user when there are molecules\nto be manipulated (rotation and translation), or group of atoms to be\nrepeated. The indication \u2018 GEOMETRY_BUILDER \u2018 is given for them. These can\nalso be skipped for the first few steps in the use of the code. \nIndeed, it should be  easy to set up the geometry of systems with less than\n20-40 atoms without this geometry builder . Even for larger systems, its\nfunctionalities could eventually be of no help. For a step-to-step description\nof this geometry builder, look at the variable \u2018 nobj \u2019. The related input\nvariables being used for preprocessing of the input file, they are not echoed\nin the output file.  Alternatively to the geometry builder, there is also a symmetriser. It allows\nto generate the full set of atoms in the primitive cell from the knowledge of\nthe symmetry operations and the atoms in the asymmetric cell. It also allows\nto generate the symmetry operations from the knowledge of the number of the\nspace group according to the international crystallographic tables. The\nindication \u2018 SYMMETRISER \u2018 is given for the variables related to its use.\nLook at the variable \u2018 spgroup \u2019. \nYou may find in the space group  help file  the\ncrystallographic equivalence of the parameters belonging to the symmetriser.\nThe related input variables being used for preprocessing of the input file,\nthey are not echoed in the output file.  Still as an alternative to the geometry builder and the symmetriser, if all\nthe coordinates of the atoms are given, the code is able to deduce all\nsymmetry operations leaving the lattice and atomic sublattices invariant, see\n\u2018 SYMMETRY_FINDER \u2019. Note that the default tolerance on the coordinates that\nare provided by the user, for a symmetry to be recognized, is on the order of\n1.e-8 . If the provided coordinates are rather inaccurate, ABINIT will not\nrecognize the symmetry, unless the input variable  tolsym  is changed.  Most of the variables can be used in the multi-dataset mode (see section 3.3),\nbut those that must have a unique value throughout all the datasets are\nsignaled with the indication \u2018 NO_MULTI \u2018  Some of the input variables, with characteristics \u2018 INPUT_ONLY \u2018 are only\nused by the parser, to initialize other input variables, but are not\ntransmitted inside the code, beyond the parser. In particular, they are not\nechoed in the output file.  At variance, some internal variables, with characteristics \u2018 INTERNAL_ONLY \u2018\nare documented in the help files, but are not accessible as input variables.\nThe documentation is provided because such variables are sometimes mentioned\nin the output file.  Most of the input variables do not change while a run is performed. Some of\nthem, by contrast, may evolve, like the atomic positions, the atomic\nvelocities, the cell shape, and the occupation numbers. Their echo, after the\nrun has proceeded, will of course differ from their input value. They are\nsignaled by the indication \u2018 EVOLVING \u2019.  The use of the atomic unit system (e.g. the Hartree for energy, about 27.211\neV, and the Bohr for lengths about 0.529 Angstroms) is strictly enforced\nwithin the code. However, the dimension of some input variables can be\nspecified and read correctly. At present, this applies to three types of\nvariables : those that have the dimension of an energy, those that have a\ndimension of length, and those that have a dimension of magnetic field. The\nfirst class of variables have the characteristics \u2018 ENERGY \u2019, and can be\nspecified in atomic units (Hartree), or electron-volts, or Rydbergs, or even\nKelvin. The second class of variables have the characteristics \u2018 LENGTH \u2019,\nand can be specified in atomic units (Bohr) and angstrom. The third class of\nvariables have the characteristics \u2018 MAGNETIC FIELD \u2019, and can be specified\nin atomic units and Tesla. The abinit parser recognize a dimension if it is\nspecified after the list of numbers following the input variable keyword, in\nthe input file. The specification can be upper or lower case, or a mix\nthereof. Here is the list of recognized chains of characters :   \u2018Ry \u2018 => Rydberg (for energies)   \u2018eV \u2018 => electron-volts (for energies)   \u2018K \u2018 => Kelvin (for energies)   \u2018Angstr\u2026\u2019 => Angstrom (for lengths)    Except in the case of \u2018Angstr\u2019, the abbreviation must be used (i.e. \u2018Rydberg\u2019\nwill not be recognized presently). Other character chains, like \u201cau\u201d (for\natomic units) or \u201cHartree\u201d, or \u201cBohr\u201d are not recognized, but make the parser\nchoose (by default) atomic units, which is the correct behaviour. Example :       acell 8 8 8 angstrom\n     ecut 8 Ry\n     tsmear 1000 K  or        acell 3*10 Bohr  ecut 270 eV  tsmear 0.01  The use of the atomic units is mandatory for other dimensioned input\nvariables, like the tolerance on forces ( toldff ), parameters that define\nan \u2018object\u2019 ( objaax, objbax ,  objatr, objbtr ), and the\ninitial velocity of atoms ( vel  - if needed).  The initial atomic positions can be input in Bohr or Angstrom through\n\u2018 xcart \u2019, but also, independently, in Angstrom through \u2018 xangst \u2019, or\neven in reduced coordinates, through \u2018 xred \u2019. Reduced cartesian coordinates\nmust be used for the eventual translations accompanying symmetry operations\n( tnons ).  In addition to giving the input variables, the input file can be useful for\nanother purpose : placing the word \u201c exit \u201d on the top line will cause the\njob to end smoothly on the very next iteration, if the  chkexit  input\nvariable is non-zero. This functions because the program closes and reopens\nthe input file on every iteration and checks the top line for the keyword\n\u201cexit\u201d. THE WORD MUST BE PLACED WITH SPACES (BLANKS) ON BOTH SIDES. Thus\nplacing exit on the top line of the input file WHILE THE JOB IS ALREADY\nRUNNING will force the job to end smoothly on the very next iteration. On some\nmachines, this does not work always (we do not know why\u2026). Another\npossibility is offered : one can create a file named \u201cabinit.exit\u201d in the\ndirectory where the job was started. The code should also smoothly end. In\nboth cases, the stop is not immediate. It can take a significant fraction\n(about 20% at most) of one SCF step to execute properly the instruction still\nneeded.  If you follow the tutorial, you should go back to the tutorial window now.",
            "title": "3.2. More about ABINIT input variables."
        },
        {
            "location": "/user-guide/help_abinit/#33-the-multi-dataset-mode",
            "text": "Until now, we have assumed that the user wants to make computations\ncorresponding to one set of data : for example, determination of the total\nenergy for some geometry, with some set of plane waves and some set of\nk-points.  It is often needed to redo the calculations for different values of some\nparameter, letting all the other things equal. As typical examples, we have\nconvergence studies needed to determine which cut-off energy gives the needed\naccuracy. In other cases, one makes chains of calculations in order to compute\nthe band structure : first a self-consistent calculation of the density and\npotential, then the eigenenergy computation along different lines.  For that purpose, the  multi-dataset mode  has been implemented.  It allows the code to treat, in one run, different sets of data, and to chain\nthem. The number of datasets to be treated is specified by the variable ndtset , while the indices of the datasets (by default 1, 2, 3, and so on)\ncan be eventually provided by the array  jdtset .  For each dataset to be treated, characterized by some index, each input\nvariable will determined by the following  rules  (actually, it is easier to\nunderstand when one looks at examples, see below) :   (1) ABINIT looks whether the variable name (e.g.  ecut  ), appended with the index of the dataset (e.g.  jdtset =2), exists (e.g. \u201cecut2\u201d ) . It will take the data that follows this keyword, if it exists.  (2) If this modified variable name does not exist, it will look whether a metacharacter, a series or a double-loop data set has been defined, see sections 3.4 or 3.5.  (3) If the variable name appended with the index of the dataset does not exist, and if there is no series nor double-loop dataset for this keyword, it looks for an occurrence of the variable name without any index appended, and take the corresponding data. (This corresponds to the single dataset mode)  (4) If such occurrences do not exist, it takes the default value. (Also, similar to the single dataset mode)  ---------------\n\n 1st example.\n\n ndtset   2\n  acell   8 8 8\n   ecut1  10\n   ecut2  15    means that there are 2 datasets : a first in which       acell 8 8 8  ecut 10  has to be used, and a second in which       acell 8 8 8  ecut 15  has to be used.       ------------------\n\n     2nd example\n\n     ndtset 2     jdtset 4 5\n\n     acell   8 8 8\n     acell5 10 10 10\n     ecut1  10\n     ecut2  15\n     ecut3  20\n     ecut4  25\n     ecut5  30  this means that there are still two datasets, but now characterized by the\nindices 4 and 5, so that the first run will use the generic \u201cacell\u201d, and\n\u201cecut4\u201d :       acell 8 8 8 ecut 25  and the second run will use \u201cacell5\u201d and \u201cecut5\u201d :       acell 10 10 10 ecut 30  Note that ecut1, ecut2 and ecut3 are not used.",
            "title": "3.3. The multi-dataset mode."
        },
        {
            "location": "/user-guide/help_abinit/#34-defining-a-series",
            "text": "Rule (2) is split in three parts : (2a), (2b) and (2c). \nSeries relate with (2b):  (2b) If the variable name appended with the index of the dataset does not\nexist, the code looks whether a series has been defined for this keyword.  There are two kinds of series :   arithmetic series (constant  increment  between terms of the series)   geometric series (constant  ratio  between terms of the series)    The first term of the series is defined by the keyword appended with a colon\n(e.g.  ecut:  ), while the increment of an arithmetic series is defined by\nthe keyword appended with a plus (e.g.  ecut+  ), and the factor of a\ngeometric series is defined by the keyword appended with a times (e.g. ecut * ).  If the index of the dataset is 1, the first term of the series is used, while\nfor index N , the appropriate input data is obtained by considering the Nth\nterm of the series.    ------------------\n\n  3rd example\n\n    ndtset 6\n    ecut1 10\n    ecut2 15\n    ecut3 20\n    ecut4 25\n    ecut5 30\n    ecut6 35  is equivalent to      ndtset 6 ecut: 10 ecut+ 5  In both cases, there are six datasets, with increasing values of  ecut .",
            "title": "3.4. Defining a series."
        },
        {
            "location": "/user-guide/help_abinit/#35-defining-a-double-loop-dataset",
            "text": "To define a double loop dataset, one has first to define the upper limit of\ntwo loop counters, thanks to the variable  udtset . The inner loop will\nexecute from 1 to  [udtset] , and the outer loop will execute from 1 to [udtset] . Note that the largest value for  [udtset]  is presently 999,\nwhile it is 9 for  [udtset]  (so, only the last digit for the inner loop).  The value of  ndtset  must be coherent with  udtset  (it must equal the\nproduct  udtset(1)*udtset(2)  ).  A dataset index is created by the concatenation of the outer loop index and\nthe inner loop index. \nFor example, if  [udtset]  is 2 and  [udtset]  is 4, the index will\nassume the following values :  11, 12, 13, 14, 21, 22, 23, and 24 .  Independently of the use of  udtset , rules (2a) and (2c) will be used to\ndefine the value of an input variable:  (2a) The question mark \u201c ? \u201d can be used as a metacharacter, replacing any\ndigit from 1 to 9, to define an index of a dataset. \nFor example,  ecut? 1 means that the input value that follows it can be used\nfor  ecut  for the datasets  01, 11, 21, 31, 41, 51, 61, 71, 81, and 91 .  (2c) If the variable name appended with the index of the dataset does not\nexist, the code looks whether a double-loop series has been defined for this\nkeyword. Series can be defined for the inner loop index or the outer loop\nindex. Two signs will be appended to the variable name (instead of one in the\nsimple series case). One of these signs must be a question mark \u201c ? \u201d, again\nused as a metacharacter able to assume the values 1 to 9. \nIf it is found in the first of the two positions, it means that the series\ndoes not care about the outer loop index (so the values generated are equal\nfor all outer loop index values). If it is found in the second of the two\npositions, the series does not care about the inner loop index. The other sign\ncan be a colon, a plus or a times, as in the case of the series defined in\n(2a), with the same meaning.  Rule (1) has precedence over them, they have precedence over rules (3) or (4),\nrule (2a) has precedence over rules (2b) or (2c) and the two latter cannot be\nused simultaneously for the same variable.       ------------------\n\n     4th example\n     ndtset 6    udtset 2 3\n     acell1?  10 10 10\n     acell2?  15 15 15\n     ecut?: 5    ecut?+ 1  is equivalent to       ndtset 6     jdtset 11 12 13  21 22 23\n     acell11  10 10 10     ecut11 5\n     acell12  10 10 10     ecut12 6\n     acell13  10 10 10     ecut13 7\n     acell21  15 15 15     ecut21 5\n     acell22  15 15 15     ecut22 6\n     acell23  15 15 15     ecut23 7  More examples can be found in the directory ~abinit/tests/v1, cases 59 and\nlater.",
            "title": "3.5. Defining a double loop dataset"
        },
        {
            "location": "/user-guide/help_abinit/#36-file-names-in-the-multi-dataset-mode",
            "text": "The root names for input and output files (potential, density, wavefunctions\nand so on) will receive an appendix : \u2018 _DS \u2018 followed by the index of the\ndataset. See section 4.  The \u2018 get \u2018 variables can be used to chain the calculations.  Until now, there are eight of them :  getwfk ,  getwfq ,  getddk , get1wf ,  getden ,  getcell ,  getxred  and  getxcart .   getwfk  allows to take the output wavefunctions of a previous dataset and use them as input wavefunctions   getwfq ,  getddk  and  get1wf  do similar things for response function calculations   getden  does the same for the density ;  getcell  does the same for  acell  and  rprim    getxred  and  getxcart  do the same for the atomic positions, either in reduced coordinates, or in cartesian coordinates.    The different variables corresponding to each dataset are echoed using the\nsame indexing convention as for the input step. For the last echo of the code\nvariables, some output variables are also summarized, using the same\nconventions :   etotal  (total energy)   fcart  (cartesian forces)   strten  (the stress tensor).    If you follow the tutorial, you should go back to the tutorial window now.",
            "title": "3.6. File names in the multi-dataset mode."
        },
        {
            "location": "/user-guide/help_abinit/#446-the-files-file",
            "text": "Note:  This \u201cfiles\u201d file is called ab.files in section 1.1 .  Contains the file names or root names needed to build file names. These are\nlisted below : there are 5 names or root names for input, output and\ntemporaries, and then a list of pseudopotentials. These names may be provided\nfrom unit 05 interactively during the run but are more typically provided by\npiping from a file in Unix (the \u201cfiles\u201d file).  ab_in   \nFilename of file containing the input data, described in the preceding\nsections.  ab_out \nFilename of the main file in which formatted output will be placed (the main\noutput file). Error messages and other diagnostics will NOT be placed in this\nfile, but sent to unit 06 (terminal or log file); the unit 06 output can be\nignored unless something goes wrong. The code repeats a lot of information to\nboth unit 06 and to the main output file. The unit 06 output is intended to be\ndiscarded if the run completes successfully, with the main output file keeping\nthe record of the run in a nicer looking format.  abi   \nThe other files READ by the code will have a name that is constructed from the\nroot \u201cabi\u201d. This apply to optionally read wavefunction, density or potential\nfiles. In the multi-dataset mode, this root will be complemented by \u2018 _DS \u2018\nand the dataset index. The list of possible input files, with their name\ncreated from the root \u2018abi\u2019, is the following (a similar list exist when\n\u2018 _DS \u2018 and the dataset index are appended to \u2018abi\u2019):    abi_WFK   \nfilename of file containing input wavefunction coefficients created from an\nearlier run (with  nqpt =0). Will be opened and read if  irdwfk  is 1 .\nThe wavefunction file is unformatted and can be very large.  Warning  : in\nthe multi dataset mode, if getwfk is non-zero, a wavefunction file build from abo  will be read.    abi_WFQ   \nfilename of file containing input wavefunction coefficients created from an\nearlier run (with  nqpt =1), as needed for response function calculations.\nThe wavefunction file is unformatted and can be very large.  Warning  : in\nthe multi dataset mode, if getwfk is non-zero, a wavefunction file build from abo  will be read.    abi_1WFxx   \nfilename of file containing input first-order wavefunctions created from an\nearlier RF run. xx is the index of the perturbation    abi_DEN   \nfilename of file containing density created from an earlier run. See\nexplanations related to negative values of  iscf . This file is also\nunformatted.  Warning  : in the multi dataset mode, if getwfk is non-zero, a\ndensity file build from  abo  will be read.    abi_HES   \nfilename of file containing an approximate hessian, for eventual\n(re)initialisation of Broyden minimisation. See brdmin.F90 routine. The use of restartxf  is preferred.    abo   \nExcept \u201cab_out\u201d and \u201clog\u201d, the other files WRITTEN by the code will have a\nname that is constructed from the root \u201cabo\u201d. This apply to optionally written\nwavefunction, density, potential, or density of states files. In the multi-\ndataset mode, this root will be complemented by \u2018 _DS \u2018 and the dataset\nindex. Also in the multi-dataset mode, the root \u201cabo\u201d can be used to build the\nname of  input  files, thanks to the \u2018get\u2019 variables. The list of possible\noutput files, with their name created from the root \u2018abo\u2019 is the following (a\nsimilar list exists when \u2018 _DS \u2018 and the dataset index are appended to\n\u2018abo\u2019) :    abo_WFK   \nFilename of file containing output wavefunction coefficients, if  nqpt =0.\nThe wavefunction file is unformatted and can be very large.    abo_WFQ   \nSame as  abo_WFK , but for the case  nqpt =1. The wavefunctions are always\noutput, either with the name  abo_WFK , or with the name  abo_WFQ .    abo_1WFxx   \nSame as  abo_WFK , but for first-order wavefunctions, xx is the index of the\nperturbation, see the section  6.3  of the help_respfn .    abo_DDB   \nThe derivative database, produced by a response-function dataset, see the\nsection  6.5  of the  help_respfn    abo_DEN   \nfilename of file containing density, in the case  ionmov =0. See the keyword prtden . This file is unformatted, but can be read by cut3d.    abo_TIMx_DEN   \nfilenames of files containing density, in the case  ionmov /=0. The value of\n\u201cx\u201d after \u201c TIM \u201d is described hereafter. See the keyword  prtden . This\nfile is unformatted, but can be read by cut3d.    abo_POT   \nfilename of file containing Kohn-Sham potential See the keyword  prtpot .\nThis file is unformatted, but can be read by cut3d.    abo_TIMx_POT   \nfilenames of files containing Kohn-Sham potential in the case  ionmov /=0.\nThe value of \u201cx\u201d after \u201cTIM\u201d is described hereafter. See the keyword prtpot . This file is unformatted, but can be read by cut3d.    abo_DOS   \nfilename of file containing density of states. See the keyword  prtdos .\nThis file is formatted.    abo_TIMx_DOS   \nfilenames of files containing the density of states in the case  prtdos =2\nand  ionmov =1 or 2. The value of \u201cx\u201d after \u201cTIM\u201d is described hereafter.\nSee also the keyword  prtdos . This file is formatted.    abo_GEO   \nfilename of file containing the geometrical analysis (bond lengths and bond\nangles) in the case  ionmov =0. See the keyword  prtgeo . This file is\nformatted.    abo_TIMx_GEO   \nfilenames of files containing the geometrical analysis (bond lengths and bond\nangles) in the case  ionmov =1 or 2. The value of \u201cx\u201d after \u201cTIM\u201d is\ndescribed hereafter. See also the keyword  prtgeo . This file is formatted.    abo_KSS   \nfilename of file containing output wavefunction coefficients, if nbandkss /=0. This wavefunction file is unformatted and can be very large.\nIts purpose is to start a GW calculation using M.Torrent\u2019s code. A different\nformat than for  abo_WFK  is used, see the file\n~abinit/doc/developers/format_KSS.txt .    abo_EIG   \nA file containing the electronic eigenvalues, for subsequent plotting of band\nstructure.    When  ionmov /=0, the  POT ,  DEN , or  GEO  files are output each\ntime that a SCF cycle is finished. The \u201c x \u201d of  TIMx  aims at giving each\nof these files a different name. It is attributed as follows: \n- case ionmov==1 : there is an initialization phase, that takes 4 calls to\nthe SCF calculation. The value of x will be A, B, C, and D. Then, x will be 1,\n2, 3 \u2026 , actually in agreement with the value of itime (see the keyword ntime ) \n- other ionmov cases : the initialisation phase take only one SCF call. The\nvalue of x will be 0 for that call. Then, the value of x is 1, 2, 3 \u2026 in\nagreement with the value of itime (see the keyword  ntime )  tmp   \nThe temporary files created by the codes will have a name that is constructed\nfrom the root \u201c tmp \u201d. tmp should usually be chosen such as to give access\nto a disk of the machine that is running the job, not a remote (NFS) disk.\nUnder Unix, the name might be something like  /tmp/user_name/temp . As an\nexample,  tmp_STATUS \ngives the status of advancement of the calculation, and is updated very\nfrequently  psp1   \nfilename of first pseudopotential input file. The pseudopotential data files\nare formatted. There must be as many filenames provided sequentially here as\nthere are types of atoms in the system, and the order in which the names are\ngiven establishes the identity of the atoms in the unit cell. (psp2, psp3, \u2026\n)  _If you follow the tutorial, you should go back to the tutorial window now. _",
            "title": "4. The \"files\" file"
        },
        {
            "location": "/user-guide/help_abinit/#546-the-pseudopotential-files",
            "text": "Actually, no real understanding of these files is needed to run the code, but\nfor different other reasons, it might be useful to be able to understand the\nfile structures. Different format are possible (labelled 1 to 7 presently) The\nassociated internal variable is called pspcod. Examples of use are found in\n~abinit/test/v1 . Information on the file structure can be found in the\n~abinit/doc/psp_infos directory.   pspcod=1 : Troullier-Martins pseudopotentials, generated by DC Allan and A Khein, see ~abinit/doc/psp_infos/psp1_info.txt ;   pspcod=2 : Goedecker-Teter-Hutter (GTH) pseudopotentials. See Phys. Rev. B 54, 1703 (1996) if needed ;   pspcod=3 : Hartwigsen-Goedecker-Hutter pseudopotentials. See Phys. Rev. B 58, 3641 (1998) if needed, and the file ~abinit/doc/psp_infos/psp3_info.txt ;   pspcod=4 or 5 : old format pseudopotentials, see ~abinit/doc/psp_infos/psp45_info.txt ;   pspcod=6 : pseudopotentials from the fhi98pp code, see ~abinit/doc/psp_infos/psp6_info.txt ;   pspcod=7 : pseudo atomic data for PAW ;   pspcod=8 : pseudopotential file format from Don Hamann, providing additional flexibility.",
            "title": "5. The pseudopotential files"
        },
        {
            "location": "/user-guide/help_abinit/#646-the-different-output-files",
            "text": "Explanation of the output from the code  Output from the code goes to several places listed below.",
            "title": "6. The different output files"
        },
        {
            "location": "/user-guide/help_abinit/#61-the-log-file",
            "text": "The \u201clog\u201d file (this is the standard UNIX output file, and corresponds to\nFortran unit number 06) : a file which echoes the values of the input\nparameters and describes various steps of the calculation, typically in much\nmore detail than is desired as a permanent record of the run. This log file is\nintended to be informative in case of an error or for a fuller description of\nthe run. For a successful run the user will generally delete the log file\nafterwards. There are four types of exception messages :  ERROR ,  BUG , WARNING  and  COMMENT  messages.  ERROR  and  BUG  messages cause the code to stop, immediately, or after a very small delay. An  ERROR  is attributed to the user, while a  BUG  is attributed to the developer.   A  WARNING  message indicates that something happened that is not as\nexpected, but this something is not so important as to make the code stop. A COMMENT  message gives some information to the user, concerning something\nunusual. None of them should appear when the run is completely normal.  After a run is completed, always have a look at the end of the log file, to\nsee whether an  ERROR  or a  BUG  occurred.    Also, the code gives the number of  WARNING  or  COMMENT  it issued. It is\nadvised to read at least the  WARNING  messages, during the first month of\nABINIT use.  If you follow the tutorial, you should go back to the tutorial window now.",
            "title": "6.1. The log file"
        },
        {
            "location": "/user-guide/help_abinit/#62-the-main-output-file",
            "text": "The  main output file  is a formatted output file to be kept as the\npermanent record of the run.  Note that it is expected  not  to exist at the beginning of the run: \nIf a file with the name specified in the \u201cfiles\u201d file already exists, the code\nwill generate, from the given one, another name, appended with  .A  . If\nthis new name already exists, it will try to append  .B  , and so on, until .Z  . \nThen, the code stops, and asks you to clean the directory.  The  main output file  starts with a heading:   version number and specified platform   copyright notice and distribution licence   date   echo of \u201cfiles\u201d file (except pseudopotential name)    Then, for each dataset, it reports the point symmetry group and Bravais\nlattice, and the expected memory needs. It echoes the input data, and report\non checks of data consistency for each dataset.  If you follow the tutorial, you should go back to the tutorial window now.",
            "title": "6.2. The main output file"
        },
        {
            "location": "/user-guide/help_abinit/#63-more-on-the-main-output-file",
            "text": "Then, for each dataset, the real computation is done, and the code will report\non some initialisations, the SCF convergence, and the final analysis of\nresults for this dataset. Each of these phases is now described in more\ndetails.  The code reports:   the real and reciprocal space translation vectors ( Note : the definition of the reciprocal vector is such that Ri.Gj= deltaij)  the volume of the unit cell   the ratio between linear dimension of the FFT box and the sphere of plane waves, called \u201c boxcut \u201d.  \nIt must be above 2 for exact treatment of convolutions by FFT.  ngfft  has\nbeen automatically chosen to give a boxcut value larger than 2, but not much\nlarger, since more CPU time is needed for larger FFT grids;    the code also mention that for the same FFT grid you might treat (slightly) larger  ecut  (so, with a rather small increase of CPU time)    the heading for each pseudopotential which has been input   from the inwffil subroutine, a description of the wavefunction initialization (random number initialization or input from a disk file), that is, a report of the number of planewaves (npw) in the basis at each k point  from the setup2 subroutine, the average number of planewaves over all k points is reported in two forms, arithmetic average and geometric average.    Until here, the output of a ground-state computation is identical to the one\nof a response-function calculation. See the  help_respfn  for the latter,\nespecially section  6.2 .  Next the code reports information for each SCF iteration:   the iteration number   the (pseudo) total energy (Etot) in Hartree [This is not the total energy of the system, since the pseudopotential approximation has been made : a constant energy (in the frozen-core approximation) should be added to the present pseudo total energy in order to obtain a total energy, that includes the contributions from the core electrons. Since only differences of total energy matter (except is extremely rare cases), one can work with this pseudo energy like if it were the true total energy, except that the missing constant depends on the pseudopotential that has been used. Thus one has to perform differences of pseudo energies between simulations that use the same pseudopotentials].   the change in Etot since last iteration (deltaE)   the maximum squared residual residm over all bands and k points (residm - the residual measures the quality of the wavefunction convergence)   the squared residual of the potential in the SCF procedure (vres2)   the maximum change in the gradients of Etot with respect to fractional coordinates (diffor, in Hartree)    the rms value of the gradients of Etot with respect to fractional coordinates (maxfor, in Hartree).  The latter two are directly related to forces on each atom.    Then comes an assessment of the SCF convergence : the criterion for fulfillment of the SCF criterion (defined by  toldfe ,  toldff ,  tolwfr  or  tolvrs ) might be satisfied or not \u2026    Then the stresses are reported.    This ends the content of a fixed atomic position calculation.  Many such blocks can follow.  When the atomic positions have been eventually relaxed, according to the value\nof  ntime , the code output more information:   The squared residuals for each band are reported, k point by k point.   Then the fractional or reduced coordinates are given,   followed by the energy gradients,   followed by the cartesian coordinates in Angstroms,   followed by the cartesian forces in Hartree/Bohr and eV/Angstrom.   Also are given the rms force ( frms ) and the maximum absolute value of any force component ( max ).   Next are the length scales of the unit cell in Bohr and in Angstroms.   Next are the eigenvalues of each band for each k point, in eV or Hartree or both depending on the choice of  enunit .      NOTE that the average electrostatic potential of a periodically repeated cell is UNDEFINED. \nIn the present implementation, the average Hartree potential and local\npotential are imposed to be zero, but not the average exchange-correlation\npotential. This definition gives some meaning to the absolute values of\neigenenergies, thanks to Janak\u2019s theorem: they are derivatives of the total\nenergy with respect to occupation number. Indeed, the G=0 contributions of the\nHartree, local potential and ion-ion to the total energy is independent of the\noccupation number in the present implementation. With this noticeable\nexception, one should always work with  differences  in eigenenergies, as\nwell as  differences  between eigenenergies and the potential. For example,\nthe absolute eigenenergies of a bulk cell should not be used to try to predict\na work function. The latter quantity should be obtained in a supercell\ngeometry, by comparing the Fermi energy in a slab and the potential in the\nvacuum in the same supercell.   Next are the minimum and maximum values for charge density, and next smaller or larger values (in order to see degeneracies).   Next are the total energy (Ha and eV) and its components:   kinetic,   Hartree,   exchange and correlation (xc),   Ewald (ion-ion energy),   \u201c core correction \u201d to the local pseudopotential,   local pseudopotential, and   nonlocal pseudopotential.  The sum of the Kohn-Sham energies (termed \u201cband energy\u201d) is also given.     Next is the stress tensor,  \n(1/ucvol) d(Etot)/d(strain(a,b)) \nfor Etot=total energy per unit cell and  a , b  are  x ,  y , or  z  components of strain.  \nThe stress tensor is given in cartesian coordinates in Hartree/Bohr3 and GPa. \nThe basics of the stress tensor are described in O. H. Nielsen and Richard M.\nMartin, see the bibliography  file.   Having finished all the calculations for the different datasets, the code\nechoes the parameters listed in the input file, using the latest values e.g.\nfor  xred ,  vel , and  xcart , and supplement them with the values\nobtained for the total energy, the forces and stresses, as well as occupation\nnumbers. \nThe latter echoes are very convenient for a quick look at the result of\ncalculation !  This is followed finally by the timing output: both \u201ccpu\u201d time and \u201cwall\nclock\u201d time as provided by calls within the code. \nThe total cpu and wall clock times are reported first, in seconds, minutes,\nand hours for convenient checking at a glance. \nNext are the cpu and wall times for the principal time-consuming subroutine\ncalls, each of which is independent of the others. The sum of these times\nusually accounts for about 90% of the run time. \nThe main subroutines, for BIG jobs, are   (1) fourwf: the subroutine which performs the fast Fourier transform for the wavefunctions:   (2) fourdp: the subroutine which performs the fast Fourier transform related to density and potential   (3) rhohxc: computes the Hartree and exchange-correlation energy and potential and sometimes derivative of potential; only the XC timing is reported, excluding time connected to the FFTs :  xc:pot/=fourdp.  (4) nonlop: computes  < G | Vnon-local | C >    the matrix elements of the nonlocal pseudopotential;   (5) projbd: Gram-Schmidt orthogonalisation    In case of small jobs, other (initialisation) routines may take a larger\nshare, and the sum of the times for the principal time-consuming subroutine\ncalls will not make 90% of the run time..  If the long printing option has been selected ( prtvol =1), the code gives\nmuch more information in the whole output file. These should be rather self-\nexplanatory, usually. Some need more explanation. \nIn particular the cpu and wall times for major subroutines which are NOT\nindependent of each other; for example vtorho conducts the loop over k points\nand calls practically everything else. In case of a ground state calculation,\nat fixed atomic positions, these subroutines are   (1)  abinit : the main routine   (2)  driver  : select ground state or response calculations   (3)  gstate  : the driver of the ground state calculations   (4)  scfcv  : the SCF cycle driver   (5)  vtorho  : compute the density from the potential (it includes a loop over spins and k-points)   (6)  vtowfk  : compute the wavefunctions at one particular k-point (includes a non self consistent loop, and a loop over bands)   (7)  cgwf  : optimize one wavefunction in a fixed potential   (8)  getghc : computes < G | H | C >, that is, applies the Hamiltonian operator to an input vector.    If you follow the tutorial, you should go back to the tutorial window now.",
            "title": "6.3. More on the main output file"
        },
        {
            "location": "/user-guide/help_abinit/#64-the-header",
            "text": "The  wavefunction files ,  density files , and  potential files  all\nbegin with the same records, called the \u201cheader\u201d. \nThis header is treated using a hdr_type datastructure inside ABINIT. There are\ndedicated routines inside ABINIT for initializing a header, updating it,\nreading the header of an unformatted disk file, writing a header to an\nunformatted disk file, echoing a header to a formatted disk file, cleaning a\nheader datastructure.  The header is made of 4+ ntypat  unformatted records, obtained by the\nfollowing Fortran90 instructions (format 5.7):    write ( unit = header )   codvsn , headform , fform \n  write ( unit = header )   bantot , date , intxc , ixc , natom , ngfft ( 1 : 3 ),& \n     nkpt , nspden , nspinor , nsppol , nsym , npsp , ntypat , occopt , pertcase , usepaw ,& \n     ecut , ecutdg , ecutsm , ecut_eff , qptn ( 1 : 3 ), rprimd ( 1 : 3 , 1 : 3 ), stmbias , tphysel , tsmear , usewvl \n\n  write ( unit = header )   istwfk ( 1 : nkpt ), nband ( 1 : nkpt * nsppol ),& \n     npwarr ( 1 : nkpt ), so_psp ( 1 : npsp ), symafm ( 1 : nsym ), symrel ( 1 : 3 , 1 : 3 , 1 : nsym ), typat ( 1 : natom ),& \n     kpt ( 1 : 3 , 1 : nkpt ), occ ( 1 : bantot ), tnons ( 1 : 3 , 1 : nsym ), znucltypat ( 1 : ntypat ), wtk ( 1 : nkpt ) \n  do  ipsp = 1 , npsp  ! (npsp lines, 1 for each pseudopotential ; npsp=ntypat, except if alchemical pseudo-atoms) \n   write ( unit = unit )   title , znuclpsp , zionpsp , pspso , pspdat , pspcod , pspxc , lmn_size \n  enddo  !(in case of usepaw==0, final record: residm, coordinates, total energy, Fermi energy) \n  write ( unit = unit )   residm , xred ( 1 : 3 , 1 : natom ), etotal , fermie  !(in case of usepaw==1, there are some additional records) \n  if   ( usepaw == 1 ) then    write ( unit = unit )(   pawrhoij ( iatom )% nrhoijsel ( 1 : nspden ), iatom = 1 , natom ),   cplex ,   nspden \n   write ( unit = unit )(( pawrhoij ( iatom )% rhoijselect ( 1 :        nrhoijsel ( ispden ), ispden ), ispden = 1 , nspden ), iatom = 1 , natom ),& \n                   (( pawrhoij ( iatom )% rhoijp       ( 1 : cplex * nrhoijsel ( ispden ), ispden ), ispden = 1 , nspden ), iatom = 1 , natom ) \n  endif   where the type of the different variables is :  character * 6   ::   codvsn  integer   ::   headform , fform  integer   ::   bantot , date , intxc , ixc , natom , ngfft ( 3 ), nkpt , npsp ,  nspden , nspinor , nsppol , nsym , ntypat , occopt , pertcase , usepaw  integer   ::   usewvl ,   cplex ,   nspden  double precision   ::   acell ( 3 ), ecut , ecutdg , ecutsm , ecut_eff , qptn ( 3 ), rprimd ( 3 , 3 ), stmbias , tphysel , tsmear  integer   ::   istwfk ( nkpt ), nband ( nkpt * nsppol ), npwarr ( nkpt ), so_psp ( npsp ),&  &   symafm ( nsym ), symrel ( 3 , 3 , nsym ), typat ( natom ), nrhoijsel ( nspden ), rhoijselect ( * , nspden )  double precision   ::   kpt ( 3 , nkpt ), occ ( bantot ), tnons ( 3 , nsym ), znucltypat ( ntypat ), wtk ( nkpt )  character * 132   ::   title  double precision   ::   znuclpsp , zionpsp  integer   ::   pspso , pspdat , pspcod , pspxc , lmax , lloc , mmax = integers  double precision   ::   residm , xred ( 3 , natom ), etotal , fermie , rhoij ( * , nspden )   NOTE :  etotal is set to its true value only for density and potential files.\nFor other files, it is set to 1.0d20 \nNOTE :  ecut_eff= ecut * dilatmx 2 \nNOTE :  For all cases where occupation numbers are defined (that is, positive\niscf, and iscf=-3), and for non-metallic occupation numbers, the Fermi energy\nis set to the highest occupied eigenenergy. This might not correspond to the\nexpected Fermi energy for a later non-self-consistent calculation (e.g. the\nband structure)  The header might differ for different versions of ABINIT. One pre-v5.3 format\nis described below. Note however, that the current version of ABINIT should be\nable to read all the previous formats (not to write them), with the exception\nof wavefunction files for which the ecutsm  value was\nnon-zero (there has been a change of definition of the smearing function in\nv4.4).  The format for version 4.4, 4.5, 4.6, 5.0, 5.1 and 5.2 was :    write ( unit = header )   codvsn , headform , fform \n  write ( unit = header )   bantot , date , intxc , ixc , natom , ngfft ( 1 : 3 ),&  &   nkpt , nspden , nspinor , nsppol , nsym , npsp , ntypat , occopt , pertcase , usepaw ,&  &   ecut , ecutdg , ecutsm , ecut_eff , qptn ( 1 : 3 ), rprimd ( 1 : 3 , 1 : 3 ), stmbias , tphysel , tsmear \n  write ( unit = header )   istwfk ( 1 : nkpt ), nband ( 1 : nkpt * nsppol ),&  &   npwarr ( 1 : nkpt ), so_typat ( 1 : ntypat ), symafm ( 1 : nsym ), symrel ( 1 : 3 , 1 : 3 , 1 : nsym ), typat ( 1 : natom ),&  &   kpt ( 1 : 3 , 1 : nkpt ), occ ( 1 : bantot ), tnons ( 1 : 3 , 1 : nsym ), znucltypat ( 1 : ntypat ) \n  do  ipsp = 1 , npsp  ! (npsp lines, 1 for each pseudopotential ; npsp=ntypat, except if alchemical pseudo-atoms) \n   write ( unit = unit )   title , znuclpsp , zionpsp , pspso , pspdat , pspcod , pspxc , lmn_size \n  enddo  !(in case of usepaw==0, final record: residm, coordinates, total energy, Fermi energy) \n  write ( unit = unit )   residm , xred ( 1 : 3 , 1 : natom ), etotal , fermie  !(in case of usepaw==1, there are some additional records) \n  if   ( usepaw == 1 ) then    write ( unit = unit )( pawrhoij ( iatom )% nrhoijsel ( 1 : nspden ), iatom = 1 , natom ) \n   write ( unit = unit )(( pawrhoij ( iatom )% rhoijselect ( 1 : nrhoijsel ( ispden ), ispden ), ispden = 1 , nspden ), iatom = 1 , natom ),&  &                   (( pawrhoij ( iatom )% rhoijp       ( 1 : nrhoijsel ( ispden ), ispden ), ispden = 1 , nspden ), iatom = 1 , natom ) \n  endif",
            "title": "6.4. The header"
        },
        {
            "location": "/user-guide/help_abinit/#65-the-density-output-file",
            "text": "This is an unformatted data file containing the electron density on the real\nspace FFT grid. It consists of the header records followed by  do  ispden = 1 , nspden \n  write ( unit )   ( rhor ( ir ), ir = 1 , cplex * ngfft ( 1 ) * ngfft ( 2 ) * ngfft ( 3 ))  enddo   where  rhor  is the electron density in electrons/Bohr^3, and cplex is the\nnumber of complex components of the density (cplex=1 for GS calculations -the\ndensity is real-, and cplex=1 or 2 for RF). The input variable  nspden \ndescribes the number of components of the density. The first component (the\nonly one present when  nspden =1) is always the total charge density. When nspden =2, the second component is the density associated with spin-up\nelectrons. When  nspden =4, the second, third and fourth components\ncorrespond to the x, y and z projections of the local magnetization, in units\nof hbar/2 . Note that the meaning of the different components of the density\ndiffers for the density array (rhor) and for the different potential arrays\n(vxc \u2026), see section  6.6 .  To identify the points in real space which correspond with the index \u201cir\u201d\nabove, consider the following. \nThe first array value (ir=1) corresponds with the first grid point which is at\nthe origin of the unit cell, (x=0, y=0, z=0). \nThe next grid point (ir=2) lies along the first primitive translation at the\nnext fft grid point, which is (1/ [ngfft] ) [acell] [rprim] .\nThis is 1/ [ngfft]  of the way along the first primitive translation. \nThe rest of the values up to ir= [ngfft]  lie along this vector, at\n(ir-1)/ [ngfft]  of the way along the first primitive translation. The\npoint at ir= [ngfft] +1 lies at 1/ [ngfft]  along the second primitive\ntranslation. \nThe next points up to ir= [ngfft] + [ngfft]  are displaced in the\ndirection of the second primitive translation by 1/ [ngfft]  and in the\nfirst translation by (ir- [ngfft] -1)/ [ngfft] . \nThis pattern continues until ir= [ngfft] [ngfft] . \nThe next point after that is displaced along the third primitive translation\nby 1/ngfft(3), and so forth until ir varies all the way from 1 to [ngfft] [ngfft] * [ngfft] . This last point is in the corner\ndiagonally opposite from the origin, or right alongside the origin if the\nwhole grid is viewed as being periodically repeated.",
            "title": "6.5. The density output file"
        },
        {
            "location": "/user-guide/help_abinit/#66-the-potential-files",
            "text": "Also unformatted files consisting of the header records and  do  ispden = 1 , nspden \n  write ( unit )   ( potential ( ir ), ir = 1 , cplex * ngfft ( 1 ) * ngfft ( 2 ) * ngfft ( 3 ))  enddo   where  potential  can be either the sum of the Hartree potential, exchange-\ncorrelation and local pseudopotential (see  prtpot ), the Hartree potential\n(see  prtvha ), the Hartree+XC potential (see  prtvhxc ), the local\npseudopotential (see  prtvpsp ) or the XC potential (see  prtvxc ), These\nare defined on the real space grid in Hartree energy units. The underlying\ngrid is as described above. If  nspden =2, the different components are the\nspin-up potential and the spin-down potential. In the case  nspden =4, the\ncomponents correspond to the up-up potential, the down-down potential, the\nreal part of the up-down potential, and the imaginary part of the up-down\npotential. Note that the Hartree potential is NOT spin-dependent, but in order\nto use the same format as for the other potential files, the spin-independent\narray is written twice, once for spin-up and one for spin-down.",
            "title": "6.6. The potential files"
        },
        {
            "location": "/user-guide/help_abinit/#67-the-wavefunction-output-file",
            "text": "This is an unformatted data file containing the planewaves coefficients of all\nthe wavefunctions, and different supplementary data.  The  ground-state  wf file consists of the header records, and data written\nwith the following lines of FORTRAN (version 4.0 and more recent versions):  bantot = 0                                      <--   counts   over   all  bands  index = 0                                       <--   index  for   the   wavefunction   location  do  isppol = 1 , nsppol \n  do  ikpt = 1 , nkpt \n   write ( unit )   npw , nspinor , nband                      <--   for   each   k   point \n   write ( unit )   kg ( 1 : 3 , 1 : npw )                          <--   plane   wave   reduced   coordinates \n   write ( unit )   eigen ( 1 + bantot : nband + bantot ),          <--   eigenvalues   for   this   k   point \n               occ ( 1 + bantot : nband + bantot )             <--   occupation   numbers   for   this   k   point \n   do  iband = 1 , nband \n    write ( unit )   ( cg ( ii + index ), ii = 1 , 2 * npw * nspinor )     <--   wavefunction   coefficients \n   enddo                                              for   a   single   band   and  k   point \n   bantot = bantot + nband \n   index = index + 2 * npw * nspinor * nband \n  enddo  enddo   If the job ended without problem, a few supplementary lines are added, in\norder to give the history of atomic positions and corresponding forces. The\ninteger nxfh gives the number of pairs (x,f) of positions and forces in\nreduced coordinates :    write ( unit ) nxfh \n  do  ixfh = 1 , nxfh \n   write ( unit )   xred ( 1 : 3 , 1 : natom , ixfh ), dummy ( 1 : 3 , 1 : 4 ),&  &               fred ( 1 : 3 , 1 : natom , ixfh ), dummy ( 1 : 3 , 1 : 4 ) \n  enddo   The dummy variables might contain, in the future, the description of the unit\ncell, and the stresses. The type of the different variables is :  integer   ::   kg , nband , npw , nspinor , nxfh  double precision   ::   cg , dummy , eigen , fred , occ , xred   The  response-function  wf file consists of the header records, and data\nwritten with the following lines of FORTRAN (version 4.0 and more recent\nversions):  bantot = 0                                      <--   counts   over   all  bands  do  isppol = 1 , nsppol \n  do  ikpt = 1 , nkpt \n   write ( unit )   npw , nspinor , nband                      <--   for   each   k   point \n   write ( unit )   kg ( 1 : 3 , 1 : npw )                          <--   plane   wave   reduced   coordinates \n   do  iband = 1 , nband \n    write ( unit )   ( eigen ( jband + ( iband - 1 ) * nband + bantot ), jband = 1 , 2 * nband )    <--   column   of   eigenvalue   matrix \n    write ( unit )   ( cg ( ii + index ), ii = 1 , 2 * npw * nspinor )       <--   wavefunction   coefficients \n   enddo                                              for   a   single   band   and  k   point \n   bantot = bantot + nband \n  enddo  enddo   In version previous to 4.0 , npw and nspinor were combined :  write ( unit )   npw * nspinor , nband   while the planewave coordinate record was not present (in both GS and RF\ncases).  Note that there is an alternative format (_KSS) for the output of the\nwavefunction coefficients, activated by a non-zero value of  nbandkss .",
            "title": "6.7. The wavefunction output file"
        },
        {
            "location": "/user-guide/help_abinit/#68-other-output-files",
            "text": "There are many other output files, optionally written, all formatted files at\npresent. Their use is usually governed by a specific input variable. Please\nconsult the description of this input variable, in order to have more\ninformation on such files :   prtdos  to print a file with the electronic Density-Of-States  prteig  to print a file with the list of k points and eigenenergies  prtgeo  to print a file with a geometrical analysis (bond lengths and bond angles), that also contains an XMOL section  prt1dm  to print a one-dimensional projection of potential and density, for the three axes.   _If you follow the tutorial, you should go back to the tutorial window now. _",
            "title": "6.8. Other output files."
        },
        {
            "location": "/user-guide/help_abinit/#69-control-of-output-in-the-parallel-case",
            "text": "For massively parallel runs, one cannot afford to have some of the output\nfiles that are usually created. Explicitly, the log file and also the status\nfile become problematic. By default, with less than N processors, they are\ncreated, but beyond N processors, they are deactivated except for the main log\nfile (master processor).  This default behaviour can be changed as follows. If a file named \u201c_NOLOG\u201d\nexists in the current directory, then no log file and no status file will be\ncreated, even with less than N processors. By contrast, if a file \u201c_LOG\u201d\nexists in the current directory, then a log file and the status files will be\ncreated, even with more than N processors. Alternatively, if a file named\n\u201c_MAINLOG\u201d exists and there are less than N processors, only the master\nprocessor writes the log and status files (this mimic the default behavior\nwhen using more than N processors but with less than N processors)  In ABINITv7, N was set at N=100. However, with ABINITv8, N has been switched\nto 2. It can be changed \u201cby hand\u201d, though : modify NPROC_NO_EXTRA_LOG in\nsrc/10_defs/defs_basis.F90 and recompile. See src/95_drive/iofn1.F90 for more\nexplanation.",
            "title": "6.9. Control of output in the parallel case."
        },
        {
            "location": "/user-guide/help_abinit/#746-numerical-quality-of-the-calculations",
            "text": "The following section describes various parameters which affect convergence\nand the numerical quality of calculations.  The list of these input parameters is   (1)  ecut    (2)  toldfe ,  toldff ,  tolwfr , and  tolvrs , as well as  nstep    (3)  nkpt    (4)  ngfft    (5)  tolmxf , as well as  amu ,  dtion ,  vis ,  ntime    (6)  acell  and  rprim     The technical design of the pseudopotential also affects the quality of the\nresults.  (1) The first issue regarding convergence is the number of planewaves in the\nbasis for a given set of atoms. Some atoms (notably those in the first row or\nfirst transition series row) have relatively deep pseudopotentials which\nrequire many planewaves for convergence. In contrast are atoms like Si for\nwhich fewer planewaves are needed. A typical value of  ecut  for silicon\nmight be 5-10 Hartree for quite good convergence, while the value for oxygen\nmight be 25-35 Hartree or more depending on the convergence desired and the\ndesign of the pseudo- potential.  NOTE: It is necessary in every new problem to  TEST  the convergence by RAISING   ecut  for a given calculation until the results being computed\nare constant to within some tolerance. This is up to the user and is very\nimportant. For a given  acell  and  rprim ,  ecut  is the parameter\nwhich controls the number of planewaves. Of course if  rprim  or  acell \nis varied then the number of planewaves will also change.  Let us reiterate that extremely careful pseudopotential design can optimize\nthe convergence of  e.g.  the total energy within some range of planewave\nnumber or  ecut . It is appropriate to attempt to optimize this convergence,\nespecially for difficult atoms like oxygen or copper, as long as one does not\nsignificantly compromise the quality or transferability of the\npseudopotential. There are many people working on new techniques for\noptimizing convergence.  For information on extended norm conservation, see E. L. Shirley, D. C. Allan,\nR. M. Martin, and J. D. Joannopoulos, Phys. Rev. B 40, 3652 (1989).  For information on optimizing the convergence of pseudopotentials, see A. M.\nRappe, K. M. Rabe, E. Kaxiras, and J. D. Joannopoulos, Phys. Rev. B 41, 1227\n(1990).  (2) In addition to achieving convergence in the number of planewaves in the\nbasis, one must ensure that the SCF iterations which solve the electronic\nstructure for a given set of atomic coordinates are also converged. This\nconvergence is controlled by the parameters  toldfe ,  toldff , tolwfr , and  tolvrs , as well as the parameter  nstep . One of the\n\u201ctolerance\u201d parameters must be chosen, and, when the required level of\ntolerance is fulfilled, the SCF cycles will stop. The  nstep  variable also\ncontrols convergence in preconditioned conjugate gradient iterations by\nforcing the calculation to stop whenever the number of such iterations exceeds\nnstep. Usually one wants nstep to be set larger than needed to reach a given\ntolerance, or else one wants to restart insufficiently converged calculations\nuntil the required tolerance is reached.  Note that, if the gap in the system closes (e.g. due to defect formation or if\nthe system is metallic in the first place), the presently coded algorithm will\nbe slower to converge than for insulating materials. Convergence trouble\nduring iterations usually signals closure of the gap. The code will suggest to\ntreat at least one unoccupied state (or band) in order to be able to monitor\nsuch a closure.  (3) For self consistent calculations ( iscf  positive) it is important to\ntest the adequacy of the k point integration. If symmetry is used then one\nusually tests a set of \u201cspecial point\u201d grids. Otherwise one tests the addition\nof more and more k points, presumably on uniform grids, to ensure that a\nsufficient number has been included for good k point integration. The\nparameter nkpt indicates how many k points are being used, and their\ncoordinates are given by kpt and kptnrm, described above. The weight given to\neach k point is provided by input variable  wtk . Systematic tests of k\npoint integration are much more difficult than tests of the adequacy of the\nnumber of planewaves. The difficulty I refer to is simply the lack of a very\nsystematic method for generating k point grids for tests.  (4) It is possible to run calculations for which the fft box is not quite\nlarge enough to avoid aliasing error in fft convolutions. An aliasing error,\nor a Fourier filter approximation, is occurring when the output variable\n\u201c boxcut \u201d is less than 2. boxcut is the smallest ratio of the fft box side\nto the planewave basis sphere diameter. If this ratio is 2 or larger then e.g.\nthe calculation of the Hartree potential from the charge density is done\nwithout approximation. \nNOTE : the values of  [ngfft]  are chosen automatically by the code to\ngive boxcut > 2, if  ngfft  has not been set by hand. At ratios smaller than\n2, certain of the highest Fourier components are corrupted in the convolution.\nIf the basis is nearly complete, this Fourier filter can be an excellent\napproximation. In this case values of boxcut can be as small as about 1.5\nwithout incurring significant error. For a given  ecut ,  acell , and rprim , one should run tests for which  ngfft  is large enough to give\nboxcut >= 2, and then one may try smaller values of  ngfft  if the results\nare not significantly altered. See the descriptions of these variables above.  (5) If you are running calculations to relax or equilibrate structures, i.e.\nwith  ionmov =1 and possibly  vis >0, then the quality of your molecular\ndynamics or relaxation will be affected by the parameters  amu ,  dtion , vis ,  ntime ,  tolmxf . Clearly if you want a relaxed structure you\nmust either run long enough or make repeated runs until the largest force in\nthe problem (output as fmax) is smaller than what you will tolerate (see tolmxf ). \nIf  dtion  is too large for the given values of masses ( amu ) and\nviscosity ( vis ) then the molecular dynamics will be unstable. If  dtion \nis too small, then the molecular dynamics will move inefficiently slowly. A\nconsensus exists in the community that forces larger than about 0.1\neV/Angstrom are really too large to consider the relaxation to be converged.\nIt is best for the user to get experience with this in his/her own\napplication. \nThe option  ionmov =2, 3 or 7 are also available This uses the Broyden\n(BFGS) scheme for structural optimization and is much more efficient than\nviscous damping for structural relaxation.  (6) If you are running supercell calculations (i.e. an isolated atom or\nmolecule in a big box, or a defect in a solid, or a slab calculation) you must\ncheck the convergence of your calculation with respect to the supercell and\nsystem size.   For an isolated molecule in a big box : increase concurrently the three dimensions of your supercell ( acell ), and check the convergence of your physical property.   For a defect in a solid : your supercell must be a multiple of the primitive cell of the bulk solid, so you have less freedom. Still, be sure that your supercell is large enough for your properties of interest to be accurate at the level you want it to be.   For a slab calculation : you must increase the vacuum in the cell, but also the thickness of your slab systematically\u2026    _If you follow the tutorial, you should go back to the tutorial window now. _",
            "title": "7. Numerical quality of the calculations"
        },
        {
            "location": "/user-guide/help_abinit/#846-final-remarks",
            "text": "The ABINIT package is developed by the ABINIT group. The status of this\npackage and the ABINIT group are explained in the file\n~abinit/doc/users/context.txt and ~abinit/doc/developers/planning.txt , or\nsome recent version of them.",
            "title": "8. Final remarks"
        },
        {
            "location": "/user-guide/help_mrgddb/",
            "text": "The user is advised to be familiar with the main \nhelp_file\n before reading\nthe present file. It is important to read also the \nAnalysis of Derivative\nDataBase code (Anaddb) help file\n to complement the\npresent reading.\n\n\nThe mrgddb code has the purpose to merge \u201ctransfer\u201d DDBs\n(that were generated from the ABINIT code) to make a complete DDB\nthat can be exploited by the Anaddb code.\n\n\nThe input is very simple, and could be given directly at the screen,\nor more conveniently, piped from a file.\nThe user should provide first the name of the new (output) DDB.\nHe/she should then give a short description (one line) of this new DDB\nthat will be created. This line will be printed at the beginning\nof the DDB.\n\n\nThe user should then give the number of DDBs that will be merged, then\nthe whole set of filenames for the DDBs to be merged, one on each line.\n\n\n\n\nIs a merging code really useful ?\n\n\nThe ABINIT code in its present\nversion is only able to produce results for one q wavevector\nfor each dataset.  A database for more than one q point can thus be created\nusing MRGDDB. Also, it is useful to be able to merge different DDBs\nif they are produced independently on different machines.\n\n\n\n\nHow does the merging code work ?\n\n\nThe DDBs are made of two parts. The first\npart is a list of the parameters that were used to make the DDB,\nand the second part lists the 2DTEs and 3DTEs.\n\n\nThe merging code will check if the following variables are exactly\nthe same in the different input DDB : natom,\n\nntypat\n, \nnband\n, \nacell\n, \namu\n, \necut\n, \nixc\n, lloc, \nngfft\n, \nocc\n, \nrprim\n,\n\ntypat\n, \nxred\n, zion.\n\n\nFor \nnband\n and \nocc\n, the value of \noccopt\n is taken into account\n(see abinit help file). If possible, MRGDDB will produce\na DDB with occopt=0.\n\n\nIn case of two different data sets, the code will print an error message and stop.\nThe code cannot merge two DDB that have been generated\nusing two different geometries\nor convergence (\necut\n, \u2026) parameters.\n\n\nThe only exception is connected to the possibility to use Time-reversal\nsymmetry to decrease the number of special k points when the\nwavevector of the perturbation is Gamma. In that case, the code\nwill merge the DDBs and put the largest set of k-points inside\nthe new DDB.\n\n\nMRGDDB will copy the latest date of the transfer or current\nDDB and copy it in the new DDB.\n\n\nIt will also take the less accurate tolwfr and copy it in the new DDB.\n\n\nThis ends the first part of the action of MRGDDB, namely\nto compare the information of the two different DDB.\n\n\nWhen the checking is done, MRGDDB will check the content\nof the different data blocks and constitute the new DDB by\ncopying sequentially the non-identical blocks and merging the\nidentical blocks. In case two elements are identical, MRGDDB\ncopies the value of the transfer DDB.\n(This latter property makes it easy to get rid of old, erroneous data\nand put new, correct data in its place)\n\n\nFinally, the summary of the block content of the DDB is provided\nat the end of the DDB file.",
            "title": "Mrgddb"
        },
        {
            "location": "/user-guide/help_optic/",
            "text": "This file explains the i/o parameters needed for the calculation of the\nfrequency dependent linear optical dielectric function and second order\nnonlinear optical susceptibility, in the RPA approximation (sum over states\nusing independent electronic states) thanks to the Optic utility of the ABINIT\npackage.\n\n\nThe user is advised to be familiar with the main \nhelp_abinit\n before\nreading the present file.\n\n\nA knowledge of the computation of the linear response d/dk perturbation,\nexplained in the \nABINIT (respfn) help file\n, is also\nrequested. Actually, a full understanding of the ABINIT treatment of\nperturbation (respfn) should NOT be requested in order to use Optic, but with\nthe present ordering of the help files and tutorial, this is not obvious. In a\nfuture version, the tutorials and help files will be reorder and modified.\n\n\nIt will be easier to discover the present file with the help of the tutorial (\nlesson_optic\n).\n\nIt is worthwhile to print this help file, for ease of reading.\n\n\n\n\n\n\n1. Introduction\n\n\n2. How to run Optic ?\n\n\n3. Optic input file and input variables\n\n\n4. Optic output files\n\n\n4.1. Linear optical response data files\n\n\n4.2. Non-linear optical response data files\n\n\n\n\n\n\n5. Trouble shooting\n\n\n\n\n\n\n\n\n1. Introduction \n\u00b6\n\n\nOptic allows to compute the frequency dependent linear optical dielectric\nfunction and second order nonlinear optical susceptibility. An introduction to\nsuch computations is given in the following paper :\n\n\n\n\nRef. 1 : S. Sharma and C. Ambrosch-Draxl Physica Scripta T109, 128 (2004) or online: \nhttp://arxiv.org/abs/cond-mat/0305016\n\n\n\n\nThe following are also very useful references :\n\n\n\n\nRef. 2 : James L. P. Hughes and J. E. Sipe, Phys. Rev. B 53 10751 (1996) \n\n\nRef. 3 : C. Ambrosch-Draxl and J. O. Sofo, online: \nhttp://arxiv.org/abs/cond-mat/0402523\n\n\nRef. 4 : S. Sharma J. K. Dewhurst and C. Ambrosch-Draxl Phys. Rev. B 67 165332 (2003) or online: \nhttp://arxiv.org/abs/cond-mat/0211512\n\n\n\n\nBefore going to the detailed explanation of the Optic utility, the user is\nadvised to get familiar to the theory behind it, explained in these\nreferences. So, either you know this theory and you continue the tutorial, or\nyou should stop the tutorial here, and read at least Ref. 1.\n\n\nThe specific purpose of the Optic utility is to read in the position matrix\nelements generated by ABINIT (also giving the momentum matrix elements), and\nthen use Eq. 46 in Ref. 1 to determine the linear and Eqs. 49, 50 and 51 in\nRef. 1 to determine the nonlinear optical response of the material under\ninvestigation.\n\n\n\n\n2. How to run Optic ? \n\u00b6\n\n\nThe use of Optic is quite simple :\n\n\n    $ optic < optic.files > optic.log\n\n\n\n\n\nwhere the optic.files file contains three information : the name of the input\nfile, the name of an output file (actually unused), and the root name for all\nother output files. These input files will be described in the next section.\n\n\nHowever, before being able to use Optic, you must have obtained, from the main\nabinit program, four different files, corresponding to the physical system\nthat you want to study:\n\n\n\n\nThe ground state wavefunction file, indexed with _WFK \n\n\nThree files containing the matrix elements of the position operator (or the derivative with respect to wavevector), one for each direction of space\n\n\n\n\nSupposing you have read the \nmain ABINIT help file\n, the\nproduction of the first file should not require any additional explanation.\nHowever, the way to obtain the matrix elements is worth explaining.\n\nThe long-wave method as well as the Berry-phase treatment of electric field,\nallow to establish the equivalence between the off-diagonal matrix elements of\nthe position operator, and the off-diagonal matrix elements of the derivative\nwith respect to the wavevector (d/dk), for the periodic part of the Bloch\nfunctions, see for example section VI of X. Gonze, Phys. Rev. B 55, 10337\n(1997), or Nunes and Gonze, Phys. Rev. B 63, 155107 (2001), and references\ntherein. Moreover, a straightforward relationship exists between these matrix\nelements, and the matrix elements of the momentum operator.\n\n\nThe main abinit program has the capability to compute derivatives of\nwavefunctions with respect to their wavevector. This is explained in the\n\nABINIT (respfn) help file\n. Such a calculation implies\ntreating three d/dk perturbations, with numbers 3\nnatom+1, 3\nnatom+2 and\n3*natom+3 (that is, for a unit cell with 2 atoms, perturbations number 7, 8\nand 9). In the 2-atom case, the associated files needed for Optic have the\nindex _1WF7 , _1WF8 , and _1WF9 .\n\n\nThe formalism implemented in Optic treats explicitly the eigenstates lying in\nthe range of energy between the lowest occupied wavefunction and the highest\none plus the maximal excitation energy (chosen by the user). All the other\nones are neglected. This has two important consequences for the preliminary\nruns :\n\n\n\n\nThe ground calculation must produce explicitly all the eigenstates and eigenvalues for that target range of energy, so it cannot be restricted to the occupied wavefunctions only\n\n\nOne does not need the full change of Bloch wavefunctions with respect to d/dk, but only the matrix elements between the wavefunctions of this range of energy\n\n\n\n\nBecause of the latter, the computation of the response to d/dk perturbations\nis much shorter than usual : indeed, the matrix elements between the\nexplicitly ground-state wavefunctions are computed at the very beginning of\nthe abinit(respfn) run. It is not worth to make a full calculation of the\nmodification of the wavefunctions due to a change of wavevector.\n\n\n\n\n3. Optic input file and input variables \n\u00b6\n\n\nA typical optic.files file is presented below :\n\n\n    optic.in     ! Name of input file\n    optic.out    ! Unused\n    optic        ! Root name for all files that will be produced\n\n\n\n\n\nPlease note that the format of input files for Optic has changed from Abinit\nv8.0 Since very few input parameters are required for Optic, the optic.in file\ncontains them with the namelist format. The order of the three parts, namely\nFILES, PARAMETERS and COMPUTATIONS must be kept unaltered.\n\n\n    &FILES\n     ddkfile_1 = 'toptic_1o_DS4_1WF7',\n     ddkfile_2 = 'toptic_1o_DS5_1WF8',\n     ddkfile_3 = 'toptic_1o_DS6_1WF9',\n     wfkfile = 'toptic_1o_DS3_WFK'\n    /\n    &PARAMETERS\n     broadening = 0.002,\n     domega = 0.0003,\n     maxomega = 0.3,\n     scissor = 0.000,\n     tolerance = 0.002\n    /\n    &COMPUTATIONS\n     num_lin_comp = 1,\n     lin_comp = 11,\n     num_nonlin_comp = 2,\n     nonlin_comp = 123,222,\n    /\n\n\n\n\n\n\n\nddkfile_X : name of the ddk file on the direction X (no default)\n\nVariable type: string with the filename  \n\n\nSpecify the filename that has been produced by the preparatory Abinit run.\nThis file must contain the matrix elements of the d/dk operator along\ndirection X. It must not contain the first-order wavefunctions and may be\ngenerated using prtwf 3.\n\nYou should make sure that the number of bands, of spin channels and of\nk-points are the same in all the files.  \n\n\nGo to the top\n\n\n\n\nwfkfile : name of the wfk file (no default)\n\nVariable type: string with the filename  \n\n\nSpecify the filename that has been produced by the preparatory Abinit run.\nThis file must contain the eigenenergies on the set of k-points and bands to\nbe included in the calculation.\n\nYou should make sure that the number of bands, of spin channels and of\nk-points are the same in all the files.  \n\n\nGo to the top\n\n\n\n\nbroadening (default = 1.0d-3 Ha)\n\nVariable type: real parameter, given in Hartree  \n\n\nIn Eq. 46 of Ref. 1, it is clear that when ever wnm(k) is equal to w, there is\na resonance. Numerically this would lead to an infinity. In order to avoid\nthis one could do two things. You could change the sum over k-points to\nintegration and then use linear tetrahedron method (see Ref. 2 for details).\nAnother way to get around the problem is, like we do in the present case,\navoid this singularity by adding a small complex number to the denominator.\nThis prevents the denominator from ever going to 0 and acts as a broadening to\nthe spectrum. The broadening should not be too large as this would wash out\nthe features in the spectrum.  \n\n\nGo to the top\n\n\n\n\ndomega : Frequency grid step (default = 1.0d-3 Ha)\n\nVariable type: two real parameters, given in Hartree  \n\n\nThe step and maximum sets your energy grid for the calculation using the\nformula number of energy mesh points=maximum/step (zero excluded). So in order\nto capture more features you can decrease the step size to get a finer energy\ngrid. In order to go to higher frequency, increase the maximum.  \n\n\nGo to the top\n\n\n\n\nmaxomega : Maximum of frequency grid (default = 1 Ha)\n\nVariable type: two real parameters, given in Hartree  \n\n\nThe step and maximum sets your energy grid for the calculation using the\nformula number of energy mesh points=maximum/step (zero excluded). So in order\nto capture more features you can decrease the step size to get a finer energy\ngrid. In order to go to higher frequency, increase the maximum.  \n\n\nGo to the top\n\n\n\n\nscissor : Scissors shift (default = 0.0 [ no scissor ])\n\nVariable type: real parameter, given in Hartree  \n\n\nLDA/GGA are well known to underestimate the band-gap by up to 100%. In order\nto get the optical spectrum and make a realistic comparison with experiments\none needs to correct for this. This can be achieved in two ways. The scissors\nshift is normally chosen to be the difference between the experimental and\ntheoretical band-gap and is used to shift the conduction bands only. Another\nway in which you do not have to rely on experimental data is to determine the\nself energy using the \nGW\napproach\n. In this case the\nopening of the gap due to the GW correction can be used as scissor shift.  \n\n\nGo to the top\n\n\n\n\ntolerance (default = 1.0d-3 Ha)\n\nVariable type: real parameter, given in Hartree  \n\n\nWhen energy denominators are smaller than tolerance, the term is discarded\nfrom the sum.  \n\n\nGo to the top\n\n\n\n\nnum_lin_comp: Number of components for linear response\n\nVariable type: integer  \n\n\nHow many components out of 9 of the linear optical dielectric tensor do you\nwant to calculate. Most of these are either equal or zero depending upon the\nsymmetry of the material (for detail see Ref. 3).\n\nNote that the directions are along the Cartesian axis.  \n\n\nGo to the top\n\n\n\n\nlin_comp: Components of the linear response\n\nVariable type: integers(num_lin_comp)  \n\n\nThis tells which component of the dielectric tensor you want to calculate.\nThese numbers are called a and b Eqs. 46 in Ref. 1. 1 2 3 represent x y and z\nrespectively. For example 11 would be xx and 32 would mean zy.  \n\n\nGo to the top\n\n\n\n\nnum_nonlin_comp: Number of components for nonlinear response\n\nVariable type: integer  \n\n\nHow many components out of 27 of the non-linear optical dielectric tensor do\nyou want to calculate. Most of these are either equal or zero depending upon\nthe symmetry of the material (for detail see Ref. 3).\n\nNote that the directions are along the Cartesian axis.  \n\n\nGo to the top\n\n\n\n\nnonlin_comp: Components of the nonlinear response\n\nVariable type: integers(num_nonlin_comp)  \n\n\nThis tells which component of the dielectric tensor you want to calculate.\nThese numbers are called a, b and c in Ref. 1. 1 2 3 represent x y and z\nrespectively. For example 111 would be xxx and 321 would mean zyx.  \n\n\nGo to the top\n\n\n\n\n\n\n4. Optic output files \n\u00b6\n\n\n4.1. Linear optical response data files\n\u00b6\n\n\nName: case_a_b-linopt.out\n\nContains the following 3 data sets\n\n\n\n\n1) Column 1 - energy(eV), column 2 - imaginary part of the ab component of the frequency dependent linear dielectric tensor.\n\n\n2) Column 1 - energy(eV), column 2 - real part of the ab component of the frequency dependent linear dielectric tensor.\n\n\n3) Column 1 - energy(eV), column 2 - absolute value of the ab component of the frequency dependent linear dielectric tensor.\n\n\n\n\nIn the header of the file you can find information about the calculation. Some\nresults for GaAs(LiF???) are presented in this document to show what can be\nexpected.\n\n\n4.2. Non-linear optical response data files\n\u00b6\n\n\nName: case_a_b_c-ChiKIND1.out\n\nKIND1:This can be TotIm, TotRe or TotAbs\n\nContains: column 1 - energy(eV), column 2 and 3 - imaginary (KIND1=TotIm),\nreal (KIND1=TotRe) or absolute (KIND1=TotAbs) value of the abc component of\nthe nonlinear optical susceptibility. Second column contains values in\nelectro-static units (esu) and third column contains values in the SI units.  \n\n\nName: case_a_b_c-ChiKIND2.out\n\nKIND2:This can be Im, Re or abs\n\nContains: column 1 - energy(eV), column 2, 3 inter and column 4, 5 intra band\ncontributions to the imaginary (KIND2=Im), real (KIND2=Re) or absolute\n(KIND2=Abs) value of the abc component of the nonlinear optical\nsusceptibility. These components are labeled as inter and intra in Eqs. 49-51\nin Ref. 1.  \n\n\nAll the values are in electro-static units (esu). In the header of all the\nabove files you can find information about the calculation. Some results of\nnonlinear optical spectrum for GaAs(LiF???) are presented in this document to\nshow what can be expected.\n\n\n\n\n5. Trouble shooting \n\u00b6\n\n\n1) All I get is zeros in my *-linopt.out file. Why?\n\n\nThere are several possibilities.\n\nLet us explore some of them here:\n\n\n\n\n(i) The component of the dielectric tensor that you are looking at could be zero due to symmetry of the crystal. Normally zz component is a good place to start. It is almost never zero. So check the file case__0003_0003-linopt.out.\n\n\n(ii) If the components zz is zero this is more serious, if you are using the default input file t57.in then please check that on the line number 10 the second number is 33. If you are not using the default input file please calculate the 33 (or zz) component and make sure it is not zero.\n\n\n(iii) If even zz component is zero then possibilities are endless maximum frequency on line number 6 of t57.in is too small, or the number of bands used for performing ground state calculation are too small.\n\n\n\n\n2) All I get is zeros in my *-ChiKIND.out file. Why?\n\n\nTwo most common mistakes are:\n\n\n\n\n(i) You are calculating the second order response for material with inversion symmetry in this case all the components will be correctly zero or very small like 10-15.\n\n\n(ii) Most components out of the 27 are zero due to the symmetry of the crystal. Please calculate a different component.",
            "title": "Optic"
        },
        {
            "location": "/user-guide/help_optic/#146-introduction",
            "text": "Optic allows to compute the frequency dependent linear optical dielectric\nfunction and second order nonlinear optical susceptibility. An introduction to\nsuch computations is given in the following paper :   Ref. 1 : S. Sharma and C. Ambrosch-Draxl Physica Scripta T109, 128 (2004) or online:  http://arxiv.org/abs/cond-mat/0305016   The following are also very useful references :   Ref. 2 : James L. P. Hughes and J. E. Sipe, Phys. Rev. B 53 10751 (1996)   Ref. 3 : C. Ambrosch-Draxl and J. O. Sofo, online:  http://arxiv.org/abs/cond-mat/0402523  Ref. 4 : S. Sharma J. K. Dewhurst and C. Ambrosch-Draxl Phys. Rev. B 67 165332 (2003) or online:  http://arxiv.org/abs/cond-mat/0211512   Before going to the detailed explanation of the Optic utility, the user is\nadvised to get familiar to the theory behind it, explained in these\nreferences. So, either you know this theory and you continue the tutorial, or\nyou should stop the tutorial here, and read at least Ref. 1.  The specific purpose of the Optic utility is to read in the position matrix\nelements generated by ABINIT (also giving the momentum matrix elements), and\nthen use Eq. 46 in Ref. 1 to determine the linear and Eqs. 49, 50 and 51 in\nRef. 1 to determine the nonlinear optical response of the material under\ninvestigation.",
            "title": "1. Introduction"
        },
        {
            "location": "/user-guide/help_optic/#246-how-to-run-optic",
            "text": "The use of Optic is quite simple :      $ optic < optic.files > optic.log  where the optic.files file contains three information : the name of the input\nfile, the name of an output file (actually unused), and the root name for all\nother output files. These input files will be described in the next section.  However, before being able to use Optic, you must have obtained, from the main\nabinit program, four different files, corresponding to the physical system\nthat you want to study:   The ground state wavefunction file, indexed with _WFK   Three files containing the matrix elements of the position operator (or the derivative with respect to wavevector), one for each direction of space   Supposing you have read the  main ABINIT help file , the\nproduction of the first file should not require any additional explanation.\nHowever, the way to obtain the matrix elements is worth explaining. \nThe long-wave method as well as the Berry-phase treatment of electric field,\nallow to establish the equivalence between the off-diagonal matrix elements of\nthe position operator, and the off-diagonal matrix elements of the derivative\nwith respect to the wavevector (d/dk), for the periodic part of the Bloch\nfunctions, see for example section VI of X. Gonze, Phys. Rev. B 55, 10337\n(1997), or Nunes and Gonze, Phys. Rev. B 63, 155107 (2001), and references\ntherein. Moreover, a straightforward relationship exists between these matrix\nelements, and the matrix elements of the momentum operator.  The main abinit program has the capability to compute derivatives of\nwavefunctions with respect to their wavevector. This is explained in the ABINIT (respfn) help file . Such a calculation implies\ntreating three d/dk perturbations, with numbers 3 natom+1, 3 natom+2 and\n3*natom+3 (that is, for a unit cell with 2 atoms, perturbations number 7, 8\nand 9). In the 2-atom case, the associated files needed for Optic have the\nindex _1WF7 , _1WF8 , and _1WF9 .  The formalism implemented in Optic treats explicitly the eigenstates lying in\nthe range of energy between the lowest occupied wavefunction and the highest\none plus the maximal excitation energy (chosen by the user). All the other\nones are neglected. This has two important consequences for the preliminary\nruns :   The ground calculation must produce explicitly all the eigenstates and eigenvalues for that target range of energy, so it cannot be restricted to the occupied wavefunctions only  One does not need the full change of Bloch wavefunctions with respect to d/dk, but only the matrix elements between the wavefunctions of this range of energy   Because of the latter, the computation of the response to d/dk perturbations\nis much shorter than usual : indeed, the matrix elements between the\nexplicitly ground-state wavefunctions are computed at the very beginning of\nthe abinit(respfn) run. It is not worth to make a full calculation of the\nmodification of the wavefunctions due to a change of wavevector.",
            "title": "2. How to run Optic ?"
        },
        {
            "location": "/user-guide/help_optic/#346-optic-input-file-and-input-variables",
            "text": "A typical optic.files file is presented below :      optic.in     ! Name of input file\n    optic.out    ! Unused\n    optic        ! Root name for all files that will be produced  Please note that the format of input files for Optic has changed from Abinit\nv8.0 Since very few input parameters are required for Optic, the optic.in file\ncontains them with the namelist format. The order of the three parts, namely\nFILES, PARAMETERS and COMPUTATIONS must be kept unaltered.      &FILES\n     ddkfile_1 = 'toptic_1o_DS4_1WF7',\n     ddkfile_2 = 'toptic_1o_DS5_1WF8',\n     ddkfile_3 = 'toptic_1o_DS6_1WF9',\n     wfkfile = 'toptic_1o_DS3_WFK'\n    /\n    &PARAMETERS\n     broadening = 0.002,\n     domega = 0.0003,\n     maxomega = 0.3,\n     scissor = 0.000,\n     tolerance = 0.002\n    /\n    &COMPUTATIONS\n     num_lin_comp = 1,\n     lin_comp = 11,\n     num_nonlin_comp = 2,\n     nonlin_comp = 123,222,\n    /   ddkfile_X : name of the ddk file on the direction X (no default) \nVariable type: string with the filename    Specify the filename that has been produced by the preparatory Abinit run.\nThis file must contain the matrix elements of the d/dk operator along\ndirection X. It must not contain the first-order wavefunctions and may be\ngenerated using prtwf 3. \nYou should make sure that the number of bands, of spin channels and of\nk-points are the same in all the files.    Go to the top   wfkfile : name of the wfk file (no default) \nVariable type: string with the filename    Specify the filename that has been produced by the preparatory Abinit run.\nThis file must contain the eigenenergies on the set of k-points and bands to\nbe included in the calculation. \nYou should make sure that the number of bands, of spin channels and of\nk-points are the same in all the files.    Go to the top   broadening (default = 1.0d-3 Ha) \nVariable type: real parameter, given in Hartree    In Eq. 46 of Ref. 1, it is clear that when ever wnm(k) is equal to w, there is\na resonance. Numerically this would lead to an infinity. In order to avoid\nthis one could do two things. You could change the sum over k-points to\nintegration and then use linear tetrahedron method (see Ref. 2 for details).\nAnother way to get around the problem is, like we do in the present case,\navoid this singularity by adding a small complex number to the denominator.\nThis prevents the denominator from ever going to 0 and acts as a broadening to\nthe spectrum. The broadening should not be too large as this would wash out\nthe features in the spectrum.    Go to the top   domega : Frequency grid step (default = 1.0d-3 Ha) \nVariable type: two real parameters, given in Hartree    The step and maximum sets your energy grid for the calculation using the\nformula number of energy mesh points=maximum/step (zero excluded). So in order\nto capture more features you can decrease the step size to get a finer energy\ngrid. In order to go to higher frequency, increase the maximum.    Go to the top   maxomega : Maximum of frequency grid (default = 1 Ha) \nVariable type: two real parameters, given in Hartree    The step and maximum sets your energy grid for the calculation using the\nformula number of energy mesh points=maximum/step (zero excluded). So in order\nto capture more features you can decrease the step size to get a finer energy\ngrid. In order to go to higher frequency, increase the maximum.    Go to the top   scissor : Scissors shift (default = 0.0 [ no scissor ]) \nVariable type: real parameter, given in Hartree    LDA/GGA are well known to underestimate the band-gap by up to 100%. In order\nto get the optical spectrum and make a realistic comparison with experiments\none needs to correct for this. This can be achieved in two ways. The scissors\nshift is normally chosen to be the difference between the experimental and\ntheoretical band-gap and is used to shift the conduction bands only. Another\nway in which you do not have to rely on experimental data is to determine the\nself energy using the  GW\napproach . In this case the\nopening of the gap due to the GW correction can be used as scissor shift.    Go to the top   tolerance (default = 1.0d-3 Ha) \nVariable type: real parameter, given in Hartree    When energy denominators are smaller than tolerance, the term is discarded\nfrom the sum.    Go to the top   num_lin_comp: Number of components for linear response \nVariable type: integer    How many components out of 9 of the linear optical dielectric tensor do you\nwant to calculate. Most of these are either equal or zero depending upon the\nsymmetry of the material (for detail see Ref. 3). \nNote that the directions are along the Cartesian axis.    Go to the top   lin_comp: Components of the linear response \nVariable type: integers(num_lin_comp)    This tells which component of the dielectric tensor you want to calculate.\nThese numbers are called a and b Eqs. 46 in Ref. 1. 1 2 3 represent x y and z\nrespectively. For example 11 would be xx and 32 would mean zy.    Go to the top   num_nonlin_comp: Number of components for nonlinear response \nVariable type: integer    How many components out of 27 of the non-linear optical dielectric tensor do\nyou want to calculate. Most of these are either equal or zero depending upon\nthe symmetry of the material (for detail see Ref. 3). \nNote that the directions are along the Cartesian axis.    Go to the top   nonlin_comp: Components of the nonlinear response \nVariable type: integers(num_nonlin_comp)    This tells which component of the dielectric tensor you want to calculate.\nThese numbers are called a, b and c in Ref. 1. 1 2 3 represent x y and z\nrespectively. For example 111 would be xxx and 321 would mean zyx.    Go to the top",
            "title": "3. Optic input file and input variables"
        },
        {
            "location": "/user-guide/help_optic/#446-optic-output-files",
            "text": "",
            "title": "4. Optic output files"
        },
        {
            "location": "/user-guide/help_optic/#41-linear-optical-response-data-files",
            "text": "Name: case_a_b-linopt.out \nContains the following 3 data sets   1) Column 1 - energy(eV), column 2 - imaginary part of the ab component of the frequency dependent linear dielectric tensor.  2) Column 1 - energy(eV), column 2 - real part of the ab component of the frequency dependent linear dielectric tensor.  3) Column 1 - energy(eV), column 2 - absolute value of the ab component of the frequency dependent linear dielectric tensor.   In the header of the file you can find information about the calculation. Some\nresults for GaAs(LiF???) are presented in this document to show what can be\nexpected.",
            "title": "4.1. Linear optical response data files"
        },
        {
            "location": "/user-guide/help_optic/#42-non-linear-optical-response-data-files",
            "text": "Name: case_a_b_c-ChiKIND1.out \nKIND1:This can be TotIm, TotRe or TotAbs \nContains: column 1 - energy(eV), column 2 and 3 - imaginary (KIND1=TotIm),\nreal (KIND1=TotRe) or absolute (KIND1=TotAbs) value of the abc component of\nthe nonlinear optical susceptibility. Second column contains values in\nelectro-static units (esu) and third column contains values in the SI units.    Name: case_a_b_c-ChiKIND2.out \nKIND2:This can be Im, Re or abs \nContains: column 1 - energy(eV), column 2, 3 inter and column 4, 5 intra band\ncontributions to the imaginary (KIND2=Im), real (KIND2=Re) or absolute\n(KIND2=Abs) value of the abc component of the nonlinear optical\nsusceptibility. These components are labeled as inter and intra in Eqs. 49-51\nin Ref. 1.    All the values are in electro-static units (esu). In the header of all the\nabove files you can find information about the calculation. Some results of\nnonlinear optical spectrum for GaAs(LiF???) are presented in this document to\nshow what can be expected.",
            "title": "4.2. Non-linear optical response data files"
        },
        {
            "location": "/user-guide/help_optic/#546-trouble-shooting",
            "text": "1) All I get is zeros in my *-linopt.out file. Why?  There are several possibilities. \nLet us explore some of them here:   (i) The component of the dielectric tensor that you are looking at could be zero due to symmetry of the crystal. Normally zz component is a good place to start. It is almost never zero. So check the file case__0003_0003-linopt.out.  (ii) If the components zz is zero this is more serious, if you are using the default input file t57.in then please check that on the line number 10 the second number is 33. If you are not using the default input file please calculate the 33 (or zz) component and make sure it is not zero.  (iii) If even zz component is zero then possibilities are endless maximum frequency on line number 6 of t57.in is too small, or the number of bands used for performing ground state calculation are too small.   2) All I get is zeros in my *-ChiKIND.out file. Why?  Two most common mistakes are:   (i) You are calculating the second order response for material with inversion symmetry in this case all the components will be correctly zero or very small like 10-15.  (ii) Most components out of the 27 are zero due to the symmetry of the crystal. Please calculate a different component.",
            "title": "5. Trouble shooting"
        },
        {
            "location": "/input_variables/varlist_abinit/",
            "text": "a\n\n\nb\n\n\nc\n\n\nd\n\n\ne\n\n\nf\n\n\ng\n\n\ni\n\n\nj\n\n\nk\n\n\nl\n\n\nm\n\n\nn\n\n\no\n\n\np\n\n\nq\n\n\nr\n\n\ns\n\n\nt\n\n\nu\n\n\nv\n\n\nw\n\n\nx\n\n\nz\n\n\n\n\n\n\n\n        \n\n\naccuracy\n \nacell\n \nadpimd\n \nadpimd_gamma\n \nalgalch\n \namu\n \nangdeg\n \nasr\n \natvshift\n \nautoparal\n \nawtr\n\n\n\n\n\n\nbandpp\n \nbdberry\n \nbdeigrf\n \nbdgw\n \nberryopt\n \nberrysav\n \nberrystep\n \nbfield\n \nbmass\n \nboxcenter\n \nboxcutmin\n \nbrvltt\n \nbs_algorithm\n \nbs_calctype\n \nbs_coulomb_term\n \nbs_coupling\n \nbs_eh_cutoff\n \nbs_exchange_term\n \nbs_freq_mesh\n \nbs_hayd_term\n \nbs_haydock_niter\n \nbs_haydock_tol\n \nbs_interp_kmult\n \nbs_interp_m3_width\n \nbs_interp_method\n \nbs_interp_mode\n \nbs_interp_prep\n \nbs_interp_rl_nb\n \nbs_loband\n \nbs_nstates\n \nbuiltintest\n \nbxctmindg\n\n\n\n\n\n\ncd_customnimfrqs\n \ncd_frqim_method\n \ncd_full_grid\n \ncd_halfway_freq\n \ncd_imfrqs\n \ncd_max_freq\n \ncd_subset_freq\n \ncgtyphf\n \ncharge\n \nchempot\n \nchkexit\n \nchkprim\n \nchksymbreak\n \nchneut\n \ncineb_start\n \ncpuh\n \ncpum\n \ncpus\n\n\n\n\n\n\nd3e_pert1_atpol\n \nd3e_pert1_dir\n \nd3e_pert1_elfd\n \nd3e_pert1_phon\n \nd3e_pert2_atpol\n \nd3e_pert2_dir\n \nd3e_pert2_elfd\n \nd3e_pert2_phon\n \nd3e_pert3_atpol\n \nd3e_pert3_dir\n \nd3e_pert3_elfd\n \nd3e_pert3_phon\n \nddamp\n \nddb_ngqpt\n \nddb_shiftq\n \ndelayperm\n \ndensfor_pred\n \ndensty\n \ndfield\n \ndfpt_sciss\n \ndiecut\n \ndiegap\n \ndielam\n \ndielng\n \ndiemac\n \ndiemix\n \ndiemixmag\n \ndiismemory\n \ndilatmx\n \ndipdip\n \ndmatpawu\n \ndmatpuopt\n \ndmatudiag\n \ndmft_dc\n \ndmft_entropy\n \ndmft_iter\n \ndmft_mxsf\n \ndmft_nlambda\n \ndmft_nwli\n \ndmft_nwlo\n \ndmft_read_occnd\n \ndmft_rslf\n \ndmft_solv\n \ndmft_t2g\n \ndmft_tolfreq\n \ndmft_tollc\n \ndmftbandf\n \ndmftbandi\n \ndmftcheck\n \ndmftctqmc_basis\n \ndmftctqmc_check\n \ndmftctqmc_correl\n \ndmftctqmc_gmove\n \ndmftctqmc_grnns\n \ndmftctqmc_meas\n \ndmftctqmc_mov\n \ndmftctqmc_mrka\n \ndmftctqmc_order\n \ndmftctqmc_triqs_nleg\n \ndmftqmc_l\n \ndmftqmc_n\n \ndmftqmc_seed\n \ndmftqmc_therm\n \ndosdeltae\n \ndtion\n \ndynimage\n\n\n\n\n\n\necut\n \necuteps\n \necutsigx\n \necutsm\n \necutwfn\n \neffmass\n \nefield\n \nefmas\n \nefmas_bands\n \nefmas_calc_dirs\n \nefmas_deg\n \nefmas_deg_tol\n \nefmas_dim\n \nefmas_dirs\n \nefmas_n_dirs\n \nefmas_ntheta\n \neinterp\n \nelph2_imagden\n \nenunit\n \neph_extrael\n \neph_fermie\n \neph_fsewin\n \neph_fsmear\n \neph_intmeth\n \neph_mustar\n \neph_ngqpt_fine\n \neph_task\n \neph_transport\n \neshift\n \nesmear\n \nexchmix\n \nexchn2n3d\n \nextrapwf\n\n\n\n\n\n\nf4of2_sla\n \nf6of2_sla\n \nfband\n \nfermie_nest\n \nfftalg\n \nfftcache\n \nfftgw\n \nfreqim_alpha\n \nfreqremax\n \nfreqremin\n \nfreqspmax\n \nfreqspmin\n \nfriction\n \nfrzfermi\n \nfxcartfactor\n\n\n\n\n\n\nga_algor\n \nga_fitness\n \nga_n_rules\n \nga_opt_percent\n \nga_rules\n \ngenafm\n \nget1den\n \nget1wf\n \ngetbscoup\n \ngetbseig\n \ngetbsreso\n \ngetcell\n \ngetddb\n \ngetddk\n \ngetden\n \ngetgam_eig2nkq\n \ngethaydock\n \ngetocc\n \ngetqps\n \ngetscr\n \ngetsuscep\n \ngetvel\n \ngetwfk\n \ngetwfkfine\n \ngetwfq\n \ngetxcart\n \ngetxred\n \ngoprecon\n \ngoprecprm\n \ngpu_devices\n \ngpu_linalg_limit\n \ngw_customnfreqsp\n \ngw_freqsp\n \ngw_frqim_inzgrid\n \ngw_frqre_inzgrid\n \ngw_frqre_tangrid\n \ngw_invalid_freq\n \ngw_nqlwl\n \ngw_nstep\n \ngw_qlwl\n \ngw_qprange\n \ngw_sctype\n \ngw_sigxcore\n \ngw_toldfeig\n \ngwcalctyp\n \ngwcomp\n \ngwencomp\n \ngwfockmix\n \ngwgamma\n \ngwls_band_index\n \ngwls_correlation\n \ngwls_dielectric_model\n \ngwls_exchange\n \ngwls_first_seed\n \ngwls_kmax_analytic\n \ngwls_kmax_complement\n \ngwls_kmax_numeric\n \ngwls_kmax_poles\n \ngwls_list_proj_freq\n \ngwls_model_parameter\n \ngwls_n_proj_freq\n \ngwls_npt_gauss_quad\n \ngwls_nseeds\n \ngwls_print_debug\n \ngwls_recycle\n \ngwls_second_model_parameter\n \ngwls_sternheimer_kmax\n \ngwmem\n \ngwpara\n \ngwrpacorr\n\n\n\n\n\n\niatcon\n \niatfix\n \niatfixx\n \niatfixy\n \niatfixz\n \niatsph\n \niboxcut\n \nicoulomb\n \nicutcoul\n \nieig2rf\n \nimgmov\n \ninclvkb\n \nintxc\n \niomode\n \nionmov\n \niprcel\n \niprcfc\n \niqpt\n \nirandom\n \nird1den\n \nird1wf\n \nirdbscoup\n \nirdbseig\n \nirdbsreso\n \nirdddb\n \nirdddk\n \nirdden\n \nirdhaydock\n \nirdqps\n \nirdscr\n \nirdsuscep\n \nirdvdw\n \nirdwfk\n \nirdwfkfine\n \nirdwfq\n \niscf\n \nisecur\n \nistatimg\n \nistatr\n \nistatshft\n \nistwfk\n \nixc\n \nixcpositron\n\n\n\n\n\n\njdtset\n \njellslab\n \njfielddir\n \njpawu\n\n\n\n\n\n\nkberry\n \nkpt\n \nkptbounds\n \nkptgw\n \nkptnrm\n \nkptns\n \nkptopt\n \nkptrlatt\n \nkptrlen\n \nkssform\n\n\n\n\n\n\nlexexch\n \nlocalrdwf\n \nlotf_classic\n \nlotf_nitex\n \nlotf_nneigx\n \nlotf_version\n \nlpawu\n\n\n\n\n\n\nmacro_uj\n \nmagcon_lambda\n \nmagconon\n \nmax_ncpus\n \nmaxestep\n \nmaxnsym\n \nmband\n \nmbpt_sciss\n \nmdf_epsinf\n \nmdtemp\n \nmdwall\n \nmem_test\n \nmep_mxstep\n \nmep_solver\n \nmgfft\n \nmgfftdg\n \nmixalch\n \nmpw\n \nmqgrid\n \nmqgriddg\n\n\n\n\n\n\nnatcon\n \nnatfix\n \nnatfixx\n \nnatfixy\n \nnatfixz\n \nnatom\n \nnatpawu\n \nnatrd\n \nnatsph\n \nnatsph_extra\n \nnatvshift\n \nnband\n \nnbandhf\n \nnbandkss\n \nnbdblock\n \nnbdbuf\n \nnberry\n \nnc_xccc_gspace\n \nnconeq\n \nnctime\n \nndivk\n \nndivsm\n \nndtset\n \nndynimage\n \nneb_algo\n \nneb_spring\n \nnelect\n \nnfft\n \nnfftdg\n \nnfreqim\n \nnfreqmidm\n \nnfreqre\n \nnfreqsp\n \nngfft\n \nngfftdg\n \nngkpt\n \nngqpt\n \nnimage\n \nnkpath\n \nnkpt\n \nnkptgw\n \nnkpthf\n \nnline\n \nnloc_alg\n \nnloc_mem\n \nnnos\n \nnnsclo\n \nnnsclohf\n \nnobj\n \nnomegasf\n \nnomegasi\n \nnomegasrd\n \nnormpawu\n \nnoseinert\n \nnp_slk\n \nnpband\n \nnpfft\n \nnphf\n \nnpimage\n \nnpkpt\n \nnppert\n \nnpsp\n \nnpspalch\n \nnpspinor\n \nnpulayit\n \nnpvel\n \nnpweps\n \nnpwkss\n \nnpwsigx\n \nnpwwfn\n \nnqpt\n \nnqptdm\n \nnscforder\n \nnshiftk\n \nnshiftq\n \nnspden\n \nnspinor\n \nnsppol\n \nnstep\n \nnsym\n \nntime\n \nntimimage\n \nntypalch\n \nntypat\n \nntyppure\n \nnucdipmom\n \nnwfshist\n \nnzchempot\n\n\n\n\n\n\nobjaat\n \nobjaax\n \nobjan\n \nobjarf\n \nobjaro\n \nobjatr\n \nobjbat\n \nobjbax\n \nobjbn\n \nobjbrf\n \nobjbro\n \nobjbtr\n \nocc\n \noccopt\n \nomegasimax\n \nomegasrdmax\n \noptcell\n \noptdriver\n \noptforces\n \noptnlxccc\n \noptstress\n \nortalg\n\n\n\n\n\n\npapiopt\n \nparal_atom\n \nparal_kgb\n \nparal_rf\n \npawcpxocc\n \npawcross\n \npawecutdg\n \npawfatbnd\n \npawlcutd\n \npawlmix\n \npawmixdg\n \npawnhatxc\n \npawnphi\n \npawntheta\n \npawnzlm\n \npawoptmix\n \npawoptosc\n \npawovlp\n \npawprt_b\n \npawprt_k\n \npawprtden\n \npawprtdos\n \npawprtvol\n \npawprtwf\n \npawspnorb\n \npawstgylm\n \npawsushat\n \npawujat\n \npawujrad\n \npawujv\n \npawusecp\n \npawxcdev\n \nph_intmeth\n \nph_ndivsm\n \nph_ngqpt\n \nph_nqpath\n \nph_nqshift\n \nph_qpath\n \nph_qshift\n \nph_smear\n \nph_wstep\n \npimass\n \npimd_constraint\n \npitransform\n \nplowan_bandf\n \nplowan_bandi\n \nplowan_compute\n \nplowan_iatom\n \nplowan_it\n \nplowan_lcalc\n \nplowan_natom\n \nplowan_nbl\n \nplowan_nt\n \nplowan_projcalc\n \nplowan_realspace\n \npolcen\n \nposdoppler\n \npositron\n \nposnstep\n \nposocc\n \npostoldfe\n \npostoldff\n \nppmfrq\n \nppmodel\n \nprepanl\n \nprepgkk\n \nprepscphon\n \nprt1dm\n \nprtatlist\n \nprtbbb\n \nprtbltztrp\n \nprtcif\n \nprtden\n \nprtdensph\n \nprtdipole\n \nprtdos\n \nprtdosm\n \nprtebands\n \nprtefg\n \nprteig\n \nprtelf\n \nprtfc\n \nprtfsurf\n \nprtgden\n \nprtgeo\n \nprtgkk\n \nprtgsr\n \nprtkden\n \nprtkpt\n \nprtlden\n \nprtnabla\n \nprtnest\n \nprtphbands\n \nprtphdos\n \nprtphsurf\n \nprtposcar\n \nprtpot\n \nprtpsps\n \nprtspcur\n \nprtstm\n \nprtsuscep\n \nprtvclmb\n \nprtvdw\n \nprtvha\n \nprtvhxc\n \nprtvol\n \nprtvolimg\n \nprtvpsp\n \nprtvxc\n \nprtwant\n \nprtwf\n \nprtwf_full\n \nprtxml\n \nptcharge\n \nptgroupma\n \npvelmax\n \npw_unbal_thresh\n\n\n\n\n\n\nqmass\n \nqprtrb\n \nqpt\n \nqptdm\n \nqptn\n \nqptnrm\n \nqptopt\n \nqptrlatt\n \nquadmom\n\n\n\n\n\n\nrandom_atpos\n \nratsph\n \nratsph_extra\n \nrcut\n \nrecefermi\n \nrecgratio\n \nrecnpath\n \nrecnrec\n \nrecptrott\n \nrecrcut\n \nrectesteg\n \nrectolden\n \nred_dfield\n \nred_efield\n \nred_efieldbar\n \nrestartxf\n \nrf2_dkdk\n \nrfasr\n \nrfatpol\n \nrfddk\n \nrfdir\n \nrfelfd\n \nrfmagn\n \nrfmeth\n \nrfphon\n \nrfstrs\n \nrfuser\n \nrhoqpmix\n \nrprim\n \nrprimd\n\n\n\n\n\n\nscalecart\n \nscphon_supercell\n \nscphon_temp\n \nshiftk\n \nshiftq\n \nsignperm\n \nslabwsrad\n \nslabzbeg\n \nslabzend\n \nsmdelta\n \nso_psp\n \nspbroad\n \nspgaxor\n \nspgorig\n \nspgroup\n \nspgroupma\n \nspinat\n \nspinmagntarget\n \nspmeth\n \nspnorbscl\n \nstmbias\n \nstrfact\n \nstring_algo\n \nstrprecon\n \nstrtarget\n \nsymafm\n \nsymchi\n \nsymdynmat\n \nsymmorphi\n \nsymrel\n \nsymsigma\n\n\n\n\n\n\ntd_maxene\n \ntd_mexcit\n \ntfkinfunc\n \ntfw_toldfe\n \ntimopt\n \ntl_nprccg\n \ntl_radius\n \ntnons\n \ntoldfe\n \ntoldff\n \ntolimg\n \ntolmxde\n \ntolmxf\n \ntolrde\n \ntolrff\n \ntolsym\n \ntolvrs\n \ntolwfr\n \ntphysel\n \ntsmear\n \ntypat\n\n\n\n\n\n\nucrpa\n \nucrpa_bands\n \nucrpa_window\n \nudtset\n \nupawu\n \nuse_gemm_nonlop\n \nuse_gpu_cuda\n \nuse_nonscf_gkk\n \nuse_slk\n \nusedmatpu\n \nusedmft\n \nuseexexch\n \nusefock\n \nusekden\n \nusepaw\n \nusepawu\n \nusepotzero\n \nuserec\n \nuseria\n \nuserib\n \nuseric\n \nuserid\n \nuserie\n \nuserra\n \nuserrb\n \nuserrc\n \nuserrd\n \nuserre\n \nusewvl\n \nusexcnhat\n \nuseylm\n\n\n\n\n\n\nvaclst\n \nvacnum\n \nvacuum\n \nvacwidth\n \nvcutgeo\n \nvdw_df_acutmin\n \nvdw_df_aratio\n \nvdw_df_damax\n \nvdw_df_damin\n \nvdw_df_dcut\n \nvdw_df_dratio\n \nvdw_df_dsoft\n \nvdw_df_gcut\n \nvdw_df_ndpts\n \nvdw_df_ngpts\n \nvdw_df_nqpts\n \nvdw_df_nrpts\n \nvdw_df_nsmooth\n \nvdw_df_phisoft\n \nvdw_df_qcut\n \nvdw_df_qratio\n \nvdw_df_rcut\n \nvdw_df_rsoft\n \nvdw_df_threshold\n \nvdw_df_tolerance\n \nvdw_df_tweaks\n \nvdw_df_zab\n \nvdw_nfrag\n \nvdw_supercell\n \nvdw_tol\n \nvdw_tol_3bt\n \nvdw_typfrag\n \nvdw_xc\n \nvel\n \nvel_cell\n \nvis\n \nvprtrb\n\n\n\n\n\n\nw90iniprj\n \nw90prtunk\n \nwfoptalg\n \nwtatcon\n \nwtk\n \nwtq\n \nwvl_bigdft_comp\n \nwvl_crmult\n \nwvl_frmult\n \nwvl_hgrid\n \nwvl_ngauss\n \nwvl_nprccg\n\n\n\n\n\n\nxangst\n \nxc_denpos\n \nxc_tb09_c\n \nxcart\n \nxclevel\n \nxred\n \nxredsph_extra\n \nxyzfile\n\n\n\n\n\n\nzcut\n \nzeemanfield\n \nziontypat\n \nznucl",
            "title": "All Variables"
        },
        {
            "location": "/input_variables/varbas/",
            "text": "accuracy\n\u00b6\n\n\nMnemonics: ACCURACY\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nAllows to tune the accuracy of a calculation by setting automatically the\nvariables \necut\n, \nboxcutmin\n, \nfband\n, \ntolvrs\n, \ntolmxf\n,\n\noptforces\n, \ntimopt\n, \nnpulayit\n, \nnstep\n, \nprteig\n, \nprtden\n,\nand if \nusepaw\n=1, \npawecutdg\n, \nbxctmindg\n, \npawxcdev\n, \npawmixdg\n,\n\npawovlp\n, \npawnhatxc\n, according to the following table:\n\n\naccuracy\n\n\n|\n\n\n1\n\n\n|\n\n\n2\n\n\n|\n\n\n3\n\n\n|\n\n\n4\n\n\n|\n\n\n5\n\n\n|\n\n\n6  \n\n\n\u2014|\u2014|\u2014|\u2014|\u2014|\u2014|\u2014  \n\n\necut\n\n\n|\n\n\nE_min\n\n\n|\n\n\nE_med\n\n\n|\n\n\nE_med\n\n\n|\n\n\nE_max\n\n\n|\n\n\nE_max\n\n\n|\n\n\nE_max\n  \n\n\npawecutdg\n\n\n|\n\n\necut\n\n\n|\n\n\necut\n\n\n|\n\n\n1.2*ecut\n\n\n|\n\n\n1.5*ecut\n\n\n|\n\n\n2*ecut\n\n\n|\n\n\n2*ecut  \n\n\nfband\n\n\n|\n\n\n0.5\n\n\n|\n\n\n0.5\n\n\n|\n\n\n0.5\n\n\n|\n\n\n0.5\n\n\n|\n\n\n0.75\n\n\n|\n\n\n0.75  \n\n\nboxcutmin\n\n\n|\n\n\n1.5\n\n\n|\n\n\n1.8\n\n\n|\n\n\n1.8\n\n\n|\n\n\n2.0\n\n\n|\n\n\n2.0\n\n\n|\n\n\n2.0\n  \n\n\nbxctmindg\n\n\n|\n\n\n1.5\n\n\n|\n\n\n1.8\n\n\n|\n\n\n1.8\n\n\n|\n\n\n2.0\n\n\n|\n\n\n2.0\n\n\n|\n\n\n2.0\n  \n\n\npawxcdev\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n2\n\n\n|\n\n\n2  \n\n\npawmixdg\n\n\n|\n\n\n0\n\n\n|\n\n\n0\n\n\n|\n\n\n0\n\n\n|\n\n\n0\n\n\n|\n\n\n1\n\n\n|\n\n\n1  \n\n\npawovlp\n\n\n|\n\n\n10\n\n\n|\n\n\n7\n\n\n|\n\n\n7\n\n\n|\n\n\n5\n\n\n|\n\n\n5\n\n\n|\n\n\n5\n  \n\n\npawnhatxc\n\n\n|\n\n\n0\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n  \n\n\ntolvrs\n\n\n|\n\n\n1.0d-3\n\n\n|\n\n\n1.0d-5\n\n\n|\n\n\n1.0d-7\n\n\n|\n\n\n1.0d-9\n\n\n|\n\n\n1.0d-10\n\n\n|\n\n\n1.0d-12  \n\n\ntolmxf\n\n\n|\n\n\n1.0d-3\n\n\n|\n\n\n5.0d-4\n\n\n|\n\n\n1.0d-4\n\n\n|\n\n\n5.0d-5\n\n\n|\n\n\n1.0d-6\n\n\n|\n\n\n1.0d-6  \n\n\noptforces\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n2\n\n\n|\n\n\n2\n\n\n|\n\n\n2\n\n\n|\n\n\n2\n  \n\n\ntimopt\n\n\n|\n\n\n0\n\n\n|\n\n\n0\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n  \n\n\nnpulayit\n\n\n|\n\n\n4\n\n\n|\n\n\n7\n\n\n|\n\n\n7\n\n\n|\n\n\n7\n\n\n|\n\n\n15\n\n\n|\n\n\n15  \n\n\nnstep\n\n\n|\n\n\n30\n\n\n|\n\n\n30\n\n\n|\n\n\n30\n\n\n|\n\n\n30\n\n\n|\n\n\n50\n\n\n|\n\n\n50  \n\n\nprteig\n\n\n|\n\n\n0\n\n\n|\n\n\n0\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n  \n\n\nprtden\n\n\n|\n\n\n0\n\n\n|\n\n\n0\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n\n\n|\n\n\n1\n  \n\n\nFor a parallel calculation, \ntimopt\n is enforced to be 0.\n\nE_min, E_med and E_max may be read from the pseudopotential file (available\nonly for XML PAW atomic data files). If E_min, E_med and E_max are not given\nin the pseudopotential file, \necut\n must be given in the input file and\nE_max=E_med=E_max=ecut.\n\nThe values in bold font are the default values of ABINIT. \naccuracy\n=4\ncorresponds to the default tuning of ABINIT. It is already a very accurate\ntuning.\n\nIf the user wants to modify one of the input variable automatically tuned by\n\naccuracy\n, he must put it in the input file. The other input variables\nautomatically tuned by \naccuracy\n will not be affected.\n\n\naccuracy\n=0 means that this input variable is desactivated.\n\n\nacell\n\u00b6\n\n\nMnemonics: CELL lattice vector scaling\n\nVariable type: real\n\nDimensions: (3)\n\ncommentdims represented internally as acell(3,\nnimage\n)\n\nDefault value: 3*1  \n\n\nGives the length scales by which dimensionless primitive translations (in\n\nrprim\n) are to be multiplied. By default, given in Bohr atomic units (1\nBohr=0.5291772108 Angstroms), although Angstrom can be specified, if\npreferred, since \nacell\n has the \u2018\nLENGTH\n\u2018 characteristics. See further\ndescription of \nacell\n related to the \nrprim\n input variable, the\n\nscalecart\n input variable, and the associated internal \nrprimd\n input\nvariable.\n\n\nNote that \nacell\n is NOT the length of the conventional orthogonal basis\nvectors, but the scaling factors of the primitive vectors. Use \nscalecart\n\nto scale the cartesian coordinates.\n\n\nangdeg\n\u00b6\n\n\nMnemonics: ANGles in DEGrees\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: None\n\nComment: deduced from \u2018\nrprim\n\u2018  \n\n\nGives the angles between directions of primitive vectors of the unit cell (in\ndegrees), as an alternative to the input array \nrprim\n . Will be used to set\nup \nrprim\n, that, together with the array \nacell\n, will be used to define\nthe primitive vectors.\n\n\n\n\n[angdeg]\n is the angle between the 2nd and 3rd vectors, \n\n\n[angdeg]\n is the angle between the 1st and 3rd vectors, \n\n\n[angdeg]\n is the angle between the 1st and 2nd vectors, \n\n\n\n\nIf the three angles are equal within 1.0d-12 (except if they are exactly 90\ndegrees), the three primitive vectors are chosen so that the trigonal symmetry\nthat exchange them is along the z cartesian axis :\n\n\nR1=( a , 0,c)\nR2=(-a/2, sqrt(3)/2*a,c)\nR3=(-a/2,-sqrt(3)/2*a,c)\n\n\n\n\n\nwhere a  2  +c  2  =1.0d0\n\nIf the angles are not all equal (or if they are all 90 degrees), one will have\nthe following generic form :\n\n\n\n\nR1=(1,0,0) \n\n\nR2=(a,b,0) \n\n\nR3=(c,d,e) \n\n\n\n\nwhere each of the vectors is normalized, and form the desired angles with the\nothers.\n\n\necut\n\u00b6\n\n\nMnemonics: Energy CUToff\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: None  \n\n\nUsed for kinetic energy cutoff which controls number of planewaves at given k\npoint by:\n\n(1/2)[(2 Pi)*(k+Gmax)]  2  =\necut\n for Gmax.\n\nAll planewaves inside this \u201cbasis sphere\u201d centered at k are included in the\nbasis (except if \ndilatmx\n is defined).\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \necut\n has the\n\u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV)\n\nThis is the single parameter which can have an enormous effect on the quality\nof a calculation; basically the larger \necut\n is, the better converged the\ncalculation is. For fixed geometry, the total energy MUST always decrease as\n\necut\n is raised because of the variational nature of the problem.\n\n\n_ Usually one runs at least several calculations at various \necut\n to\ninvestigate the convergence needed for reliable results. _\n\n\nFor k-points whose coordinates are build from 0 or 1/2, the implementation of\ntime-reversal symmetry that links coefficients of the wavefunctions in\nreciprocal space has been realized. See the input variable \nistwfk\n. If\nactivated (which corresponds to the Default mode), this input variable\n\nistwfk\n will allow to divide the number of plane wave (npw) treated\nexplicitly by a factor of two. Still, the final result should be identical\nwith the \u2018full\u2019 set of plane waves.\n\n\nSee the input variable \necutsm\n, for the smoothing of the kinetic energy,\nneeded to optimize unit cell parameters.\n\n\neinterp\n\u00b6\n\n\nMnemonics: Electron bands INTERPolation\n\nVariable type: real\n\nDimensions: (4)\n\nDefault value: [0, 0, 0, 0]  \n\n\nThis variable activates the interpolation of the electronic eigenvalues. It\ncan be used to interpolate KS eigenvalues at the end of the GS run or to\ninterpolate GW energies in sigma calculations (\noptdriver\n = 4). The k-path\ncan be specified with \nkptbounds\n and \nnkpath\n. einterp consists of 4\nentries. The first element specificies the interpolation method.\n\n\n\n\n0 \u2013> No interpolation (default) \n\n\n1 \u2013> Star-function interpolation (Shankland-Koelling-Wood Fourier interpolation scheme, see \nPickett1988\n \n\n\n2 \u2013> B-spline interpolation. \n\n\n\n\nThe meaning of the other entries depend on the interpolation technique\nselected.\n\nIn the case of star-function interpolation:\n\n\n\n\neinterp(2): Number of star-functions per ab-initio k-point \n\n\neinterp(3): If non-zero, activate Fourier filtering according to Eq 9 of \nUehara2000\n. In this case, rcut is given by einterp(2) * Rmax where Rmax is the maximum length of the lattice vectors included in the star expansion \n\n\neinterp(4): Used if einterp(2) /= 0. It defines rsigma in Eq 9\n\n\n\n\nFor B-spline interpolation: einterp(2:4): Order of B-spline for the three\nreduced directions. Cubic spline (3) is the recomended value.\n\n\niscf\n\u00b6\n\n\nMnemonics: Integer for Self-Consistent-Field cycles\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 17 if \nusepaw\n==1,\n0 if \nusewvl\n==1,\n7 otherwise.\n\n\nControls the self-consistency.\n\nPositive values => this is the usual choice for doing the usual ground\nstate (GS) calculations or for structural relaxation, where the potential has\nto be determined self-consistently. The choice between different algorithms\nfor SCF is possible :\n\n\n\n\n=0 => SCF cycle, direct minimization scheme on the gradient of the wavefunctions. This algorithm is faster than diagonalisation and mixing but is working only for systems with a gap. It is implemented only on the wavelet basis set, when \nusewvl\n=1. \n\n\n\n\n=1 => get the largest eigenvalue of the SCF cycle \n\n(\nDEVELOP\n option, used with \nirdwfk\n=1 or \nirdwfq\n=1)\n\n\n\n\n\n\n=2 => SCF cycle, simple mixing of the potential \n\n\n\n\n=3 => SCF cycle, Anderson mixing of the potential \n\n\n=4 => SCF cycle, Anderson mixing of the potential based on the two previous iterations \n\n\n=5 => SCF cycle, CG based on the minim. of the energy with respect to the potential \n\n\n=7 => SCF cycle, Pulay mixing of the potential based on the \nnpulayit\n previous iterations \n\n\n=12 => SCF cycle, simple mixing of the density \n\n\n=13 => SCF cycle, Anderson mixing of the density \n\n\n=14 => SCF cycle, Anderson mixing of the density based on the two previous iterations \n\n\n=15 => SCF cycle, CG based on the minim. of the energy with respect to the density \n\n\n=17 => SCF cycle, Pulay mixing of the density based on the \nnpulayit\n previous iterations \n\n\nOther positive values, including zero ones, are not allowed. \n\n\n\n\nSuch algorithms for treating the \u201cSCF iteration history\u201d should be coupled\nwith accompanying algorithms for the SCF \u201cpreconditioning\u201d. See the input\nvariable \niprcel\n. The default value \niprcel\n=0 is often a good choice,\nbut for inhomogeneous systems, you might gain a lot with \niprcel\n=45.\n\n\n(Warning : if \niscf\n>10, at present (v4.6), the energy printed at each\nSCF cycle is not variational - this should not affect the other properties,\nand at convergence, all values are OK)\n\n\n- In the norm-conserving case, the default option is \niscf\n=7, which is a\ncompromise between speed and reliability. The value \niscf\n= 2 is safer but\nslower.\n\n- In the PAW case, default option is \niscf\n=17. In PAW you have the\npossibility to mix density/potential on the fine or coarse FFT grid (see\n\npawmixdg\n).\n\n- Note that a Pulay mixing (\niscf\n=7 or 17) with \nnpulayit\n =1 (resp. 2)\nis equivalent to an Anderson mixing with \niscf\n=3 or 13 (resp. 4 or 14).\n\n- Also note that:\n\n\n when mixing is done on potential (iscf <10), total energy is computed by \u201cdirect\u201d decomposition. \n\n\n when mixing is done on density (iscf >=10), total energy is computed by \u201cdouble counting\u201d decomposition. \n\n\u201cDirect\u201d and \u201cdouble counting\u201d decomposition of energy are equal when SCF\ncycle is converged. Note that, when using GGA XC functionals, these\ndecompositions of energy can be slightly different due to imprecise\ncomputation of density gradients on FFT grid (difference decreases as size of\nFFT grid increases - see \necut\n for NC pseudopotentials, \npawecutdg\n for\nPAW).  \n\n\nOther (negative) options:\n\n\n\n\n\n\n= -2 => a non-self-consistent calculation is to be done; in this case an electron density rho(r) on a real space grid (produced in a previous calculation) will be read from a disk file (automatically if \nndtset\n=0, or according to the value of \ngetden\n if \nndtset\n/=0). \n\nThe name of the density file must be given as indicated in the \n section 4\n\n of \nhelp_abinit\n.\n\niscf\n=-2 would be used for band structure calculations, to permit\ncomputation of the eigenvalues of occupied and unoccupied states at arbitrary\nk points in the fixed self consistent potential produced by some integration\ngrid of k points. Due to this typical use, ABINIT insist that either\n\nprtvol\n>2 or \nprteig\n does not vanish when there are more than 50 k\npoints.\n\nTo compute the eigenvalues (and wavefunctions) of unoccupied states in a\nseparate (non-selfconsistent) run, the user should save the self-consistent\nrho(r) and then run \niscf\n=-2 for the intended set of k-points and bands.\n\nTo prepare a run with \niscf\n=-2, a density file can be produced using the\nparameter \nprtden\n (see its description). When a self-consistent set of\nwavefunctions is already available, abinit can be used with \nnstep\n=0 (see\nTest_v2/t47.in), and the adequate value of \nprtden\n.\n\n\n\n\n\n\n= -3 => like -2, but initialize \nocc\n and \nwtk\n, directly or indirectly (using \nngkpt\n or \nkptrlatt\n) depending on the value of \noccopt\n. \n\nFor GS, this option might be used to generate Density-of-states (thanks to\n\nprtdos\n), or to produce STM charge density map (thanks to \nprtstm\n).\n\nFor RF, this option is needed to compute the response to ddk perturbation.\n\n\n\n\n\n\n= -1 => like -2, but the non-self-consistent calculation is followed by the determination of excited states within \nTDDFT\n. This is only possible for \nnkpt\n=1, with \nkpt\n=0 0 0. Note that the oscillator strength needs to be defined with respect to an origin of coordinate, thanks to the input variable \nboxcenter\n. The maximal number of Kohn-Sham excitations to be used to build the excited state \nTDDFT\n matrix can be defined by \ntd_mexcit\n, or indirectly by the maximum Kohn-Sham excitation energy \ntd_maxene\n. \n\n\n\n\n\n\nixc\n\u00b6\n\n\nMnemonics: Integer for eXchange-Correlation choice\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nComment: Default corresponds to Teter parametrization. However, if all the pseudopotentials have the same value of pspxc, the initial value of ixc will be that common value  \n\n\nControls the choice of exchange and correlation (xc). The list of XC\nfunctionals is given below. Positive values are for ABINIT native library of\nXC functionals, while negative values are for calling the much wider set of\nfunctionals from the ETSF LibXC library (by M. Marques), also available at the\n\n ETSF library Web page\n\n\nNote that the choice made here should agree with the choice made in generating\nthe original pseudopotential, except for \nixc\n=0 (usually only used for\ndebugging). A warning is issued if this is not the case. However, the choices\n\nixc\n=1, 2, 3 and 7 are fits to the same data, from Ceperley-Alder, and are\nrather similar, at least for spin-unpolarized systems.\n\nThe choice between the non-spin-polarized and spin-polarized case is governed\nby the value of \nnsppol\n (see below).\n\n\n Native ABINIT XC functionals \n\n\nNOTE : in the implementation of the spin-dependence of these functionals, and\nin order to avoid divergences in their derivatives, the interpolating function\nbetween spin-unpolarized and fully-spin-polarized function has been slightly\nmodified, by including a zeta rescaled by 1.d0-1.d-6. This should affect total\nenergy at the level of 1.d-6Ha, and should have an even smaller effect on\ndifferences of energies, or derivatives.\n\nThe value \nixc\n=10 is used internally : gives the difference between\n\nixc\n=7 and \nixc\n=9, for use with an accurate RPA correlation energy.\n\n\n\n\n\n\n0=> NO xc; \n\n\n\n\n\n\n1=> LDA or LSD, Teter Pade parametrization (4/93, published in \nGoedecker1996\n, which reproduces Perdew-Wang (which reproduces Ceperley-Alder!). \n\n\n\n\n2=> LDA, Perdew-Zunger-Ceperley-Alder (no spin-polarization) \nPerdew1981\n \n\n\n3=> LDA, old Teter rational polynomial parametrization (4/91) fit to Ceperley-Alder data (no spin-polarization) \n\n\n4=> LDA, Wigner functional (no spin-polarization) \n\n\n5=> LDA, Hedin-Lundqvist functional (no spin-polarization) \n\n\n6=> LDA, \u201cX-alpha\u201d functional (no spin-polarization) \n\n\n7=> LDA or LSD, Perdew-Wang 92 functional \n\n\n8=> LDA or LSD, x-only part of the Perdew-Wang 92 functional \n\n\n\n\n9=> LDA or LSD, x- and RPA correlation part of the Perdew-Wang 92 functional \n\n\n\n\n\n\n11=> GGA, Perdew-Burke-Ernzerhof GGA functional \n\n\n\n\n12=> GGA, x-only part of Perdew-Burke-Ernzerhof GGA functional \n\n\n13=> GGA potential of van Leeuwen-Baerends, while for energy, Perdew-Wang 92 functional \n\n\n14=> GGA, revPBE of Y. Zhang and W. Yang, Phys. Rev. Lett. 80, 890 (1998) \n\n\n15=> GGA, RPBE of B. Hammer, L.B. Hansen and J.K. Norskov, Phys. Rev. B 59, 7413 (1999) \n\n\n16=> GGA, HTCH93 of F.A. Hamprecht, A.J. Cohen, D.J. Tozer, N.C. Handy, J. Chem. Phys. 109, 6264 (1998) \n\n\n17=> GGA, HTCH120 of A.D. Boese, N.L. Doltsinis, N.C. Handy, and M. Sprik, J. Chem. Phys 112, 1670 (1998) - The usual HCTH functional. \n\n\n18=> (NOT AVAILABLE : used internally for GGA BLYP pseudopotentials from M. Krack, see Theor. Chem. Acc. 114, 145 (2005), available from the \n CP2K repository \n - use the LibXC instead, with \nixc\n=-106131. \n\n\n\n\n19=> (NOT AVAILABLE : used internally for GGA BP86 pseudopotentials from M. Krack, see Theor. Chem. Acc. 114, 145 (2005), available from the \n CP2K repository \n - use the LibXC instead, with \nixc\n=-106132. \n\n\n\n\n\n\n20=> Fermi-Amaldi xc ( -1/N Hartree energy, where N is the number of electrons per cell ; G=0 is not taken into account however), for \nTDDFT\n tests. No spin-pol. Does not work for RF. \n\n\n\n\n21=> same as 20, except that the xc-kernel is the LDA (\nixc\n=1) one, for \nTDDFT\n tests. \n\n\n22=> same as 20, except that the xc-kernel is the Burke-Petersilka-Gross hybrid, for \nTDDFT\n tests. \n\n\n23=> GGA of Z. Wu and R.E. Cohen, Phys. Rev. 73, 235116 (2006). \n\n\n24=> GGA, C09x exchange of V. R. Cooper, PRB 81, 161104(R) (2010). \n\n\n26=> GGA, HTCH147 of A.D. Boese, N.L. Doltsinis, N.C. Handy, and M. Sprik, J. Chem. Phys 112, 1670 (1998). \n\n\n27=> GGA, HTCH407 of A.D. Boese, and N.C. Handy, J. Chem. Phys 114, 5497 (2001). \n\n\n\n\n28=> (NOT AVAILABLE : used internally for GGA OLYP pseudopotentials from M. Krack, see Theor. Chem. Acc. 114, 145 (2005), available from the \n CP2K repository \n - use the LibXC instead, with \nixc\n=-110131. \n\n\n\n\n\n\n40=> Hartree-Fock \n\n\n\n\n41=> PBE0, J.P. Perdew, M. Ernzerhof and K. Burke, J. Chem. Phys. 105, 9982 (1996) \n\n\n42=> PBE0-1/3, C.A. Guido, E. Bremond, C. Adamo and P. Cortona, J. Chem. Phys. 138, 021104 (2013) \n\n\n\n\n ETSF Lib XC functionals \n\n\nNote that you must compile ABINIT with the LibXC plug-in in order to be able\nto access these functionals.\n\nThe LibXC functionals are accessed by \n negative values \n of \nixc\n. The\nLibXC contains functional forms for either exchange-only functionals,\ncorrelation-only functionals, or combined exchange and correlation\nfunctionals. Each of them is to be specified by a three-digit number. In case\nof a combined exchange and correlation functional, only one such three-digit\nnumber has to be specified as value of \nixc\n, with a minus sign (to indicate\nthat it comes from the LibXC). In the case of separate exchange functional\n(let us represent its identifier by XXX) and correlation functional (let us\nrepresent its identified by CCC), a six-digit number will have to be specified\nfor \nixc\n, by concatenation, be it XXXCCC or CCCXXX. As an example,\n\nixc\n=-020 gives access to the Teter93 LDA, while \nixc\n=-101130 gives\naccess to the PBE GGA. In version 0.9 of LibXC (December 2008), there are 16\nthree-dimensional (S)LDA functionals (1 for X, 14 for C, 1 for combined XC),\nand there are 41 three-dimensional GGA (23 for X, 8 for C, 10 for combined\nXC). Note that for a meta-GGA, the kinetic energy density is needed. This\nmeans having \nusekden\n=1 .\n\n\n(S)LDA functionals (do not forget to add a minus sign, as discussed above)\n\n\n\n\n001=> XC_LDA_X [PAM Dirac, Proceedings of the Cambridge Philosophical Society 26, 376 (1930); F Bloch, Zeitschrift fuer Physik 57, 545 (1929) ] \n\n\n002=> XC_LDA_C_WIGNER Wigner parametrization [EP Wigner, Trans. Faraday Soc. 34, 678 (1938) ] \n\n\n003=> XC_LDA_C_RPA Random Phase Approximation [M Gell-Mann and KA Brueckner, Phys. Rev. 106, 364 (1957) ] \n\n\n004=> XC_LDA_C_HL Hedin & Lundqvist [L Hedin and BI Lundqvist, J. Phys. C 4, 2064 (1971) ] \n\n\n005=> XC_LDA_C_GL ! Gunnarson & Lundqvist [O Gunnarsson and BI Lundqvist, PRB 13, 4274 (1976) ] \n\n\n006=> XC_LDA_C_XALPHA ! Slater\u2019s Xalpha ] \n\n\n007=> XC_LDA_C_VWN ! Vosko, Wilk, & Nussair [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ] \n\n\n008=> XC_LDA_C_VWN_RPA ! Vosko, Wilk, & Nussair (RPA) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ] \n\n\n009=> XC_LDA_C_PZ ! Perdew & Zunger \nPerdew1981\n \n\n\n010=> XC_LDA_C_PZ_MOD ! Perdew & Zunger (Modified) \nPerdew1981\n Modified to improve the matching between the low and high rs part ] \n\n\n011=> XC_LDA_C_OB_PZ ! Ortiz & Ballone (PZ) [G Ortiz and P Ballone, Phys. Rev. B 50, 1391 (1994) ; G Ortiz and P Ballone, Phys. Rev. B 56, 9970(E) (1997) ; \nPerdew1981\n ] \n\n\n012=> XC_LDA_C_PW ! Perdew & Wang [JP Perdew and Y Wang, Phys. Rev. B 45, 13244 (1992) ] \n\n\n013=> XC_LDA_C_PW_MOD ! Perdew & Wang (Modified) [JP Perdew and Y Wang, Phys. Rev. B 45, 13244 (1992) ; Added extra digits to some constants as in the PBE routine see \n https://www.chem.uci.edu/~kieron/dftold2/pbe.php \n (at some point it was available at http://dft.uci.edu/pbe.php) ] \n\n\n014=> XC_LDA_C_OB_PW ! Ortiz & Ballone (PW) [G Ortiz and P Ballone, Phys. Rev. B 50, 1391 (1994) ; G Ortiz and P Ballone, Phys. Rev. B 56, 9970(E) (1997) ; JP Perdew and Y Wang, Phys. Rev. B 45, 13244 (1992) ] \n\n\n017=> XC_LDA_C_vBH ! von Barth & Hedin [U von Barth and L Hedin, J. Phys. C: Solid State Phys. 5, 1629 (1972) ] \n\n\n020=> XC_LDA_XC_TETER93 ! Teter 93 parametrization [S Goedecker, M Teter, J Hutter, PRB 54, 1703 (1996) ] \n\n\n022=> XC_LDA_C_ML1 ! Modified LSD (version 1) of Proynov and Salahub [EI Proynov and D Salahub, Phys. Rev. B 49, 7874 (1994) ] \n\n\n023=> XC_LDA_C_ML2 ! Modified LSD (version 2) of Proynov and Salahub [EI Proynov and D Salahub, Phys. Rev. B 49, 7874 (1994) ] \n\n\n024=> XC_LDA_C_GOMBAS ! Gombas parametrization [P. Gombas, Pseudopotentials (Springer-Verlag, New York, 1967) ] \n\n\n025=> XC_LDA_C_PW_RPA ! Perdew & Wang fit of the RPA [JP Perdew and Y Wang, Phys. Rev. B 45, 13244 (1992) ] \n\n\n027=> XC_LDA_C_RC04 ! Ragot-Cortona [S Ragot and P Cortona, J. Chem. Phys. 121, 7671 (2004) ] \n\n\n028=> XC_LDA_C_VWN_1 ! Vosko, Wilk, & Nussair (1) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ] \n\n\n029=> XC_LDA_C_VWN_2 ! Vosko, Wilk, & Nussair (2) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ] \n\n\n030=> XC_LDA_C_VWN_3 ! Vosko, Wilk, & Nussair (3) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ] \n\n\n031=> XC_LDA_C_VWN_4 ! Vosko, Wilk, & Nussair (4) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ] \n\n\n\n\nGGA functionals (do not forget to add a minus sign, as discussed above)\n\n\n\n\n84=> XC_GGA_C_OP_XALPHA ! one-parameter progressive functional (G96 version) [T Tsuneda, T Suzumura, and K Hirao, J. Chem. Phys. 111, 5656 (1999) ] \n\n\n85=> XC_GGA_C_OP_G96 ! one-parameter progressive functional (G96 version) [T Tsuneda, T Suzumura, and K Hirao, J. Chem. Phys. 111, 5656 (1999) ] \n\n\n86=> XC_GGA_C_OP_PBE ! one-parameter progressive functional (PBE version) [T Tsuneda, T Suzumura, and K Hirao, J. Chem. Phys. 111, 5656 (1999) ] \n\n\n87=> XC_GGA_C_OP_B88 ! one-parameter progressive functional (B88 version) [T Tsuneda, T Suzumura, and K Hirao, J. Chem. Phys. 111, 5656 (1999) ] \n\n\n88=> XC_GGA_C_FT97 ! Filatov & Thiel correlation [M Filatov & W Thiel, Int. J. Quant. Chem. 62, 603-616 (1997) ; M Filatov & W Thiel, Mol Phys 91, 847 (1997) ] WARNING : this functional is not tested. Use at your own risks. \n\n\n89=> XC_GGA_C_SPBE ! PBE correlation to be used with the SSB exchange [M Swart, M Sola, and FM Bickelhaupt, J. Chem. Phys. 131, 094103 (2009) ] \n\n\n90=> XC_GGA_X_SSB_SW ! Swarta, Sola and Bickelhaupt correction to PBE [M Swart, M Sola, and FM Bickelhaupt, J. Comp. Meth. Sci. Engin. 9, 69 (2009) ] \n\n\n91=> XC_GGA_X_SSB ! WARNING : This functional gives NaN on IBM (XG20130608). Swarta, Sola and Bickelhaupt [M Swart, M Sola, and FM Bickelhaupt, J. Chem. Phys. 131, 094103 (2009) ] \n\n\n92=> XC_GGA_X_SSB_D ! WARNING : This functional gives NaN on IBM (XG20130608). Swarta, Sola and Bickelhaupt dispersion [M Swart, M Sola, and FM Bickelhaupt, J. Chem. Phys. 131, 094103 (2009) ] \n\n\n93=> XC_GGA_XC_HCTH_407P ! HCTH/407+ [AD Boese, A Chandra, JML Martin, and Dominik Marx, J. Chem. Phys. 119, 5965 (2003) ] \n\n\n94=> XC_GGA_XC_HCTH_P76 ! HCTH p=7/6 [G Menconi, PJ Wilson, and DJ Tozer, J. Chem. Phys. 114, 3958 (2001) ] \n\n\n95=> XC_GGA_XC_HCTH_P14 ! HCTH p=1/4 [G Menconi, PJ Wilson, and DJ Tozer, J. Chem. Phys. 114, 3958 (2001) ] \n\n\n96=> XC_GGA_XC_B97_GGA1 ! Becke 97 GGA-1 [AJ Cohen and NC Handy, Chem. Phys. Lett. 316, 160-166 (2000) ] \n\n\n97=> XC_GGA_XC_HCTH_A ! HCTH-A [FA Hamprecht, AJ Cohen, DJ Tozer, and NC Handy, J. Chem. Phys. 109, 6264 (1998) ] \n\n\n98=> XC_GGA_X_BPCCAC ! BPCCAC (GRAC for the energy) [E Bremond, D Pilard, I Ciofini, H Chermette, C Adamo, and P Cortona, Theor Chem Acc 131, 1184 (2012) ] \n\n\n99=> XC_GGA_C_REVTCA ! Tognetti, Cortona, Adamo (revised) [V Tognetti, P Cortona, and C Adamo, Chem. Phys. Lett. 460, 536-539 (2008) ] \n\n\n100=> XC_GGA_C_TCA ! Tognetti, Cortona, Adamo [V Tognetti, P Cortona, and C Adamo, J. Chem. Phys. 128, 034101 (2008) ] \n\n\n101=> XC_GGA_X_PBE ! Perdew, Burke & Ernzerhof exchange [JP Perdew, K Burke, and M Ernzerhof, Phys. Rev. Lett. 77, 3865 (1996) ; JP Perdew, K Burke, and M Ernzerhof, Phys. Rev. Lett. 78, 1396(E) (1997) ] \n\n\n102=> XC_GGA_X_PBE_R ! Perdew, Burke & Ernzerhof exchange (revised) [Y Zhang and W Yang, Phys. Rev. Lett 80, 890 (1998) ] \n\n\n103=> XC_GGA_X_B86 ! Becke 86 Xalfa,beta,gamma [AD Becke, J. Chem. Phys 84, 4524 (1986) ] \n\n\n104=> XC_GGA_X_HERMAN ! Herman Xalphabeta GGA [F Herman, JP Van Dyke, and IB Ortenburger, Phys. Rev. Lett. 22, 807 (1969) ; F Herman, IB Ortenburger, and JP Van Dyke, Int. J. Quantum Chem. Symp. 3, 827 (1970) ] \n\n\n105=> XC_GGA_X_B86_MGC ! Becke 86 Xalfa,beta,gamma (with mod. grad. correction) [AD Becke, J. Chem. Phys 84, 4524 (1986) ; AD Becke, J. Chem. Phys 85, 7184 (1986) ] \n\n\n106=> XC_GGA_X_B88 ! Becke 88 [AD Becke, Phys. Rev. A 38, 3098 (1988) ] \n\n\n107=> XC_GGA_X_G96 ! Gill 96 [PMW Gill, Mol. Phys. 89, 433 (1996) ] \n\n\n108=> XC_GGA_X_PW86 ! Perdew & Wang 86 [JP Perdew and Y Wang, Phys. Rev. B 33, 8800 (1986) ] \n\n\n109=> XC_GGA_X_PW91 ! Perdew & Wang 91 [JP Perdew, in Proceedings of the 21st Annual International Symposium on the Electronic Structure of Solids, ed. by P Ziesche and H Eschrig (Akademie Verlag, Berlin, 1991), p. 11. ; JP Perdew, JA Chevary, SH Vosko, KA Jackson, MR Pederson, DJ Singh, and C Fiolhais, Phys. Rev. B 46, 6671 (1992) ; JP Perdew, JA Chevary, SH Vosko, KA Jackson, MR Pederson, DJ Singh, and C Fiolhais, Phys. Rev. B 48, 4978(E) (1993) ] \n\n\n110=> XC_GGA_X_OPTX ! Handy & Cohen OPTX 01 [NC Handy and AJ Cohen, Mol. Phys. 99, 403 (2001) ] \n\n\n111=> XC_GGA_X_DK87_R1 ! dePristo & Kress 87 (version R1) [AE DePristo and JD Kress, J. Chem. Phys. 86, 1425 (1987) ] \n\n\n112=> XC_GGA_X_DK87_R2 ! dePristo & Kress 87 (version R2) [AE DePristo and JD Kress, J. Chem. Phys. 86, 1425 (1987) ] \n\n\n113=> XC_GGA_X_LG93 ! Lacks & Gordon 93 [DJ Lacks and RG Gordon, Phys. Rev. A 47, 4681 (1993) ] \n\n\n114=> XC_GGA_X_FT97_A ! Filatov & Thiel 97 (version A) [M Filatov and W Thiel, Mol. Phys 91, 847 (1997) ] \n\n\n115=> XC_GGA_X_FT97_B ! Filatov & Thiel 97 (version B) [M Filatov and W Thiel, Mol. Phys 91, 847 (1997) ] \n\n\n116=> XC_GGA_X_PBE_SOL ! Perdew, Burke & Ernzerhof exchange (solids) [JP Perdew, et al, Phys. Rev. Lett. 100, 136406 (2008) ] \n\n\n117=> XC_GGA_X_RPBE ! Hammer, Hansen & Norskov (PBE-like) [B Hammer, LB Hansen and JK Norskov, Phys. Rev. B 59, 7413 (1999) ] \n\n\n118=> XC_GGA_X_WC ! Wu & Cohen [Z Wu and RE Cohen, Phys. Rev. B 73, 235116 (2006) ] \n\n\n119=> XC_GGA_X_mPW91 ! Modified form of PW91 by Adamo & Barone [C Adamo and V Barone, J. Chem. Phys. 108, 664 (1998) ] \n\n\n120=> XC_GGA_X_AM05 ! Armiento & Mattsson 05 exchange [R Armiento and AE Mattsson, Phys. Rev. B 72, 085108 (2005) ; AE Mattsson, R Armiento, J Paier, G Kresse, JM Wills, and TR Mattsson, J. Chem. Phys. 128, 084714 (2008) ] \n\n\n121=> XC_GGA_X_PBEA ! Madsen (PBE-like) [G Madsen, Phys. Rev. B 75, 195108 (2007) ] \n\n\n122=> XC_GGA_X_MPBE ! Adamo & Barone modification to PBE [C Adamo and V Barone, J. Chem. Phys. 116, 5933 (2002) ] \n\n\n123=> XC_GGA_X_XPBE ! xPBE reparametrization by Xu & Goddard [X Xu and WA Goddard III, J. Chem. Phys. 121, 4068 (2004) ] \n\n\n125=> XC_GGA_X_BAYESIAN ! Bayesian best fit for the enhancement factor [JJ Mortensen, K Kaasbjerg, SL Frederiksen, JK Norskov, JP Sethna, and KW Jacobsen, Phys. Rev. Lett. 95, 216401 (2005) ] \n\n\n126=> XC_GGA_X_PBE_JSJR ! PBE JSJR reparametrization by Pedroza, Silva & Capelle [LS Pedroza, AJR da Silva, and K. Capelle, Phys. Rev. B 79, 201106(R) (2009) ] \n\n\n130=> XC_GGA_C_PBE ! Perdew, Burke & Ernzerhof correlation [JP Perdew, K Burke, and M Ernzerhof, Phys. Rev. Lett. 77, 3865 (1996) ; JP Perdew, K Burke, and M Ernzerhof, Phys. Rev. Lett. 78, 1396(E) (1997) ] \n\n\n131=> XC_GGA_C_LYP ! Lee, Yang & Parr [C Lee, W Yang and RG Parr, Phys. Rev. B 37, 785 (1988) B Miehlich, A Savin, H Stoll and H Preuss, Chem. Phys. Lett. 157, 200 (1989) ] \n\n\n132=> XC_GGA_C_P86 ! Perdew 86 [JP Perdew, Phys. Rev. B 33, 8822 (1986) ] \n\n\n133=> XC_GGA_C_PBE_SOL ! Perdew, Burke & Ernzerhof correlation SOL [JP Perdew, et al, Phys. Rev. Lett. 100, 136406 (2008) ] \n\n\n134=> XC_GGA_C_PW91 ! Perdew & Wang 91 [JP Perdew, JA Chevary, SH Vosko, KA Jackson, MR Pederson, DJ Singh, and C Fiolhais, Phys. Rev. B 46, 6671 (1992) ] \n\n\n135=> XC_GGA_C_AM05 ! Armiento & Mattsson 05 correlation [ R Armiento and AE Mattsson, Phys. Rev. B 72, 085108 (2005) ; AE Mattsson, R Armiento, J Paier, G Kresse, JM Wills, and TR Mattsson, J. Chem. Phys. 128, 084714 (2008) ] \n\n\n136=> XC_GGA_C_XPBE ! xPBE reparametrization by Xu & Goddard [X Xu and WA Goddard III, J. Chem. Phys. 121, 4068 (2004) ] \n\n\n137=> XC_GGA_C_LM ! Langreth and Mehl correlation [DC Langreth and MJ Mehl, Phys. Rev. Lett. 47, 446 (1981) ] \n\n\n138=> XC_GGA_C_PBE_JRGX ! JRGX reparametrization by Pedroza, Silva & Capelle [LS Pedroza, AJR da Silva, and K. Capelle, Phys. Rev. B 79, 201106(R) (2009) ] \n\n\n139=> XC_GGA_X_OPTB88_VDW ! Becke 88 reoptimized to be used with vdW functional of Dion et al [J Klimes, DR Bowler, and A Michaelides, J. Phys.: Condens. Matter 22, 022201 (2010) ] \n\n\n140=> XC_GGA_X_PBEK1_VDW ! PBE reparametrization for vdW [J Klimes, DR Bowler, and A Michaelides, J. Phys.: Condens. Matter 22, 022201 (2010) ] \n\n\n141=> XC_GGA_X_OPTPBE_VDW ! PBE reparametrization for vdW [J Klimes, DR Bowler, and A Michaelides, J. Phys.: Condens. Matter 22, 022201 (2010) ] \n\n\n142=> XC_GGA_X_RGE2 ! Regularized PBE [A Ruzsinszky, GI Csonka, and G Scuseria, J. Chem. Theory Comput. 5, 763 (2009) ] \n\n\n143=> XC_GGA_C_RGE2 ! Regularized PBE [A Ruzsinszky, GI Csonka, and G Scuseria, J. Chem. Theory Comput. 5, 763 (2009) ] \n\n\n144=> XC_GGA_X_RPW86 ! refitted Perdew & Wang 86 [ED Murray, K Lee and DC Langreth, J. Chem. Theory Comput. 5, 2754-2762 (2009) ] \n\n\n145=> XC_GGA_X_KT1 ! Keal and Tozer version 1 [TW Keal and DJ Tozer, J. Chem. Phys. 119, 3015 (2003) ] \n\n\n146=> XC_GGA_XC_KT2 ! WARNING : This functional gives NaN on IBM (XG20130608). Keal and Tozer version 2 [TW Keal and DJ Tozer, J. Chem. Phys. 119, 3015 (2003) ] \n\n\n147=> XC_GGA_C_WL ! Wilson & Levy [LC Wilson and M Levy, Phys. Rev. B 41, 12930 (1990) ] \n\n\n148=> XC_GGA_C_WI ! Wilson & Ivanov [LC Wilson & S Ivanov, Int. J. Quantum Chem. 69, 523-532 (1998) ] \n\n\n149=> XC_GGA_X_MB88 ! Modified Becke 88 for proton transfer [V Tognetti and C Adamo, J. Phys. Chem. A 113, 14415-14419 (2009) ] \n\n\n150=> XC_GGA_X_SOGGA ! Second-order generalized gradient approximation [Y Zhao and DG Truhlar, J. Chem. Phys. 128, 184109 (2008) ; http://comp.chem.umn.edu/mfm/index.html ] \n\n\n151=> XC_GGA_X_SOGGA11 ! Second-order generalized gradient approximation 2011 [R Peverati, Y Zhao, and DG Truhlar, J. Phys. Chem. Lett. 2, 1911-1997 (2011); http://comp.chem.umn.edu/mfm/index.html ] \n\n\n152=> XC_GGA_C_SOGGA11 ! Second-order generalized gradient approximation 2011 [R Peverati, Y Zhao, and DG Truhlar, J. Phys. Chem. Lett. 2, 1911-1997 (2011); http://comp.chem.umn.edu/mfm/index.html ] \n\n\n153=> XC_GGA_C_WI0 ! Wilson & Ivanov initial version [LC Wilson & S Ivanov, Int. J. Quantum Chem. 69, 523-532 (1998) ] \n\n\n154=> XC_GGA_XC_TH1 ! Tozer and Handy v. 1 [DJ Tozer and NC Handy, J. Chem. Phys. 108, 2545 (1998) ] WARNING : this functional is not tested. Use at your own risks. \n\n\n155=> XC_GGA_XC_TH2 ! Tozer and Handy v. 2 [DJ Tozer and NC Handy, J. Phys. Chem. A 102, 3162 (1998) ] \n\n\n156=> XC_GGA_XC_TH3 ! Tozer and Handy v. 3 [DJ Tozer and NC Handy, Mol. Phys. 94, 707 (1998) ] \n\n\n157=> XC_GGA_XC_TH4 ! Tozer and Handy v. 4 [DJ Tozer and NC Handy, Mol. Phys. 94, 707 (1998) ] \n\n\n158=> XC_GGA_X_C09X ! C09x to be used with the VdW of Rutgers-Chalmers [VR Cooper, PRB 81, 161104(R) (2010) ] \n\n\n159=> XC_GGA_C_SOGGA11_X ! To be used with hyb_gga_x_SOGGA11-X [R Peverati and DG Truhlar, J. Chem. Phys. 135, 191102 (2011); http://comp.chem.umn.edu/mfm/index.html ] \n\n\n161=> XC_GGA_XC_HCTH_93 ! HCTH functional fitted to 93 molecules [FA Hamprecht, AJ Cohen, DJ Tozer, and NC Handy, J. Chem. Phys. 109, 6264 (1998) ] \n\n\n162=> XC_GGA_XC_HCTH_120 ! HCTH functional fitted to 120 molecules [AD Boese, NL Doltsinis, NC Handy, and M Sprik, J. Chem. Phys. 112, 1670 (2000) ] \n\n\n163=> XC_GGA_XC_HCTH_147 ! HCTH functional fitted to 147 molecules [AD Boese, NL Doltsinis, NC Handy, and M Sprik, J. Chem. Phys. 112, 1670 (2000) ] \n\n\n164=> XC_GGA_XC_HCTH_407 ! HCTH functional fitted to 407 molecules [AD Boese, and NC Handy, J. Chem. Phys. 114, 5497 (2001) ] \n\n\n165=> XC_GGA_XC_EDF1 ! Empirical functionals from Adamson, Gill, and Pople [RD Adamson, PMW Gill, and JA Pople, Chem. Phys. Lett. 284 6 (1998) ] \n\n\n166=> XC_GGA_XC_XLYP ! XLYP functional [X Xu and WA Goddard, III, PNAS 101, 2673 (2004) ] \n\n\n167=> XC_GGA_XC_B97 ! Becke 97 [AD Becke, J. Chem. Phys. 107, 8554-8560 (1997) ] \n\n\n168=> XC_GGA_XC_B97_1 ! Becke 97-1 [FA Hamprecht, AJ Cohen, DJ Tozer, and NC Handy, J. Chem. Phys. 109, 6264 (1998); AD Becke, J. Chem. Phys. 107, 8554-8560 (1997) ] \n\n\n169=> XC_GGA_XC_B97_2 ! Becke 97-2 [AD Becke, J. Chem. Phys. 107, 8554-8560 (1997) ] \n\n\n170=> XC_GGA_XC_B97_D ! Grimme functional to be used with C6 vdW term [S Grimme, J. Comput. Chem. 27, 1787 (2006) ] \n\n\n171=> XC_GGA_XC_B97_K ! Boese-Martin for Kinetics [AD Boese and JML Martin, J. Chem. Phys., Vol. 121, 3405 (2004) ] \n\n\n172=> XC_GGA_XC_B97_3 ! Becke 97-3 [TW Keal and DJ Tozer, J. Chem. Phys. 123, 121103 (2005) ] \n\n\n173=> XC_GGA_XC_PBE1W ! Functionals fitted for water [EE Dahlke and DG Truhlar, J. Phys. Chem. B 109, 15677 (2005) ] \n\n\n174=> XC_GGA_XC_MPWLYP1W ! Functionals fitted for water [EE Dahlke and DG Truhlar, J. Phys. Chem. B 109, 15677 (2005) ] \n\n\n175=> XC_GGA_XC_PBELYP1W ! Functionals fitted for water [EE Dahlke and DG Truhlar, J. Phys. Chem. B 109, 15677 (2005) ] \n\n\n176=> XC_GGA_XC_SB98_1a ! Schmider-Becke 98 parameterization 1a [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ] \n\n\n177=> XC_GGA_XC_SB98_1b ! Schmider-Becke 98 parameterization 1b [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ] \n\n\n178=> XC_GGA_XC_SB98_1c ! Schmider-Becke 98 parameterization 1c [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ] \n\n\n179=> XC_GGA_XC_SB98_2a ! Schmider-Becke 98 parameterization 2a [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ] \n\n\n180=> XC_GGA_XC_SB98_2b ! Schmider-Becke 98 parameterization 2b [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ] \n\n\n181=> XC_GGA_XC_SB98_2c ! Schmider-Becke 98 parameterization 2c [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ] \n\n\n183=> XC_GGA_X_OL2 ! Exchange form based on Ou-Yang and Levy v.2 [P Fuentealba and O Reyes, Chem. Phys. Lett. 232, 31-34 (1995) ; H Ou-Yang, M Levy, Int. J. of Quant. Chem. 40, 379-388 (1991) ] \n\n\n184=> XC_GGA_X_APBE ! mu fixed from the semiclassical neutral atom [LA Constantin, E Fabiano, S Laricchia, and F Della Sala, Phys. Rev. Lett. 106, 186406 (2011) ] \n\n\n186=> XC_GGA_C_APBE ! mu fixed from the semiclassical neutral atom [LA Constantin, E Fabiano, S Laricchia, and F Della Sala, Phys. Rev. Lett. 106, 186406 (2011) ] \n\n\n191=> XC_GGA_X_HTBS! Haas, Tran, Blaha, and Schwarz [P Haas, F Tran, P Blaha, and K Schwarz, Phys. Rev. B 83, 205117 (2011) ] \n\n\n192=> XC_GGA_X_AIRY ! Constantin et al based on the Airy gas [LA Constantin, A Ruzsinszky, and JP Perdew, Phys. Rev. B 80, 035125 (2009) ] \n\n\n193=> XC_GGA_X_LAG ! Local Airy Gas [L Vitos, B Johansson, J Kollar, and HL Skriver, Phys. Rev. B 62, 10046-10050 (2000) ] \n\n\n194=> XC_GGA_XC_MOHLYP ! Functional for organometallic chemistry [NE Schultz, Y Zhao, DGJ Truhlar, Phys. Chem. A, 109, 11127 (2005) ] \n\n\n195=> XC_GGA_XC_MOHLYP2 ! Functional for barrier heights [J Zheng, Y Zhao, DGJ Truhlar, Chem. Theory. Comput. 5, 808 (2009) ] \n\n\n196=> XC_GGA_XC_TH_FL ! Tozer and Handy v. FL [DJ Tozer, NC Handy, amd WH Green, Chem. Phys. Lett. 273, 183-194 (1997) ] \n\n\n197=> XC_GGA_XC_TH_FC ! Tozer and Handy v. FC [DJ Tozer, NC Handy, amd WH Green, Chem. Phys. Lett. 273, 183-194 (1997) ] \n\n\n198=> XC_GGA_XC_TH_FCFO ! Tozer and Handy v. FCFO [DJ Tozer, NC Handy, amd WH Green, Chem. Phys. Lett. 273, 183-194 (1997) ] \n\n\n199=> XC_GGA_XC_TH_FCO ! Tozer and Handy v. FCO [DJ Tozer, NC Handy, amd WH Green, Chem. Phys. Lett. 273, 183-194 (1997) ] \n\n\n200=> XC_GGA_C_OPTC ! Optimized correlation functional of Cohen and Handy [AJ Cohen and NC Handy, Mol. Phys. 99, 607-615 (2001) ] \n\n\n524=> XC_GGA_X_WPBEH ! short-range version of the PBE [J Heyd, GE Scuseria, and M Ernzerhof, J. Chem. Phys. 118, 8207 (2003) ] \n\n\n525=> XC_GGA_X_HJS_PBE ! HJS screened exchange PBE version [TM Henderson, BG Janesko, and GE Scuseria, J. Chem. Phys. 128, 194105 (2008) ] \n\n\n526=> XC_GGA_X_HJS_PBE_SOL ! HJS screened exchange PBE_SOL version [TM Henderson, BG Janesko, and GE Scuseria, J. Chem. Phys. 128, 194105 (2008) ] \n\n\n527=> XC_GGA_X_HJS_B88 ! HJS screened exchange B88 version [TM Henderson, BG Janesko, and GE Scuseria, J. Chem. Phys. 128, 194105 (2008) ] WARNING : this functional is not tested. Use at your own risks. \n\n\n528=> XC_GGA_X_HJS_B97X ! HJS screened exchange B97x version [TM Henderson, BG Janesko, and GE Scuseria, J. Chem. Phys. 128, 194105 (2008) ] \n\n\n529=> XC_GGA_X_ITYH ! short-range recipe for exchange GGA functionals [H Iikura, T Tsuneda, T Yanai, and K Hirao, J. Chem. Phys. 115, 3540 (2001) ] WARNING : this functional is not tested. Use at your own risks. \n\n\n\n\nMetaGGA functionals (do not forget to add a minus sign, as discussed above).\nSee Sun et al, PRB 84, 035117 (2011) for the formulas.\n\n\n\n\n202=> XC_MGGA_X_TPSS ! Tao, Perdew, Staroverov & Scuseria [J Tao, JP Perdew, VN Staroverov, and G Scuseria, Phys. Rev. Lett. 91, 146401 (2003) ; JP Perdew, J Tao, VN Staroverov, and G Scuseria, J. Chem. Phys. 120, 6898 (2004) ] \n\n\n203=> XC_MGGA_X_M06L ! Zhao, Truhlar exchange [Y Zhao and DG Truhlar, JCP 125, 194101 (2006); Y Zhao and DG Truhlar, Theor. Chem. Account 120, 215 (2008) ] \n\n\n204=> XC_MGGA_X_GVT4 ! GVT4 (X part of VSXC) from van Voorhis and Scuseria [T Van Voorhis and GE Scuseria, JCP 109, 400 (1998) ] \n\n\n205=> XC_MGGA_X_TAU_HCTH ! tau-HCTH from Boese and Handy [AD Boese and NC Handy, JCP 116, 9559 (2002) ] \n\n\n207=> XC_MGGA_X_BJ06 ! Becke & Johnson correction to Becke-Roussel 89 [AD Becke and ER Johnson, J. Chem. Phys. 124, 221101 (2006) ] WARNING : this Vxc-only mGGA can only be used with a LDA correlation, typically Perdew-Wang 92. \n\n\n208=> XC_MGGA_X_TB09 ! Tran-blaha - correction to Becke & Johnson correction to Becke-Roussel 89 [F Tran and P Blaha, Phys. Rev. Lett. 102, 226401 (2009) ] WARNING : this Vxc-only mGGA can only be used with a LDA correlation, typically Perdew-Wang 92. \n\n\n209=> XC_MGGA_X_RPP09 ! Rasanen, Pittalis, and Proetto correction to Becke & Johnson [E Rasanen, S Pittalis & C Proetto, arXiv:0909.1477 (2009) ] WARNING : this Vxc-only mGGA can only be used with a LDA correlation, typically Perdew-Wang 92. \n\n\n232=> XC_MGGA_C_VSXC ! VSxc from Van Voorhis and Scuseria (correlation part) [T Van Voorhis and GE Scuseria, JCP 109, 400 (1998) ] \n\n\n\n\nHybrid functionals (do not forget to add a minus sign, as discussed above).\n\n\n\n\n402=> XC_HYB_GGA_XC_B3LYP ! The (in)famous B3LYP [PJ Stephens, FJ Devlin, CF Chabalowski, MJ Frisch, J. Phys. Chem. 98 11623 (1994) ] \n\n\n406=> XC_HYB_GGA_XC_PBEH ! PBEH (PBE0) [C Adamo and V Barone, J. Chem. Phys. 110, 6158 (1999); M. Ernzerhof, G. E. Scuseria, J. Chem. Phys. 110, 5029 (1999) ] \n\n\n\n\n427=> XC_HYB_GGA_XC_HSE03 ! The 2003 version of the screened hybrid HSE (in this case one should use omega^HF = 0.15/sqrt(2) and omega^PBE = 0.15*(2.0)\n1/3) \n\n428=> XC_HYB_GGA_XC_HSE06 ! The 2006 version of the screened hybrid HSE (in\nthis case one should use omega^HF = omega^PBE = 0.11)\n\n(The following section is taken from the LibXC sources. In ABINIT, we stick to\nthe LibXC choice.) Note that there is an enormous mess in the literature\nconcerning the values of omega in HSE. This is due to an error in the original\npaper that stated that they had used omega=0.15. This was in fact not true,\nand the real value used was omega^HF = 0.15/sqrt(2) ~ 0.1061 and omega^PBE =\n0.15*(2.0)\n1/3 ~ 0.1890. In 2006 Krukau et al [JCP 125, 224106 (2006)] tried\nto clarify the situation, and called HSE03 to the above choice of parameters,\nand called HSE06 to the functional where omega^HF=omega^PBE. By testing\nseveral properties for atoms they reached the conclusion that the best value\nfor omega=0.11. Of course, codes are just as messy as the papers. In espresso\nHSE06 has the value omega=0.106. VASP, on the other hand, uses for HSE03 the\nsame value omega^HF = omega^PBE = 0.3 (A^-1) ~ 0.1587 and for HSE06 omega^HF =\nomega^PBE = 0.2 (A^-1) ~ 0.1058. [J Heyd, GE Scuseria, and M Ernzerhof, J.\nChem. Phys. 118, 8207 (2003); J Heyd, GE Scuseria, and M Ernzerhof, J. Chem.\nPhys. 124, 219906 (2006); AV Krukau, OA Vydrov, AF Izmaylov, and GE Scuseria,\nJ. Chem. Phys. 125, 224106 (2006) ]\n\n\n\n\n\n\n456=> XC_HYB_GGA_XC_PBE0_13 ! PBE0-1/3 [P Cortona, J. Chem. Phys. 136, 086101 (2012) ] \n\n\n\n\n\n\njdtset\n\u00b6\n\n\nMnemonics: index -J- for DaTaSETs\n\nVariable type: integer\n\nDimensions: (\nndtset\n)\n\nDefault value: [1 .. \nndtset\n]  \n\n\nGives the dataset index of each of the datasets. This index will be used :\n\n\n\n\nto determine which input variables are specific to each dataset, since the variable names for this dataset will be made from the bare variable name concatenated with this index, and only if such a composite variable name does not exist, the code will consider the bare variable name, or even, the Default; \n\n\nto characterize output variable names, if their content differs from dataset to dataset; \n\n\nto characterize output files ( root names appended with _DSx where \u2018x\u2019 is the dataset index ). \n\n\n\n\nThe allowed index values are between 1 and 9999.\n\nAn input variable name appended with 0 is not allowed.\n\nWhen \nndtset\n==0, this array is not used, and moreover, no input variable\nname appended with a digit is allowed. This array might be initialized thanks\nto the use of the input variable \nudtset\n. In this case, \njdtset\n cannot\nbe used.\n\n\nkpt\n\u00b6\n\n\nMnemonics: K - PoinTs\n\nVariable type: real\n\nDimensions: (3,\nnkpt\n)\n\nDefault value: [0, 0, 0]\n\nComment: Adequate for one molecule in a supercell  \n\n\nContains the k points in terms of reciprocal space primitive translations (NOT\nin cartesian coordinates!).\n\nNeeded ONLY if \nkptopt\n=0, otherwise deduced from other input variables.\n\n\nIt contains dimensionless numbers in terms of which the cartesian coordinates\nwould be:\n\nk_cartesian = k1\nG1+k2\nG2+k3*G3\n\nwhere  (k1,k2,k3)  represent the dimensionless \u201creduced coordinates\u201d and  G1,\nG2, G3  are the cartesian coordinates of the primitive translation vectors.\nG1,G2,G3 are related to the choice of direct space primitive translation\nvectors made in \nrprim\n. Note that an overall norm for the k points is\nsupplied by \nkptnrm\n. This allows one to avoid supplying many digits for the\nk points to represent such points as (1,1,1)/3.\n\nNote: one of the algorithms used to set up the sphere of G vectors for the\nbasis needs components of k-points in the range [-1,1], so the remapping is\neasily done by adding or subtracting 1 from each component until it is in the\nrange [-1,1]. That is, given the k point normalization \nkptnrm\n described\nbelow, each component must lie in [-\nkptnrm\n,\nkptnrm\n].\n\nNote: a global shift can be provided by \nqptn\n\nNot read if \nkptopt\n/=0 .\n\n\nkptnrm\n\u00b6\n\n\nMnemonics: K - PoinTs NoRMalization\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nEstablishes a normalizing denominator for each k point. Needed only if\n\nkptopt\n<=0, otherwise deduced from other input variables.\n\nThe k point coordinates as fractions of reciprocal lattice translations are\ntherefore \n[kpt]\n/\nkptnrm\n. \nkptnrm\n defaults to 1 and can be\nignored by the user. It is introduced to avoid the need for many digits in\nrepresenting numbers such as 1/3.\n\nIt cannot be smaller than 1.0d0\n\n\nkptopt\n\u00b6\n\n\nMnemonics: KPoinTs OPTion\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 4 if \nnspden\n==4,\n1 otherwise.\n\n\nControls the set up of the k-points list. The aim will be to initialize, by\nstraight reading or by a preprocessing approach based on other input\nvariables, the following input variables, giving the k points, their number,\nand their weight: \nkpt\n, \nkptnrm\n, \nnkpt\n, and, for \niscf\n/=-2,\n\nwtk\n.\n\n\nOften, the k points will form a lattice in reciprocal space. In this case, one\nwill also aim at initializing input variables that give the reciprocal of this\nk-point lattice, as well as its shift with respect to the origin: \nngkpt\n or\n\nkptrlatt\n, as well as on \nnshiftk\n and \nshiftk\n.\n\n\nA global additional shift can be provided by \nqptn\n\n\n\n\n0=> read directly \nnkpt\n, \nkpt\n, \nkptnrm\n and \nwtk\n. \n\n\n\n\n1=> rely on \nngkpt\n or \nkptrlatt\n, as well as on \nnshiftk\n and \nshiftk\n to set up the k points. Take fully into account the symmetry to generate the k points in the Irreducible Brillouin Zone only, with the appropriate weights. \n\n(This is the usual mode for GS calculations)\n\n\n\n\n\n\n2=> rely on \nngkpt\n or \nkptrlatt\n, as well as on \nnshiftk\n and \nshiftk\n to set up the k points. Take into account only the time-reversal symmetry : k points will be generated in half the Brillouin zone, with the appropriate weights. \n\n(This is to be used when preparing or executing a RF calculation at q=(0 0 0)\n)\n\n\n\n\n\n\n3=> rely on \nngkpt\n or \nkptrlatt\n, as well as on \nnshiftk\n and \nshiftk\n to set up the k points. Do not take into account any symmetry : k points will be generated in the full Brillouin zone, with the appropriate weights. \n\n(This is to be used when preparing or executing a RF calculation at non-zero q\n)\n\n\n\n\n\n\n4=> rely on \nngkpt\n or \nkptrlatt\n, as well as on \nnshiftk\n and \nshiftk\n to set up the k points. Take into account all the symmetries EXCEPT the time-reversal symmetry to generate the k points in the Irreducible Brillouin Zone, with the appropriate weights. \n\nThis has to be used when performing calculations with non-collinear magnetism\nallowed (\nnspden\n=4)\n\n\n\n\n\n\nA negative value => rely on \nkptbounds\n, and \nndivk\n to set up a band structure calculation along different lines (allowed only for \niscf\n==-2). The absolute value of \nkptopt\n gives the number of segments of the band structure. Weights are usually irrelevant with this option, and will be left to their default value. \n\n\n\n\n\n\nIn the case of a grid of k points, the auxiliary variables \nkptrlen\n,\n\nngkpt\n and \nprtkpt\n might help you to select the optimal grid.\n\n\nnatom\n\u00b6\n\n\nMnemonics: Number of ATOMs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nGives the total number of atoms in the unit cell. Default is 1 but you will\nobviously want to input this value explicitly.\n\nNote that \nnatom\n refers to all atoms in the unit cell, not only to the\nirreducible set of atoms in the unit cell (using symmetry operations, this set\nallows to recover all atoms). If you want to specify only the irreducible set\nof atoms, use the symmetriser, see the input variable \nnatrd\n.\n\n\nnband\n\u00b6\n\n\nMnemonics: Number of BANDs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None\n\nComment:  the estimated number of occupied bands +1 (TODO provide the mathematical formulation)  \n\n\nGives number of bands, occupied plus possibly unoccupied, for which\nwavefunctions are being computed along with eigenvalues.\n\nNote : if the parameter \noccopt\n (see below) is not set to 2, \nnband\n is a\nscalar integer, but if the parameter \noccopt\n is set to 2, then \nnband\n\nmust be an array \n[nband]\n giving the number of bands\nexplicitly for each k point. This option is provided in order to allow the\nnumber of bands treated to vary from k point to k point.\n\nFor the values of \noccopt\n not equal to 0 or 2, \nnband\n can be omitted.\nThe number of bands will be set up thanks to the use of the variable\n\nfband\n. The present Default will not be used.\n\n\nIf \nnspinor\n is 2, nband must be even for each k point.\n\n\nIn the case of a \nGW\n calculation (\noptdriver\n=3 or 4), \nnband\n gives\nthe number of bands to be treated to generate the screening (susceptibility\nand dielectric matrix), as well as the self-energy. However, to generate the\n_KSS file (see \nkssform\n) the relevant number of bands is given by\n\nnbandkss\n.\n\n\nnbandhf\n\u00b6\n\n\nMnemonics: Number of BANDs for (Hartree)-Fock exact exchange\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None\n\nComment: the estimated number of occupied bands (TODO : provide the mathematical formulation)  \n\n\nGives the maximum number of occupied bands with which Fock exact exchange is\nbeing computed for the wavefunctions.\n\n\nndtset\n\u00b6\n\n\nMnemonics: Number of DaTaSETs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of data sets to be treated.\n\nIf 0, means that the multi-data set treatment is not used, so that the root\nfilenames will not be appended with _DSx, where \u2018x\u2019 is the dataset index\ndefined by the input variable \njdtset\n, and also that input names with a\ndataset index are not allowed. Otherwise, \nndtset\n=0 is equivalent to\n\nndtset\n=1.\n\n\nngkpt\n\u00b6\n\n\nMnemonics: Number of Grid points for K PoinTs generation\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \nkptopt\n >=0, \n\nThe use of this variable forbids the use of specified(\nkptrlatt\n)  \n\n\nUsed when \nkptopt\n>=0, if \nkptrlatt\n has not been defined (\nkptrlatt\n\nand \nngkpt\n are exclusive of each other).\n\nIts three positive components give the number of k points of Monkhorst-Pack\ngrids (defined with respect to primitive axis in reciprocal space) in each of\nthe three dimensions. \nngkpt\n will be used to generate the corresponding\n\nkptrlatt\n input variable. The use of \nnshiftk\n and \nshiftk\n, allows to\ngenerate shifted grids, or Monkhorst-Pack grids defined with respect to\nconventional unit cells.\n\n\nWhen \nnshiftk\n=1, \nkptrlatt\n is initialized as a diagonal (3x3) matrix,\nwhose diagonal elements are the three values \n[ngkpt]\n. When \nnshiftk\n\nis greater than 1, ABINIT will try to generate \nkptrlatt\n on the basis of\nthe primitive vectors of the k-lattice: the number of shifts might be reduced,\nin which case \nkptrlatt\n will not be diagonal anymore.\n\n\nMonkhorst-Pack grids are usually the most efficient when their defining\ninteger numbers are even. For a measure of the efficiency, see the input\nvariable \nkptrlen\n.\n\n\nnkpath\n\u00b6\n\n\nMnemonics: Number of K-points defining the PATH\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis variable is used to define the number of high-symmetry k-points in the\n\nkptbounds\n array when \nkptopt\n > 0. Historically, \nkptbounds\n is used\nin conjuction with a negative value of \nkptopt\n when performing a NSCF band\nstructure calculation. In this case, the number of k-points in kptbounds is\ngiven by abs(kptopt) + 1. There are, however, other cases in which one has to\nspecify a k-path in the input file in order to activate some kind of post-\nprocessing tool. Typical examples are the interpolation of the GW corrections\nat the end of the sigma run or the interpolation of the KS eigenvalues along a\npath at the end of the SCF run (see also \neinterp\n) In a nutshell, nkpath\nreplaces \nkptopt\n when we are not performing a NSCF calculation. Note that,\nunlike \nkptopt\n, nkpath represents the total number of points in the\n\nkptbounds\n array.\n\n\nnkpt\n\u00b6\n\n\nMnemonics: Number of K - Points\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \nkptopt\n==0,\n0 otherwise.\n\n\nIf non-zero, \nnkpt\n gives the number of k points in the k point array\n\nkpt\n. These points are used either to sample the Brillouin zone, or to\nbuild a band structure along specified lines.\n\n\nIf \nnkpt\n is zero, the code deduces from other input variables (see the list\nin the description of \nkptopt\n) the number of k points, which is possible\nonly when \nkptopt\n/=0. If \nkptopt\n/=0 and the input value of \nnkpt\n/=0,\nthen ABINIT will check that the number of k points generated from the other\ninput variables is exactly the same than \nnkpt\n.\n\n\nIf \nkptopt\n is positive, \nnkpt\n must be coherent with the values of\n\nkptrlatt\n, \nnshiftk\n and \nshiftk\n.\n\nFor ground state calculations, one should select the k point in the\nirreducible Brillouin Zone (obtained by taking into account point symmetries\nand the time-reversal symmetry).\n\nFor response function calculations, one should select k points in the full\nBrillouin zone, if the wavevector of the perturbation does not vanish, or in a\nhalf of the Brillouin Zone if q=0. The code will automatically decrease the\nnumber of k points to the minimal set needed for each particular perturbation.\n\n\nIf \nkptopt\n is negative, \nnkpt\n will be the sum of the number of points on\nthe different lines of the band structure. For example, if \nkptopt\n=-3, one\nwill have three segments; supposing \nndivk\n is 10 12 17, the total number of\nk points of the circuit will be 10+12+17+1(for the final point)=40.\n\n\nnkpthf\n\u00b6\n\n\nMnemonics: Number of K - Points for (Hartree) Fock exact exchange\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None\n\nComment:  the total number of k-point in the full Brillouin zone (TODO : provide the mathematical formulation)  \n\n\nnkpthf\n gives the number of k points used to sample the full Brillouin zone\nfor the Fock exact exchange contribution.\n\n\nnshiftk\n\u00b6\n\n\nMnemonics: Number of SHIFTs for K point grids\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis parameter gives the number of shifted grids to be used concurrently to\ngenerate the full grid of k points. It can be used with primitive grids\ndefined either from \nngkpt\n or \nkptrlatt\n. The maximum allowed value of\n\nnshiftk\n is 8. The values of the shifts are given by \nshiftk\n.\n\n\nnsppol\n\u00b6\n\n\nMnemonics: Number of SPin POLarization\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nGive the number of INDEPENDENT spin polarisations, for which there are non-\nrelated wavefunctions. Can take the values 1 or 2.\n\n\nIf \nnsppol\n=1, one has an unpolarized calculation (\nnspinor\n=1,\n\nnspden\n=1) or an antiferromagnetic system (\nnspinor\n=1, \nnspden\n=2), or\na calculation in which spin up and spin down cannot be disentangled\n(\nnspinor\n=2), that is, either non-collinear magnetism or presence of spin-\norbit coupling, for which one needs spinor wavefunctions.\n\n\nIf \nnsppol\n=2, one has a spin-polarized (collinear) calculation with\nseparate and different wavefunctions for up and down spin electrons for each\nband and k point. Compatible only with \nnspinor\n=1, \nnspden\n=2. If\n\nnsppol\n=2, one usually uses a metallic value for \noccopt\n, in order to\nlet ABINIT find the magnetization. On the contrary, if \noccopt\n==1 is used,\nthe user has to impose the magnetization, using \nspinmagntarget\n, except for\nthe case of a single isolated Hydrogen atom.\n\n\nIn the present status of development, with \nnsppol\n=1, all values of \nixc\n\nare allowed, while with \nnsppol\n=2, some values of \nixc\n might not be\nallowed (e.g. 2, 3, 4, 5, 6, 20, 21, 22 are not allowed).\n\n\nSee also the input variable \nnspden\n for the components of the density\nmatrix with respect to the spin-polarization.\n\n\nnstep\n\u00b6\n\n\nMnemonics: Number of (non-)self-consistent field STEPS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 30  \n\n\nGives the maximum number of cycles (or \u201citerations\u201d) in a SCF or non-SCF run.\n\nFull convergence from random numbers is usually achieved in 12-20 SCF\niterations. Each can take from minutes to hours. In certain difficult cases,\nusually related to a small or zero bandgap or magnetism, convergence\nperformance may be much worse. When the convergence tolerance \ntolwfr\n on\nthe wavefunctions is satisfied, iterations will stop, so for well converged\ncalculations you should set \nnstep\n to a value larger than you think will be\nneeded for full convergence, e.g. if using 20 steps usually converges the\nsystem, set \nnstep\n to 30.\n\nFor non-self-consistent runs ( \niscf\n < 0) nstep governs the number of\ncycles of convergence for the wavefunctions for a fixed density and\nHamiltonian.\n\n\nNOTE that a choice of \nnstep\n=0 is permitted; this will either read\nwavefunctions from disk (with \nirdwfk\n=1 or \nirdwfq\n=1, or non-zero\n\ngetwfk\n or \ngetwfq\n in the case of multi-dataset) and compute the\ndensity, the total energy and stop, or else (with all of the above vanishing)\nwill initialize randomly the wavefunctions and compute the resulting density\nand total energy. This is provided for testing purposes.\n\nAlso NOTE that \nnstep\n=0 with \nirdwfk\n=1 will exactly give the same result\nas the previous run only if the latter is done with \niscf\n<10 (potential\nmixing).\n\nOne can output the density by using \nprtden\n.\n\nThe forces and stress tensor are computed with \nnstep\n=0.\n\n\nnsym\n\u00b6\n\n\nMnemonics: Number of SYMmetry operations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives number of space group symmetries to be applied in this problem.\nSymmetries will be input in array \u201c\nsymrel\n\u201d and (nonsymmorphic)\ntranslations vectors will be input in array \u201c\ntnons\n\u201d. If there is no\nsymmetry in the problem then set \nnsym\n to 1, because the identity is still\na symmetry.\n\nIn case of a RF calculation, the code is able to use the symmetries of the\nsystem to decrease the number of perturbations to be calculated, and to\ndecrease of the number of special k points to be used for the sampling of the\nBrillouin zone. After the response to the perturbations have been calculated,\nthe symmetries are used to generate as many as possible elements of the 2DTE\nfrom those already computed.\n\n\nSYMMETRY_FINDER\n mode (Default mode). If \nnsym\n is 0, all the atomic\ncoordinates must be explicitely given (one cannot use the geometry builder and\nthe symmetrizer): the code will then find automatically the symmetry\noperations that leave the lattice and each atomic sublattice invariant. It\nalso checks whether the cell is primitive (see \nchkprim\n).\n\nNote that the tolerance on symmetric atomic positions and lattice is rather\nstringent : for a symmetry operation to be admitted, the lattice and atomic\npositions must map on themselves within 1.0e-8 .\n\n\nThe user is allowed to set up systems with non-primitive unit cells (i.e.\nconventional FCC or BCC cells, or supercells without any distortion). In this\ncase, pure translations will be identified as symmetries of the system by the\nsymmetry finder. Then, the combined \u201cpure translation + usual rotation and\ninversion\u201d symmetry operations can be very numerous. For example, a\nconventional FCC cell has 192 symmetry operations, instead of the 48 ones of\nthe primitive cell. A maximum limit of 384 symmetry operations is hard-coded.\nThis corresponds to the maximum number of symmetry operations of a 2x2x2\nundistorted supercell. Going beyond that number will make the code stop very\nrapidly. If you want nevertheless, for testing purposes, to treat a larger\nnumber of symmetries, change the initialization of \u201cmsym\u201d in the abinit.F90\nmain routine, then recompile the code.\n\n\nFor \nGW\n calculation, the user might want to select only the symmetry\noperations whose non-symmorphic translation vector \ntnons\n is zero. This can\nbe done with the help of the input variable \nsymmorphi\n\n\nntypat\n\u00b6\n\n\nMnemonics: Number of TYPes of AToms\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nGives the number of types of atoms. E.g. for a homopolar system (e.g. pure Si)\n\nntypat\n is 1.\n\nThe code tries to read the same number of pseudopotential files.\n\nThe first pseudopotential is assigned type number 1, and so on \u2026\n\n\noccopt\n\u00b6\n\n\nMnemonics: OCCupation OPTion\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nControls how input parameters \nnband\n, \nocc\n, and \nwtk\n are handled.\n\n\n\n\n\n\noccopt\n=0: \n\nAll k points have the same number of bands and the same occupancies of bands.\n\nnband\n is given as a single number, and \n[occ]\n is an array of\n\nnband\n elements, read in by the code.\n\nThe k point weights in array \n[wtk]\n are automatically normalized by\nthe code to add to 1.\n\n\n\n\n\n\noccopt\n=1: \n\nSame as \noccopt\n=0, except that the array \nocc\n is automatically generated\nby the code, to give a semiconductor.\n\nAn error occurs when filling cannot be done with occupation numbers equal to 2\nor 0 in each k-point (non-spin-polarized case), or with occupation numbers\nequal to 1 or 0 in each k-point (spin-polarized case). If \nnsppol\n=2 and\n\noccopt\n==1 is used, the user has to impose the magnetization, using\n\nspinmagntarget\n, except for the case of a single isolated Hydrogen atom.\n\n\n\n\n\n\noccopt\n=2: \n\nk points may optionally have different numbers of bands and different\noccupancies. \n[nband]\n is given explicitly as an array of\n\nnkpt\n*\nnsppol\n elements. \n[occ]\n is given explicitly for all bands at\neach k point, and eventually for each spin \u2013 the total number of elements is\nthe sum of \n[nband]\n over all k points and spins. The k point weights\n\nwtk\n (\nnkpt\n) are NOT automatically normalized under this option.\n\n\n\n\n\n\noccopt\n=3, 4, 5, 6 and 7 \n\nMetallic occupation of levels, using different occupation schemes (see below).\nThe corresponding thermal broadening, or cold smearing, is defined by the\ninput variable \ntsmear\n (see below : the variable xx is the energy in Ha,\ndivided by \ntsmear\n)\n\nLike for \noccopt\n=1, the variable \nocc\n is not read\n\nAll k points have the same number of bands, \nnband\n is given as a single\nnumber, read by the code.\n\nThe k point weights in array \n[wtk]\n are automatically normalized by\nthe code to add to 1.\n\n\n\n\n\n\noccopt\n=3: \n\nFermi-Dirac smearing (finite-temperature metal) Smeared delta function :\n0.25d0/(cosh(xx/2.0d0)**2)\n\n\n\n\n\n\noccopt\n=4: \n\n\u201cCold smearing\u201d of N. Marzari (see his thesis work), with a=-.5634\n(minimization of the bump)\n\nSmeared delta function :\n\nexp(-xx  2  )/sqrt(pi) * (1.5d0+xx\n(-a\n1.5d0+xx\n(-1.0d0+a\nxx)))\n\n\n\n\n\n\noccopt\n=5: \n\n\u201cCold smearing\u201d of N. Marzari (see his thesis work), with a=-.8165 (monotonic\nfunction in the tail)\n\nSame smeared delta function as \noccopt\n=4, with different a.\n\n\n\n\n\n\noccopt\n=6: \n\nSmearing of Methfessel and Paxton \nMethfessel1989\n with Hermite polynomial\nof degree 2, corresponding to \u201cCold smearing\u201d of N. Marzari with a=0 (so, same\nsmeared delta function as \noccopt\n=4, with different a).\n\n\n\n\n\n\noccopt\n=7: \n\nGaussian smearing, corresponding to the 0 order Hermite polynomial of\nMethfessel and Paxton.\n\nSmeared delta function : 1.0d0\nexp(-xx\n*2)/sqrt(pi)\n\n\n\n\n\n\noccopt\n=8: \n\nUniform smearing (the delta function is replaced by a constant function of\nvalue one over ]-1/2,1/2[ (with one-half value at the boundaries). Used for\ntesting purposes only.\n\n\n\n\n\n\n\n\n\n\nWARNING : one can use metallic occupation of levels in the case of a molecule,\nin order to avoid any problem with degenerate levels. However, it is advised\nNOT to use \noccopt\n=6 (and to a lesser extent \noccopt\n=4 and 5), since the\nassociated number of electron versus the Fermi energy is NOT guaranteed to be\na monotonic function. For true metals, AND a sufficiently dense sampling of\nthe Brillouin zone, this should not happen, but be cautious ! As an indication\nof this problem, a small variation of input parameters might lead to a jump of\ntotal energy, because there might be two or even three possible values of the\nFermi energy, and the bissection algorithm find one or the other.\n\n\nrprim\n\u00b6\n\n\nMnemonics: Real space PRIMitive translations\n\nVariable type: real\n\nDimensions: (3,3)\n\ncommentdims Internally, it is represented as rprim(3,3,\nnimage\n)\n\nDefault value: [[1, 0, 0], [0, 1, 0], [0, 0, 1]]  \n\n\nGive, in columnwise entry, the three dimensionless primitive translations in\nreal space, to be rescaled by \nacell\n and \nscalecart\n.\n\nIt is \nEVOLVING\n only if \nionmov\n==2 and \noptcell\n/=0, otherwise it is\nfixed.\n\nIf the Default is used, that is, \nrprim\n is the unity matrix, the three\ndimensionless primitive vectors are three unit vectors in cartesian\ncoordinates. Each will be (possibly) multiplied by the corresponding \nacell\n\nvalue, then (possibly) stretched along the cartesian coordinates by the\ncorresponding \nscalecart\n value, to give the dimensional primitive vectors,\ncalled \nrprimd\n.\n\nIn the general case, the dimensional cartesian coordinates of the crystal\nprimitive translations R1p, R2p and R3p, see \nrprimd\n, are\n\n\n\n\nR1p(i)=\n[scalecart]\n[rprim]\n*\n[acell]\n \n\n\nR2p(i)=\n[scalecart]\n[rprim]\n*\n[acell]\n \n\n\nR3p(i)=\n[scalecart]\n[rprim]\n*\n[acell]\n \n\n\n\n\nwhere i=1,2,3 is the component of the primitive translation (i.e. x, y, and\nz).  \n\n\nThe \nrprim\n variable, scaled by \nscalecart\n, is thus used to define\ndirections of the primitive vectors, that will be multiplied (so keeping the\ndirection unchanged) by the appropriate length scale \n[acell]\n,\n\n[acell]\n, or \n[acell]\n, respectively to give the dimensional primitive\ntranslations in real space in cartesian coordinates.\n\nPresently, it is requested that the mixed product (R1xR2).R3 is positive. If\nthis is not the case, simply exchange a pair of vectors.\n\nTo be more specific, keeping the default value of \nscalecart\n=1 to simplify\nthe matter, \nrprim\n 1 2 3 4 5 6 7 8 9 corresponds to input of the three\nprimitive translations R1=(1,2,3) (to be multiplied by \n[acell]\n),\nR2=(4,5,6) (to be multiplied by \n[acell]\n), and R3=(7,8,9) (to be\nmultiplied by [\nacell\n).\n\nNote carefully that the first three numbers input are the first column of\n\nrprim\n, the next three are the second, and the final three are the third.\nThis corresponds with the usual Fortran order for arrays. The matrix whose\ncolumns are the reciprocal space primitive translations is the inverse\ntranspose of the matrix whose columns are the direct space primitive\ntranslations.\n\n\nAlternatively to \nrprim\n, directions of dimensionless primitive vectors can\nbe specified by using the input variable \nangdeg\n. This is especially useful\nfor hexagonal lattices (with 120 or 60 degrees angles). Indeed, in order for\nsymmetries to be recognized, rprim must be symmetric up to \ntolsym\n (10\ndigits by default), inducing a specification such as\n\n\n  rprim  0.86602540378  0.5  0.0\n        -0.86602540378  0.5  0.0\n         0.0            0.0  1.0\n\n\n\n\n\nthat can be avoided thanks to \nangdeg\n:\n\n\n  angdeg 90 90 120\n\n\n\n\n\nAlthough the use of \nscalecart\n or \nacell\n is rather equivalent when the\nprimitive vectors are aligned with the cartesian directions, it is not the\ncase for non-orthogonal primitive vectors. In particular, beginners often make\nthe error of trying to use \nacell\n to define primitive vectors in face-\ncentered tetragonal lattice, or body-centered tetragonal lattice, or similarly\nin face or body-centered orthorhombic lattices. Let us take the example of a\nbody-centered tetragonal lattice, that might be defined using the following\n(\u201ca\u201d and \u201cc\u201d have to be replaced by the appropriate conventional cell vector\nlength):\n\n\n  rprim  \"a\"      0        0\n          0      \"a\"       0\n         \"a/2\"   \"a/2\"    \"c/2\"\nacell 3*1     scalecart 3*1    !  ( These are default values)\n\n\n\n\n\nThe following is a valid, alternative way to define the same primitive vectors\n:\n\n\n  rprim   1        0       0\n          0        1       0\n          1/2      1/2     1/2\nscalecart  \"a\"  \"a\"  \"c\"\nacell 3*1    !  ( These are default values)\n\n\n\n\n\nIndeed, the cell has been stretched along the cartesian coordinates, by \u201ca\u201d,\n\u201ca\u201d and \u201cc\u201d factors.\n\n\nAt variance, the following is WRONG :\n\n\n  rprim   1       0       0\n          0       1       0\n          1/2     1/2     1/2\nacell  \"a\"  \"a\"  \"c\"    !   THIS IS WRONG\nscalecart 3*1    !  ( These are default values)\n\n\n\n\n\nIndeed, the latter would correspond to :\n\n\n  rprim  \"a\"      0       0\n          0      \"a\"      0\n         \"c/2\"   \"c/2\"   \"c/2\"\nacell 3*1     scalecart 3*1    !  ( These are default values)\n\n\n\n\n\nNamely, the third vector has been rescaled by \u201cc\u201d. It is not at all in the\ncenter of the tetragonal cell whose basis vectors are defined by the scaling\nfactor \u201ca\u201d.\n\nAs another difference between \nscalecart\n or \nacell\n, note that\n\nscalecart\n is \nINPUT_ONLY\n : its content will be immediately applied to\nrprim, at parsing time, and then scalecart will be set to the default values\n(3*1). So, in case \nscalecart\n is used, the echo of \nrprim\n in the output\nfile is not the value contained in the input file, but the value rescaled by\n\nscalecart\n.\n\n\nrprimd\n\u00b6\n\n\nMnemonics: Real space PRIMitive translations, Dimensional\n\nVariable type: real\n\nDimensions: (3,3)\n\ncommentdims Internally, it is represented as rprimd(3,3,\nnimage\n).\n\nDefault value: None  \n\n\nThis internal variable gives the dimensional real space primitive vectors,\ncomputed from \nacell\n, \nscalecart\n, and \nrprim\n.\n\n\n\n\nR1p(i)=\n[rprimd]\n=\n[scalecart]\n[rprim]\n[acell]\n for i=1,2,3 (x,y,and z) \n\n\nR2p(i)=\n[rprimd]\n=\n[scalecart]\n[rprim]\n[acell]\n for i=1,2,3 \n\n\nR3p(i)=\n[rprimd]\n=\n[scalecart]\n[rprim]\n[acell]\n for i=1,2,3 \n\n\n\n\nIt is \nEVOLVING\n only if \nionmov\n==2 and \noptcell\n/=0, otherwise it is\nfixed.  \n\n\nscalecart\n\u00b6\n\n\nMnemonics: SCALE CARTesian coordinates\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*1  \n\n\nGives the scaling factors of cartesian coordinates by which dimensionless\nprimitive translations (in \u201c\nrprim\n\u201d) are to be multiplied. \nrprim\n input\nvariable, the \nacell\n input variable, and the associated internal \nrprimd\n\ninternal variable.\n\nEspecially useful for body-centered and face-centered tetragonal lattices, as\nwell as body-centered and face-centered orthorhombic lattices, see \nrprimd\n.\n\nNote that this input variable is \nINPUT_ONLY\n : its content will be\nimmediately applied to rprim, at parsing time, and then scalecart will be set\nto the default values. So, it will not be echoed.\n\n\nshiftk\n\u00b6\n\n\nMnemonics: SHIFT for K points\n\nVariable type: real\n\nDimensions: (3,\nnshiftk\n)\n\nDefault value: None if \nnshiftk\n>1,\n[0.5, 0.5, 0.5] otherwise.\n\n\nIt is used only when \nkptopt\n>=0, and must be defined if \nnshiftk\n is\nlarger than 1.\n\n\n[shiftk]\n defines \nnshiftk\n shifts of the homogeneous\ngrid of k points based on \nngkpt\n or \nkptrlatt\n.\n\nThe shifts induced by \nshiftk\n corresponds to the reduced coordinates in the\ncoordinate system defining the k-point lattice. For example, if the k point\nlattice is defined using \nngkpt\n, the point whose reciprocal space reduced\ncoordinates are ( \n[shiftk]\n/\n[ngkpt]\n \n[shiftk]\n/\n[ngkpt]\n\n\n[shiftk]\n/\n[ngkpt]\n ) belongs to the shifted grid number ii.\n\n\nThe user might rely on ABINIT to suggest suitable and efficient combinations\nof \nkptrlatt\n and \nshiftk\n. The procedure to be followed is described with\nthe input variables \nkptrlen\n. In what follows, we suggest some interesting\nvalues of the shifts, to be used with even values of \nngkpt\n. This list is\nmuch less exhaustive than the above-mentioned automatic procedure.\n\n\n1) When the primitive vectors of the lattice do NOT form a FCC or a BCC\nlattice, the default (shifted) Monkhorst-Pack grids are formed by using\n\nnshiftk\n=1 and \nshiftk\n 0.5 0.5 0.5 . This is often the preferred k point\nsampling, as the shift improves the sampling efficiency. However, it can also\nbreak symmetry, if the 111 direction is not an axis of rotation, e.g. in\ntetragonal or hexagonal systems. Abinit will complain about this breaking, and\nyou should adapt \nshiftk\n. For a non-shifted Monkhorst-Pack grid, use\n\nnshiftk\n=1 and \nshiftk\n 0.0 0.0 0.0 , which will be compatible with all\nsymmetries, and is necessary for some features such as k-point interpolation.\n\n\n2) When the primitive vectors of the lattice form a FCC lattice, with\n\nrprim\n\n\n  0.0 0.5 0.5\n  0.5 0.0 0.5\n  0.5 0.5 0.0\n\n\n\n\n\nthe (very efficient) usual Monkhorst-Pack sampling will be generated by using\n\nnshiftk\n= 4 and \nshiftk\n\n\n  0.5 0.5 0.5\n  0.5 0.0 0.0\n  0.0 0.5 0.0\n  0.0 0.0 0.5\n\n\n\n\n\n3) When the primitive vectors of the lattice form a BCC lattice, with\n\nrprim\n\n\n  -0.5  0.5  0.5\n   0.5 -0.5  0.5\n   0.5  0.5 -0.5\n\n\n\n\n\nthe usual Monkhorst-Pack sampling will be generated by using \nnshiftk\n= 2\nand \nshiftk\n\n\n  0.25  0.25  0.25\n -0.25 -0.25 -0.25\n\n\n\n\n\nHowever, the simple sampling \nnshiftk\n=1 and \nshiftk\n 0.5 0.5 0.5 is\nexcellent.\n\n\n4) For hexagonal lattices with hexagonal axes, e.g. \nrprim\n\n\n  1.0  0.0       0.0\n -0.5  sqrt(3)/2 0.0\n  0.0  0.0       1.0\n\n\n\n\n\none can use \nnshiftk\n= 1 and \nshiftk\n 0.0 0.0 0.5\n\n\nIn rhombohedral axes, e.g. using \nangdeg\n 3*60., this corresponds to\n\nshiftk\n 0.5 0.5 0.5, to keep the shift along the symmetry axis.\n\n\nsymrel\n\u00b6\n\n\nMnemonics: SYMmetry in REaL space\n\nVariable type: integer\n\nDimensions: (3,3,\nnsym\n)\n\nDefault value: [[1, 0, 0], [0, 1, 0], [0, 0, 1]] if \nnsym\n==1,\nNone otherwise.\n\n\nGives \u201c\nnsym\n\u201d 3x3 matrices expressing space group symmetries in terms of\ntheir action on the direct (or real) space primitive translations.\n\nIt turns out that these can always be expressed as integers.\n\nAlways give the identity matrix even if no other symmetries hold, e.g.\n\nsymrel\n 1 0 0 0 1 0 0 0 1\n\nAlso note that for this array as for all others the array elements are filled\nin a columnwise order as is usual for Fortran.\n\nThe relation between the above symmetry matrices \nsymrel\n, expressed in the\nbasis of primitive translations, and the same symmetry matrices expressed in\ncartesian coordinates, is as follows. Denote the matrix whose columns are the\nprimitive translations as R, and denote the cartesian symmetry matrix as S.\nThen\n\n\nsymrel\n = R(inverse) * S * R\n\nwhere matrix multiplication is implied.\n\nWhen the symmetry finder is used (see \nnsym\n), \nsymrel\n will be computed\nautomatically.\n\n\ntnons\n\u00b6\n\n\nMnemonics: Translation NON-Symmorphic vectors\n\nVariable type: real\n\nDimensions: (3,\nnsym\n)\n\nDefault value: None  \n\n\nGives the (nonsymmorphic) translation vectors associated with the symmetries\nexpressed in \u201c\nsymrel\n\u201d.\n\nThese may all be 0, or may be fractional (nonprimitive) translations expressed\nrelative to the real space primitive translations (so, using the \u201creduced\u201d\nsystem of coordinates, see \u201c\nxred\n\u201d). If all elements of the space group\nleave 0 0 0 invariant, then these are all 0.\n\nWhen the symmetry finder is used (see \nnsym\n), \ntnons\n is computed\nautomatically.\n\n\ntoldfe\n\u00b6\n\n\nMnemonics: TOLerance on the DiFference of total Energy\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria \ntolwfr\n, \ntoldff\n, \ntolrff\n, \ntoldfe\n or \ntolvrs\n must differ from zero.\n\nThe use of this variable forbids the use of specified(\ntolwfr\n) or specified(\ntoldff\n) or specified(\ntolrff\n) or specified(\ntolvrs\n)  \n\n\nSets a tolerance for absolute differences of total energy that, reached TWICE\nsuccessively, will cause one SCF cycle to stop (and ions to be moved).\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \ntoldfe\n has\nthe \u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV)\n\nIf set to zero, this stopping condition is ignored.\n\nEffective only when SCF cycles are done (\niscf\n>0).\n\nBecause of machine precision, it is not worth to try to obtain differences in\nenergy that are smaller than about 1.0d-12 of the total energy. To get\naccurate stresses may be quite demanding.\n\nWhen the geometry is optimized (relaxation of atomic positions or primitive\nvectors), the use of \ntoldfe\n is to be avoided. The use of \ntoldff\n or\n\ntolrff\n is by far preferable, in order to have a handle on the geometry\ncharacteristics. When all forces vanish by symmetry (e.g. optimization of the\nlattice parameters of a high-symmetry crystal), then place \ntoldfe\n to\n1.0d-12, or use (better) \ntolvrs\n.\n\nSince \ntoldfe\n, \ntoldff\n, \ntolrff\n, \ntolvrs\n and \ntolwfr\n are aimed\nat the same goal (causing the SCF cycle to stop), they are seen as a unique\ninput variable at reading. Hence, it is forbidden that two of these input\nvariables have non-zero values for the same dataset, or generically (for all\ndatasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.\n\n\ntoldff\n\u00b6\n\n\nMnemonics: TOLerance on the DiFference of Forces\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria \ntolwfr\n, \ntoldff\n, \ntolrff\n, \ntoldfe\n or \ntolvrs\n must differ from zero.\n\nThe use of this variable forbids the use of specified(\ntolwfr\n) or specified(\ntoldfe\n) or specified(\ntolrff\n) or specified(\ntolvrs\n)  \n\n\nSets a tolerance for differences of forces (in hartree/Bohr) that, reached\nTWICE successively, will cause one SCF cycle to stop (and ions to be moved).\n\nIf set to zero, this stopping condition is ignored.\n\nEffective only when SCF cycles are done (\niscf\n>0). This tolerance\napplies to any particular cartesian component of any atom, INCLUDING fixed\nones. This is to be used when trying to equilibrate a structure to its lowest\nenergy configuration (\nionmov\n=2), or in case of molecular dynamics\n(\nionmov\n=1)\n\nA value ten times smaller than \ntolmxf\n is suggested (for example 5.0d-6\nhartree/Bohr).\n\nThis stopping criterion is not allowed for RF calculations.\n\nSince \n toldfe \n , \ntoldff\n, \ntolrff\n, \ntolvrs\n and \ntolwfr\n are\naimed at the same goal (causing the SCF cycle to stop), they are seen as a\nunique input variable at reading. Hence, it is forbidden that two of these\ninput variables have non-zero values for the same dataset, or generically (for\nall datasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.\n\n\ntolrff\n\u00b6\n\n\nMnemonics: TOLerance on the Relative diFference of Forces\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria \ntolwfr\n, \ntoldff\n, \ntolrff\n, \ntoldfe\n or \ntolvrs\n must differ from zero.\n\nThe use of this variable forbids the use of specified(\ntolwfr\n) or specified(\ntoldfe\n) or specified(\ntoldff\n) or specified(\ntolvrs\n)\u2019  \n\n\nSets a tolerance for the ratio of differences of forces (in hartree/Bohr) to\nmaximum force, that, reached TWICE successively, will cause one SCF cycle to\nstop (and ions to be moved) : diffor < tolrff * maxfor.\n\nIf set to zero, this stopping condition is ignored.\n\nEffective only when SCF cycles are done (\niscf\n>0). This tolerance\napplies to any particular cartesian component of any atom, INCLUDING fixed\nones. This is to be used when trying to equilibrate a structure to its lowest\nenergy configuration (\nionmov\n=2), or in case of molecular dynamics\n(\nionmov\n=1)\n\nA value of 0.02 is suggested.\n\nThis stopping criterion is not allowed for RF calculations.\n\nSince \n toldfe \n , \ntoldff\n, \ntolrff\n, \ntolvrs\n and \ntolwfr\n are\naimed at the same goal (causing the SCF cycle to stop), they are seen as a\nunique input variable at reading. Hence, it is forbidden that two of these\ninput variables have non-zero values for the same dataset, or generically (for\nall datasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.\n\n\ntolvrs\n\u00b6\n\n\nMnemonics: TOLerance on the potential V(r) ReSidual\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria \ntolwfr\n, \ntoldff\n, \ntolrff\n, \ntoldfe\n or \ntolvrs\n must differ from zero.\n\nThe use of this variable forbids the use of specified(\ntolwfr\n) or specified(\ntoldfe\n) or specified(\ntoldff\n) or specified(\ntolrff\n)\u2019  \n\n\nSets a tolerance for potential residual that, when reached, will cause one SCF\ncycle to stop (and ions to be moved).\n\nIf set to zero, this stopping condition is ignored.\n\nEffective only when SCF cycles are done (\niscf\n>0).\n\nTo get accurate stresses may be quite demanding. For simple materials with\ninternal positions determined by symmetries, a value of \ntolvrs\n=10^-12\nempirically leads to a very approximate 10^-6 atomic unit accuracy for the\noptimized lattice parameter.\n\n\nAdditional explanation : the residual of the potential is the difference\nbetween the input potential and the output potential, when the latter is\nobtained from the density determined from the eigenfunctions of the input\npotential. When the self-consistency loop is achieved, both input and output\npotentials must be equal, and the residual of the potential must be zero. The\ntolerance on the potential residual is imposed by first subtracting the mean\nof the residual of the potential (or the trace of the potential matrix, if the\nsystem is spin-polarized), then summing the square of this function over all\nFFT grid points. The result should be lower than \ntolvrs\n.\n\nSince \n toldfe \n , \ntoldff\n, \ntolrff\n, \ntolvrs\n and \ntolwfr\n are\naimed at the same goal (causing the SCF cycle to stop), they are seen as a\nunique input variable at reading. Hence, it is forbidden that two of these\ninput variables have non-zero values for the same dataset, or generically (for\nall datasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.\n\n\ntolwfr\n\u00b6\n\n\nMnemonics: TOLerance on WaveFunction squared Residual\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria \ntolwfr\n, \ntoldff\n, \ntolrff\n, \ntoldfe\n or \ntolvrs\n must differ from zero.\n\nThe use of this variable forbids the use of specified(\ntoldfe\n) or specified(\ntoldff\n) or specified(\ntolrff\n) or specified(\ntolvrs\n)  \n\n\nThe signification of this tolerance depends on the basis set. In plane waves,\nit gives a convergence tolerance for the largest squared \u201cresidual\u201d (defined\nbelow) for any given band. The squared residual is:  \n\n\n  < nk|(H-E)2|nk >,    E = < nk|H|nk >\n\n\n\n\n\nwhich clearly is nonnegative and goes to 0 as the iterations converge to an\neigenstate. With the squared residual expressed in Hartrees  2  (Hartrees\nsquared), the largest squared residual (called residm) encountered over all\nbands and k points must be less than \ntolwfr\n for iterations to halt due to\nsuccessful convergence.\n\nNote that if \niscf\n>0, this criterion should be replaced by those based\non \ntoldfe\n (preferred for \nionmov\n==0), \ntoldff\n \ntolrff\n (preferred\nfor \nionmov\n/=0), or \ntolvrs\n (preferred for theoretical reasons!).\n\nWhen \ntolwfr\n is 0.0, this criterion is ignored, and a finite value of\n\ntoldfe\n, \ntoldff\n or \ntolvrs\n must be specified. This also imposes a\nrestriction on taking an ion step; ion steps are not permitted unless the\nlargest squared residual is less than \ntolwfr\n, ensuring accurate forces.\n\nTo get accurate stresses may be quite demanding.\n\nNote that the preparatory GS calculations before a RF calculations must be\nhighly converged.\n\nTypical values for these preparatory runs are \ntolwfr\n between 1.0d-16 and\n1.0d-22.\n\n\nNote that \ntolwfr\n is often used in the test cases, but this is _ tolwfr _\npurely for historical reasons : except when \niscf\n<0, other critera\nshould be used.\n\n\nIn the wavelet case (see \nusewvl\n = 1), this criterion is the favoured one.\nIt is based on the norm 2 of the gradient of the wavefunctions. Typical values\nrange from 5\n10  -4  to 5\n10  -5  .\n\n\nSince \n toldfe \n , \ntoldff\n, \ntolrff\n, \ntolvrs\n and \ntolwfr\n are\naimed at the same goal (causing the SCF cycle to stop), they are seen as a\nunique input variable at reading. Hence, it is forbidden that two of these\ninput variables have non-zero values for the same dataset, or generically (for\nall datasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.\n\n\ntypat\n\u00b6\n\n\nMnemonics: TYPe of AToms\n\nVariable type: integer\n\nDimensions: [3, \u2018\nnatrd\n\u2019] if \nnatrd\n<\nnatom\n,\n[3, \u2018\nnatom\n\u2019] otherwise.\n\n\nDefault value: 1 if \nnatom\n==1,\nNone otherwise.\n\n\nArray giving an integer label to every atom in the unit cell to denote its\ntype.\n\nThe different types of atoms are constructed from the pseudopotential files.\nThere are at most \nntypat\n types of atoms.\n\nAs an example, for BaTiO3, where the pseudopotential for Ba is number 1, the\none of Ti is number 2, and the one of O is number 3, the actual value of the\n\ntypat\n array might be :\n\n\n  typat 1 2 3 3 3\n\n\n\n\n\nThe array \ntypat\n has to agree with the actual locations of atoms given in\n\nxred\n , \nxcart\n or \nxangst\n, and the input of pseudopotentials has to\nbe ordered to agree with the atoms identified in \ntypat\n.\n\nThe nuclear charge of the elements, given by the array \nznucl\n, also must\nagree with the type of atoms designated in \u201c\ntypat\n\u201d.\n\nThe array \ntypat\n is not constrained to be increasing. An internal\nrepresentation of the list of atoms, deep in the code (array atindx), groups\nthe atoms of same type together. This should be transparent to the user, while\nkeeping efficiency.\n\n\nudtset\n\u00b6\n\n\nMnemonics: Upper limit on DaTa SETs\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: None\n\nComment: It is not used when it is not defined  \n\n\nUsed to define the set of indices in the multi-data set mode, when a double\nloop is needed (see later).\n\nThe values of \n[udtset]\n must be between 1 and 999, the values of\n\n[udtset]\n must be between 1 and 9, and their product must be equal to\n\nndtset\n.\n\nThe values of \njdtset\n are obtained by looping on the two indices defined by\n\n[udtset]\n and \n[udtset]\n as follows :\n\n\n  do i1=1,intarr(1)\n   do i2=1,intarr(2)\n    idtset=idtset+1\n    dtsets(idtset)%jdtset=i1*10+i2\n   end do\n  end do\n\n\n\n\n\nSo, \n[udtset]\n sets the largest value for the unity digit, that varies\nbetween 1 and \n[udtset]\n.\n\nIf \nudtset\n is used, the input variable \njdtset\n cannot be used.\n\n\nusewvl\n\u00b6\n\n\nMnemonics: Use WaVeLet basis set\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nComment: use plane-wave basis set  \n\n\nUsed to define if the calculation is done on a wavelet basis set or not.\n\nThe values of \nusewvl\n must be 0 or 1. Putting \nusewvl\n to 1, makes\n\nicoulomb\n mandatory to 1. The number of band (\nnband\n) must be set\nmanually to the strict number need for an isolator system ( _ i.e. _ number of\nelectron over two). The cut-off is not relevant in the wavelet case, use\n\nwvl_hgrid\n instead.\n\nIn wavelet case, the system must be isolated systems (molecules or clusters).\nAll geometry optimization are available (see \nionmov\n, especially the\ngeometry optimisation and the molecular dynamics).\n\nThe spin computation is not currently possible with wavelets and metalic\nsystems may be slow to converge.\n\n\nwtk\n\u00b6\n\n\nMnemonics: WeighTs for K points\n\nVariable type: real\n\nDimensions: (\nnkpt\n)\n\nDefault value: \nnkpt\n*1.0\n\nComment: Except when \nkptopt\n/=0  \n\n\nGives the k point weights.\n\nThe k point weights will have their sum (re)normalized to 1 (unless\n\noccopt\n=2 and \nkptopt\n=0; see description of \noccopt\n) within the\nprogram and therefore may be input with any arbitrary normalization. This\nfeature helps avoid the need for many digits in representing fractional\nweights such as 1/3.\n\n\nwtk\n is ignored if \niscf\n is not positive, except if \niscf\n=-3.\n\n\nwvl_hgrid\n\u00b6\n\n\nMnemonics: WaVeLet H step GRID\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.5  \n\n\nIt gives the step size in real space for the grid resolution in the wavelet\nbasis set. This value is highly responsible for the memory occupation in the\nwavelet computation. The value is a length in atomic units.\n\n\nxangst\n\u00b6\n\n\nMnemonics: vectors (X) of atom positions in cartesian coordinates -length in ANGSTrom-\n\nVariable type: real\n\nDimensions: (3,min(\nnatom\n,\nnatrd\n))\n\nDefault value: None  \n\n\nGives the cartesian coordinates of atoms within unit cell, in angstrom. This\ninformation is redundant with that supplied by array \nxred\n or \nxcart\n.\n\nIf \nxred\n and \nxangst\n are ABSENT from the input file and \nxcart\n is\nprovided, then the values of \nxred\n will be computed from the provided\n\nxcart\n (i.e. the user may use xangst instead of \nxred\n or \nxcart\n to\nprovide starting coordinates).\n\nOne and only one of \nxred\n, \nxcart\n and \nxangst\n must be provided.\n\nThe conversion factor between Bohr and Angstrom is 1 Bohr=0.5291772108\nAngstrom, see the \n NIST site\n\n .\n\nAtomic positions evolve if \nionmov\n/=0 . In constrast with \nxred\n and\n\nxcart\n, \nxangst\n is not internal.\n\n\nxcart\n\u00b6\n\n\nMnemonics: vectors (X) of atom positions in CARTesian coordinates\n\nVariable type: real\n\nDimensions: (3,min(\nnatom\n,\nnatrd\n))\n\nDefault value: None  \n\n\nGives the cartesian coordinates of atoms within unit cell. This information is\nredundant with that supplied by array \nxred\n or \nxangst\n. By default,\n\nxcart\n is given in Bohr atomic units (1 Bohr=0.5291772108 Angstroms),\nalthough Angstrom can be specified, if preferred, since \nxcart\n has the\n\u2018\nLENGTH\n\u2018 characteristics.\n\nIf \nxred\n and \nxangst\n are ABSENT from the input file and \nxcart\n is\nprovided, then the values of \nxred\n will be computed from the provided\n\nxcart\n (i.e. the user may use \nxcart\n instead of \nxred\n or \nxangst\n\nto provide starting coordinates).\n\nOne and only one of \nxred\n, \nxcart\n and \n xangst \n must be provided.\n\nAtomic positions evolve if \nionmov\n/=0 .\n\n\nxred\n\u00b6\n\n\nMnemonics: vectors (X) of atom positions in REDuced coordinates\n\nVariable type: real\n\nDimensions: (3,min(\nnatom\n,\nnatrd\n))\n\ncommentdims represented internally as xred(3,\nnatom\n,\nnimage\n)\n\nDefault value: *0.0  \n\n\nGives the atomic locations within unit cell in coordinates relative to real\nspace primitive translations (NOT in cartesian coordinates). Thus these are\nfractional numbers typically between 0 and 1 and are dimensionless. The\ncartesian coordinates of atoms (in Bohr) are given by:\n\nR_cartesian = xred1\nrprimd1+xred2\nrprimd2+xred3*rprimd3\n\nwhere (xred1,xred2,xred3) are the \u201creduced coordinates\u201d given in columns of\n\u201c\nxred\n\u201d, (rprimd1,rprimd2,rprimd3) are the columns of primitive vectors\narray \u201c\nrprimd\n\u201d in Bohr.\n\nIf you prefer to work only with cartesian coordinates, you may work entirely\nwith \u201c\nxcart\n\u201d or \u201c\nxangst\n\u201d and ignore \nxred\n, in which case \nxred\n\nmust be absent from the input file.\n\nOne and only one of \nxred\n, \nxcart\n and \nxangst\n must be provided.\n\nAtomic positions evolve if \nionmov\n/=0 .\n\n\nznucl\n\u00b6\n\n\nMnemonics: charge -Z- of the NUCLeus\n\nVariable type: real\n\nDimensions: (\nnpsp\n)\n\nDefault value: None  \n\n\nGives nuclear charge for each type of pseudopotential, in order.\n\nIf \nznucl\n does not agree with nuclear charge, as given in pseudopotential\nfiles, the program writes an error message and stops.\n\n\nN.B. : In the pseudopotential files, \nznucl\n is called \u201czatom\u201d.\n\n\nFor a \u201cdummy\u201d atom, with \nznucl\n=0 , as used in the case of calculations\nwith only a jellium surface, ABINIT sets arbitrarily the covalent radius to\none.",
            "title": "Basic"
        },
        {
            "location": "/input_variables/varbas/#accuracy",
            "text": "Mnemonics: ACCURACY \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Allows to tune the accuracy of a calculation by setting automatically the\nvariables  ecut ,  boxcutmin ,  fband ,  tolvrs ,  tolmxf , optforces ,  timopt ,  npulayit ,  nstep ,  prteig ,  prtden ,\nand if  usepaw =1,  pawecutdg ,  bxctmindg ,  pawxcdev ,  pawmixdg , pawovlp ,  pawnhatxc , according to the following table:  accuracy  |  1  |  2  |  3  |  4  |  5  |  6    \u2014|\u2014|\u2014|\u2014|\u2014|\u2014|\u2014    ecut  |  E_min  |  E_med  |  E_med  |  E_max  |  E_max  |  E_max     pawecutdg  |  ecut  |  ecut  |  1.2*ecut  |  1.5*ecut  |  2*ecut  |  2*ecut    fband  |  0.5  |  0.5  |  0.5  |  0.5  |  0.75  |  0.75    boxcutmin  |  1.5  |  1.8  |  1.8  |  2.0  |  2.0  |  2.0     bxctmindg  |  1.5  |  1.8  |  1.8  |  2.0  |  2.0  |  2.0     pawxcdev  |  1  |  1  |  1  |  1  |  2  |  2    pawmixdg  |  0  |  0  |  0  |  0  |  1  |  1    pawovlp  |  10  |  7  |  7  |  5  |  5  |  5     pawnhatxc  |  0  |  1  |  1  |  1  |  1  |  1     tolvrs  |  1.0d-3  |  1.0d-5  |  1.0d-7  |  1.0d-9  |  1.0d-10  |  1.0d-12    tolmxf  |  1.0d-3  |  5.0d-4  |  1.0d-4  |  5.0d-5  |  1.0d-6  |  1.0d-6    optforces  |  1  |  1  |  2  |  2  |  2  |  2     timopt  |  0  |  0  |  1  |  1  |  1  |  1     npulayit  |  4  |  7  |  7  |  7  |  15  |  15    nstep  |  30  |  30  |  30  |  30  |  50  |  50    prteig  |  0  |  0  |  1  |  1  |  1  |  1     prtden  |  0  |  0  |  1  |  1  |  1  |  1     For a parallel calculation,  timopt  is enforced to be 0. \nE_min, E_med and E_max may be read from the pseudopotential file (available\nonly for XML PAW atomic data files). If E_min, E_med and E_max are not given\nin the pseudopotential file,  ecut  must be given in the input file and\nE_max=E_med=E_max=ecut. \nThe values in bold font are the default values of ABINIT.  accuracy =4\ncorresponds to the default tuning of ABINIT. It is already a very accurate\ntuning. \nIf the user wants to modify one of the input variable automatically tuned by accuracy , he must put it in the input file. The other input variables\nautomatically tuned by  accuracy  will not be affected.  accuracy =0 means that this input variable is desactivated.",
            "title": "accuracy"
        },
        {
            "location": "/input_variables/varbas/#acell",
            "text": "Mnemonics: CELL lattice vector scaling \nVariable type: real \nDimensions: (3) \ncommentdims represented internally as acell(3, nimage ) \nDefault value: 3*1    Gives the length scales by which dimensionless primitive translations (in rprim ) are to be multiplied. By default, given in Bohr atomic units (1\nBohr=0.5291772108 Angstroms), although Angstrom can be specified, if\npreferred, since  acell  has the \u2018 LENGTH \u2018 characteristics. See further\ndescription of  acell  related to the  rprim  input variable, the scalecart  input variable, and the associated internal  rprimd  input\nvariable.  Note that  acell  is NOT the length of the conventional orthogonal basis\nvectors, but the scaling factors of the primitive vectors. Use  scalecart \nto scale the cartesian coordinates.",
            "title": "acell"
        },
        {
            "location": "/input_variables/varbas/#angdeg",
            "text": "Mnemonics: ANGles in DEGrees \nVariable type: real \nDimensions: (3) \nDefault value: None \nComment: deduced from \u2018 rprim \u2018    Gives the angles between directions of primitive vectors of the unit cell (in\ndegrees), as an alternative to the input array  rprim  . Will be used to set\nup  rprim , that, together with the array  acell , will be used to define\nthe primitive vectors.   [angdeg]  is the angle between the 2nd and 3rd vectors,   [angdeg]  is the angle between the 1st and 3rd vectors,   [angdeg]  is the angle between the 1st and 2nd vectors,    If the three angles are equal within 1.0d-12 (except if they are exactly 90\ndegrees), the three primitive vectors are chosen so that the trigonal symmetry\nthat exchange them is along the z cartesian axis :  R1=( a , 0,c)\nR2=(-a/2, sqrt(3)/2*a,c)\nR3=(-a/2,-sqrt(3)/2*a,c)  where a  2  +c  2  =1.0d0 \nIf the angles are not all equal (or if they are all 90 degrees), one will have\nthe following generic form :   R1=(1,0,0)   R2=(a,b,0)   R3=(c,d,e)    where each of the vectors is normalized, and form the desired angles with the\nothers.",
            "title": "angdeg"
        },
        {
            "location": "/input_variables/varbas/#ecut",
            "text": "Mnemonics: Energy CUToff \nVariable type: real \nDimensions: scalar \nDefault value: None    Used for kinetic energy cutoff which controls number of planewaves at given k\npoint by: \n(1/2)[(2 Pi)*(k+Gmax)]  2  = ecut  for Gmax. \nAll planewaves inside this \u201cbasis sphere\u201d centered at k are included in the\nbasis (except if  dilatmx  is defined). \nCan be specified in Ha (the default), Ry, eV or Kelvin, since  ecut  has the\n\u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV) \nThis is the single parameter which can have an enormous effect on the quality\nof a calculation; basically the larger  ecut  is, the better converged the\ncalculation is. For fixed geometry, the total energy MUST always decrease as ecut  is raised because of the variational nature of the problem.  _ Usually one runs at least several calculations at various  ecut  to\ninvestigate the convergence needed for reliable results. _  For k-points whose coordinates are build from 0 or 1/2, the implementation of\ntime-reversal symmetry that links coefficients of the wavefunctions in\nreciprocal space has been realized. See the input variable  istwfk . If\nactivated (which corresponds to the Default mode), this input variable istwfk  will allow to divide the number of plane wave (npw) treated\nexplicitly by a factor of two. Still, the final result should be identical\nwith the \u2018full\u2019 set of plane waves.  See the input variable  ecutsm , for the smoothing of the kinetic energy,\nneeded to optimize unit cell parameters.",
            "title": "ecut"
        },
        {
            "location": "/input_variables/varbas/#einterp",
            "text": "Mnemonics: Electron bands INTERPolation \nVariable type: real \nDimensions: (4) \nDefault value: [0, 0, 0, 0]    This variable activates the interpolation of the electronic eigenvalues. It\ncan be used to interpolate KS eigenvalues at the end of the GS run or to\ninterpolate GW energies in sigma calculations ( optdriver  = 4). The k-path\ncan be specified with  kptbounds  and  nkpath . einterp consists of 4\nentries. The first element specificies the interpolation method.   0 \u2013> No interpolation (default)   1 \u2013> Star-function interpolation (Shankland-Koelling-Wood Fourier interpolation scheme, see  Pickett1988    2 \u2013> B-spline interpolation.    The meaning of the other entries depend on the interpolation technique\nselected. \nIn the case of star-function interpolation:   einterp(2): Number of star-functions per ab-initio k-point   einterp(3): If non-zero, activate Fourier filtering according to Eq 9 of  Uehara2000 . In this case, rcut is given by einterp(2) * Rmax where Rmax is the maximum length of the lattice vectors included in the star expansion   einterp(4): Used if einterp(2) /= 0. It defines rsigma in Eq 9   For B-spline interpolation: einterp(2:4): Order of B-spline for the three\nreduced directions. Cubic spline (3) is the recomended value.",
            "title": "einterp"
        },
        {
            "location": "/input_variables/varbas/#iscf",
            "text": "Mnemonics: Integer for Self-Consistent-Field cycles \nVariable type: integer \nDimensions: scalar \nDefault value: 17 if  usepaw ==1,\n0 if  usewvl ==1,\n7 otherwise.  Controls the self-consistency. \nPositive values => this is the usual choice for doing the usual ground\nstate (GS) calculations or for structural relaxation, where the potential has\nto be determined self-consistently. The choice between different algorithms\nfor SCF is possible :   =0 => SCF cycle, direct minimization scheme on the gradient of the wavefunctions. This algorithm is faster than diagonalisation and mixing but is working only for systems with a gap. It is implemented only on the wavelet basis set, when  usewvl =1.    =1 => get the largest eigenvalue of the SCF cycle  \n( DEVELOP  option, used with  irdwfk =1 or  irdwfq =1)    =2 => SCF cycle, simple mixing of the potential    =3 => SCF cycle, Anderson mixing of the potential   =4 => SCF cycle, Anderson mixing of the potential based on the two previous iterations   =5 => SCF cycle, CG based on the minim. of the energy with respect to the potential   =7 => SCF cycle, Pulay mixing of the potential based on the  npulayit  previous iterations   =12 => SCF cycle, simple mixing of the density   =13 => SCF cycle, Anderson mixing of the density   =14 => SCF cycle, Anderson mixing of the density based on the two previous iterations   =15 => SCF cycle, CG based on the minim. of the energy with respect to the density   =17 => SCF cycle, Pulay mixing of the density based on the  npulayit  previous iterations   Other positive values, including zero ones, are not allowed.    Such algorithms for treating the \u201cSCF iteration history\u201d should be coupled\nwith accompanying algorithms for the SCF \u201cpreconditioning\u201d. See the input\nvariable  iprcel . The default value  iprcel =0 is often a good choice,\nbut for inhomogeneous systems, you might gain a lot with  iprcel =45.  (Warning : if  iscf >10, at present (v4.6), the energy printed at each\nSCF cycle is not variational - this should not affect the other properties,\nand at convergence, all values are OK)  - In the norm-conserving case, the default option is  iscf =7, which is a\ncompromise between speed and reliability. The value  iscf = 2 is safer but\nslower. \n- In the PAW case, default option is  iscf =17. In PAW you have the\npossibility to mix density/potential on the fine or coarse FFT grid (see pawmixdg ). \n- Note that a Pulay mixing ( iscf =7 or 17) with  npulayit  =1 (resp. 2)\nis equivalent to an Anderson mixing with  iscf =3 or 13 (resp. 4 or 14). \n- Also note that:   when mixing is done on potential (iscf <10), total energy is computed by \u201cdirect\u201d decomposition.    when mixing is done on density (iscf >=10), total energy is computed by \u201cdouble counting\u201d decomposition.  \n\u201cDirect\u201d and \u201cdouble counting\u201d decomposition of energy are equal when SCF\ncycle is converged. Note that, when using GGA XC functionals, these\ndecompositions of energy can be slightly different due to imprecise\ncomputation of density gradients on FFT grid (difference decreases as size of\nFFT grid increases - see  ecut  for NC pseudopotentials,  pawecutdg  for\nPAW).    Other (negative) options:    = -2 => a non-self-consistent calculation is to be done; in this case an electron density rho(r) on a real space grid (produced in a previous calculation) will be read from a disk file (automatically if  ndtset =0, or according to the value of  getden  if  ndtset /=0).  \nThe name of the density file must be given as indicated in the   section 4  of  help_abinit . iscf =-2 would be used for band structure calculations, to permit\ncomputation of the eigenvalues of occupied and unoccupied states at arbitrary\nk points in the fixed self consistent potential produced by some integration\ngrid of k points. Due to this typical use, ABINIT insist that either prtvol >2 or  prteig  does not vanish when there are more than 50 k\npoints. \nTo compute the eigenvalues (and wavefunctions) of unoccupied states in a\nseparate (non-selfconsistent) run, the user should save the self-consistent\nrho(r) and then run  iscf =-2 for the intended set of k-points and bands. \nTo prepare a run with  iscf =-2, a density file can be produced using the\nparameter  prtden  (see its description). When a self-consistent set of\nwavefunctions is already available, abinit can be used with  nstep =0 (see\nTest_v2/t47.in), and the adequate value of  prtden .    = -3 => like -2, but initialize  occ  and  wtk , directly or indirectly (using  ngkpt  or  kptrlatt ) depending on the value of  occopt .  \nFor GS, this option might be used to generate Density-of-states (thanks to prtdos ), or to produce STM charge density map (thanks to  prtstm ). \nFor RF, this option is needed to compute the response to ddk perturbation.    = -1 => like -2, but the non-self-consistent calculation is followed by the determination of excited states within  TDDFT . This is only possible for  nkpt =1, with  kpt =0 0 0. Note that the oscillator strength needs to be defined with respect to an origin of coordinate, thanks to the input variable  boxcenter . The maximal number of Kohn-Sham excitations to be used to build the excited state  TDDFT  matrix can be defined by  td_mexcit , or indirectly by the maximum Kohn-Sham excitation energy  td_maxene .",
            "title": "iscf"
        },
        {
            "location": "/input_variables/varbas/#ixc",
            "text": "Mnemonics: Integer for eXchange-Correlation choice \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nComment: Default corresponds to Teter parametrization. However, if all the pseudopotentials have the same value of pspxc, the initial value of ixc will be that common value    Controls the choice of exchange and correlation (xc). The list of XC\nfunctionals is given below. Positive values are for ABINIT native library of\nXC functionals, while negative values are for calling the much wider set of\nfunctionals from the ETSF LibXC library (by M. Marques), also available at the  ETSF library Web page \nNote that the choice made here should agree with the choice made in generating\nthe original pseudopotential, except for  ixc =0 (usually only used for\ndebugging). A warning is issued if this is not the case. However, the choices ixc =1, 2, 3 and 7 are fits to the same data, from Ceperley-Alder, and are\nrather similar, at least for spin-unpolarized systems. \nThe choice between the non-spin-polarized and spin-polarized case is governed\nby the value of  nsppol  (see below).   Native ABINIT XC functionals   NOTE : in the implementation of the spin-dependence of these functionals, and\nin order to avoid divergences in their derivatives, the interpolating function\nbetween spin-unpolarized and fully-spin-polarized function has been slightly\nmodified, by including a zeta rescaled by 1.d0-1.d-6. This should affect total\nenergy at the level of 1.d-6Ha, and should have an even smaller effect on\ndifferences of energies, or derivatives. \nThe value  ixc =10 is used internally : gives the difference between ixc =7 and  ixc =9, for use with an accurate RPA correlation energy.    0=> NO xc;     1=> LDA or LSD, Teter Pade parametrization (4/93, published in  Goedecker1996 , which reproduces Perdew-Wang (which reproduces Ceperley-Alder!).    2=> LDA, Perdew-Zunger-Ceperley-Alder (no spin-polarization)  Perdew1981    3=> LDA, old Teter rational polynomial parametrization (4/91) fit to Ceperley-Alder data (no spin-polarization)   4=> LDA, Wigner functional (no spin-polarization)   5=> LDA, Hedin-Lundqvist functional (no spin-polarization)   6=> LDA, \u201cX-alpha\u201d functional (no spin-polarization)   7=> LDA or LSD, Perdew-Wang 92 functional   8=> LDA or LSD, x-only part of the Perdew-Wang 92 functional    9=> LDA or LSD, x- and RPA correlation part of the Perdew-Wang 92 functional     11=> GGA, Perdew-Burke-Ernzerhof GGA functional    12=> GGA, x-only part of Perdew-Burke-Ernzerhof GGA functional   13=> GGA potential of van Leeuwen-Baerends, while for energy, Perdew-Wang 92 functional   14=> GGA, revPBE of Y. Zhang and W. Yang, Phys. Rev. Lett. 80, 890 (1998)   15=> GGA, RPBE of B. Hammer, L.B. Hansen and J.K. Norskov, Phys. Rev. B 59, 7413 (1999)   16=> GGA, HTCH93 of F.A. Hamprecht, A.J. Cohen, D.J. Tozer, N.C. Handy, J. Chem. Phys. 109, 6264 (1998)   17=> GGA, HTCH120 of A.D. Boese, N.L. Doltsinis, N.C. Handy, and M. Sprik, J. Chem. Phys 112, 1670 (1998) - The usual HCTH functional.   18=> (NOT AVAILABLE : used internally for GGA BLYP pseudopotentials from M. Krack, see Theor. Chem. Acc. 114, 145 (2005), available from the   CP2K repository   - use the LibXC instead, with  ixc =-106131.    19=> (NOT AVAILABLE : used internally for GGA BP86 pseudopotentials from M. Krack, see Theor. Chem. Acc. 114, 145 (2005), available from the   CP2K repository   - use the LibXC instead, with  ixc =-106132.     20=> Fermi-Amaldi xc ( -1/N Hartree energy, where N is the number of electrons per cell ; G=0 is not taken into account however), for  TDDFT  tests. No spin-pol. Does not work for RF.    21=> same as 20, except that the xc-kernel is the LDA ( ixc =1) one, for  TDDFT  tests.   22=> same as 20, except that the xc-kernel is the Burke-Petersilka-Gross hybrid, for  TDDFT  tests.   23=> GGA of Z. Wu and R.E. Cohen, Phys. Rev. 73, 235116 (2006).   24=> GGA, C09x exchange of V. R. Cooper, PRB 81, 161104(R) (2010).   26=> GGA, HTCH147 of A.D. Boese, N.L. Doltsinis, N.C. Handy, and M. Sprik, J. Chem. Phys 112, 1670 (1998).   27=> GGA, HTCH407 of A.D. Boese, and N.C. Handy, J. Chem. Phys 114, 5497 (2001).    28=> (NOT AVAILABLE : used internally for GGA OLYP pseudopotentials from M. Krack, see Theor. Chem. Acc. 114, 145 (2005), available from the   CP2K repository   - use the LibXC instead, with  ixc =-110131.     40=> Hartree-Fock    41=> PBE0, J.P. Perdew, M. Ernzerhof and K. Burke, J. Chem. Phys. 105, 9982 (1996)   42=> PBE0-1/3, C.A. Guido, E. Bremond, C. Adamo and P. Cortona, J. Chem. Phys. 138, 021104 (2013)     ETSF Lib XC functionals   Note that you must compile ABINIT with the LibXC plug-in in order to be able\nto access these functionals. \nThe LibXC functionals are accessed by   negative values   of  ixc . The\nLibXC contains functional forms for either exchange-only functionals,\ncorrelation-only functionals, or combined exchange and correlation\nfunctionals. Each of them is to be specified by a three-digit number. In case\nof a combined exchange and correlation functional, only one such three-digit\nnumber has to be specified as value of  ixc , with a minus sign (to indicate\nthat it comes from the LibXC). In the case of separate exchange functional\n(let us represent its identifier by XXX) and correlation functional (let us\nrepresent its identified by CCC), a six-digit number will have to be specified\nfor  ixc , by concatenation, be it XXXCCC or CCCXXX. As an example, ixc =-020 gives access to the Teter93 LDA, while  ixc =-101130 gives\naccess to the PBE GGA. In version 0.9 of LibXC (December 2008), there are 16\nthree-dimensional (S)LDA functionals (1 for X, 14 for C, 1 for combined XC),\nand there are 41 three-dimensional GGA (23 for X, 8 for C, 10 for combined\nXC). Note that for a meta-GGA, the kinetic energy density is needed. This\nmeans having  usekden =1 .  (S)LDA functionals (do not forget to add a minus sign, as discussed above)   001=> XC_LDA_X [PAM Dirac, Proceedings of the Cambridge Philosophical Society 26, 376 (1930); F Bloch, Zeitschrift fuer Physik 57, 545 (1929) ]   002=> XC_LDA_C_WIGNER Wigner parametrization [EP Wigner, Trans. Faraday Soc. 34, 678 (1938) ]   003=> XC_LDA_C_RPA Random Phase Approximation [M Gell-Mann and KA Brueckner, Phys. Rev. 106, 364 (1957) ]   004=> XC_LDA_C_HL Hedin & Lundqvist [L Hedin and BI Lundqvist, J. Phys. C 4, 2064 (1971) ]   005=> XC_LDA_C_GL ! Gunnarson & Lundqvist [O Gunnarsson and BI Lundqvist, PRB 13, 4274 (1976) ]   006=> XC_LDA_C_XALPHA ! Slater\u2019s Xalpha ]   007=> XC_LDA_C_VWN ! Vosko, Wilk, & Nussair [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ]   008=> XC_LDA_C_VWN_RPA ! Vosko, Wilk, & Nussair (RPA) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ]   009=> XC_LDA_C_PZ ! Perdew & Zunger  Perdew1981    010=> XC_LDA_C_PZ_MOD ! Perdew & Zunger (Modified)  Perdew1981  Modified to improve the matching between the low and high rs part ]   011=> XC_LDA_C_OB_PZ ! Ortiz & Ballone (PZ) [G Ortiz and P Ballone, Phys. Rev. B 50, 1391 (1994) ; G Ortiz and P Ballone, Phys. Rev. B 56, 9970(E) (1997) ;  Perdew1981  ]   012=> XC_LDA_C_PW ! Perdew & Wang [JP Perdew and Y Wang, Phys. Rev. B 45, 13244 (1992) ]   013=> XC_LDA_C_PW_MOD ! Perdew & Wang (Modified) [JP Perdew and Y Wang, Phys. Rev. B 45, 13244 (1992) ; Added extra digits to some constants as in the PBE routine see   https://www.chem.uci.edu/~kieron/dftold2/pbe.php   (at some point it was available at http://dft.uci.edu/pbe.php) ]   014=> XC_LDA_C_OB_PW ! Ortiz & Ballone (PW) [G Ortiz and P Ballone, Phys. Rev. B 50, 1391 (1994) ; G Ortiz and P Ballone, Phys. Rev. B 56, 9970(E) (1997) ; JP Perdew and Y Wang, Phys. Rev. B 45, 13244 (1992) ]   017=> XC_LDA_C_vBH ! von Barth & Hedin [U von Barth and L Hedin, J. Phys. C: Solid State Phys. 5, 1629 (1972) ]   020=> XC_LDA_XC_TETER93 ! Teter 93 parametrization [S Goedecker, M Teter, J Hutter, PRB 54, 1703 (1996) ]   022=> XC_LDA_C_ML1 ! Modified LSD (version 1) of Proynov and Salahub [EI Proynov and D Salahub, Phys. Rev. B 49, 7874 (1994) ]   023=> XC_LDA_C_ML2 ! Modified LSD (version 2) of Proynov and Salahub [EI Proynov and D Salahub, Phys. Rev. B 49, 7874 (1994) ]   024=> XC_LDA_C_GOMBAS ! Gombas parametrization [P. Gombas, Pseudopotentials (Springer-Verlag, New York, 1967) ]   025=> XC_LDA_C_PW_RPA ! Perdew & Wang fit of the RPA [JP Perdew and Y Wang, Phys. Rev. B 45, 13244 (1992) ]   027=> XC_LDA_C_RC04 ! Ragot-Cortona [S Ragot and P Cortona, J. Chem. Phys. 121, 7671 (2004) ]   028=> XC_LDA_C_VWN_1 ! Vosko, Wilk, & Nussair (1) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ]   029=> XC_LDA_C_VWN_2 ! Vosko, Wilk, & Nussair (2) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ]   030=> XC_LDA_C_VWN_3 ! Vosko, Wilk, & Nussair (3) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ]   031=> XC_LDA_C_VWN_4 ! Vosko, Wilk, & Nussair (4) [SH Vosko, L Wilk, and M Nusair, Can. J. Phys. 58, 1200 (1980) ]    GGA functionals (do not forget to add a minus sign, as discussed above)   84=> XC_GGA_C_OP_XALPHA ! one-parameter progressive functional (G96 version) [T Tsuneda, T Suzumura, and K Hirao, J. Chem. Phys. 111, 5656 (1999) ]   85=> XC_GGA_C_OP_G96 ! one-parameter progressive functional (G96 version) [T Tsuneda, T Suzumura, and K Hirao, J. Chem. Phys. 111, 5656 (1999) ]   86=> XC_GGA_C_OP_PBE ! one-parameter progressive functional (PBE version) [T Tsuneda, T Suzumura, and K Hirao, J. Chem. Phys. 111, 5656 (1999) ]   87=> XC_GGA_C_OP_B88 ! one-parameter progressive functional (B88 version) [T Tsuneda, T Suzumura, and K Hirao, J. Chem. Phys. 111, 5656 (1999) ]   88=> XC_GGA_C_FT97 ! Filatov & Thiel correlation [M Filatov & W Thiel, Int. J. Quant. Chem. 62, 603-616 (1997) ; M Filatov & W Thiel, Mol Phys 91, 847 (1997) ] WARNING : this functional is not tested. Use at your own risks.   89=> XC_GGA_C_SPBE ! PBE correlation to be used with the SSB exchange [M Swart, M Sola, and FM Bickelhaupt, J. Chem. Phys. 131, 094103 (2009) ]   90=> XC_GGA_X_SSB_SW ! Swarta, Sola and Bickelhaupt correction to PBE [M Swart, M Sola, and FM Bickelhaupt, J. Comp. Meth. Sci. Engin. 9, 69 (2009) ]   91=> XC_GGA_X_SSB ! WARNING : This functional gives NaN on IBM (XG20130608). Swarta, Sola and Bickelhaupt [M Swart, M Sola, and FM Bickelhaupt, J. Chem. Phys. 131, 094103 (2009) ]   92=> XC_GGA_X_SSB_D ! WARNING : This functional gives NaN on IBM (XG20130608). Swarta, Sola and Bickelhaupt dispersion [M Swart, M Sola, and FM Bickelhaupt, J. Chem. Phys. 131, 094103 (2009) ]   93=> XC_GGA_XC_HCTH_407P ! HCTH/407+ [AD Boese, A Chandra, JML Martin, and Dominik Marx, J. Chem. Phys. 119, 5965 (2003) ]   94=> XC_GGA_XC_HCTH_P76 ! HCTH p=7/6 [G Menconi, PJ Wilson, and DJ Tozer, J. Chem. Phys. 114, 3958 (2001) ]   95=> XC_GGA_XC_HCTH_P14 ! HCTH p=1/4 [G Menconi, PJ Wilson, and DJ Tozer, J. Chem. Phys. 114, 3958 (2001) ]   96=> XC_GGA_XC_B97_GGA1 ! Becke 97 GGA-1 [AJ Cohen and NC Handy, Chem. Phys. Lett. 316, 160-166 (2000) ]   97=> XC_GGA_XC_HCTH_A ! HCTH-A [FA Hamprecht, AJ Cohen, DJ Tozer, and NC Handy, J. Chem. Phys. 109, 6264 (1998) ]   98=> XC_GGA_X_BPCCAC ! BPCCAC (GRAC for the energy) [E Bremond, D Pilard, I Ciofini, H Chermette, C Adamo, and P Cortona, Theor Chem Acc 131, 1184 (2012) ]   99=> XC_GGA_C_REVTCA ! Tognetti, Cortona, Adamo (revised) [V Tognetti, P Cortona, and C Adamo, Chem. Phys. Lett. 460, 536-539 (2008) ]   100=> XC_GGA_C_TCA ! Tognetti, Cortona, Adamo [V Tognetti, P Cortona, and C Adamo, J. Chem. Phys. 128, 034101 (2008) ]   101=> XC_GGA_X_PBE ! Perdew, Burke & Ernzerhof exchange [JP Perdew, K Burke, and M Ernzerhof, Phys. Rev. Lett. 77, 3865 (1996) ; JP Perdew, K Burke, and M Ernzerhof, Phys. Rev. Lett. 78, 1396(E) (1997) ]   102=> XC_GGA_X_PBE_R ! Perdew, Burke & Ernzerhof exchange (revised) [Y Zhang and W Yang, Phys. Rev. Lett 80, 890 (1998) ]   103=> XC_GGA_X_B86 ! Becke 86 Xalfa,beta,gamma [AD Becke, J. Chem. Phys 84, 4524 (1986) ]   104=> XC_GGA_X_HERMAN ! Herman Xalphabeta GGA [F Herman, JP Van Dyke, and IB Ortenburger, Phys. Rev. Lett. 22, 807 (1969) ; F Herman, IB Ortenburger, and JP Van Dyke, Int. J. Quantum Chem. Symp. 3, 827 (1970) ]   105=> XC_GGA_X_B86_MGC ! Becke 86 Xalfa,beta,gamma (with mod. grad. correction) [AD Becke, J. Chem. Phys 84, 4524 (1986) ; AD Becke, J. Chem. Phys 85, 7184 (1986) ]   106=> XC_GGA_X_B88 ! Becke 88 [AD Becke, Phys. Rev. A 38, 3098 (1988) ]   107=> XC_GGA_X_G96 ! Gill 96 [PMW Gill, Mol. Phys. 89, 433 (1996) ]   108=> XC_GGA_X_PW86 ! Perdew & Wang 86 [JP Perdew and Y Wang, Phys. Rev. B 33, 8800 (1986) ]   109=> XC_GGA_X_PW91 ! Perdew & Wang 91 [JP Perdew, in Proceedings of the 21st Annual International Symposium on the Electronic Structure of Solids, ed. by P Ziesche and H Eschrig (Akademie Verlag, Berlin, 1991), p. 11. ; JP Perdew, JA Chevary, SH Vosko, KA Jackson, MR Pederson, DJ Singh, and C Fiolhais, Phys. Rev. B 46, 6671 (1992) ; JP Perdew, JA Chevary, SH Vosko, KA Jackson, MR Pederson, DJ Singh, and C Fiolhais, Phys. Rev. B 48, 4978(E) (1993) ]   110=> XC_GGA_X_OPTX ! Handy & Cohen OPTX 01 [NC Handy and AJ Cohen, Mol. Phys. 99, 403 (2001) ]   111=> XC_GGA_X_DK87_R1 ! dePristo & Kress 87 (version R1) [AE DePristo and JD Kress, J. Chem. Phys. 86, 1425 (1987) ]   112=> XC_GGA_X_DK87_R2 ! dePristo & Kress 87 (version R2) [AE DePristo and JD Kress, J. Chem. Phys. 86, 1425 (1987) ]   113=> XC_GGA_X_LG93 ! Lacks & Gordon 93 [DJ Lacks and RG Gordon, Phys. Rev. A 47, 4681 (1993) ]   114=> XC_GGA_X_FT97_A ! Filatov & Thiel 97 (version A) [M Filatov and W Thiel, Mol. Phys 91, 847 (1997) ]   115=> XC_GGA_X_FT97_B ! Filatov & Thiel 97 (version B) [M Filatov and W Thiel, Mol. Phys 91, 847 (1997) ]   116=> XC_GGA_X_PBE_SOL ! Perdew, Burke & Ernzerhof exchange (solids) [JP Perdew, et al, Phys. Rev. Lett. 100, 136406 (2008) ]   117=> XC_GGA_X_RPBE ! Hammer, Hansen & Norskov (PBE-like) [B Hammer, LB Hansen and JK Norskov, Phys. Rev. B 59, 7413 (1999) ]   118=> XC_GGA_X_WC ! Wu & Cohen [Z Wu and RE Cohen, Phys. Rev. B 73, 235116 (2006) ]   119=> XC_GGA_X_mPW91 ! Modified form of PW91 by Adamo & Barone [C Adamo and V Barone, J. Chem. Phys. 108, 664 (1998) ]   120=> XC_GGA_X_AM05 ! Armiento & Mattsson 05 exchange [R Armiento and AE Mattsson, Phys. Rev. B 72, 085108 (2005) ; AE Mattsson, R Armiento, J Paier, G Kresse, JM Wills, and TR Mattsson, J. Chem. Phys. 128, 084714 (2008) ]   121=> XC_GGA_X_PBEA ! Madsen (PBE-like) [G Madsen, Phys. Rev. B 75, 195108 (2007) ]   122=> XC_GGA_X_MPBE ! Adamo & Barone modification to PBE [C Adamo and V Barone, J. Chem. Phys. 116, 5933 (2002) ]   123=> XC_GGA_X_XPBE ! xPBE reparametrization by Xu & Goddard [X Xu and WA Goddard III, J. Chem. Phys. 121, 4068 (2004) ]   125=> XC_GGA_X_BAYESIAN ! Bayesian best fit for the enhancement factor [JJ Mortensen, K Kaasbjerg, SL Frederiksen, JK Norskov, JP Sethna, and KW Jacobsen, Phys. Rev. Lett. 95, 216401 (2005) ]   126=> XC_GGA_X_PBE_JSJR ! PBE JSJR reparametrization by Pedroza, Silva & Capelle [LS Pedroza, AJR da Silva, and K. Capelle, Phys. Rev. B 79, 201106(R) (2009) ]   130=> XC_GGA_C_PBE ! Perdew, Burke & Ernzerhof correlation [JP Perdew, K Burke, and M Ernzerhof, Phys. Rev. Lett. 77, 3865 (1996) ; JP Perdew, K Burke, and M Ernzerhof, Phys. Rev. Lett. 78, 1396(E) (1997) ]   131=> XC_GGA_C_LYP ! Lee, Yang & Parr [C Lee, W Yang and RG Parr, Phys. Rev. B 37, 785 (1988) B Miehlich, A Savin, H Stoll and H Preuss, Chem. Phys. Lett. 157, 200 (1989) ]   132=> XC_GGA_C_P86 ! Perdew 86 [JP Perdew, Phys. Rev. B 33, 8822 (1986) ]   133=> XC_GGA_C_PBE_SOL ! Perdew, Burke & Ernzerhof correlation SOL [JP Perdew, et al, Phys. Rev. Lett. 100, 136406 (2008) ]   134=> XC_GGA_C_PW91 ! Perdew & Wang 91 [JP Perdew, JA Chevary, SH Vosko, KA Jackson, MR Pederson, DJ Singh, and C Fiolhais, Phys. Rev. B 46, 6671 (1992) ]   135=> XC_GGA_C_AM05 ! Armiento & Mattsson 05 correlation [ R Armiento and AE Mattsson, Phys. Rev. B 72, 085108 (2005) ; AE Mattsson, R Armiento, J Paier, G Kresse, JM Wills, and TR Mattsson, J. Chem. Phys. 128, 084714 (2008) ]   136=> XC_GGA_C_XPBE ! xPBE reparametrization by Xu & Goddard [X Xu and WA Goddard III, J. Chem. Phys. 121, 4068 (2004) ]   137=> XC_GGA_C_LM ! Langreth and Mehl correlation [DC Langreth and MJ Mehl, Phys. Rev. Lett. 47, 446 (1981) ]   138=> XC_GGA_C_PBE_JRGX ! JRGX reparametrization by Pedroza, Silva & Capelle [LS Pedroza, AJR da Silva, and K. Capelle, Phys. Rev. B 79, 201106(R) (2009) ]   139=> XC_GGA_X_OPTB88_VDW ! Becke 88 reoptimized to be used with vdW functional of Dion et al [J Klimes, DR Bowler, and A Michaelides, J. Phys.: Condens. Matter 22, 022201 (2010) ]   140=> XC_GGA_X_PBEK1_VDW ! PBE reparametrization for vdW [J Klimes, DR Bowler, and A Michaelides, J. Phys.: Condens. Matter 22, 022201 (2010) ]   141=> XC_GGA_X_OPTPBE_VDW ! PBE reparametrization for vdW [J Klimes, DR Bowler, and A Michaelides, J. Phys.: Condens. Matter 22, 022201 (2010) ]   142=> XC_GGA_X_RGE2 ! Regularized PBE [A Ruzsinszky, GI Csonka, and G Scuseria, J. Chem. Theory Comput. 5, 763 (2009) ]   143=> XC_GGA_C_RGE2 ! Regularized PBE [A Ruzsinszky, GI Csonka, and G Scuseria, J. Chem. Theory Comput. 5, 763 (2009) ]   144=> XC_GGA_X_RPW86 ! refitted Perdew & Wang 86 [ED Murray, K Lee and DC Langreth, J. Chem. Theory Comput. 5, 2754-2762 (2009) ]   145=> XC_GGA_X_KT1 ! Keal and Tozer version 1 [TW Keal and DJ Tozer, J. Chem. Phys. 119, 3015 (2003) ]   146=> XC_GGA_XC_KT2 ! WARNING : This functional gives NaN on IBM (XG20130608). Keal and Tozer version 2 [TW Keal and DJ Tozer, J. Chem. Phys. 119, 3015 (2003) ]   147=> XC_GGA_C_WL ! Wilson & Levy [LC Wilson and M Levy, Phys. Rev. B 41, 12930 (1990) ]   148=> XC_GGA_C_WI ! Wilson & Ivanov [LC Wilson & S Ivanov, Int. J. Quantum Chem. 69, 523-532 (1998) ]   149=> XC_GGA_X_MB88 ! Modified Becke 88 for proton transfer [V Tognetti and C Adamo, J. Phys. Chem. A 113, 14415-14419 (2009) ]   150=> XC_GGA_X_SOGGA ! Second-order generalized gradient approximation [Y Zhao and DG Truhlar, J. Chem. Phys. 128, 184109 (2008) ; http://comp.chem.umn.edu/mfm/index.html ]   151=> XC_GGA_X_SOGGA11 ! Second-order generalized gradient approximation 2011 [R Peverati, Y Zhao, and DG Truhlar, J. Phys. Chem. Lett. 2, 1911-1997 (2011); http://comp.chem.umn.edu/mfm/index.html ]   152=> XC_GGA_C_SOGGA11 ! Second-order generalized gradient approximation 2011 [R Peverati, Y Zhao, and DG Truhlar, J. Phys. Chem. Lett. 2, 1911-1997 (2011); http://comp.chem.umn.edu/mfm/index.html ]   153=> XC_GGA_C_WI0 ! Wilson & Ivanov initial version [LC Wilson & S Ivanov, Int. J. Quantum Chem. 69, 523-532 (1998) ]   154=> XC_GGA_XC_TH1 ! Tozer and Handy v. 1 [DJ Tozer and NC Handy, J. Chem. Phys. 108, 2545 (1998) ] WARNING : this functional is not tested. Use at your own risks.   155=> XC_GGA_XC_TH2 ! Tozer and Handy v. 2 [DJ Tozer and NC Handy, J. Phys. Chem. A 102, 3162 (1998) ]   156=> XC_GGA_XC_TH3 ! Tozer and Handy v. 3 [DJ Tozer and NC Handy, Mol. Phys. 94, 707 (1998) ]   157=> XC_GGA_XC_TH4 ! Tozer and Handy v. 4 [DJ Tozer and NC Handy, Mol. Phys. 94, 707 (1998) ]   158=> XC_GGA_X_C09X ! C09x to be used with the VdW of Rutgers-Chalmers [VR Cooper, PRB 81, 161104(R) (2010) ]   159=> XC_GGA_C_SOGGA11_X ! To be used with hyb_gga_x_SOGGA11-X [R Peverati and DG Truhlar, J. Chem. Phys. 135, 191102 (2011); http://comp.chem.umn.edu/mfm/index.html ]   161=> XC_GGA_XC_HCTH_93 ! HCTH functional fitted to 93 molecules [FA Hamprecht, AJ Cohen, DJ Tozer, and NC Handy, J. Chem. Phys. 109, 6264 (1998) ]   162=> XC_GGA_XC_HCTH_120 ! HCTH functional fitted to 120 molecules [AD Boese, NL Doltsinis, NC Handy, and M Sprik, J. Chem. Phys. 112, 1670 (2000) ]   163=> XC_GGA_XC_HCTH_147 ! HCTH functional fitted to 147 molecules [AD Boese, NL Doltsinis, NC Handy, and M Sprik, J. Chem. Phys. 112, 1670 (2000) ]   164=> XC_GGA_XC_HCTH_407 ! HCTH functional fitted to 407 molecules [AD Boese, and NC Handy, J. Chem. Phys. 114, 5497 (2001) ]   165=> XC_GGA_XC_EDF1 ! Empirical functionals from Adamson, Gill, and Pople [RD Adamson, PMW Gill, and JA Pople, Chem. Phys. Lett. 284 6 (1998) ]   166=> XC_GGA_XC_XLYP ! XLYP functional [X Xu and WA Goddard, III, PNAS 101, 2673 (2004) ]   167=> XC_GGA_XC_B97 ! Becke 97 [AD Becke, J. Chem. Phys. 107, 8554-8560 (1997) ]   168=> XC_GGA_XC_B97_1 ! Becke 97-1 [FA Hamprecht, AJ Cohen, DJ Tozer, and NC Handy, J. Chem. Phys. 109, 6264 (1998); AD Becke, J. Chem. Phys. 107, 8554-8560 (1997) ]   169=> XC_GGA_XC_B97_2 ! Becke 97-2 [AD Becke, J. Chem. Phys. 107, 8554-8560 (1997) ]   170=> XC_GGA_XC_B97_D ! Grimme functional to be used with C6 vdW term [S Grimme, J. Comput. Chem. 27, 1787 (2006) ]   171=> XC_GGA_XC_B97_K ! Boese-Martin for Kinetics [AD Boese and JML Martin, J. Chem. Phys., Vol. 121, 3405 (2004) ]   172=> XC_GGA_XC_B97_3 ! Becke 97-3 [TW Keal and DJ Tozer, J. Chem. Phys. 123, 121103 (2005) ]   173=> XC_GGA_XC_PBE1W ! Functionals fitted for water [EE Dahlke and DG Truhlar, J. Phys. Chem. B 109, 15677 (2005) ]   174=> XC_GGA_XC_MPWLYP1W ! Functionals fitted for water [EE Dahlke and DG Truhlar, J. Phys. Chem. B 109, 15677 (2005) ]   175=> XC_GGA_XC_PBELYP1W ! Functionals fitted for water [EE Dahlke and DG Truhlar, J. Phys. Chem. B 109, 15677 (2005) ]   176=> XC_GGA_XC_SB98_1a ! Schmider-Becke 98 parameterization 1a [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ]   177=> XC_GGA_XC_SB98_1b ! Schmider-Becke 98 parameterization 1b [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ]   178=> XC_GGA_XC_SB98_1c ! Schmider-Becke 98 parameterization 1c [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ]   179=> XC_GGA_XC_SB98_2a ! Schmider-Becke 98 parameterization 2a [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ]   180=> XC_GGA_XC_SB98_2b ! Schmider-Becke 98 parameterization 2b [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ]   181=> XC_GGA_XC_SB98_2c ! Schmider-Becke 98 parameterization 2c [HL Schmider and AD Becke, J. Chem. Phys. 108, 9624 (1998) ]   183=> XC_GGA_X_OL2 ! Exchange form based on Ou-Yang and Levy v.2 [P Fuentealba and O Reyes, Chem. Phys. Lett. 232, 31-34 (1995) ; H Ou-Yang, M Levy, Int. J. of Quant. Chem. 40, 379-388 (1991) ]   184=> XC_GGA_X_APBE ! mu fixed from the semiclassical neutral atom [LA Constantin, E Fabiano, S Laricchia, and F Della Sala, Phys. Rev. Lett. 106, 186406 (2011) ]   186=> XC_GGA_C_APBE ! mu fixed from the semiclassical neutral atom [LA Constantin, E Fabiano, S Laricchia, and F Della Sala, Phys. Rev. Lett. 106, 186406 (2011) ]   191=> XC_GGA_X_HTBS! Haas, Tran, Blaha, and Schwarz [P Haas, F Tran, P Blaha, and K Schwarz, Phys. Rev. B 83, 205117 (2011) ]   192=> XC_GGA_X_AIRY ! Constantin et al based on the Airy gas [LA Constantin, A Ruzsinszky, and JP Perdew, Phys. Rev. B 80, 035125 (2009) ]   193=> XC_GGA_X_LAG ! Local Airy Gas [L Vitos, B Johansson, J Kollar, and HL Skriver, Phys. Rev. B 62, 10046-10050 (2000) ]   194=> XC_GGA_XC_MOHLYP ! Functional for organometallic chemistry [NE Schultz, Y Zhao, DGJ Truhlar, Phys. Chem. A, 109, 11127 (2005) ]   195=> XC_GGA_XC_MOHLYP2 ! Functional for barrier heights [J Zheng, Y Zhao, DGJ Truhlar, Chem. Theory. Comput. 5, 808 (2009) ]   196=> XC_GGA_XC_TH_FL ! Tozer and Handy v. FL [DJ Tozer, NC Handy, amd WH Green, Chem. Phys. Lett. 273, 183-194 (1997) ]   197=> XC_GGA_XC_TH_FC ! Tozer and Handy v. FC [DJ Tozer, NC Handy, amd WH Green, Chem. Phys. Lett. 273, 183-194 (1997) ]   198=> XC_GGA_XC_TH_FCFO ! Tozer and Handy v. FCFO [DJ Tozer, NC Handy, amd WH Green, Chem. Phys. Lett. 273, 183-194 (1997) ]   199=> XC_GGA_XC_TH_FCO ! Tozer and Handy v. FCO [DJ Tozer, NC Handy, amd WH Green, Chem. Phys. Lett. 273, 183-194 (1997) ]   200=> XC_GGA_C_OPTC ! Optimized correlation functional of Cohen and Handy [AJ Cohen and NC Handy, Mol. Phys. 99, 607-615 (2001) ]   524=> XC_GGA_X_WPBEH ! short-range version of the PBE [J Heyd, GE Scuseria, and M Ernzerhof, J. Chem. Phys. 118, 8207 (2003) ]   525=> XC_GGA_X_HJS_PBE ! HJS screened exchange PBE version [TM Henderson, BG Janesko, and GE Scuseria, J. Chem. Phys. 128, 194105 (2008) ]   526=> XC_GGA_X_HJS_PBE_SOL ! HJS screened exchange PBE_SOL version [TM Henderson, BG Janesko, and GE Scuseria, J. Chem. Phys. 128, 194105 (2008) ]   527=> XC_GGA_X_HJS_B88 ! HJS screened exchange B88 version [TM Henderson, BG Janesko, and GE Scuseria, J. Chem. Phys. 128, 194105 (2008) ] WARNING : this functional is not tested. Use at your own risks.   528=> XC_GGA_X_HJS_B97X ! HJS screened exchange B97x version [TM Henderson, BG Janesko, and GE Scuseria, J. Chem. Phys. 128, 194105 (2008) ]   529=> XC_GGA_X_ITYH ! short-range recipe for exchange GGA functionals [H Iikura, T Tsuneda, T Yanai, and K Hirao, J. Chem. Phys. 115, 3540 (2001) ] WARNING : this functional is not tested. Use at your own risks.    MetaGGA functionals (do not forget to add a minus sign, as discussed above).\nSee Sun et al, PRB 84, 035117 (2011) for the formulas.   202=> XC_MGGA_X_TPSS ! Tao, Perdew, Staroverov & Scuseria [J Tao, JP Perdew, VN Staroverov, and G Scuseria, Phys. Rev. Lett. 91, 146401 (2003) ; JP Perdew, J Tao, VN Staroverov, and G Scuseria, J. Chem. Phys. 120, 6898 (2004) ]   203=> XC_MGGA_X_M06L ! Zhao, Truhlar exchange [Y Zhao and DG Truhlar, JCP 125, 194101 (2006); Y Zhao and DG Truhlar, Theor. Chem. Account 120, 215 (2008) ]   204=> XC_MGGA_X_GVT4 ! GVT4 (X part of VSXC) from van Voorhis and Scuseria [T Van Voorhis and GE Scuseria, JCP 109, 400 (1998) ]   205=> XC_MGGA_X_TAU_HCTH ! tau-HCTH from Boese and Handy [AD Boese and NC Handy, JCP 116, 9559 (2002) ]   207=> XC_MGGA_X_BJ06 ! Becke & Johnson correction to Becke-Roussel 89 [AD Becke and ER Johnson, J. Chem. Phys. 124, 221101 (2006) ] WARNING : this Vxc-only mGGA can only be used with a LDA correlation, typically Perdew-Wang 92.   208=> XC_MGGA_X_TB09 ! Tran-blaha - correction to Becke & Johnson correction to Becke-Roussel 89 [F Tran and P Blaha, Phys. Rev. Lett. 102, 226401 (2009) ] WARNING : this Vxc-only mGGA can only be used with a LDA correlation, typically Perdew-Wang 92.   209=> XC_MGGA_X_RPP09 ! Rasanen, Pittalis, and Proetto correction to Becke & Johnson [E Rasanen, S Pittalis & C Proetto, arXiv:0909.1477 (2009) ] WARNING : this Vxc-only mGGA can only be used with a LDA correlation, typically Perdew-Wang 92.   232=> XC_MGGA_C_VSXC ! VSxc from Van Voorhis and Scuseria (correlation part) [T Van Voorhis and GE Scuseria, JCP 109, 400 (1998) ]    Hybrid functionals (do not forget to add a minus sign, as discussed above).   402=> XC_HYB_GGA_XC_B3LYP ! The (in)famous B3LYP [PJ Stephens, FJ Devlin, CF Chabalowski, MJ Frisch, J. Phys. Chem. 98 11623 (1994) ]   406=> XC_HYB_GGA_XC_PBEH ! PBEH (PBE0) [C Adamo and V Barone, J. Chem. Phys. 110, 6158 (1999); M. Ernzerhof, G. E. Scuseria, J. Chem. Phys. 110, 5029 (1999) ]    427=> XC_HYB_GGA_XC_HSE03 ! The 2003 version of the screened hybrid HSE (in this case one should use omega^HF = 0.15/sqrt(2) and omega^PBE = 0.15*(2.0) 1/3)  \n428=> XC_HYB_GGA_XC_HSE06 ! The 2006 version of the screened hybrid HSE (in\nthis case one should use omega^HF = omega^PBE = 0.11) \n(The following section is taken from the LibXC sources. In ABINIT, we stick to\nthe LibXC choice.) Note that there is an enormous mess in the literature\nconcerning the values of omega in HSE. This is due to an error in the original\npaper that stated that they had used omega=0.15. This was in fact not true,\nand the real value used was omega^HF = 0.15/sqrt(2) ~ 0.1061 and omega^PBE =\n0.15*(2.0) 1/3 ~ 0.1890. In 2006 Krukau et al [JCP 125, 224106 (2006)] tried\nto clarify the situation, and called HSE03 to the above choice of parameters,\nand called HSE06 to the functional where omega^HF=omega^PBE. By testing\nseveral properties for atoms they reached the conclusion that the best value\nfor omega=0.11. Of course, codes are just as messy as the papers. In espresso\nHSE06 has the value omega=0.106. VASP, on the other hand, uses for HSE03 the\nsame value omega^HF = omega^PBE = 0.3 (A^-1) ~ 0.1587 and for HSE06 omega^HF =\nomega^PBE = 0.2 (A^-1) ~ 0.1058. [J Heyd, GE Scuseria, and M Ernzerhof, J.\nChem. Phys. 118, 8207 (2003); J Heyd, GE Scuseria, and M Ernzerhof, J. Chem.\nPhys. 124, 219906 (2006); AV Krukau, OA Vydrov, AF Izmaylov, and GE Scuseria,\nJ. Chem. Phys. 125, 224106 (2006) ]    456=> XC_HYB_GGA_XC_PBE0_13 ! PBE0-1/3 [P Cortona, J. Chem. Phys. 136, 086101 (2012) ]",
            "title": "ixc"
        },
        {
            "location": "/input_variables/varbas/#jdtset",
            "text": "Mnemonics: index -J- for DaTaSETs \nVariable type: integer \nDimensions: ( ndtset ) \nDefault value: [1 ..  ndtset ]    Gives the dataset index of each of the datasets. This index will be used :   to determine which input variables are specific to each dataset, since the variable names for this dataset will be made from the bare variable name concatenated with this index, and only if such a composite variable name does not exist, the code will consider the bare variable name, or even, the Default;   to characterize output variable names, if their content differs from dataset to dataset;   to characterize output files ( root names appended with _DSx where \u2018x\u2019 is the dataset index ).    The allowed index values are between 1 and 9999. \nAn input variable name appended with 0 is not allowed. \nWhen  ndtset ==0, this array is not used, and moreover, no input variable\nname appended with a digit is allowed. This array might be initialized thanks\nto the use of the input variable  udtset . In this case,  jdtset  cannot\nbe used.",
            "title": "jdtset"
        },
        {
            "location": "/input_variables/varbas/#kpt",
            "text": "Mnemonics: K - PoinTs \nVariable type: real \nDimensions: (3, nkpt ) \nDefault value: [0, 0, 0] \nComment: Adequate for one molecule in a supercell    Contains the k points in terms of reciprocal space primitive translations (NOT\nin cartesian coordinates!). \nNeeded ONLY if  kptopt =0, otherwise deduced from other input variables.  It contains dimensionless numbers in terms of which the cartesian coordinates\nwould be: \nk_cartesian = k1 G1+k2 G2+k3*G3 \nwhere  (k1,k2,k3)  represent the dimensionless \u201creduced coordinates\u201d and  G1,\nG2, G3  are the cartesian coordinates of the primitive translation vectors.\nG1,G2,G3 are related to the choice of direct space primitive translation\nvectors made in  rprim . Note that an overall norm for the k points is\nsupplied by  kptnrm . This allows one to avoid supplying many digits for the\nk points to represent such points as (1,1,1)/3. \nNote: one of the algorithms used to set up the sphere of G vectors for the\nbasis needs components of k-points in the range [-1,1], so the remapping is\neasily done by adding or subtracting 1 from each component until it is in the\nrange [-1,1]. That is, given the k point normalization  kptnrm  described\nbelow, each component must lie in [- kptnrm , kptnrm ]. \nNote: a global shift can be provided by  qptn \nNot read if  kptopt /=0 .",
            "title": "kpt"
        },
        {
            "location": "/input_variables/varbas/#kptnrm",
            "text": "Mnemonics: K - PoinTs NoRMalization \nVariable type: real \nDimensions: scalar \nDefault value: 1    Establishes a normalizing denominator for each k point. Needed only if kptopt <=0, otherwise deduced from other input variables. \nThe k point coordinates as fractions of reciprocal lattice translations are\ntherefore  [kpt] / kptnrm .  kptnrm  defaults to 1 and can be\nignored by the user. It is introduced to avoid the need for many digits in\nrepresenting numbers such as 1/3. \nIt cannot be smaller than 1.0d0",
            "title": "kptnrm"
        },
        {
            "location": "/input_variables/varbas/#kptopt",
            "text": "Mnemonics: KPoinTs OPTion \nVariable type: integer \nDimensions: scalar \nDefault value: 4 if  nspden ==4,\n1 otherwise.  Controls the set up of the k-points list. The aim will be to initialize, by\nstraight reading or by a preprocessing approach based on other input\nvariables, the following input variables, giving the k points, their number,\nand their weight:  kpt ,  kptnrm ,  nkpt , and, for  iscf /=-2, wtk .  Often, the k points will form a lattice in reciprocal space. In this case, one\nwill also aim at initializing input variables that give the reciprocal of this\nk-point lattice, as well as its shift with respect to the origin:  ngkpt  or kptrlatt , as well as on  nshiftk  and  shiftk .  A global additional shift can be provided by  qptn   0=> read directly  nkpt ,  kpt ,  kptnrm  and  wtk .    1=> rely on  ngkpt  or  kptrlatt , as well as on  nshiftk  and  shiftk  to set up the k points. Take fully into account the symmetry to generate the k points in the Irreducible Brillouin Zone only, with the appropriate weights.  \n(This is the usual mode for GS calculations)    2=> rely on  ngkpt  or  kptrlatt , as well as on  nshiftk  and  shiftk  to set up the k points. Take into account only the time-reversal symmetry : k points will be generated in half the Brillouin zone, with the appropriate weights.  \n(This is to be used when preparing or executing a RF calculation at q=(0 0 0)\n)    3=> rely on  ngkpt  or  kptrlatt , as well as on  nshiftk  and  shiftk  to set up the k points. Do not take into account any symmetry : k points will be generated in the full Brillouin zone, with the appropriate weights.  \n(This is to be used when preparing or executing a RF calculation at non-zero q\n)    4=> rely on  ngkpt  or  kptrlatt , as well as on  nshiftk  and  shiftk  to set up the k points. Take into account all the symmetries EXCEPT the time-reversal symmetry to generate the k points in the Irreducible Brillouin Zone, with the appropriate weights.  \nThis has to be used when performing calculations with non-collinear magnetism\nallowed ( nspden =4)    A negative value => rely on  kptbounds , and  ndivk  to set up a band structure calculation along different lines (allowed only for  iscf ==-2). The absolute value of  kptopt  gives the number of segments of the band structure. Weights are usually irrelevant with this option, and will be left to their default value.     In the case of a grid of k points, the auxiliary variables  kptrlen , ngkpt  and  prtkpt  might help you to select the optimal grid.",
            "title": "kptopt"
        },
        {
            "location": "/input_variables/varbas/#natom",
            "text": "Mnemonics: Number of ATOMs \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Gives the total number of atoms in the unit cell. Default is 1 but you will\nobviously want to input this value explicitly. \nNote that  natom  refers to all atoms in the unit cell, not only to the\nirreducible set of atoms in the unit cell (using symmetry operations, this set\nallows to recover all atoms). If you want to specify only the irreducible set\nof atoms, use the symmetriser, see the input variable  natrd .",
            "title": "natom"
        },
        {
            "location": "/input_variables/varbas/#nband",
            "text": "Mnemonics: Number of BANDs \nVariable type: integer \nDimensions: scalar \nDefault value: None \nComment:  the estimated number of occupied bands +1 (TODO provide the mathematical formulation)    Gives number of bands, occupied plus possibly unoccupied, for which\nwavefunctions are being computed along with eigenvalues. \nNote : if the parameter  occopt  (see below) is not set to 2,  nband  is a\nscalar integer, but if the parameter  occopt  is set to 2, then  nband \nmust be an array  [nband]  giving the number of bands\nexplicitly for each k point. This option is provided in order to allow the\nnumber of bands treated to vary from k point to k point. \nFor the values of  occopt  not equal to 0 or 2,  nband  can be omitted.\nThe number of bands will be set up thanks to the use of the variable fband . The present Default will not be used.  If  nspinor  is 2, nband must be even for each k point.  In the case of a  GW  calculation ( optdriver =3 or 4),  nband  gives\nthe number of bands to be treated to generate the screening (susceptibility\nand dielectric matrix), as well as the self-energy. However, to generate the\n_KSS file (see  kssform ) the relevant number of bands is given by nbandkss .",
            "title": "nband"
        },
        {
            "location": "/input_variables/varbas/#nbandhf",
            "text": "Mnemonics: Number of BANDs for (Hartree)-Fock exact exchange \nVariable type: integer \nDimensions: scalar \nDefault value: None \nComment: the estimated number of occupied bands (TODO : provide the mathematical formulation)    Gives the maximum number of occupied bands with which Fock exact exchange is\nbeing computed for the wavefunctions.",
            "title": "nbandhf"
        },
        {
            "location": "/input_variables/varbas/#ndtset",
            "text": "Mnemonics: Number of DaTaSETs \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of data sets to be treated. \nIf 0, means that the multi-data set treatment is not used, so that the root\nfilenames will not be appended with _DSx, where \u2018x\u2019 is the dataset index\ndefined by the input variable  jdtset , and also that input names with a\ndataset index are not allowed. Otherwise,  ndtset =0 is equivalent to ndtset =1.",
            "title": "ndtset"
        },
        {
            "location": "/input_variables/varbas/#ngkpt",
            "text": "Mnemonics: Number of Grid points for K PoinTs generation \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  kptopt  >=0,  \nThe use of this variable forbids the use of specified( kptrlatt )    Used when  kptopt >=0, if  kptrlatt  has not been defined ( kptrlatt \nand  ngkpt  are exclusive of each other). \nIts three positive components give the number of k points of Monkhorst-Pack\ngrids (defined with respect to primitive axis in reciprocal space) in each of\nthe three dimensions.  ngkpt  will be used to generate the corresponding kptrlatt  input variable. The use of  nshiftk  and  shiftk , allows to\ngenerate shifted grids, or Monkhorst-Pack grids defined with respect to\nconventional unit cells.  When  nshiftk =1,  kptrlatt  is initialized as a diagonal (3x3) matrix,\nwhose diagonal elements are the three values  [ngkpt] . When  nshiftk \nis greater than 1, ABINIT will try to generate  kptrlatt  on the basis of\nthe primitive vectors of the k-lattice: the number of shifts might be reduced,\nin which case  kptrlatt  will not be diagonal anymore.  Monkhorst-Pack grids are usually the most efficient when their defining\ninteger numbers are even. For a measure of the efficiency, see the input\nvariable  kptrlen .",
            "title": "ngkpt"
        },
        {
            "location": "/input_variables/varbas/#nkpath",
            "text": "Mnemonics: Number of K-points defining the PATH \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This variable is used to define the number of high-symmetry k-points in the kptbounds  array when  kptopt  > 0. Historically,  kptbounds  is used\nin conjuction with a negative value of  kptopt  when performing a NSCF band\nstructure calculation. In this case, the number of k-points in kptbounds is\ngiven by abs(kptopt) + 1. There are, however, other cases in which one has to\nspecify a k-path in the input file in order to activate some kind of post-\nprocessing tool. Typical examples are the interpolation of the GW corrections\nat the end of the sigma run or the interpolation of the KS eigenvalues along a\npath at the end of the SCF run (see also  einterp ) In a nutshell, nkpath\nreplaces  kptopt  when we are not performing a NSCF calculation. Note that,\nunlike  kptopt , nkpath represents the total number of points in the kptbounds  array.",
            "title": "nkpath"
        },
        {
            "location": "/input_variables/varbas/#nkpt",
            "text": "Mnemonics: Number of K - Points \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  kptopt ==0,\n0 otherwise.  If non-zero,  nkpt  gives the number of k points in the k point array kpt . These points are used either to sample the Brillouin zone, or to\nbuild a band structure along specified lines.  If  nkpt  is zero, the code deduces from other input variables (see the list\nin the description of  kptopt ) the number of k points, which is possible\nonly when  kptopt /=0. If  kptopt /=0 and the input value of  nkpt /=0,\nthen ABINIT will check that the number of k points generated from the other\ninput variables is exactly the same than  nkpt .  If  kptopt  is positive,  nkpt  must be coherent with the values of kptrlatt ,  nshiftk  and  shiftk . \nFor ground state calculations, one should select the k point in the\nirreducible Brillouin Zone (obtained by taking into account point symmetries\nand the time-reversal symmetry). \nFor response function calculations, one should select k points in the full\nBrillouin zone, if the wavevector of the perturbation does not vanish, or in a\nhalf of the Brillouin Zone if q=0. The code will automatically decrease the\nnumber of k points to the minimal set needed for each particular perturbation.  If  kptopt  is negative,  nkpt  will be the sum of the number of points on\nthe different lines of the band structure. For example, if  kptopt =-3, one\nwill have three segments; supposing  ndivk  is 10 12 17, the total number of\nk points of the circuit will be 10+12+17+1(for the final point)=40.",
            "title": "nkpt"
        },
        {
            "location": "/input_variables/varbas/#nkpthf",
            "text": "Mnemonics: Number of K - Points for (Hartree) Fock exact exchange \nVariable type: integer \nDimensions: scalar \nDefault value: None \nComment:  the total number of k-point in the full Brillouin zone (TODO : provide the mathematical formulation)    nkpthf  gives the number of k points used to sample the full Brillouin zone\nfor the Fock exact exchange contribution.",
            "title": "nkpthf"
        },
        {
            "location": "/input_variables/varbas/#nshiftk",
            "text": "Mnemonics: Number of SHIFTs for K point grids \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This parameter gives the number of shifted grids to be used concurrently to\ngenerate the full grid of k points. It can be used with primitive grids\ndefined either from  ngkpt  or  kptrlatt . The maximum allowed value of nshiftk  is 8. The values of the shifts are given by  shiftk .",
            "title": "nshiftk"
        },
        {
            "location": "/input_variables/varbas/#nsppol",
            "text": "Mnemonics: Number of SPin POLarization \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Give the number of INDEPENDENT spin polarisations, for which there are non-\nrelated wavefunctions. Can take the values 1 or 2.  If  nsppol =1, one has an unpolarized calculation ( nspinor =1, nspden =1) or an antiferromagnetic system ( nspinor =1,  nspden =2), or\na calculation in which spin up and spin down cannot be disentangled\n( nspinor =2), that is, either non-collinear magnetism or presence of spin-\norbit coupling, for which one needs spinor wavefunctions.  If  nsppol =2, one has a spin-polarized (collinear) calculation with\nseparate and different wavefunctions for up and down spin electrons for each\nband and k point. Compatible only with  nspinor =1,  nspden =2. If nsppol =2, one usually uses a metallic value for  occopt , in order to\nlet ABINIT find the magnetization. On the contrary, if  occopt ==1 is used,\nthe user has to impose the magnetization, using  spinmagntarget , except for\nthe case of a single isolated Hydrogen atom.  In the present status of development, with  nsppol =1, all values of  ixc \nare allowed, while with  nsppol =2, some values of  ixc  might not be\nallowed (e.g. 2, 3, 4, 5, 6, 20, 21, 22 are not allowed).  See also the input variable  nspden  for the components of the density\nmatrix with respect to the spin-polarization.",
            "title": "nsppol"
        },
        {
            "location": "/input_variables/varbas/#nstep",
            "text": "Mnemonics: Number of (non-)self-consistent field STEPS \nVariable type: integer \nDimensions: scalar \nDefault value: 30    Gives the maximum number of cycles (or \u201citerations\u201d) in a SCF or non-SCF run. \nFull convergence from random numbers is usually achieved in 12-20 SCF\niterations. Each can take from minutes to hours. In certain difficult cases,\nusually related to a small or zero bandgap or magnetism, convergence\nperformance may be much worse. When the convergence tolerance  tolwfr  on\nthe wavefunctions is satisfied, iterations will stop, so for well converged\ncalculations you should set  nstep  to a value larger than you think will be\nneeded for full convergence, e.g. if using 20 steps usually converges the\nsystem, set  nstep  to 30. \nFor non-self-consistent runs (  iscf  < 0) nstep governs the number of\ncycles of convergence for the wavefunctions for a fixed density and\nHamiltonian.  NOTE that a choice of  nstep =0 is permitted; this will either read\nwavefunctions from disk (with  irdwfk =1 or  irdwfq =1, or non-zero getwfk  or  getwfq  in the case of multi-dataset) and compute the\ndensity, the total energy and stop, or else (with all of the above vanishing)\nwill initialize randomly the wavefunctions and compute the resulting density\nand total energy. This is provided for testing purposes. \nAlso NOTE that  nstep =0 with  irdwfk =1 will exactly give the same result\nas the previous run only if the latter is done with  iscf <10 (potential\nmixing). \nOne can output the density by using  prtden . \nThe forces and stress tensor are computed with  nstep =0.",
            "title": "nstep"
        },
        {
            "location": "/input_variables/varbas/#nsym",
            "text": "Mnemonics: Number of SYMmetry operations \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives number of space group symmetries to be applied in this problem.\nSymmetries will be input in array \u201c symrel \u201d and (nonsymmorphic)\ntranslations vectors will be input in array \u201c tnons \u201d. If there is no\nsymmetry in the problem then set  nsym  to 1, because the identity is still\na symmetry. \nIn case of a RF calculation, the code is able to use the symmetries of the\nsystem to decrease the number of perturbations to be calculated, and to\ndecrease of the number of special k points to be used for the sampling of the\nBrillouin zone. After the response to the perturbations have been calculated,\nthe symmetries are used to generate as many as possible elements of the 2DTE\nfrom those already computed.  SYMMETRY_FINDER  mode (Default mode). If  nsym  is 0, all the atomic\ncoordinates must be explicitely given (one cannot use the geometry builder and\nthe symmetrizer): the code will then find automatically the symmetry\noperations that leave the lattice and each atomic sublattice invariant. It\nalso checks whether the cell is primitive (see  chkprim ). \nNote that the tolerance on symmetric atomic positions and lattice is rather\nstringent : for a symmetry operation to be admitted, the lattice and atomic\npositions must map on themselves within 1.0e-8 .  The user is allowed to set up systems with non-primitive unit cells (i.e.\nconventional FCC or BCC cells, or supercells without any distortion). In this\ncase, pure translations will be identified as symmetries of the system by the\nsymmetry finder. Then, the combined \u201cpure translation + usual rotation and\ninversion\u201d symmetry operations can be very numerous. For example, a\nconventional FCC cell has 192 symmetry operations, instead of the 48 ones of\nthe primitive cell. A maximum limit of 384 symmetry operations is hard-coded.\nThis corresponds to the maximum number of symmetry operations of a 2x2x2\nundistorted supercell. Going beyond that number will make the code stop very\nrapidly. If you want nevertheless, for testing purposes, to treat a larger\nnumber of symmetries, change the initialization of \u201cmsym\u201d in the abinit.F90\nmain routine, then recompile the code.  For  GW  calculation, the user might want to select only the symmetry\noperations whose non-symmorphic translation vector  tnons  is zero. This can\nbe done with the help of the input variable  symmorphi",
            "title": "nsym"
        },
        {
            "location": "/input_variables/varbas/#ntypat",
            "text": "Mnemonics: Number of TYPes of AToms \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Gives the number of types of atoms. E.g. for a homopolar system (e.g. pure Si) ntypat  is 1. \nThe code tries to read the same number of pseudopotential files. \nThe first pseudopotential is assigned type number 1, and so on \u2026",
            "title": "ntypat"
        },
        {
            "location": "/input_variables/varbas/#occopt",
            "text": "Mnemonics: OCCupation OPTion \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Controls how input parameters  nband ,  occ , and  wtk  are handled.    occopt =0:  \nAll k points have the same number of bands and the same occupancies of bands. nband  is given as a single number, and  [occ]  is an array of nband  elements, read in by the code. \nThe k point weights in array  [wtk]  are automatically normalized by\nthe code to add to 1.    occopt =1:  \nSame as  occopt =0, except that the array  occ  is automatically generated\nby the code, to give a semiconductor. \nAn error occurs when filling cannot be done with occupation numbers equal to 2\nor 0 in each k-point (non-spin-polarized case), or with occupation numbers\nequal to 1 or 0 in each k-point (spin-polarized case). If  nsppol =2 and occopt ==1 is used, the user has to impose the magnetization, using spinmagntarget , except for the case of a single isolated Hydrogen atom.    occopt =2:  \nk points may optionally have different numbers of bands and different\noccupancies.  [nband]  is given explicitly as an array of nkpt * nsppol  elements.  [occ]  is given explicitly for all bands at\neach k point, and eventually for each spin \u2013 the total number of elements is\nthe sum of  [nband]  over all k points and spins. The k point weights wtk  ( nkpt ) are NOT automatically normalized under this option.    occopt =3, 4, 5, 6 and 7  \nMetallic occupation of levels, using different occupation schemes (see below).\nThe corresponding thermal broadening, or cold smearing, is defined by the\ninput variable  tsmear  (see below : the variable xx is the energy in Ha,\ndivided by  tsmear ) \nLike for  occopt =1, the variable  occ  is not read \nAll k points have the same number of bands,  nband  is given as a single\nnumber, read by the code. \nThe k point weights in array  [wtk]  are automatically normalized by\nthe code to add to 1.    occopt =3:  \nFermi-Dirac smearing (finite-temperature metal) Smeared delta function :\n0.25d0/(cosh(xx/2.0d0)**2)    occopt =4:  \n\u201cCold smearing\u201d of N. Marzari (see his thesis work), with a=-.5634\n(minimization of the bump) \nSmeared delta function : \nexp(-xx  2  )/sqrt(pi) * (1.5d0+xx (-a 1.5d0+xx (-1.0d0+a xx)))    occopt =5:  \n\u201cCold smearing\u201d of N. Marzari (see his thesis work), with a=-.8165 (monotonic\nfunction in the tail) \nSame smeared delta function as  occopt =4, with different a.    occopt =6:  \nSmearing of Methfessel and Paxton  Methfessel1989  with Hermite polynomial\nof degree 2, corresponding to \u201cCold smearing\u201d of N. Marzari with a=0 (so, same\nsmeared delta function as  occopt =4, with different a).    occopt =7:  \nGaussian smearing, corresponding to the 0 order Hermite polynomial of\nMethfessel and Paxton. \nSmeared delta function : 1.0d0 exp(-xx *2)/sqrt(pi)    occopt =8:  \nUniform smearing (the delta function is replaced by a constant function of\nvalue one over ]-1/2,1/2[ (with one-half value at the boundaries). Used for\ntesting purposes only.      WARNING : one can use metallic occupation of levels in the case of a molecule,\nin order to avoid any problem with degenerate levels. However, it is advised\nNOT to use  occopt =6 (and to a lesser extent  occopt =4 and 5), since the\nassociated number of electron versus the Fermi energy is NOT guaranteed to be\na monotonic function. For true metals, AND a sufficiently dense sampling of\nthe Brillouin zone, this should not happen, but be cautious ! As an indication\nof this problem, a small variation of input parameters might lead to a jump of\ntotal energy, because there might be two or even three possible values of the\nFermi energy, and the bissection algorithm find one or the other.",
            "title": "occopt"
        },
        {
            "location": "/input_variables/varbas/#rprim",
            "text": "Mnemonics: Real space PRIMitive translations \nVariable type: real \nDimensions: (3,3) \ncommentdims Internally, it is represented as rprim(3,3, nimage ) \nDefault value: [[1, 0, 0], [0, 1, 0], [0, 0, 1]]    Give, in columnwise entry, the three dimensionless primitive translations in\nreal space, to be rescaled by  acell  and  scalecart . \nIt is  EVOLVING  only if  ionmov ==2 and  optcell /=0, otherwise it is\nfixed. \nIf the Default is used, that is,  rprim  is the unity matrix, the three\ndimensionless primitive vectors are three unit vectors in cartesian\ncoordinates. Each will be (possibly) multiplied by the corresponding  acell \nvalue, then (possibly) stretched along the cartesian coordinates by the\ncorresponding  scalecart  value, to give the dimensional primitive vectors,\ncalled  rprimd . \nIn the general case, the dimensional cartesian coordinates of the crystal\nprimitive translations R1p, R2p and R3p, see  rprimd , are   R1p(i)= [scalecart] [rprim] * [acell]    R2p(i)= [scalecart] [rprim] * [acell]    R3p(i)= [scalecart] [rprim] * [acell]     where i=1,2,3 is the component of the primitive translation (i.e. x, y, and\nz).    The  rprim  variable, scaled by  scalecart , is thus used to define\ndirections of the primitive vectors, that will be multiplied (so keeping the\ndirection unchanged) by the appropriate length scale  [acell] , [acell] , or  [acell] , respectively to give the dimensional primitive\ntranslations in real space in cartesian coordinates. \nPresently, it is requested that the mixed product (R1xR2).R3 is positive. If\nthis is not the case, simply exchange a pair of vectors. \nTo be more specific, keeping the default value of  scalecart =1 to simplify\nthe matter,  rprim  1 2 3 4 5 6 7 8 9 corresponds to input of the three\nprimitive translations R1=(1,2,3) (to be multiplied by  [acell] ),\nR2=(4,5,6) (to be multiplied by  [acell] ), and R3=(7,8,9) (to be\nmultiplied by [ acell ). \nNote carefully that the first three numbers input are the first column of rprim , the next three are the second, and the final three are the third.\nThis corresponds with the usual Fortran order for arrays. The matrix whose\ncolumns are the reciprocal space primitive translations is the inverse\ntranspose of the matrix whose columns are the direct space primitive\ntranslations.  Alternatively to  rprim , directions of dimensionless primitive vectors can\nbe specified by using the input variable  angdeg . This is especially useful\nfor hexagonal lattices (with 120 or 60 degrees angles). Indeed, in order for\nsymmetries to be recognized, rprim must be symmetric up to  tolsym  (10\ndigits by default), inducing a specification such as    rprim  0.86602540378  0.5  0.0\n        -0.86602540378  0.5  0.0\n         0.0            0.0  1.0  that can be avoided thanks to  angdeg :    angdeg 90 90 120  Although the use of  scalecart  or  acell  is rather equivalent when the\nprimitive vectors are aligned with the cartesian directions, it is not the\ncase for non-orthogonal primitive vectors. In particular, beginners often make\nthe error of trying to use  acell  to define primitive vectors in face-\ncentered tetragonal lattice, or body-centered tetragonal lattice, or similarly\nin face or body-centered orthorhombic lattices. Let us take the example of a\nbody-centered tetragonal lattice, that might be defined using the following\n(\u201ca\u201d and \u201cc\u201d have to be replaced by the appropriate conventional cell vector\nlength):    rprim  \"a\"      0        0\n          0      \"a\"       0\n         \"a/2\"   \"a/2\"    \"c/2\"\nacell 3*1     scalecart 3*1    !  ( These are default values)  The following is a valid, alternative way to define the same primitive vectors\n:    rprim   1        0       0\n          0        1       0\n          1/2      1/2     1/2\nscalecart  \"a\"  \"a\"  \"c\"\nacell 3*1    !  ( These are default values)  Indeed, the cell has been stretched along the cartesian coordinates, by \u201ca\u201d,\n\u201ca\u201d and \u201cc\u201d factors.  At variance, the following is WRONG :    rprim   1       0       0\n          0       1       0\n          1/2     1/2     1/2\nacell  \"a\"  \"a\"  \"c\"    !   THIS IS WRONG\nscalecart 3*1    !  ( These are default values)  Indeed, the latter would correspond to :    rprim  \"a\"      0       0\n          0      \"a\"      0\n         \"c/2\"   \"c/2\"   \"c/2\"\nacell 3*1     scalecart 3*1    !  ( These are default values)  Namely, the third vector has been rescaled by \u201cc\u201d. It is not at all in the\ncenter of the tetragonal cell whose basis vectors are defined by the scaling\nfactor \u201ca\u201d. \nAs another difference between  scalecart  or  acell , note that scalecart  is  INPUT_ONLY  : its content will be immediately applied to\nrprim, at parsing time, and then scalecart will be set to the default values\n(3*1). So, in case  scalecart  is used, the echo of  rprim  in the output\nfile is not the value contained in the input file, but the value rescaled by scalecart .",
            "title": "rprim"
        },
        {
            "location": "/input_variables/varbas/#rprimd",
            "text": "Mnemonics: Real space PRIMitive translations, Dimensional \nVariable type: real \nDimensions: (3,3) \ncommentdims Internally, it is represented as rprimd(3,3, nimage ). \nDefault value: None    This internal variable gives the dimensional real space primitive vectors,\ncomputed from  acell ,  scalecart , and  rprim .   R1p(i)= [rprimd] = [scalecart] [rprim] [acell]  for i=1,2,3 (x,y,and z)   R2p(i)= [rprimd] = [scalecart] [rprim] [acell]  for i=1,2,3   R3p(i)= [rprimd] = [scalecart] [rprim] [acell]  for i=1,2,3    It is  EVOLVING  only if  ionmov ==2 and  optcell /=0, otherwise it is\nfixed.",
            "title": "rprimd"
        },
        {
            "location": "/input_variables/varbas/#scalecart",
            "text": "Mnemonics: SCALE CARTesian coordinates \nVariable type: real \nDimensions: (3) \nDefault value: 3*1    Gives the scaling factors of cartesian coordinates by which dimensionless\nprimitive translations (in \u201c rprim \u201d) are to be multiplied.  rprim  input\nvariable, the  acell  input variable, and the associated internal  rprimd \ninternal variable. \nEspecially useful for body-centered and face-centered tetragonal lattices, as\nwell as body-centered and face-centered orthorhombic lattices, see  rprimd . \nNote that this input variable is  INPUT_ONLY  : its content will be\nimmediately applied to rprim, at parsing time, and then scalecart will be set\nto the default values. So, it will not be echoed.",
            "title": "scalecart"
        },
        {
            "location": "/input_variables/varbas/#shiftk",
            "text": "Mnemonics: SHIFT for K points \nVariable type: real \nDimensions: (3, nshiftk ) \nDefault value: None if  nshiftk >1,\n[0.5, 0.5, 0.5] otherwise.  It is used only when  kptopt >=0, and must be defined if  nshiftk  is\nlarger than 1.  [shiftk]  defines  nshiftk  shifts of the homogeneous\ngrid of k points based on  ngkpt  or  kptrlatt . \nThe shifts induced by  shiftk  corresponds to the reduced coordinates in the\ncoordinate system defining the k-point lattice. For example, if the k point\nlattice is defined using  ngkpt , the point whose reciprocal space reduced\ncoordinates are (  [shiftk] / [ngkpt]   [shiftk] / [ngkpt]  [shiftk] / [ngkpt]  ) belongs to the shifted grid number ii.  The user might rely on ABINIT to suggest suitable and efficient combinations\nof  kptrlatt  and  shiftk . The procedure to be followed is described with\nthe input variables  kptrlen . In what follows, we suggest some interesting\nvalues of the shifts, to be used with even values of  ngkpt . This list is\nmuch less exhaustive than the above-mentioned automatic procedure.  1) When the primitive vectors of the lattice do NOT form a FCC or a BCC\nlattice, the default (shifted) Monkhorst-Pack grids are formed by using nshiftk =1 and  shiftk  0.5 0.5 0.5 . This is often the preferred k point\nsampling, as the shift improves the sampling efficiency. However, it can also\nbreak symmetry, if the 111 direction is not an axis of rotation, e.g. in\ntetragonal or hexagonal systems. Abinit will complain about this breaking, and\nyou should adapt  shiftk . For a non-shifted Monkhorst-Pack grid, use nshiftk =1 and  shiftk  0.0 0.0 0.0 , which will be compatible with all\nsymmetries, and is necessary for some features such as k-point interpolation.  2) When the primitive vectors of the lattice form a FCC lattice, with rprim    0.0 0.5 0.5\n  0.5 0.0 0.5\n  0.5 0.5 0.0  the (very efficient) usual Monkhorst-Pack sampling will be generated by using nshiftk = 4 and  shiftk    0.5 0.5 0.5\n  0.5 0.0 0.0\n  0.0 0.5 0.0\n  0.0 0.0 0.5  3) When the primitive vectors of the lattice form a BCC lattice, with rprim    -0.5  0.5  0.5\n   0.5 -0.5  0.5\n   0.5  0.5 -0.5  the usual Monkhorst-Pack sampling will be generated by using  nshiftk = 2\nand  shiftk    0.25  0.25  0.25\n -0.25 -0.25 -0.25  However, the simple sampling  nshiftk =1 and  shiftk  0.5 0.5 0.5 is\nexcellent.  4) For hexagonal lattices with hexagonal axes, e.g.  rprim    1.0  0.0       0.0\n -0.5  sqrt(3)/2 0.0\n  0.0  0.0       1.0  one can use  nshiftk = 1 and  shiftk  0.0 0.0 0.5  In rhombohedral axes, e.g. using  angdeg  3*60., this corresponds to shiftk  0.5 0.5 0.5, to keep the shift along the symmetry axis.",
            "title": "shiftk"
        },
        {
            "location": "/input_variables/varbas/#symrel",
            "text": "Mnemonics: SYMmetry in REaL space \nVariable type: integer \nDimensions: (3,3, nsym ) \nDefault value: [[1, 0, 0], [0, 1, 0], [0, 0, 1]] if  nsym ==1,\nNone otherwise.  Gives \u201c nsym \u201d 3x3 matrices expressing space group symmetries in terms of\ntheir action on the direct (or real) space primitive translations. \nIt turns out that these can always be expressed as integers. \nAlways give the identity matrix even if no other symmetries hold, e.g. symrel  1 0 0 0 1 0 0 0 1 \nAlso note that for this array as for all others the array elements are filled\nin a columnwise order as is usual for Fortran. \nThe relation between the above symmetry matrices  symrel , expressed in the\nbasis of primitive translations, and the same symmetry matrices expressed in\ncartesian coordinates, is as follows. Denote the matrix whose columns are the\nprimitive translations as R, and denote the cartesian symmetry matrix as S.\nThen  symrel  = R(inverse) * S * R \nwhere matrix multiplication is implied. \nWhen the symmetry finder is used (see  nsym ),  symrel  will be computed\nautomatically.",
            "title": "symrel"
        },
        {
            "location": "/input_variables/varbas/#tnons",
            "text": "Mnemonics: Translation NON-Symmorphic vectors \nVariable type: real \nDimensions: (3, nsym ) \nDefault value: None    Gives the (nonsymmorphic) translation vectors associated with the symmetries\nexpressed in \u201c symrel \u201d. \nThese may all be 0, or may be fractional (nonprimitive) translations expressed\nrelative to the real space primitive translations (so, using the \u201creduced\u201d\nsystem of coordinates, see \u201c xred \u201d). If all elements of the space group\nleave 0 0 0 invariant, then these are all 0. \nWhen the symmetry finder is used (see  nsym ),  tnons  is computed\nautomatically.",
            "title": "tnons"
        },
        {
            "location": "/input_variables/varbas/#toldfe",
            "text": "Mnemonics: TOLerance on the DiFference of total Energy \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria  tolwfr ,  toldff ,  tolrff ,  toldfe  or  tolvrs  must differ from zero. \nThe use of this variable forbids the use of specified( tolwfr ) or specified( toldff ) or specified( tolrff ) or specified( tolvrs )    Sets a tolerance for absolute differences of total energy that, reached TWICE\nsuccessively, will cause one SCF cycle to stop (and ions to be moved). \nCan be specified in Ha (the default), Ry, eV or Kelvin, since  toldfe  has\nthe \u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV) \nIf set to zero, this stopping condition is ignored. \nEffective only when SCF cycles are done ( iscf >0). \nBecause of machine precision, it is not worth to try to obtain differences in\nenergy that are smaller than about 1.0d-12 of the total energy. To get\naccurate stresses may be quite demanding. \nWhen the geometry is optimized (relaxation of atomic positions or primitive\nvectors), the use of  toldfe  is to be avoided. The use of  toldff  or tolrff  is by far preferable, in order to have a handle on the geometry\ncharacteristics. When all forces vanish by symmetry (e.g. optimization of the\nlattice parameters of a high-symmetry crystal), then place  toldfe  to\n1.0d-12, or use (better)  tolvrs . \nSince  toldfe ,  toldff ,  tolrff ,  tolvrs  and  tolwfr  are aimed\nat the same goal (causing the SCF cycle to stop), they are seen as a unique\ninput variable at reading. Hence, it is forbidden that two of these input\nvariables have non-zero values for the same dataset, or generically (for all\ndatasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.",
            "title": "toldfe"
        },
        {
            "location": "/input_variables/varbas/#toldff",
            "text": "Mnemonics: TOLerance on the DiFference of Forces \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria  tolwfr ,  toldff ,  tolrff ,  toldfe  or  tolvrs  must differ from zero. \nThe use of this variable forbids the use of specified( tolwfr ) or specified( toldfe ) or specified( tolrff ) or specified( tolvrs )    Sets a tolerance for differences of forces (in hartree/Bohr) that, reached\nTWICE successively, will cause one SCF cycle to stop (and ions to be moved). \nIf set to zero, this stopping condition is ignored. \nEffective only when SCF cycles are done ( iscf >0). This tolerance\napplies to any particular cartesian component of any atom, INCLUDING fixed\nones. This is to be used when trying to equilibrate a structure to its lowest\nenergy configuration ( ionmov =2), or in case of molecular dynamics\n( ionmov =1) \nA value ten times smaller than  tolmxf  is suggested (for example 5.0d-6\nhartree/Bohr). \nThis stopping criterion is not allowed for RF calculations. \nSince   toldfe   ,  toldff ,  tolrff ,  tolvrs  and  tolwfr  are\naimed at the same goal (causing the SCF cycle to stop), they are seen as a\nunique input variable at reading. Hence, it is forbidden that two of these\ninput variables have non-zero values for the same dataset, or generically (for\nall datasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.",
            "title": "toldff"
        },
        {
            "location": "/input_variables/varbas/#tolrff",
            "text": "Mnemonics: TOLerance on the Relative diFference of Forces \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria  tolwfr ,  toldff ,  tolrff ,  toldfe  or  tolvrs  must differ from zero. \nThe use of this variable forbids the use of specified( tolwfr ) or specified( toldfe ) or specified( toldff ) or specified( tolvrs )\u2019    Sets a tolerance for the ratio of differences of forces (in hartree/Bohr) to\nmaximum force, that, reached TWICE successively, will cause one SCF cycle to\nstop (and ions to be moved) : diffor < tolrff * maxfor. \nIf set to zero, this stopping condition is ignored. \nEffective only when SCF cycles are done ( iscf >0). This tolerance\napplies to any particular cartesian component of any atom, INCLUDING fixed\nones. This is to be used when trying to equilibrate a structure to its lowest\nenergy configuration ( ionmov =2), or in case of molecular dynamics\n( ionmov =1) \nA value of 0.02 is suggested. \nThis stopping criterion is not allowed for RF calculations. \nSince   toldfe   ,  toldff ,  tolrff ,  tolvrs  and  tolwfr  are\naimed at the same goal (causing the SCF cycle to stop), they are seen as a\nunique input variable at reading. Hence, it is forbidden that two of these\ninput variables have non-zero values for the same dataset, or generically (for\nall datasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.",
            "title": "tolrff"
        },
        {
            "location": "/input_variables/varbas/#tolvrs",
            "text": "Mnemonics: TOLerance on the potential V(r) ReSidual \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria  tolwfr ,  toldff ,  tolrff ,  toldfe  or  tolvrs  must differ from zero. \nThe use of this variable forbids the use of specified( tolwfr ) or specified( toldfe ) or specified( toldff ) or specified( tolrff )\u2019    Sets a tolerance for potential residual that, when reached, will cause one SCF\ncycle to stop (and ions to be moved). \nIf set to zero, this stopping condition is ignored. \nEffective only when SCF cycles are done ( iscf >0). \nTo get accurate stresses may be quite demanding. For simple materials with\ninternal positions determined by symmetries, a value of  tolvrs =10^-12\nempirically leads to a very approximate 10^-6 atomic unit accuracy for the\noptimized lattice parameter.  Additional explanation : the residual of the potential is the difference\nbetween the input potential and the output potential, when the latter is\nobtained from the density determined from the eigenfunctions of the input\npotential. When the self-consistency loop is achieved, both input and output\npotentials must be equal, and the residual of the potential must be zero. The\ntolerance on the potential residual is imposed by first subtracting the mean\nof the residual of the potential (or the trace of the potential matrix, if the\nsystem is spin-polarized), then summing the square of this function over all\nFFT grid points. The result should be lower than  tolvrs . \nSince   toldfe   ,  toldff ,  tolrff ,  tolvrs  and  tolwfr  are\naimed at the same goal (causing the SCF cycle to stop), they are seen as a\nunique input variable at reading. Hence, it is forbidden that two of these\ninput variables have non-zero values for the same dataset, or generically (for\nall datasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.",
            "title": "tolvrs"
        },
        {
            "location": "/input_variables/varbas/#tolwfr",
            "text": "Mnemonics: TOLerance on WaveFunction squared Residual \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nComment: The default value implies that this stopping condition is ignored. For the SCF case, one and only one of the input tolerance criteria  tolwfr ,  toldff ,  tolrff ,  toldfe  or  tolvrs  must differ from zero. \nThe use of this variable forbids the use of specified( toldfe ) or specified( toldff ) or specified( tolrff ) or specified( tolvrs )    The signification of this tolerance depends on the basis set. In plane waves,\nit gives a convergence tolerance for the largest squared \u201cresidual\u201d (defined\nbelow) for any given band. The squared residual is:      < nk|(H-E)2|nk >,    E = < nk|H|nk >  which clearly is nonnegative and goes to 0 as the iterations converge to an\neigenstate. With the squared residual expressed in Hartrees  2  (Hartrees\nsquared), the largest squared residual (called residm) encountered over all\nbands and k points must be less than  tolwfr  for iterations to halt due to\nsuccessful convergence. \nNote that if  iscf >0, this criterion should be replaced by those based\non  toldfe  (preferred for  ionmov ==0),  toldff   tolrff  (preferred\nfor  ionmov /=0), or  tolvrs  (preferred for theoretical reasons!). \nWhen  tolwfr  is 0.0, this criterion is ignored, and a finite value of toldfe ,  toldff  or  tolvrs  must be specified. This also imposes a\nrestriction on taking an ion step; ion steps are not permitted unless the\nlargest squared residual is less than  tolwfr , ensuring accurate forces. \nTo get accurate stresses may be quite demanding. \nNote that the preparatory GS calculations before a RF calculations must be\nhighly converged. \nTypical values for these preparatory runs are  tolwfr  between 1.0d-16 and\n1.0d-22.  Note that  tolwfr  is often used in the test cases, but this is _ tolwfr _\npurely for historical reasons : except when  iscf <0, other critera\nshould be used.  In the wavelet case (see  usewvl  = 1), this criterion is the favoured one.\nIt is based on the norm 2 of the gradient of the wavefunctions. Typical values\nrange from 5 10  -4  to 5 10  -5  .  Since   toldfe   ,  toldff ,  tolrff ,  tolvrs  and  tolwfr  are\naimed at the same goal (causing the SCF cycle to stop), they are seen as a\nunique input variable at reading. Hence, it is forbidden that two of these\ninput variables have non-zero values for the same dataset, or generically (for\nall datasets). However, a non-zero value for one such variable for one dataset\nwill have precedence on the non-zero value for another input variable defined\ngenerically.",
            "title": "tolwfr"
        },
        {
            "location": "/input_variables/varbas/#typat",
            "text": "Mnemonics: TYPe of AToms \nVariable type: integer \nDimensions: [3, \u2018 natrd \u2019] if  natrd < natom ,\n[3, \u2018 natom \u2019] otherwise.  Default value: 1 if  natom ==1,\nNone otherwise.  Array giving an integer label to every atom in the unit cell to denote its\ntype. \nThe different types of atoms are constructed from the pseudopotential files.\nThere are at most  ntypat  types of atoms. \nAs an example, for BaTiO3, where the pseudopotential for Ba is number 1, the\none of Ti is number 2, and the one of O is number 3, the actual value of the typat  array might be :    typat 1 2 3 3 3  The array  typat  has to agree with the actual locations of atoms given in xred  ,  xcart  or  xangst , and the input of pseudopotentials has to\nbe ordered to agree with the atoms identified in  typat . \nThe nuclear charge of the elements, given by the array  znucl , also must\nagree with the type of atoms designated in \u201c typat \u201d. \nThe array  typat  is not constrained to be increasing. An internal\nrepresentation of the list of atoms, deep in the code (array atindx), groups\nthe atoms of same type together. This should be transparent to the user, while\nkeeping efficiency.",
            "title": "typat"
        },
        {
            "location": "/input_variables/varbas/#udtset",
            "text": "Mnemonics: Upper limit on DaTa SETs \nVariable type: integer \nDimensions: (2) \nDefault value: None \nComment: It is not used when it is not defined    Used to define the set of indices in the multi-data set mode, when a double\nloop is needed (see later). \nThe values of  [udtset]  must be between 1 and 999, the values of [udtset]  must be between 1 and 9, and their product must be equal to ndtset . \nThe values of  jdtset  are obtained by looping on the two indices defined by [udtset]  and  [udtset]  as follows :    do i1=1,intarr(1)\n   do i2=1,intarr(2)\n    idtset=idtset+1\n    dtsets(idtset)%jdtset=i1*10+i2\n   end do\n  end do  So,  [udtset]  sets the largest value for the unity digit, that varies\nbetween 1 and  [udtset] . \nIf  udtset  is used, the input variable  jdtset  cannot be used.",
            "title": "udtset"
        },
        {
            "location": "/input_variables/varbas/#usewvl",
            "text": "Mnemonics: Use WaVeLet basis set \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nComment: use plane-wave basis set    Used to define if the calculation is done on a wavelet basis set or not. \nThe values of  usewvl  must be 0 or 1. Putting  usewvl  to 1, makes icoulomb  mandatory to 1. The number of band ( nband ) must be set\nmanually to the strict number need for an isolator system ( _ i.e. _ number of\nelectron over two). The cut-off is not relevant in the wavelet case, use wvl_hgrid  instead. \nIn wavelet case, the system must be isolated systems (molecules or clusters).\nAll geometry optimization are available (see  ionmov , especially the\ngeometry optimisation and the molecular dynamics). \nThe spin computation is not currently possible with wavelets and metalic\nsystems may be slow to converge.",
            "title": "usewvl"
        },
        {
            "location": "/input_variables/varbas/#wtk",
            "text": "Mnemonics: WeighTs for K points \nVariable type: real \nDimensions: ( nkpt ) \nDefault value:  nkpt *1.0 \nComment: Except when  kptopt /=0    Gives the k point weights. \nThe k point weights will have their sum (re)normalized to 1 (unless occopt =2 and  kptopt =0; see description of  occopt ) within the\nprogram and therefore may be input with any arbitrary normalization. This\nfeature helps avoid the need for many digits in representing fractional\nweights such as 1/3.  wtk  is ignored if  iscf  is not positive, except if  iscf =-3.",
            "title": "wtk"
        },
        {
            "location": "/input_variables/varbas/#wvl_hgrid",
            "text": "Mnemonics: WaVeLet H step GRID \nVariable type: real \nDimensions: scalar \nDefault value: 0.5    It gives the step size in real space for the grid resolution in the wavelet\nbasis set. This value is highly responsible for the memory occupation in the\nwavelet computation. The value is a length in atomic units.",
            "title": "wvl_hgrid"
        },
        {
            "location": "/input_variables/varbas/#xangst",
            "text": "Mnemonics: vectors (X) of atom positions in cartesian coordinates -length in ANGSTrom- \nVariable type: real \nDimensions: (3,min( natom , natrd )) \nDefault value: None    Gives the cartesian coordinates of atoms within unit cell, in angstrom. This\ninformation is redundant with that supplied by array  xred  or  xcart . \nIf  xred  and  xangst  are ABSENT from the input file and  xcart  is\nprovided, then the values of  xred  will be computed from the provided xcart  (i.e. the user may use xangst instead of  xred  or  xcart  to\nprovide starting coordinates). \nOne and only one of  xred ,  xcart  and  xangst  must be provided. \nThe conversion factor between Bohr and Angstrom is 1 Bohr=0.5291772108\nAngstrom, see the   NIST site  . \nAtomic positions evolve if  ionmov /=0 . In constrast with  xred  and xcart ,  xangst  is not internal.",
            "title": "xangst"
        },
        {
            "location": "/input_variables/varbas/#xcart",
            "text": "Mnemonics: vectors (X) of atom positions in CARTesian coordinates \nVariable type: real \nDimensions: (3,min( natom , natrd )) \nDefault value: None    Gives the cartesian coordinates of atoms within unit cell. This information is\nredundant with that supplied by array  xred  or  xangst . By default, xcart  is given in Bohr atomic units (1 Bohr=0.5291772108 Angstroms),\nalthough Angstrom can be specified, if preferred, since  xcart  has the\n\u2018 LENGTH \u2018 characteristics. \nIf  xred  and  xangst  are ABSENT from the input file and  xcart  is\nprovided, then the values of  xred  will be computed from the provided xcart  (i.e. the user may use  xcart  instead of  xred  or  xangst \nto provide starting coordinates). \nOne and only one of  xred ,  xcart  and   xangst   must be provided. \nAtomic positions evolve if  ionmov /=0 .",
            "title": "xcart"
        },
        {
            "location": "/input_variables/varbas/#xred",
            "text": "Mnemonics: vectors (X) of atom positions in REDuced coordinates \nVariable type: real \nDimensions: (3,min( natom , natrd )) \ncommentdims represented internally as xred(3, natom , nimage ) \nDefault value: *0.0    Gives the atomic locations within unit cell in coordinates relative to real\nspace primitive translations (NOT in cartesian coordinates). Thus these are\nfractional numbers typically between 0 and 1 and are dimensionless. The\ncartesian coordinates of atoms (in Bohr) are given by: \nR_cartesian = xred1 rprimd1+xred2 rprimd2+xred3*rprimd3 \nwhere (xred1,xred2,xred3) are the \u201creduced coordinates\u201d given in columns of\n\u201c xred \u201d, (rprimd1,rprimd2,rprimd3) are the columns of primitive vectors\narray \u201c rprimd \u201d in Bohr. \nIf you prefer to work only with cartesian coordinates, you may work entirely\nwith \u201c xcart \u201d or \u201c xangst \u201d and ignore  xred , in which case  xred \nmust be absent from the input file. \nOne and only one of  xred ,  xcart  and  xangst  must be provided. \nAtomic positions evolve if  ionmov /=0 .",
            "title": "xred"
        },
        {
            "location": "/input_variables/varbas/#znucl",
            "text": "Mnemonics: charge -Z- of the NUCLeus \nVariable type: real \nDimensions: ( npsp ) \nDefault value: None    Gives nuclear charge for each type of pseudopotential, in order. \nIf  znucl  does not agree with nuclear charge, as given in pseudopotential\nfiles, the program writes an error message and stops.  N.B. : In the pseudopotential files,  znucl  is called \u201czatom\u201d.  For a \u201cdummy\u201d atom, with  znucl =0 , as used in the case of calculations\nwith only a jellium surface, ABINIT sets arbitrarily the covalent radius to\none.",
            "title": "znucl"
        },
        {
            "location": "/input_variables/varbse/",
            "text": "bs_algorithm\n\u00b6\n\n\nMnemonics: Bethe-Salpeter ALGORITHM\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2\n\nOnly relevant if \noptdriver\n == 99  \n\n\nThe bs_algorithm input variable defines the algorithm employed to calculate\nthe macroscopic dielectric function. Possible values are 1, 2 or 3:\n\n\n\n\n1 => The macroscopic dielectric is obtained by performing a direct diagonalization of the excitonic Hamiltonian. Advantages: It gives direct access to the excitonic eigenvalues as well as to the oscillator strengths. Drawbacks: It is a very CPU- and memory-consuming approach as the size of the Hamiltonian scales as (nk\nnc\nnv)**2. where nk is the number of k-point in the FULL Brillouin zone, and nc and nv are the number of conduction and valence states, respectively. Pros: It can be used both for resonant-only and resonant+coupling calculations (non Tamm-Dancoff approximation). \n\n\n2 => Haydock iterative method. The macroscopic dielectric function is obtained by iterative applications of the Hamiltonian on a set of vectors in the electron-hole space. Advantages: It is less memory demanding and usually faster than the direct diagonalization provided that \nzcut\n is larger than the typical energy spacing of the eigenvalues. Drawbacks: It is an iterative method therefore the convergence with respect to bs_haydock_niter should be checked. It is not possible to have direct information on the exciton spectrum, oscillator strengths and excitonic wave functions. For the time being \nbs_algorithm\n=2 cannot be used for calculations in which the coupling term is included (Tamm-Dancoff approximation). \n\n\n3 => Conjugate-gradient method. This method allows to find the few first excitonic eigenvalues. Only available for resonant calculations (Tamm-Dancoff approximation). \n\n\n\n\nbs_calctype\n\u00b6\n\n\nMnemonics: Bethe-Salpeter CALCulation TYPE\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n == 99  \n\n\nPossible values are 1,2,3.\n\n\n\n\n1 => use the KS eigenvalues and wave functions stored in the KSS file to construct the transition space \n\n\n2 => The transition space is constructed with Kohn-Sham orbitals but the energies are read from the external \nGW\n file \n\n\n3 => QP amplitudes and energies will be read from the QPS file and used to construct H_ex. Not coded yet because <\\psi|r|\\psj>^QP should be calculated taking into account the non-locality of the self-energy in the commutator [H,r]. \n\n\n\n\nbs_coulomb_term\n\u00b6\n\n\nMnemonics: Bethe-Salpeter COULOMB TERM\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 11\n\nOnly relevant if \noptdriver\n == 99  \n\n\nThis variable governs the choice among the different options that are\navailable for the treatment of Coulomb term of the \nBETHE_SALPETER\n\nHamiltonian. \nbs_coulomb_term\n is the concatenation of two digits, labelled\n(A) and (B).\n\n\nThe first digit (A) can assume the values 0,1,2:\n\n\n\n\n0 => The Coulomb term is not computed. This choice is equivalent to computing the RPA spectrum but using the representation in transition space instead of the more efficient approach based on the sum over states. \n\n\n1 => The Coulomb term is computed using the screened interaction read from an external SCR file (standard excitonic calculation). \n\n\n2 => The Coulomb term is computed using a model screening function (useful for convergence studies or for reproducing published results). \n\n\n\n\nThe second digit (B) can assume the values 0,1:\n\n\n\n\n0 => Use a diagonal approximation for W_GG\u2019 (mainly used for accelerating convergence studies). \n\n\n1 => The Coulomb term is correctly evaluated using the truly non-local W(r,r\u2019). \n\n\n\n\nbs_coupling\n\u00b6\n\n\nMnemonics: Bethe-Salpeter COUPLING\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n == 99  \n\n\nThe \nbs_coupling\n input variable defines the treatment of the coupling block\nof the \nBETHE_SALPETER\n Hamiltonian. Possible values are 0,1.\n\n\n\n\n0 => The coupling block is neglected (the so-called Tamm-Dancoff approximation). The code runs faster and the Hamiltonian matrix requires less memory (factor 4). It is a good approximation for the absorption spectrum which only requires the knowledge of Im(\\epsilon). The reliability of this approximation should be tested in the case of EELF calculations. \n\n\n1 => The coupling term is included (non Tamm-Dancoff approxmation). \n\n\n\n\nbs_eh_cutoff\n\u00b6\n\n\nMnemonics: Bethe-Salpeter Electron-Hole CUTOFF\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: [-inf, inf]\n\nOnly relevant if \noptdriver\n == 99  \n\n\nIt is used to define a cutoff in the e-h basis set. Only those transitions\nwhose energy is between bs_eh_window(1) and bs_eh_window(2) will be considered\nduring the construction of the e-h Hamiltonian.\n\n\nbs_exchange_term\n\u00b6\n\n\nMnemonics: Bethe-Salpeter EXCHANGE TERM\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n == 99  \n\n\n\n\n0 =>The exchange term is not calculated. This is equivalent to neglecting local field effects in the macroscopic dielectric function.\n\n\n1 =>The exchange term is calculated and added to the excitonic Hamiltonian. \n\n\n\n\nbs_freq_mesh\n\u00b6\n\n\nMnemonics: Bethe-Salpeter FREQuency MESH\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: [0.0, 0.0, 0.01]\n\nOnly relevant if \noptdriver\n == 99  \n\n\nbs_freq_mesh(1)\n defines the first frequency for the calculation of the macroscopic dielectric function. \n\n\nbs_freq_mesh(2)\n gives the last frequency for the calculation of the macroscopic dielectric function. If zero, \nbs_freq_mesh(2)\n is set automatically to MAX(resonant_energy) + 10%. \n\n\nbs_freq_mesh(3)\n gives the step of the linear mesh used for evaluating the macroscopic dielectric function. \n\n\nbs_hayd_term\n\u00b6\n\n\nMnemonics: Bethe-Salpeter HAYdock TERMinator\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n == 99 and \nbs_algorithm\n==2  \n\n\nDefines how to terminate the continued fraction expression for the dielectric\nfunction. The terminator reduces the number of iterations needed to converge\nby smoothing the oscillation in the high energy part of the spectrum\n\n\n\n\n0 => No terminator. The contribution given by the terms missing in the Lanczos chain are set to zero. \n\n\n1 => Use the terminator function. The particular expression depends on the type of calculation: In the resonant-only case, the a_i and b_i coefficients for i > niter, are replaced by their values at i=niter. Even the coupling block is included, the terminator function described in D. Rocca, R. Gebauer, Y. Saad, S. Baroni, J. Chem. Phys. 128, 154105 (2008) is used. \n\n\n\n\nbs_haydock_niter\n\u00b6\n\n\nMnemonics: Bethe-Salpeter HAYDOCK Number of ITERations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 100\n\nOnly relevant if \noptdriver\n == 99 and \nbs_algorithm\n==2  \n\n\nbs_haydock_niter\n defines the maximum number of iterations used to\ncalculate the macroscopic dielectric function. The iterative algorithm stops\nwhen the difference between two consecutive evaluations of the optical spectra\nis less than \nbs_haydock_tol\n.\n\n\nbs_haydock_tol\n\u00b6\n\n\nMnemonics: Bethe-Salpeter HAYDOCK TOLerance\n\nVariable type: real\n\nDimensions: (2)\n\nDefault value: [0.02, 0]\n\nOnly relevant if \noptdriver\n == 99 and \nbs_algorithm\n==2  \n\n\nDefines the convergence criterion for the Haydock iterative method. The\niterative algorithm stops when the difference between two consecutive\nevaluations of the macroscopic dielectric function is less than \n\nbs_haydock_tol(1) \n . The sign of \n bs_haydock_tol(1) \n defines how to\nestimate the convergence error. A negative value signals that the converge\nshould be reached for each frequency (strict criterion), while a positive\nvalue indicates that the converge error is estimated by averaging over the\nentire frequency range (mild criterion).\n\n\nbs_haydock_tol(2)\n defines the quantity that will be checked for convergence: \n\n\n\n\n0 -> both the real and the imaginary part must converge \n\n\n1 -> only the real part \n\n\n2 -> only the imaginary part \n\n\n\n\nbs_interp_kmult\n\u00b6\n\n\nMnemonics: Bethe-Salpeter INTERPolation K-point MULTiplication factors\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \nbs_interp_mode\n > 0 and \nbs_algorithm\n==2 and \nbs_coupling\n==0  \n\n\nbs_interp_kmult\n defines the number of divisions used to generate the dense\nmesh in the interpolation. \nngkpt\n of the dense mesh = \n bs_interp_kmult(:)\n\n * \nngkpt\n of the coarse mesh.\n\n\nbs_interp_m3_width\n\u00b6\n\n\nMnemonics: Bethe-Salpeter INTERPolation Method3 WIDTH\n\nVariable type: real\n\nDefault value: 1.0\n\nOnly relevant if \nbs_interp_mode\n==3 and \nbs_algorithm\n==2 and \nbs_coupling\n==0  \n\n\nDefines the width of the region where divergence treatment is applied for BSE\ninterpolation\n\n\nbs_interp_method\n\u00b6\n\n\nMnemonics: Bethe-Salpeter INTERPolation METHOD\n\nVariable type: integer\n\nDefault value: 1\n\nOnly relevant if \nbs_interp_mode\n > 0 and \nbs_algorithm\n==2 and \nbs_coupling\n==0  \n\n\nbs_interp_method\n selects the method of interpolation:\n\n\n\n\n0 => Interpolate using Y. Gillet technique with 8 neighbours (see Comput. Phys. Commun. 203, 83 (2016)) \n\n\n1 => Interpolation using Rohlfing & Louie technique (see above-mentioned article and Phys. Rev. B 62, 4927 (2000)) \n\n\n\n\nbs_interp_mode\n\u00b6\n\n\nMnemonics: Bethe-Salpeter INTERPolation MODE\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nbs_interp_mode\n > 0 and \nbs_algorithm\n==2 and \nbs_coupling\n==0  \n\n\nbs_interp_mode\n selects the mode of interpolation:\n\n\n\n\n0 => No interpolation. Standard \nBETHE_SALPETER\n computation is performed \n\n\n1 => Simple interpolation \n\n\n2 => Treatment of the divergence on the whole set of dense k-points \n\n\n3 => Treatment of the divergence along the diagonal in k-space and simple interpolation elsewhere. \n\n\n\n\nbs_interp_prep\n\u00b6\n\n\nMnemonics: Bethe-Salpeter INTERPolation PREParation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nbs_interp_mode\n > 0 and \nbs_algorithm\n==2 and \nbs_coupling\n==0  \n\n\nbs_interp_prep\n allows to trigger the preparation of the interpolation with\nmethod 2 or method 3. It generates the decomposition of BSR in a,b,c\ncoefficients used for the interpolation.\n\n\nbs_interp_rl_nb\n\u00b6\n\n\nMnemonics: Bethe-Salpeter INTERPolation Rohlfing & Louie NeighBour\n\nVariable type: integer\n\nDefault value: 1\n\nOnly relevant if \nbs_interp_mode\n > 0 and \nbs_algorithm\n==2 and \nbs_interp_method\n == 1 and \nbs_coupling\n==0  \n\n\nGives the index of the neighbour that is used for Rohlfing & Louie method\n\n\nbs_loband\n\u00b6\n\n\nMnemonics: Bethe-Salpeter Lowest Occupied BAND\n\nVariable type: integer\n\nDimensions: (\nnsppol\n)\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n == 99  \n\n\nThis variable defines the index of the lowest occupied band used for the\nconstruction of the electron-hole basis set. For spin polarized calculations,\none must provide two separated indices for spin up and spin down. An\nadditional cutoff energy can be applied by means of the bs_eh_window input\nvariable.\n\n\nbs_nstates\n\u00b6\n\n\nMnemonics: Bethe-Salpeter Number of STATES\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n == 99 and \nbs_algorithm\n in [2,3]  \n\n\nbs_nstates\n defines the maximum number of excitonic states calculated in\nthe direct diagonalization of the excitonic matrix or in the conjugate-\ngradient method. The number of states should be sufficiently large for a\ncorrect description of the optical properties in the frequency range of\ninterest.",
            "title": "Bethe-Salpeter"
        },
        {
            "location": "/input_variables/varbse/#bs_algorithm",
            "text": "Mnemonics: Bethe-Salpeter ALGORITHM \nVariable type: integer \nDimensions: scalar \nDefault value: 2 \nOnly relevant if  optdriver  == 99    The bs_algorithm input variable defines the algorithm employed to calculate\nthe macroscopic dielectric function. Possible values are 1, 2 or 3:   1 => The macroscopic dielectric is obtained by performing a direct diagonalization of the excitonic Hamiltonian. Advantages: It gives direct access to the excitonic eigenvalues as well as to the oscillator strengths. Drawbacks: It is a very CPU- and memory-consuming approach as the size of the Hamiltonian scales as (nk nc nv)**2. where nk is the number of k-point in the FULL Brillouin zone, and nc and nv are the number of conduction and valence states, respectively. Pros: It can be used both for resonant-only and resonant+coupling calculations (non Tamm-Dancoff approximation).   2 => Haydock iterative method. The macroscopic dielectric function is obtained by iterative applications of the Hamiltonian on a set of vectors in the electron-hole space. Advantages: It is less memory demanding and usually faster than the direct diagonalization provided that  zcut  is larger than the typical energy spacing of the eigenvalues. Drawbacks: It is an iterative method therefore the convergence with respect to bs_haydock_niter should be checked. It is not possible to have direct information on the exciton spectrum, oscillator strengths and excitonic wave functions. For the time being  bs_algorithm =2 cannot be used for calculations in which the coupling term is included (Tamm-Dancoff approximation).   3 => Conjugate-gradient method. This method allows to find the few first excitonic eigenvalues. Only available for resonant calculations (Tamm-Dancoff approximation).",
            "title": "bs_algorithm"
        },
        {
            "location": "/input_variables/varbse/#bs_calctype",
            "text": "Mnemonics: Bethe-Salpeter CALCulation TYPE \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver  == 99    Possible values are 1,2,3.   1 => use the KS eigenvalues and wave functions stored in the KSS file to construct the transition space   2 => The transition space is constructed with Kohn-Sham orbitals but the energies are read from the external  GW  file   3 => QP amplitudes and energies will be read from the QPS file and used to construct H_ex. Not coded yet because <\\psi|r|\\psj>^QP should be calculated taking into account the non-locality of the self-energy in the commutator [H,r].",
            "title": "bs_calctype"
        },
        {
            "location": "/input_variables/varbse/#bs_coulomb_term",
            "text": "Mnemonics: Bethe-Salpeter COULOMB TERM \nVariable type: integer \nDimensions: scalar \nDefault value: 11 \nOnly relevant if  optdriver  == 99    This variable governs the choice among the different options that are\navailable for the treatment of Coulomb term of the  BETHE_SALPETER \nHamiltonian.  bs_coulomb_term  is the concatenation of two digits, labelled\n(A) and (B).  The first digit (A) can assume the values 0,1,2:   0 => The Coulomb term is not computed. This choice is equivalent to computing the RPA spectrum but using the representation in transition space instead of the more efficient approach based on the sum over states.   1 => The Coulomb term is computed using the screened interaction read from an external SCR file (standard excitonic calculation).   2 => The Coulomb term is computed using a model screening function (useful for convergence studies or for reproducing published results).    The second digit (B) can assume the values 0,1:   0 => Use a diagonal approximation for W_GG\u2019 (mainly used for accelerating convergence studies).   1 => The Coulomb term is correctly evaluated using the truly non-local W(r,r\u2019).",
            "title": "bs_coulomb_term"
        },
        {
            "location": "/input_variables/varbse/#bs_coupling",
            "text": "Mnemonics: Bethe-Salpeter COUPLING \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver  == 99    The  bs_coupling  input variable defines the treatment of the coupling block\nof the  BETHE_SALPETER  Hamiltonian. Possible values are 0,1.   0 => The coupling block is neglected (the so-called Tamm-Dancoff approximation). The code runs faster and the Hamiltonian matrix requires less memory (factor 4). It is a good approximation for the absorption spectrum which only requires the knowledge of Im(\\epsilon). The reliability of this approximation should be tested in the case of EELF calculations.   1 => The coupling term is included (non Tamm-Dancoff approxmation).",
            "title": "bs_coupling"
        },
        {
            "location": "/input_variables/varbse/#bs_eh_cutoff",
            "text": "Mnemonics: Bethe-Salpeter Electron-Hole CUTOFF \nVariable type: integer \nDimensions: (2) \nDefault value: [-inf, inf] \nOnly relevant if  optdriver  == 99    It is used to define a cutoff in the e-h basis set. Only those transitions\nwhose energy is between bs_eh_window(1) and bs_eh_window(2) will be considered\nduring the construction of the e-h Hamiltonian.",
            "title": "bs_eh_cutoff"
        },
        {
            "location": "/input_variables/varbse/#bs_exchange_term",
            "text": "Mnemonics: Bethe-Salpeter EXCHANGE TERM \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver  == 99     0 =>The exchange term is not calculated. This is equivalent to neglecting local field effects in the macroscopic dielectric function.  1 =>The exchange term is calculated and added to the excitonic Hamiltonian.",
            "title": "bs_exchange_term"
        },
        {
            "location": "/input_variables/varbse/#bs_freq_mesh",
            "text": "Mnemonics: Bethe-Salpeter FREQuency MESH \nVariable type: real \nDimensions: (3) \nDefault value: [0.0, 0.0, 0.01] \nOnly relevant if  optdriver  == 99    bs_freq_mesh(1)  defines the first frequency for the calculation of the macroscopic dielectric function.   bs_freq_mesh(2)  gives the last frequency for the calculation of the macroscopic dielectric function. If zero,  bs_freq_mesh(2)  is set automatically to MAX(resonant_energy) + 10%.   bs_freq_mesh(3)  gives the step of the linear mesh used for evaluating the macroscopic dielectric function.",
            "title": "bs_freq_mesh"
        },
        {
            "location": "/input_variables/varbse/#bs_hayd_term",
            "text": "Mnemonics: Bethe-Salpeter HAYdock TERMinator \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver  == 99 and  bs_algorithm ==2    Defines how to terminate the continued fraction expression for the dielectric\nfunction. The terminator reduces the number of iterations needed to converge\nby smoothing the oscillation in the high energy part of the spectrum   0 => No terminator. The contribution given by the terms missing in the Lanczos chain are set to zero.   1 => Use the terminator function. The particular expression depends on the type of calculation: In the resonant-only case, the a_i and b_i coefficients for i > niter, are replaced by their values at i=niter. Even the coupling block is included, the terminator function described in D. Rocca, R. Gebauer, Y. Saad, S. Baroni, J. Chem. Phys. 128, 154105 (2008) is used.",
            "title": "bs_hayd_term"
        },
        {
            "location": "/input_variables/varbse/#bs_haydock_niter",
            "text": "Mnemonics: Bethe-Salpeter HAYDOCK Number of ITERations \nVariable type: integer \nDimensions: scalar \nDefault value: 100 \nOnly relevant if  optdriver  == 99 and  bs_algorithm ==2    bs_haydock_niter  defines the maximum number of iterations used to\ncalculate the macroscopic dielectric function. The iterative algorithm stops\nwhen the difference between two consecutive evaluations of the optical spectra\nis less than  bs_haydock_tol .",
            "title": "bs_haydock_niter"
        },
        {
            "location": "/input_variables/varbse/#bs_haydock_tol",
            "text": "Mnemonics: Bethe-Salpeter HAYDOCK TOLerance \nVariable type: real \nDimensions: (2) \nDefault value: [0.02, 0] \nOnly relevant if  optdriver  == 99 and  bs_algorithm ==2    Defines the convergence criterion for the Haydock iterative method. The\niterative algorithm stops when the difference between two consecutive\nevaluations of the macroscopic dielectric function is less than  \nbs_haydock_tol(1)   . The sign of   bs_haydock_tol(1)   defines how to\nestimate the convergence error. A negative value signals that the converge\nshould be reached for each frequency (strict criterion), while a positive\nvalue indicates that the converge error is estimated by averaging over the\nentire frequency range (mild criterion).  bs_haydock_tol(2)  defines the quantity that will be checked for convergence:    0 -> both the real and the imaginary part must converge   1 -> only the real part   2 -> only the imaginary part",
            "title": "bs_haydock_tol"
        },
        {
            "location": "/input_variables/varbse/#bs_interp_kmult",
            "text": "Mnemonics: Bethe-Salpeter INTERPolation K-point MULTiplication factors \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  bs_interp_mode  > 0 and  bs_algorithm ==2 and  bs_coupling ==0    bs_interp_kmult  defines the number of divisions used to generate the dense\nmesh in the interpolation.  ngkpt  of the dense mesh =   bs_interp_kmult(:)  *  ngkpt  of the coarse mesh.",
            "title": "bs_interp_kmult"
        },
        {
            "location": "/input_variables/varbse/#bs_interp_m3_width",
            "text": "Mnemonics: Bethe-Salpeter INTERPolation Method3 WIDTH \nVariable type: real \nDefault value: 1.0 \nOnly relevant if  bs_interp_mode ==3 and  bs_algorithm ==2 and  bs_coupling ==0    Defines the width of the region where divergence treatment is applied for BSE\ninterpolation",
            "title": "bs_interp_m3_width"
        },
        {
            "location": "/input_variables/varbse/#bs_interp_method",
            "text": "Mnemonics: Bethe-Salpeter INTERPolation METHOD \nVariable type: integer \nDefault value: 1 \nOnly relevant if  bs_interp_mode  > 0 and  bs_algorithm ==2 and  bs_coupling ==0    bs_interp_method  selects the method of interpolation:   0 => Interpolate using Y. Gillet technique with 8 neighbours (see Comput. Phys. Commun. 203, 83 (2016))   1 => Interpolation using Rohlfing & Louie technique (see above-mentioned article and Phys. Rev. B 62, 4927 (2000))",
            "title": "bs_interp_method"
        },
        {
            "location": "/input_variables/varbse/#bs_interp_mode",
            "text": "Mnemonics: Bethe-Salpeter INTERPolation MODE \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  bs_interp_mode  > 0 and  bs_algorithm ==2 and  bs_coupling ==0    bs_interp_mode  selects the mode of interpolation:   0 => No interpolation. Standard  BETHE_SALPETER  computation is performed   1 => Simple interpolation   2 => Treatment of the divergence on the whole set of dense k-points   3 => Treatment of the divergence along the diagonal in k-space and simple interpolation elsewhere.",
            "title": "bs_interp_mode"
        },
        {
            "location": "/input_variables/varbse/#bs_interp_prep",
            "text": "Mnemonics: Bethe-Salpeter INTERPolation PREParation \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  bs_interp_mode  > 0 and  bs_algorithm ==2 and  bs_coupling ==0    bs_interp_prep  allows to trigger the preparation of the interpolation with\nmethod 2 or method 3. It generates the decomposition of BSR in a,b,c\ncoefficients used for the interpolation.",
            "title": "bs_interp_prep"
        },
        {
            "location": "/input_variables/varbse/#bs_interp_rl_nb",
            "text": "Mnemonics: Bethe-Salpeter INTERPolation Rohlfing & Louie NeighBour \nVariable type: integer \nDefault value: 1 \nOnly relevant if  bs_interp_mode  > 0 and  bs_algorithm ==2 and  bs_interp_method  == 1 and  bs_coupling ==0    Gives the index of the neighbour that is used for Rohlfing & Louie method",
            "title": "bs_interp_rl_nb"
        },
        {
            "location": "/input_variables/varbse/#bs_loband",
            "text": "Mnemonics: Bethe-Salpeter Lowest Occupied BAND \nVariable type: integer \nDimensions: ( nsppol ) \nDefault value: 0 \nOnly relevant if  optdriver  == 99    This variable defines the index of the lowest occupied band used for the\nconstruction of the electron-hole basis set. For spin polarized calculations,\none must provide two separated indices for spin up and spin down. An\nadditional cutoff energy can be applied by means of the bs_eh_window input\nvariable.",
            "title": "bs_loband"
        },
        {
            "location": "/input_variables/varbse/#bs_nstates",
            "text": "Mnemonics: Bethe-Salpeter Number of STATES \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver  == 99 and  bs_algorithm  in [2,3]    bs_nstates  defines the maximum number of excitonic states calculated in\nthe direct diagonalization of the excitonic matrix or in the conjugate-\ngradient method. The number of states should be sufficiently large for a\ncorrect description of the optical properties in the frequency range of\ninterest.",
            "title": "bs_nstates"
        },
        {
            "location": "/input_variables/vardev/",
            "text": "builtintest\n\u00b6\n\n\nMnemonics: BUIT-IN TEST number\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nWhen \nbuiltintest\n is non-zero, the input file is a special one, that runs\nvery quickly, and that is accompanied by a specific analysis by ABINIT, at the\nend of the run, against a hard-coded value of total energy (and possibly\nstresses, forces \u2026). The echo of the analysis is done in the STATUS file. In\nparticular, such built-in tests can be used to check quickly whether ABINIT\nfallbacks have been connected or not (bigdft, etsf_io, libxc, wannier90). At\npresent, \nbuiltintest\n=1 \u2026 7 are allowed. See more information in\ntests/built-in/README .\n\n\ncgtyphf\n\u00b6\n\n\nMnemonics: Conjugate Gradient TYPe used for Hartree Fock exact exchange\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2 if \nusefock\n == 1,\n0 otherwise.\n\n\nGives how is calculated Fock exact exchange contribution in the conjugate\ngradient, in the SCF case.\n\nThe value 2 corresponds to calculate the Fock exact exchange contribution each\ntime in the conjugate gradient. The value 1 corresponds to calculate the Fock\nexact exchange contribution only for the initial guess (not for the gradient\ndirection) in the conjugate gradient\n\n\ndensfor_pred\n\u00b6\n\n\nMnemonics: DENSity and FORces PREDictor\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 6 if \nparal_kgb\n==1,\n2 otherwise.\n\n\nOnly relevant if \niscf\n >0  \n\n\nUsed when \niscf\n>0, to define:\n\n- the way a change of density is derived from a change of atomic position,\n\n- the way forces are corrected when the SCF cycle is not converged.  \n\n\nSupported values :\n\n\n\n\n0 => density not changed (fixed charge), forces not corrected \n\n\n1 => density not changed, forces corrected with rigid ion hypothesis (atomic charge moved with atom) \n\n\n2 => density changed and forces corrected with rigid ion hypothesis (atomic charge moves with atom) \n\n\n3 => density changed and forces corrected with a different implementation of the rigid ion hypothesis \n\n\n4 => density not changed, forces corrected with the use of Harris functional formula (*) \n\n\n5 => density changed using D. Alfe 2nd-order algorithm (**), forces not corrected \n\n\n6 => density changed using D. Alfe 2nd-order algorithm (*\n) and forces corrected with the use of Harris functional formula (\n) \n\n\n\n\nSimilar negative values are also allowed (see the meaning later), for\ndevelopment purposes only. No meaning for RF calculations.  \n\n\nFor the time being,\n\n- \ndensfor_pred\n=3 must be used with \nionmov\n=4 and \niscf\n=5.\n\n- \ndensfor_pred\n=4, 5 or 6 must be used when band-FFT parallelism is\nselected.\n\nOtherwise, use \ndensfor_pred\n=2  \n\n\n (*) \n _ Note concerning the correction of forces (use of \ndensfor_pred\n=1, 2, 3, 4 or 6) _ : \n\nThe force on the atom located at R is corrected by the addition of the\nfollowing term:\n\n_ F_residual=Int[dr.V_residual.dRho_atomic/dR] _ , where Rho_atomic is an\natomic (spherical) density.\n\n- When such an atomic density (Rho_atomic) is found in the pseudopotential or\nPAW file, it is used. If not, a gaussian density (defined by \ndensty\n\nparameter) is used.\n\n- When SCF mixing is done on the density (\niscf\n>=10), the potential\nresidual (V_residual) is obtained from the density residual with the first\norder formula _ V_residual=dV/drho.Rho_residual _ and uses the exchange-\ncorrelation kernel _ dVxc/drho=Kxc _ whose computation is time-consuming for\nGGA functionals. By default (positive values of \ndensfor_pred\n), the local-\ndensity part of the GGA exchange-correlation kernel is used (even for GGA, for\nwhich it seems to give a reasonable accuracy). Using the full GGA exchange\ncorrelation kernel (so, including derivatives with respect to the gradient of\nthe density) is always possible by giving a negative value to\n\ndensfor_pred\n. In case of hybrid functionals, a similar correction term is\nadded, although in the density mixing scheme, the related GGA kernel is used\ninstead of the hybrid functional kernel.  \n\n\n (\n) \n _ Note concerning the use of \ndensfor_pred\n=5 or 6 (density prediction) _ : \n\nThe algorithm is described in _ Computer Physics Communications \n 118 **\n(1999) 31-33 _ . It uses an atomic (spherical) density. When such an atomic\ndensity is found in the pseudopotential or PAW file, it is used. If not, a\ngaussian density (defined by \ndensty\n parameter) is used.\n\nAlso note that, to be efficient, this algorithm requires a minimum convergence\nof the SCF cycle; Typically, vres2 (or nres2) has to be small enough (10  -4\n\u202610  -5  ).\n\n\ndensty\n\u00b6\n\n\nMnemonics: initial DENSity for each TYpe of atom\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: 0.0  \n\n\nGives a rough description of the initial GS density, for each type of atom.\nThis value is only used to create the first exchange and correlation\npotential, and is not used anymore afterwards. For the time being, it\ncorresponds to an average radius (a.u.) of the density, and is used to\ngenerate a gaussian density. If set to 0.0d0, an optimized value is used.\n\nNo meaning for RF calculations.\n\n\ndmft_read_occnd\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: READ OCCupations (Non Diagonal)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nFlag to read/write Occupations as computed in DMFT. This flag is useful to\nrestart a DFT+DMFT calculation with self-consistency over electronic density.\nThe occupations are written each time a DMFT loop is finished. So if the\ncalculation stops because the time limit is reached, this option offers the\npossibility to restart the self-consistent loop over density at the point\nwhere it stopped (assuming a restart with the wave functions, see \ngetwfk\n).\n\n\n\n\n0=> Occupations are written but never read. \n\n\n1=> Occupations are read from I_DMFTOCCND, where I is the root for input files. \n\n\n2=> Occupations are read from O_DMFTOCCND, where O is the root for output files. \n\n\n\n\nAn alternative and more simple way to restart a DFT+DMFT calculation is to use\nthe density file (obtained with \nprtden\n=1 or \nprtden\n=-1) and the self-\nenergy (see \ndmft_rslf\n).\n\n\ndmftctqmc_basis\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo BASIS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nChoose the basis to perform CTQMC calculation.\n\n\n\n\n0=> Use the local basis in the spherical harmonics basis. Can be useful if the Hamiltonian has weak off diagonal terms and for this reason, one want to keep the original basis for simplicity and for physical insight. \n\n\n1=> Default value, diagonalize the local Hamiltonian (but only if it is not diagonal). The best choice in general. \n\n\n2=> Diagonalise the local correlated occupation matrix. Can lead to non diagonal Hamiltonian that cannot be handled by CTQMC. This option should be thus avoided. \n\n\n\n\neffmass\n\u00b6\n\n\nMnemonics: EFFective MASS\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis parameter allows to change the electron mass, with respect to its\nexperimental value.\n\n\neshift\n\u00b6\n\n\nMnemonics: Energy SHIFT\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nwfoptalg\n==3  \n\n\neshift\n gives the shift of the energy used in the shifted Hamiltonian\nsquared. The algorithm will determine eigenvalues and eigenvectors centered on\n\neshift\n.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \n ecut \n has\nthe \u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV)\n\n\nexchmix\n\u00b6\n\n\nMnemonics: EXCHange MIXing\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.25\n\nOnly relevant if \nuseexexch\n == 1  \n\n\nexchmix\n allows to tune the ratio of exact exchange when \nuseexexch\n is\nused. The default value of 0.25 corresponds to PBE0.\n\n\nexchn2n3d\n\u00b6\n\n\nMnemonics: EXCHange N2 and N3 Dimensions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf \nexchn2n3d\n is 1, the internal representation of the FFT arrays in\nreciprocal space will be array(n1,n3,n2), where the second and third\ndimensions have been switched. This is to allow to be coherent with the\n\nexchn2n3d\n=4xx FFT treatment.\n\n\nextrapwf\n\u00b6\n\n\nMnemonics: flag - EXTRAPolation of the Wave-Functions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndensfor_pred\n==5 or \ndensfor_pred\n==6  \n\n\nThis flag activates the extrapolation of wave-functions from one Molecular\nDynamics (or Structural Relaxation) step to another. The wave functions are\nextrapolated using 2nd-order algorithm of Arias, Payne and Joannopoulos (PRB\n45, 1538 (1992)).\n\nNote that, when activated, this extrapolation requires non-negligible\nadditional memory resources as the wave functions are stored for the two\nprevious time steps. Also, it can only be activated if a consistent density\nextrapolation is activated (see \ndensfor_pred\n).\n\nABINIT 7.10: this option is \nunder development\n and might give wrong\nresults.\n\n\nfermie_nest\n\u00b6\n\n\nMnemonics: FERMI Energy for printing the NESTing function\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis input variable is only effective when \nprtnest\n=1. The energy is\nrelative to the calculated fermi energy.\n\n\nfftalg\n\u00b6\n\n\nMnemonics: Fast Fourier Transform ALGorithm\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 312 if \nFFTW3\n and \nusedmft\n==0,\n401 if \nparal_kgb\n==1,\n112 otherwise.\n\n\nThis keyword is \n irrelevant \n when Fast Fourier Transforms are done using\n\n Graphics Processing Units \n (GPU), i.e. when \nuse_gpu_cuda\n=1 (in that\ncase, it is ignored).  \n\n\nAllows to choose the algorithm for Fast Fourier Transforms. These have to be\nused when applied to wavefunctions (routine fourwf.F90), as well as when\napplied to densities and potentials (routine fourdp.F90). Presently, it is the\nconcatenation of three digits, labelled (A), (B) and (C).  \n\n\nThe first digit (A) is to be chosen among 1, 2, 3, 4 or 5 :\n\n\n\n\n1=> use FFT routines written by S. Goedecker. \n\n\n2=> not available anymore \n\n\n3=> use serial or multi-threaded FFTW3 fortran routines ( \n http://www.fftw.org \n ). Currently implemented with \nfftalg\n=312. \n\n\n4=> use FFT routines written by S. Goedecker, 2002 version, that will be suited for MPI and OpenMP parallelism. \n\n\n5=> use serial or multi-threaded MKL routines Currently implemented with \nfftalg\n=512. \n\n\n\n\nThe second digit (B) is related to fourdp.f :\n\n\n\n\n0=> only use Complex-to-complex FFT \n\n\n1=> real-to-complex is also allowed (only coded for A==1, A==3 and A==5) \n\n\n\n\nThe third digit (C) is related to fourwf.f :\n\n\n\n\n0=> no use of zero padding \n\n\n1=> use of zero padding (only coded for A==1, A==4) \n\n\n2=> use of zero padding, and also combines actual FFT operations (using 2 routines from S. Goedecker) with important pre- and post-processing operations, in order to maximize cache data reuse. This is very efficient for cache architectures. (coded for A==1 and A==4, but A==4 is not yet sufficiently tested) \n\n\n\n\nInternal representation as \n[ngfft]\n.\n\n\nfftcache\n\u00b6\n\n\nMnemonics: Fast Fourier Transform CACHE size\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 16\n\nComment: todo: Not yet machine-dependent  \n\n\nGives the cache size of the current machine, in Kbytes.\n\nInternal representation as \n[ngfft]\n.\n\n\ngetgam_eig2nkq\n\u00b6\n\n\nMnemonics: GET the GAMma phonon data EIG2NKQ from dataset\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nieig2rf\n != 0 and \nqpt\n != (0.0,0.0,0.0)  \n\n\nRelevant for second-order eigenvalue calculations using response-functions\n(\nieig2rf\n != 0), and only for non-zero wavevectors \nqpt\n.\n\nFrom the electron-phonon matrix elements at some wavevector only, it is not\npossible to determine the Debye-Waller contribution : one has to know also the\nq=Gamma electron-phonon matrix elements.\n\nThe variable \ngetgam_eig2nkq\n allows to transmit the information about the\nsecond-order derivatives of the eigenvalues for q=Gamma from the dataset where\nthe calculation at Gamma was done, to the datasets for other wavevectors.\n\n\ngetwfkfine\n\u00b6\n\n\nMnemonics: GET the fine grid wavefunctions from _WFK file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to \nirdwfkfine\n. One should first\nread the explanations given for these latter variables.\n\nThe \ngetwfkfine\n variables is typically used to chain the calculations in\nthe multi-dataset mode, since they describe from which dataset the OUTPUT\nwavefunctions are to be taken, as INPUT wavefunctions of the present dataset.\n\nIf \ngetwfkfine\n==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done.\n\nIf \ngetwfkfine\n is positive, its value gives the index of the dataset for\nwhich the output wavefunction file appended with _WFK must be used.\n\nIf \ngetwfkfine\n is -1, the output wf file with _WFK of the previous dataset\nmust be taken, which is a frequently occurring case.\n\nIf \ngetwfkfine\n is a negative number, it indicates the number of datasets to\ngo backward to find the needed wavefunction file. In this case, if one refers\nto a non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if \ngetwfkfine\n=0 for that\ninitialisation. Thanks to this rule, the use of \ngetwfkfine\n -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized. Response-function\ncalculation :\n\n\n\n\none and only one of \ngetwfkfine\n or \nirdwfkfine\n MUST be non-zero \n\n\nif \ngetwfkfine\n = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nReading the fine grid wavefunction will trigger the k-points interpolation technique of the temperature dependent calculations. \n\n\n\n\nBethe-Salpeter calculation :\n\n\n\n\none and only one of \ngetwfkfine\n or \nirdwfkfine\n MUST be non-zero \n\n\nif \ngetwfkfine\n = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nThis variable or \nirdwfkfine\n is mandatory when \nbs_interp_mode\n == 1 \n\n\n\n\n This variable is experimental. In development. \n\n\nintxc\n\u00b6\n\n\nMnemonics: INTerpolation for eXchange-Correlation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\n\n\n0=> do \u201cusual\u201d xc quadrature on fft grid \n\n\n1=> do higher accuracy xc quadrature using fft grid and additional points at the centers of each cube (doubles number of grid points)\u2013the high accuracy version is only valid for boxcut>=2. If boxcut < 2, the code stops. \n\n\n\n\nFor RF calculations only \nintxc\n=0 is allowed yet. Moreover, the GS\npreparation runs (giving the density file and zero-order wavefunctions) must\nbe done with \nintxc\n=0\n\n\nPrior to ABINITv2.3, the choice \nintxc\n=1 was favoured (it was the default),\nbut the continuation of the development of the code lead to prefer the default\n\nintxc\n=0 . Indeed, the benefit of \nintxc\n=1 is rather small, while making\nit available for all cases is a non-negligible development effort. Other\ntargets are prioritary\u2026 You will notice that many automatic tests use\n\nintxc\n=1. Please, do not follow this historical choice for your production\nruns.\n\n\niomode\n\u00b6\n\n\nMnemonics: Input-Output MODE\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \nMPI_IO\n and \nparal_kgb\n==1,\n0 otherwise.\n\n\nThis option selects the format used to produce the output wavefunction files\nand the files containing densities and potentials. It mainly affects the\ncreation of the output files since several parts of Abinit are able to read\ndata from files independently of their format (either binary files or netcdf\nfiles). The possible values are:\n\n\n\n\n0 => Use standard Fortran IO (ok for sequential runs, not suitable for large parallel runs) \n\n\n1 => Use MPI/IO routines (ok both for sequential and large parallel runs) \n\n\n3 => Use NetCDF library to produce files according to the ETSF specification (ok for sequential, requires netcdf4 + hdf5 + MPI-IO support for large parallel runs) \n\n\n\n\nBy default, Abinit produces Fortran files and uses parallel MPI-IO under the\nhood when these operations cannot be implemented in terms of simple Fortran\nwrite/read statements. For example, \nparal_kgb\n=1 uses the MPI-IO API\nprovided by your MPI library.\n\n\nIn a nutshell, use the default value and make sure that your MPI library\nsupports MPI-IO before embarking yourself in large parallel runs (HAVE_MPI_IO\nshould be set to 1 in ~abinit/config.h). Many MPI libraries, nowadays, support\nthe MPI-2 standard so it\u2019s very likely that your MPI supports parallel IO. If\nyou encounter problems, please ask your sysadmin to install a MPI library with\nMPI-IO capabilities.\n\n\nThere are cases, however, in which you would like to change the default\nbehaviour. For example, you may want to generate WFK or DEN files in etsf-io\nformat because you need data in this format. In this case, you have to use\niomode==3 in the input file to override the default behaviour. Note however\nthat you still need parallel IO capabilities enabled in the netcdf library if\nyou want to produce netcdf files in parallel with \nparal_kgb\n=1 (i.e.\nnetcdf4 + hdf5 + MPI-IO). At present, the internal fallbacks provided by\nAbinit do not support netcdf4 so you have to link against an external netcdf\nlibrary that supports hdf5+MPI-IO and is compatible with the mpif90 used to\ncompile Abinit. See ~abinit/doc/build/config-examples/ubu_gnu_4.9_mpich.ac for\na typical configuration file.\n\n\nReferences:\n\n\n\n\n\u201cSpecification of an extensible and portable file format for electronic structure and crystallographic data\u201d, X. Gonze, C.-O. Almbladh, A. Cucca, D. Caliste, C. Freysoldt, M. Marques, V. Olevano, Y. Pouillon, M.J. Verstraete, Comput. Mat. Science 43, 1056 (2008) \n\n\n\u201cSharing electronic structure and crystallographic data with ETSF_IO\u201d, D. Caliste, Y. Pouillon, M.J. Verstraete, V. Olevano, X. Gonze, Comput. Physics Communications 179, 748 (2008) \n\n\nsee also \n http://www.etsf.eu/fileformats \n . \n\n\n\n\niprcfc\n\u00b6\n\n\nMnemonics: Integer for PReConditioner of Force Constants\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed when \niscf\n>0, to define the SCF preconditioning scheme. Potential-\nbased preconditioning schemes for the SCF loop are still under development.\n\nThe present parameter (force constant part) describes the way a change of\nforce is derived from a change of atomic position.\n\nSupported values :\n\n\n\n\n0 => hessian is the identity matrix \n\n\n1 => hessian is 0.5 times the identity matrix \n\n\n2 => hessian is 0.25 times the identity matrix \n\n\n-1=> hessian is twice the identity matrix \n\n\n\u2026 (simply corresponding power of 2 times the identity matrix) \n\n\n\n\nNo meaning for RF calculations.\n\n\nirandom\n\u00b6\n\n\nMnemonics: Integer for the choice of the RANDOM number generator\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 3  \n\n\nFor the time being, only used when \nimgmov\n=9 (Langevin Path-Integral\nMolecular Dynamics).\n\n\nirandom\n defines the random number generator.  \n\n\nSupported values :\n\n\n\n\n1 => \u201cuniformrandom\u201d, delivered with ABINIT package (initially comes from numerical recipes). \n\n\n2 => intrinsic Fortran 90 random number generator. \n\n\n3 => \u201cZBQ\u201d non-deterministic random number generator by R. Chandler and P. Northrop. (Available at [). \n\n\n\n\nirandom\n=3 is strongly advised when performing Molecular Dynamics restarts\n(avoids bias).\n\n\nirdwfkfine\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of the grid _WFK file on the FINE grid\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIndicates eventual starting wavefunctions. As alternative, one can use the\ninput variables \ngetwfkfine\n.  \n\n\nGround-state calculation :\n\n\n\n\nonly \nirdwfkfine\n and \ngetwfkfine\n have a meaning \n\n\nat most one of \nirdwfkfine\n or \ngetwfkfine\n can be non-zero \n\n\nif \nirdwfkfine\n = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state fine grid calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nResponse-function calculation :\n\n\n\n\none and only one of \nirdwfkfine\n or \ngetwfkfine\n MUST be non-zero \n\n\nif \nirdwfkfine\n = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nReading the fine grid wavefunction will trigger the k-points interpolation technique of the temperature dependent calculations. \n\n\n\n\nBethe-Salpeter calculation :\n\n\n\n\none and only one of \nirdwfkfine\n or \ngetwfkfine\n MUST be non-zero \n\n\nif \nirdwfkfine\n = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nThis variable or \ngetwfkfine\n is mandatory when \nbs_interp_mode\n = 1 \n\n\n\n\n This variable is experimental. In development. \n\n\nisecur\n\u00b6\n\n\nMnemonics: Integer for level of SECURity choice\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIn the presently used algorithms, there is a compromise between speed and\nrobustness, that can be tuned by using \nisecur\n.\n\nIf \nisecur\n =0, an extrapolation of out-of-line data is allowed, and might\nsave one non-SCF calculation every two line minimisation when some stability\nconditions are fulfilled (since there are 2 non-SCF calculations per line\nminimisation, 1 out of 4 is saved)\n\nUsing \nisecur\n=1 or higher integers will raise gradually the threshold to\nmake extrapolation.\n\nUsing \nisecur\n=-2 will allow to save 2 non-SCF calculations every three line\nminimisation, but this can make the algorithm unstable. Lower values of\n\nisecur\n allows for more (tentative) savings. In any case, there must be one\nnon-SCF computation per line minimisation.\n\nNo meaning for RF calculations yet.\n\n\nistatr\n\u00b6\n\n\nMnemonics: Integer for STATus file rate\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nComment: Values lower than 10 may not work on some machines.  \n\n\nGovern the rate of output of the status file. This status file is written when\nthe number of the call to the status subroutine is equal to \u2018 \n istatshft \n\n\u2018 modulo \u2018\nistatr\n\u2019, so that it is written once every \u2018\nistatr\n\u2018 call.\nWhen \u2018\nistatr\n\u2018=0, there is no writing of a status file (which is the\ndefault).\n\n\nistatshft\n\u00b6\n\n\nMnemonics: Integer for STATus file SHiFT\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nGovern the rate of output of the status file. This status file is written when\nthe number of the call to the status subroutine is equal to \u2018\nistatshft\n\u2018\nmodulo \u2018 \n istatr \n \u2018, so that it is written once every \u2018 \n istatr \n \u2018\ncall. There is also a writing for each of the 5 first calls, and the 10th\ncall.\n\n\nistwfk\n\u00b6\n\n\nMnemonics: Integer for choice of STorage of WaveFunction at each k point\n\nVariable type: integer\n\nDimensions: (\nnkpt\n)\n\nDefault value: *0\n\nComment: For RF calculations, the Default is not used : \nistwfk\n is forced to be 1 deep inside the code, for all k points. For spin-orbit calculations (\nnspinor\n=2), \nistwfk\n is also forced to be 1, for all k points.  \n\n\nControl the way the wavefunction for each k-point is stored inside ABINIT, in\nreciprocal space.\n\nFor the GS calculations, in the \u201ccg\u201d array containing the wavefunction\ncoefficients, there is for each k-point and each band, a segment\ncg(1:2,1:npw). The \u2018full\u2019 number of plane wave is determined by \necut\n.\nHowever, if the k-point coordinates are build only from zeroes and halves (see\nlist below), the use of time-reversal symmetry (that connects coefficients)\nhas been implemented, in order to use real-to-complex FFTs (see \nfftalg\n),\nand to treat explicitly only half of the number of plane waves (this being\nused as \u2018npw\u2019).\n\nFor the RF calculations, there is not only the \u201ccg\u201d array, but also the \u201ccgq\u201d\nand \u201ccg1\u201d arrays. For the time-reversal symmetry to decrease the number of\nplane waves of these arrays, the q vector MUST be (0 0 0). Then, for each k\npoint, the same rule as for the RF can be applied.\n\nWARNING (991018) : for the time being, the time-reversal symmetry cannot be\nused in the RF calculations.\n\n\n\n\n1=> do NOT take advantage of the time-reversal symmetry \n\n\n2=> use time-reversal symmetry for k=( 0 0 0 ) \n\n\n3=> use time-reversal symmetry for k=(1/2 0 0 ) \n\n\n4=> use time-reversal symmetry for k=( 0 0 1/2) \n\n\n5=> use time-reversal symmetry for k=(1/2 0 1/2) \n\n\n6=> use time-reversal symmetry for k=( 0 1/2 0 ) \n\n\n7=> use time-reversal symmetry for k=(1/2 1/2 0 ) \n\n\n8=> use time-reversal symmetry for k=( 0 1/2 1/2) \n\n\n9=> use time-reversal symmetry for k=(1/2 1/2 1/2) \n\n\n0=> (preprocessed) for each k point, choose automatically the appropriate time-reversal option when it is allowed, and chose \nistwfk\n=1 for all the other k points. \n\n\n\n\nlotf_classic\n\u00b6\n\n\nMnemonics: LOTF CLASSIC model for glue model\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 5  \n\n\nGlue model used in LOTF.\n\nFor the moment it is imposed to be 5.\n\n\nlotf_nitex\n\u00b6\n\n\nMnemonics: LOTF Number of ITerations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 10  \n\n\nSet the number of Molecular Dynamics iterations which are computed by LOTF.\n\n\nlotf_nneigx\n\u00b6\n\n\nMnemonics: LOTF max Number of NEIGhbours\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 5  \n\n\nSet the max number of Neighbours used in the LOTF method.\n\nFor the moment it is imposed to be 40.\n\n\nlotf_version\n\u00b6\n\n\nMnemonics: LOTF VERSION of MD algorithm\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2  \n\n\nSet the MD algorithm in the LOTF method.\n\nFor the moment it is imposed to be 2.\n\n\nmacro_uj\n\u00b6\n\n\nMnemonics: MACRO variable that activates the determination of the U and J parameter (for the PAW+U calculations)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nSets proper input values for the determination of U and J i.e. for \npawujat\n\n(first atom treated with PAW+U), \nirdwfk\n (=1), \ntolvrs\n (=10^(-8)),\n\nnstep\n (=255), \ndiemix\n (=0.45), \natvshift\n (\npawujat\n) \npawujv\n).\nDo not overwrite these variables manually unless you know what you do.\n\n\n\n\nmacro_uj\n=1 (and \nnsppol\n=2) Standard procedure to determine U on atom pawujat through a shift of the potential on both spin channels. \n\n\nmacro_uj\n=1 (and \nnsppol\n=1) Non standard procedure to determine U from potential shift on atom pawujat (experimental). \n\n\nmacro_uj\n=2 (and \nnsppol\n=2) Non standard procedure to determine U from potential shift on atom pawujat through a shift on spin channel 1 on this atom and the response on this channel (experimental). \n\n\nmacro_uj\n=3 (and \nnsppol\n=2) Standard procedure to determine J from potential shift on spin channel 1 on atom pawujat and response on spin channel 2 (experimental). \n\n\n\n\nDetermination of U and J can be done only if the symmetry of the atomic\narrangement is reduced and the atom pawujat is not connected to any other atom\nby symmetry relations (either input reduced symmetries manually, define\nconcerned atom as a separate atomic species or shift concerned atom from ideal\nposition).\n\n\nmaxnsym\n\u00b6\n\n\nMnemonics: MAXimum Number of SYMetries\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 384  \n\n\nGives the maximum number of spatial symetries allowed in the memory.\n\nThe default value is sufficient for most applications; it has to be increase\nin the case of the use of a supercell (unit cell identically repeated).\n\n\nmem_test\n\u00b6\n\n\nMnemonics: MEMory TEST\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis variable controls the memory test done in the memana routine. Possible\nvalues:\n\n\n\n\n0 no test on the available memory is performed \n\n\n1 the routine tries to allocate the estimated memory, for testing purposes, and if a failure occurs, the routine stops. \n\n\n2 like 1, but before stopping, the routine will provide an estimation of the available memory. \n\n\n\n\nmqgrid\n\u00b6\n\n\nMnemonics: Maximum number of Q-space GRID points for pseudopotentials\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 3001  \n\n\nGovern the size of the one-dimensional information related to\npseudopotentials, in reciprocal space : potentials, or projector functions.\n\n\nnbdblock\n\u00b6\n\n\nMnemonics: Number of BanDs in a BLOCK\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nIn case of non-standard, blocked algorithms for the optimization of the\nwavefunctions (that is, if \nwfoptalg\n=4):\n\n\n\n\nif \nwfoptalg\n=4, \nnbdblock\n defines the number of blocks (the number of bands in the block is then \nnband\n/\nnbdblock\n ). \n\n\n\n\nnc_xccc_gspace\n\u00b6\n\n\nMnemonics: Norm-Conserving pseudopotentials - use XC Core-Correction in G-SPACE\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0 if \nusepaw\n==0,\n1 if \nusepaw\n==1,\n0 otherwise.\n\n\nComment: 0 when \nusepaw\n=0, 1 when \nusepaw\n=1  \n\n\nHistorically, Abinit treats the model core charge used for the non-linear core\ncorrection in real space. Alternatively, it is possible to instruct the code\nto compute the core charge in G-space following the same approach used in the\nPAW code. The G-space formalism is more accurate than the interpolation in\nreal space, especially when derivatives of the model core charge are needed,\ne.g. DFPT. Preliminary tests showed that the violation of the acoustic sum\nrule is reduced when \nnc_xccc_gspace\n==1 , especially for LDA. It is worth\nstressing, however, that \nnc_xccc_gspace\n==1 should be used only in\nconjunction with NC pseudos whose model core charge that decays quickly in\nG-space. Several NC pseudos available in the Abinit table are not optimized\nfor the G-space formalism and users are strongly invited to perform\nconvergence studies with respect to ecut before using this option.\n\n\nnctime\n\u00b6\n\n\nMnemonics: NetCdf TIME between output of molecular dynamics informations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nWhen \nnctime\n is non-zero, the molecular dynamics information is output in\nNetCDF format, every \nnctime\n time step. Here is the content of an example\nfile :\n\n\nnetcdf\n \nmd32\n.\noutH_moldyn1\n \n{\n\n\ndimensions\n:\n\n   \ntime\n \n=\n \nUNLIMITED\n \n;\n \n//\n \n(11\n \ncurrently)\n\n   \nDimTensor\n \n=\n \n6\n \n;\n\n   \nDimCoord\n \n=\n \n3\n \n;\n\n   \nNbAtoms\n \n=\n \n32\n \n;\n\n   \nDimVector\n \n=\n \n3\n \n;\n\n   \nDimScalar\n \n=\n \n1\n \n;\n\n\nvariables\n:\n\n   \ndouble\n \nE_pot\n(\ntime\n)\n \n;\n\n      \nE_pot\n:\nunits\n \n=\n \n\"hartree\"\n \n;\n\n   \ndouble\n \nE_kin(time)\n \n;\n\n      \nE_kin\n:\nunits\n \n=\n \n\"hartree\"\n \n;\n\n   \ndouble\n \nStress(time,\n \nDimTensor)\n \n;\n\n      \nStress\n:\nunits\n \n=\n \n\"hartree/Bohr^3\"\n \n;\n\n   \ndouble\n \nPosition(time,\n \nDimCoord,\n \nNbAtoms)\n \n;\n\n      \nPosition\n:\nunits\n \n=\n \n\"Bohr\"\n \n;\n\n   \ndouble\n \nCelerity(time,\n \nDimCoord,\n \nNbAtoms)\n \n;\n\n      \nCelerity\n:\nunits\n \n=\n \n\"Bohr/(atomic time unit)\"\n \n;\n\n   \ndouble\n \nPrimitiveVector1(DimVector)\n \n;\n\n   \ndouble\n \nPrimitiveVector2(DimVector)\n \n;\n\n   \ndouble\n \nPrimitiveVector3(DimVector)\n \n;\n\n   \ndouble\n \nCell_Volume(DimScalar)\n \n;\n\n      \nCell_Volume\n:\nunits\n \n=\n \n\"Bohr^3\"\n \n;\n\n\n}\n\n\n\n\n\n\nnloc_alg\n\u00b6\n\n\nMnemonics: Non LOCal ALGorithm\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 4  \n\n\nAllows to choose the algorithm for non-local operator application. On super-\nscalar architectures, the default \nnloc_alg\n=4 is the best.\n\nMore detailed explanations:  \n\n\n- \nnloc_alg\n=2 : Should be efficient on vector machines. It is indeed the\nfastest algorithm for the NEC, but actual tests on Fujitsu machine did not\ngave better performances than the other options.\n\n- \nnloc_alg\n=3 : same as \nnloc_alg\n==2, but the loop order is inverted.\n\n- \nnloc_alg\n=4 : same as \nnloc_alg\n==3, but maximal use of registers has\nbeen coded. This should be especially efficient on scalar and super-scalar\nmachines. This has been confirmed by tests.  \n\n\nNote: internally, \nnloc_alg\n is stored in _ nloalg(1) _ . See also\n\nnloc_mem\n for the tuning of the memory used in the non-local operator\napplication.\n\n\nnloc_mem\n\u00b6\n\n\nMnemonics: Non LOCal MEMOry\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2 if \nusepaw\n==1,\n1 otherwise.\n\n\nControls the memory use for the application of the non-local operator.\n\nMore detailed explanations:  \n\n\n- \nnloc_mem\n==1 : (k+G) vectors are not precomputed, in order to save\nmemory space.\n\n- \nnloc_mem\n==2 : (k+G) vectors are precomputed, once per k-point.\n\n- \nnloc_mem\n==-1 or -2 : Negative values of \nnloc_mem\n correspond\npositive ones, where the phase precomputation has been suppressed, in order to\nsave memory space, as an array _ double precision :: ph3d(2,npw,\nnatom\n) _\nis saved (typically half the space needed for the wavefunctions at 1 k point -\nthis corresponds to the silicon case). However, the computation of phases\ninside nonlop is somehow time-consuming.  \n\n\nNote: internally, sign(\nnloc_mem\n) is stored in _ nloalg(2) _ and\nabs(\nnloc_mem\n)-1 is stored in _ nloalg(3) _ . See also \nnloc_alg\n for the\nalgorithm for the non-local operator application.\n\n\nnnsclo\n\u00b6\n\n\nMnemonics: Number of Non-Self Consistent LOops\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the maximum number of non-self-consistent loops of \nnline\n line\nminimisations, in the SCF case (when \niscf\n >0). In the case \niscf\n\n<=0 , the number of non-self-consistent loops is determined by \nnstep\n.\n\nThe Default value of 0 \u2013 for standard plane-wave calculations \u2013 corresponds\nto make the two first fixed potential determinations of wavefunctions have 2\nnon-self consistent loops, and the next ones to have only 1 non-self\nconsistent loop.\n\nThe Default value of 0 \u2013 for wavelets calculations (\nusewvl\n=1) \u2013\ncorresponds to make 2 steps with 3 non-self consistent loops , 2 steps with 2\nnon-self consistent loops, then the next ones with 1 non-self consistent loop.\n\n\nnnsclohf\n\u00b6\n\n\nMnemonics: Number of Non-Self Consistent LOops for (Hartree)-Fock exact exchange\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \nusefock\n==1,\n0 otherwise.\n\n\nGives the maximum number of loops with non-self-consistent occupied states\nused to calculate Fock exact exchange, in the SCF case.\n\nThe Default value is 0 when \nusefock\n = 0. Default value is 1 when\n\nusefock\n = 1 and correspond to update occupied wavefunctions at each self-\nconsistent loop.\n\n\nnormpawu\n\u00b6\n\n\nMnemonics: NORMalize atomic PAW+U projector\n\nVariable type: integer\n\nDimensions: (\nntypat\n)\n\nDefault value: 0  \n\n\nDefines whether the atomic wave function (used as projectors in PAW+U) should\nbe renormalized to 1 within PAW sphere.\n\n\n\n\nnormpawu\n=0 : leave projector \n\n\nnormpawu\n=1 : renormalize \n\n\n\n\nnpulayit\n\u00b6\n\n\nMnemonics: Number of PULAY ITerations for SC mixing\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 7\n\nOnly relevant if \niscf\n in [7,17]  \n\n\nGives the number of previous iterations involved in Pulay mixing (mixing\nduring electronic SC iterations).\n\n\nnscforder\n\u00b6\n\n\nMnemonics: Nth - SCaling Function ORDER\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 16  \n\n\nThis variable controls the order of used scaling functions when the Hartree\npotential is computed using the Poisson solver (see \nicoulomb\n imput\nvariable). This variable is of seldom use since the default value is large\nenough. Nonetheless, possible values are 8, 14, 16, 20, 24, 30, 40, 50, 60,\n100. Values greater than 20 are included in ABINIT for test purposes only.\n\n\noptforces\n\u00b6\n\n\nMnemonics: OPTions for the calculation of FORCES\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \ntoldff\n or \ntolrff\n != 0,\n2 otherwise.\n\n\nAllows to choose options for the calculation of forces.\n\n\n\n\noptforces\n=0 : the forces are set to zero, and many steps of the computation of forces are skipped \n\n\noptforces\n=1 : calculation of forces at each SCF iteration, allowing to use forces as criterion to stop the SCF cycles \n\n\noptforces\n=2 : calculation of forces at the end of the SCF iterations (like the stresses) \n\n\n\n\noptnlxccc\n\u00b6\n\n\nMnemonics: OPTion for the calculation of Non-Linear eXchange-Correlation Core Correction\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nAllows to choose options for the calculation of non-linear XC correction. At\npresent, only relevant for the FHI type of pseudopotentials, with pspcod=6 .\n\n\n\n\noptnlxccc\n=1 : uses the old psp6cc.f routine, with inconsistent treatment of real-space derivatives of the core function (computed in this routine, while splined in the other parts of the code) \n\n\noptnlxccc\n=2 : consistent calculation derivatives, in the psp6cc_dhr.f routine from DHamann. \n\n\n\n\nortalg\n\u00b6\n\n\nMnemonics: ORThogonalisation ALGorithm\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: -2 if \nwfoptalg\n >= 10 ,\n2 otherwise.\n\n\nAllows to choose the algorithm for orthogonalisation.\n\nPositive or zero values make two projections per line minimisation, one before\nthe preconditioning, one after. This is the clean application of the band-by-\nband CG gradient for finding eigenfunctions.\n\nNegative values make only one projection per line minimisation.\n\nThe orthogonalisation step is twice faster, but the convergence is less good.\nThis actually calls to a better understanding of this effect.\n\n\nortalg\n=0, 1 or -1 is the conventional coding.\n\n\nortalg\n=2 or -2 try to make better use of existing registers on the\nparticular machine one is running.\n\nMore demanding use of registers is provided by \nortalg\n=3 or -3, and so on.\n\nThe maximal value is presently 4 and -4.\n\nTests have shown that \nortalg\n=2 or -2 is suitable for use on the available\nplatforms.\n\n\npapiopt\n\u00b6\n\n\nMnemonics: PAPI OPTion\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\n PAPI \n aims to provide the tool\ndesigner and application engineer with a consistent interface and methodology\nfor use of the performance counter hardware found in most major\nmicroprocessors. PAPI enables software engineers to see, in near real time,\nthe relation between software performance and processor events.\n\nThis option can be used only when ABINIT has been compiled with the \n--enable-papi\n configure option.\n\nIf \npapiopt\n=1, then PAPI counters are used instead of the usual time()\nroutine. All the timing output of ABINIT is then done with PAPI values. The\nmeasurements are more accurate and give also access to the flops of the\ncalculation.\n\n\npawprt_b\n\u00b6\n\n\nMnemonics: PAW PRinT band\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nForces the output of the all-electron wavefunction for only a single band. To\nbe used in conjuction with: \n\n\npawprtwf\n=1 \n and \npawprt_k\n. The indexing of the bands start with one\nfor the lowest occupied band and goes up from there.\n\n\npawprt_k\n\u00b6\n\n\nMnemonics: PAW PRinT K-point\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nForces the output of the all-electron wavefunction for only a single k-point.\nTo be used in conjuction with: \n\n\npawprtwf\n=1 \n and \npawprt_b\n. The indexing follows the order in ouptput\nof the internal variable \n kpt \n in the beginning of the run.\n\n\npawujat\n\u00b6\n\n\nMnemonics: PAW+macro_UJ, ATom number\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nComment:  i.e. the first atom treated with PAW+U.  \n\n\nDetermines the atom for which U (or J) should be determined. See also\n\nmacro_uj\n.\n\n\npawujrad\n\u00b6\n\n\nMnemonics: PAW+macro_UJ, sphere RADius\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 20 a.u.  \n\n\nThe sphere radius serves to extrapolate the U value calculated at r_paw to a\nlarger sphere radius. See also \nmacro_uj\n. As most projector functions are\nlocalized within r_paw to \u224880%, 20 a.u. contains \u2248100% of the wavefunction and\ncorresponds to r_paw -> \u221e.\n\n\npawujv\n\u00b6\n\n\nMnemonics: PAW+macro_UJ, potential shift (V)\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.1 eV  \n\n\nAmplitude of the potential shift for the determination of U (or J). See also\n\nmacro_uj\n.\n\n\nplowan_bandf\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions BAND Final\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the upper band to include in the calculation of Wannier functions\n\n\nplowan_bandi\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions BAND Initial\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the lower band to include in the calculation of Wannier functions\n\n\nplowan_compute\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions COMPUTATION\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nActivate computation of Projected Local Orbital Wannier functions (PLO\nWannier) and corresponding band structure. Variables \nplowan_bandi\n,\n\nplowan_bandf\n, \nplowan_natom\n, \nplowan_nbl\n, \nplowan_iatom\n,\n\nplowan_lcalc\n, \nplowan_projcalc\n are mandatory to precise the nature of\nthe projections.\n\n\n\n\n0=> Default value: do not activate calculation of PLO Wannier. \n\n\n1=> Compute PLO Wannier and band structure \n\n\n2=> Compute PLO Wannier and band structure. In this case, the coupling in k-space between blocks of Wannier functions belonging to different angular momenta or atoms is removed. \n\n\n\n\nOther related variables are \nplowan_realspace\n, \nplowan_nt\n,\n\nplowan_it\n. The implementation is not symetrized over k-point and not\nparallelized. (The calculation of projections is detailed in \n Phys. Rev. B\n77, 205112, (2008)\n\n )\n\n\nplowan_iatom\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions, Index of ATOM\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the indices of the \nplowan_natom\n atoms on which the projections will\nbe done.\n\n\nplowan_it\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions,  Index of Translation.\n\nVariable type: integer\n\nDimensions: (3,\nplowan_nt\n)\n\nDefault value: 0  \n\n\nRequires \nplowan_realspace\n to be greater than 0 and \nplowan_nt\n to be\ngreater than 0. Precise a given set of selected real space translation by\nusing the real space vectors basis. These atoms are used to define Wannier\nfunctions in real space. These real space Wannier functions are used as a\nbasis to compute the Hamiltonian.\n\n\nplowan_lcalc\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions,  L values to use for CALCulation\n\nVariable type: integer\n\nDimensions: (sum(\nplowan_nbl\n))\n\nDefault value: -1  \n\n\nGives the \nplowan_nbl\n values of angular momenta for each atom, in the order\nof the atoms as given in \nplowan_iatom\n.\n\n\nplowan_natom\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions, Number of ATOMs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of atoms on which the projection will be done\n\n\nplowan_nbl\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions,  NumBer of L values\n\nVariable type: integer\n\nDimensions: (\nplowan_natom\n)\n\nDefault value: 0  \n\n\nGives the total number of angular momenta (over all atoms) to compute the\nprojections.\n\n\nplowan_nt\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions,  Number of Translation on which the real space values of\nenergy are computed\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nRequires \nplowan_realspace\n to be greater than 0. Gives a number of selected\natoms. These atoms are used to define Wannier functions in real space. These\nreal space Wannier functions are used as a basis to compute the Hamiltonian.\n\n\nplowan_projcalc\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions,  PROJectors values to use for CALCulation\n\nVariable type: integer\n\nDimensions: (sum(\nplowan_nbl\n))\n\nDefault value: -1  \n\n\nGives the \nplowan_nbl\n values of projectors for each atom, in the order of\nthe atoms as given in \nplowan_iatom\n. The index i for the projectors refers\nto the ith number on line orbitals of the PAW atomic data file.\n\n\nplowan_realspace\n\u00b6\n\n\nMnemonics: Projected Local Orbital WANnier functions,  activate REAL SPACE calculation.\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nCan take the following values:\n\n\n\n\n0=> Default value: do not activate calculation of real space Wannier functions. \n\n\n1=> Compute PLO Wannier in real space for analysis. These data can also be used in a following dataset to perform a Wannier interpolation. \n\n\n2=> Do simple Wannier Interpolation for a given k points starting from real space Wannier function Hamiltonian computed in a preceding dataset. \n\n\n\n\nprepscphon\n\u00b6\n\n\nMnemonics: PREPare Self-Consistent PHONon calculation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nPrint PCINFO, PHFREQ, and PHVEC files, for use with self-consistent phonon\nruns, after a perturbation calculation. Only prints out files for the present\nq-point, and there is presently no tool to symmetrize or merge these files, so\nuse anaddb instead (with prtscphon input variable). The abinit input variable\nis destined to someday bypass the use of anaddb for scphon calculations.\n\n\nprtbltztrp\n\u00b6\n\n\nMnemonics: PRinT output for BoLTZTRaP code\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nPrint out geometry (_BLZTRP_GEOM) and eigenenergy (_BLZTRP_EIGEN) files for\nthe \n BoltzTraP\ncode\n\nby Georg Madsen.\n\n\nprtcif\n\u00b6\n\n\nMnemonics: PRinT Crystallographic Information File\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1, a CIF file is output with the crystallographic data for the\npresent run (cell size shape and atomic positions).\n\n\nprtdipole\n\u00b6\n\n\nMnemonics: PRinT DIPOLE\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nPrint out dipole of unit cell, calculated in real space for the primitive cell\nonly. Under development.\n\n\nprtnest\n\u00b6\n\n\nMnemonics: PRinT NESTing function\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1, the nesting function for the k-point grid is printed. For the\nmoment the path in q space for the nesting function is fixed, but will become\nan input as well.\n\n\nprtposcar\n\u00b6\n\n\nMnemonics: PRinT POSCAR file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nPrint out VASP-style POSCAR and FORCES files, for use with PHON or frophon\ncodes for frozen phonon calculations. See the associated script in\n~abinit/extras/post_processing/phondisp2abi.py for further details on\ninterfacing with PHON, PHONOPY, etc\u2026\n\n\nrecefermi\n\u00b6\n\n\nMnemonics: RECursion - initial guess  of the FERMI Energy\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed in Recursion method (\ntfkinfunc\n=2). In the first SCF calculation it\nfixes the initial guess for the Fermi energy.\n\n\nrecgratio\n\u00b6\n\n\nMnemonics: RECursion - Grid RATIO\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nUsed in Recursion method (\ntfkinfunc\n=2). It represents the ratio of the two\ngrid step: \nrecgratio\n=fine_step/coarse_step and it is bigger or equal than\n1. It introduces a double-grid system which permits to compute the electronic\ndensity on a coarse grid, using a fine grid (defined by \nngfft\n) in the\ndiscretisation of the green kernel (see \nrecptrott\n). Successively the\ndensity and the recursion coefficients are interpolated on the fine grid by\nFFT interpolation. Note that ngfft/recgratio=number of points of the coarse\ngrid has to be compatible with the parallelization parameters.\n\n\nrecnpath\n\u00b6\n\n\nMnemonics: RECursion - Number of point for PATH integral calculations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 500  \n\n\nUsed in Recursion method (\ntfkinfunc\n=2). Determine the number of\ndiscretisation points to compute some path integral in the recursion method ;\nthose path integrals are used to compute the entropy and the eigenvalues\nenergy. during the latest SFC cycles.\n\n\nrecnrec\n\u00b6\n\n\nMnemonics: RECursion - Number of RECursions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 10  \n\n\nUsed in Recursion method (\ntfkinfunc\n=2). Determine the maximum order of\nrecursion, that is the dimension of the krylov space we use to compute\ndensity. If the precision set by \nrectolden\n is reached before that order,\nthe recursion method automatically stops.\n\n\nrecptrott\n\u00b6\n\n\nMnemonics: RECursion - TROTTer parameter\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed in Recursion method (\ntfkinfunc\n=2). Determine the trotter parameter\nused to compute the exponential of the hamiltonian in the recursion method:\nexp(-beta\n(-Delta + V)) ~ (exp(-beta/(4\nrecptrott) V) exp(-beta/(4\nrecptrott)\nDelta) exp(-beta/(4\nrecptrott) V))^(2\nrecptrott). If set to 0, we use\nrecptrott = 1/2 in the above formula. Increasing \nrecptrott\n improve the\naccuracy of the trotter formula, but increase the dicretisation error: it may\nbe necessary to increase \nngfft\n. The discretisation error is essentially\nthe discretisation error of the green kernel exp((recptrott/beta\n|r|^2)) on\nthe ngfft grid.\n\n\nrecrcut\n\u00b6\n\n\nMnemonics: RECursion - CUTing Radius\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed in Recursion method (\ntfkinfunc\n=2). Used to improve the computational\ntime in the case of the recursion method in a large cell: the density at a\npoint will be computed with taking account only of a sphere of radius\n\nrecrcut\n.\n\n\nrectesteg\n\u00b6\n\n\nMnemonics: RECursion - TEST on Electron Gas\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed in Recursion method (\ntfkinfunc\n=2). It is used to test an electron gas\nby putting the ion potential equal to zero.\n\n\nrectolden\n\u00b6\n\n\nMnemonics: RECursion - TOLerance on the difference of electronic DENsity\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nComment: Default value to be changed.  \n\n\nUsed in Recursion method (\ntfkinfunc\n=2). Sets a tolerance for differences\nof electronic density that, reached TWICE successively, will cause one SCF\ncycle to stop. That electronic density difference is computed in the infinity\nnorm (that is, it is computed point-by-point, and then the maximum difference\nis computed).\n\n\nsymmorphi\n\u00b6\n\n\nMnemonics: SYMMORPHIc symmetry operation selection\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nWith \nsymmorphi\n=1, symmetry operations with a non-symmorphic vector are\nallowed. With \nsymmorphi\n=0, they are not allowed. In the latter case, if\nthe symmetry operations are specified in the input file, the code will stop\nand print an error message if a non-symmorphic vector is encountered. By\ncontrast, if the symmetry operations are to be determined automatically (if\n\nnsym\n=0), then the set of symmetries will not include the non-symmorphic\noperations.\n\n\nNote : this feature exist because in a previous status of the \nGW\n\ncalculations, non-symmorphic symmetry operations could not be exploited. Thus,\nthe k points were restricted to the IBZ. In order to prepare \nGW\n\ncalculations, and to perform \nGW\n calculations, \nsymmorphi\n=0 was to be\nused, together with \nnsym\n=0.\n\n\ntfkinfunc\n\u00b6\n\n\nMnemonics: Thomas-Fermi KINetic energy FUNCtional\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\n\n\n\n\ntfkinfunc\n=1 : Thomas-Fermi kinetic functional (explicit functional of the density) is used instead of Kohn-Sham kinetic energy functional (implicit functional of the density through Kohn-Sham wavefunctions).\n\nSee Perrot F., Phys. Rev. A20,586-594 (1979)).\n\n\n\n\n\n\ntfkinfunc\n=11 : Thomas-Fermi-Weizsacker kinetic functional with Gradient Corrections is used.\n\nThe convergence of a calculation with this functional needs to be initialized\nfrom a calculation without Gradient Correction. This is automatically done\nwith \ntfkinfunc\n=11. For the initialization steps, the \ntfw_toldfe\n\ncriterion is used. When it is reached, then the Gradient Correction is added\nand the SCF cycle continues.\n\nNote: to obtain the convergence of a Molecular Dynamics simulation with TFW,\nit is necessary to find the best set of preconditionning parameters\n(\ndiemix\n, \ndiemac\n, \ndielng\n) and the best value of \nnpulayit\n (if\nthe default Pulay mixing is used).\n\n\n\n\n\n\ntfkinfunc\n=12 : same as \ntfkinfunc\n=11, but without the initialization steps. Gradient correction is directly added. \n\n\n\n\ntfkinfunc\n=2 : the Recursion Method is used in order to compute electronic density, entropy, Fermi energy and eigenvalues energy. This method computes the density without computing any orbital, is efficient at high temperature, with a efficient parallelization (almost perfect scalability). When that option is in use, the \necut\n input variable is no longer a convergence parameter ; \nngfft\n becomes the main convergence parameter: you should adapt ecut for the ngfft grid you need (it is not yet automatically computed). Other convergence parameter are for the energetic values: \nrecnrec\n, \nrecptrott\n, \nrecnpath\n.\n\nSince the convergence of the self-consistent cycle is determined directly by\nthe convergence of the density: \ntoldfe\n, \ntoldff\n, \ntolrff\n,\n\ntolvrs\n, \ntolwfr\n are not used, and are replaced by \nrectolden\n; the\nenergetic values, except for the fermi energy, are only computed during the\nlatest SFC cycle : the output file will show a jump of the total energy at the\nend, but it is not because of a bad convergence behavior. Computational speed\ncan be improved by the use of \nrecrcut\n and \nrecgratio\n. The recursion\nmethod has not be tested in the case of non cubic cell or with the use of\nsymmetries.\n\nIn the recursion method the following variables are set to: \nuseylm\n=1,\n\nuserec\n=1.\n\n\n\n\ntfw_toldfe\n\u00b6\n\n\nMnemonics: Thomas-Fermi-Weizsacker: TOLerance on the DiFference of total Energy, for initialization steps\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0E-6 or \ntoldfe\n is present\n\nOnly relevant if \ntfkinfunc\n=11  \n\n\nThis input variable has the same definition as \ntoldfe\n and is only relevant\nwhen \ntfkinfunc\n=11.\n\nIt sets a tolerance for absolute differences of total energy that, reached\nTWICE successively, will cause the initialization steps (without gradient\ncorrection) to stop and the gradient correction to be added.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since it has the\n\u2018ENERGY\u2019 characteristics.\n\n\ntolrde\n\u00b6\n\n\nMnemonics: TOLerance on the Relative Difference of Eigenenergies\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.005  \n\n\nSets a tolerance for the ratio of differences of eigenenergies in the line\nminimisation conjugate-gradient algorithm. It compares the decrease of the\neigenenergy due to the last line minimisation, with the one observed for the\nfirst line minimisation. When the ratio is lower than \ntolrde\n, the next\nline minimisations are skipped.\n\nThe number of line minimisations is limited by \nnline\n anyhow.\n\nThis stopping criterion is present for both GS and RF calculations. In RF\ncalculations, \ntolrde\n is actually doubled before comparing with the above-\nmentioned ratio, for historical reasons.\n\n\nuse_gemm_nonlop\n\u00b6\n\n\nMnemonics: USE the GEMM routine for the application of the NON-Local OPerator\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nComment: because it is not usually worth using it unless bandpp is large and it requires additional memory  \n\n\nThis keyword tells abinit to use a BLAS routine to speed up the computation of\nthe non-local operator. This requires the precomputation of a large matrix,\nand has a significant memory overhead. In exchange, it provides improved\nperformance when used on several bands at once (Chebyshev or LOBPCG algorithm\nwith \nbandpp\n\n\nThe memory overhead is proportional to the number of atoms, the number of\nplane waves, and the number of projectors per atom. It can be mitigated by\ndistributing the array with \nnpfft\n\n\nThe performance depends crucially on having a good BLAS installed. Provided\nthe BLAS supports OpenMP, this option also yields very good scaling for the\nnonlocal operator.\n\n\nuse_nonscf_gkk\n\u00b6\n\n\nMnemonics: USE NON-SCF calculation of GKK matrix elements (electron phonon)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nComment: Default is 0 for the moment. Do not use non-scf method.  \n\n\nWhen this flag is activated during a phonon calculation with abinit, all of\nthe perturbations are cycled through, but only the symmetry-irreducible ones\nare calculated self-consistently. For the others the perturbed density is\nrotated by the appropriate symop and the gkk matrix elements are calculated\nnon-self-consistently. As they do not depend on the perturbed wave functions,\nthey are correct from the first iteration, and nstep is set to 1 for those\nperturbations. Note that the resulting 1DEN files are simply the\nrotate/symmetric ones and that the resulting 1WF files are garbage (completely\nunconverged) except the matrix elements in the header (equivalent to GKK\nfiles, but please use the latter much smaller files for el-ph calculations).\nThe new default behavior with \nuse_nonscf_gkk\n = 1 should be transparent for\nthe user, with the same output files but a much quicker execution.\n\n\nCaveat: Note that very tight convergence of ground state and phonon\ncalculations is necessary to get good GKK matrix elements! \ntolwfr\n = 1.e-24\nor so is recommended everywhere. There may be problems using use_nonscf_gkk =\n1 with non-symmorphic symmetries - please check (at least) that lifetimes for\nphonons go to 0 for acoustic modes at Gamma.\n\n\nusedmft\n\u00b6\n\n\nMnemonics: USE Dynamical Mean Field Theory\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1, enable the use of DFT+DMFT, see in particular the important\nvariables \ndmft_solv\n, \ndmftbandi\n, \ndmftbandf\n, \ndmft_nwli\n,\n\ndmft_nwlo\n, \ndmft_tollc\n, \ndmft_tolfreq\n, and \ndmft_iter\n.\n\n\nThe current implementation uses Wannier functions obtained from \n projected\nlocal orbitals\n\n as\ncorrelated orbitals (see \ndmftbandi\n and \ndmftbandf\n input variables to\ndefine them).\n\n\nThe Green functions are computed on a mesh of linear Matsubara frequencies.\nHowever, most of the code uses logarithmic Matsubara grid to lower the\ncomputational cost. Both \ndmft_nwli\n and \ndmft_nwlo\n are thus convergence\nparameters.\n\n\nDMFT is currently available for collinear (\nnspinor\n=1) polarized or\nunpolarized calculations (\nnspden\n=\nnsppol\n=2 or \nnspden\n=\nnsppol\n=1)\nand for non collinear calculations (\nnspinor\n=2,\nnspden\n=4,\nnsppol\n=1).\nHowever it is not yet available for collinear antiferromagnetic calculations\n(\nnspden\n=2,\nnsppol\n=1) and non collinear non magnetic calculations\n(\nnspden\n=1, \nnsppol\n=1,\nnspinor\n=2). CTQMC calculations\n(\ndmft_solv\n=5) are not yet possible if \nnspinor\n=2.\n\n\nOnly static calculations without relaxation or dynamics are possible (forces\nand stress are not computed in the scheme: so the computed values should NOT\nbe trusted).\n\n\nWhen correlated density matrices are diagonal, all values of \nupawu\n and\n\njpawu\n are possible. If the correlated density matrices are non diagonal,\nonly \njpawu\n = 0 is implemented.\n\n\nRelevant direct output quantities from converged DMFT calculations are total\nenergy and occupation of correlated orbitals. For Hubbard I calculation\n(\ndmft_solv\n=2), total and partial spectral functions can be obtained with\nprtdos=1 and can be found in files OUTSpFunc* (where OUT is the root for\noutput files). For CTQMC calculations (\ndmft_solv\n=5), imaginary time\nimpurity Green function are output of the calculations and can be used to\nproduce spectral function using an external Maximum Entropy Code.\n\n\nA typical DFT+DMFT calculation involves two runs. First, a DFT calculation is\nfully converged (even unoccupied wavefunctions have to be converged). Then,\nthe DFT+DMFT calculation is started using DFT wavefunctions or density files.\nAs DFT+DMFT calculations (with CTQMC) are computationnally expensive, it is\nconvenient to use prtden=-1, to write DEN file at each DFT iteration, in order\nto be able to restart the calculation easily.\n\n\nFor details of the implementation see, \n B. Amadon, F. Lechermann, A. Georges,\nF. Jollet, T. O. Wehling, and A. I. Lichtenstein, Phys. Rev. B 77(20), (2008)\n\n , for\nWannier functions and B. Amadon, J. Phys.: Condens. Matter 24 075604 (2012)\n(doi:10.1088/0953-8984/24/7/075604), for self-consistency and Hubbard I\nimplementation. If \nusedmft\n=1 and \nnbandkss\n/=0, then, the DFT+DMFT\ncalculation is not done and only projections are computed at the end of the\ncalculation. They can be used by an external code or used to compute the\nscreened interaction (see variable \nucrpa\n).\n\n\nuseria\n\u00b6\n\n\nMnemonics: USER Integer variable A\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThese are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards).\n\nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .\n\n\nuserib\n\u00b6\n\n\nMnemonics: USER Integer variable B\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThese are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards).\n\nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .\n\n\nuseric\n\u00b6\n\n\nMnemonics: USER Integer variable C\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThese are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards).\n\nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .\n\n\nuserid\n\u00b6\n\n\nMnemonics: USER Integer variable D\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThese are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards).\n\nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .\n\n\nuserie\n\u00b6\n\n\nMnemonics: USER Integer variable E\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThese are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards).\n\nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .\n\n\nuserra\n\u00b6\n\n\nMnemonics: USER Real variable A\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nThese are user-definable with the same purpose as \nuseria\n and cie.\n\n\nuserrb\n\u00b6\n\n\nMnemonics: USER Real variable B\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nThese are user-definable with the same purpose as \nuseria\n and cie.\n\n\nuserrc\n\u00b6\n\n\nMnemonics: USER Real variable C\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nThese are user-definable with the same purpose as \nuseria\n and cie.\n\n\nuserrd\n\u00b6\n\n\nMnemonics: USER Real variable D\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nThese are user-definable with the same purpose as \nuseria\n and cie.\n\n\nuserre\n\u00b6\n\n\nMnemonics: USER Real variable E\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nThese are user-definable with the same purpose as \nuseria\n and cie.\n\n\nuseylm\n\u00b6\n\n\nMnemonics: USE YLM (the spherical harmonics)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \ntfkinfunc\n==1,\n1 if \nusepaw\n==1,\n0 otherwise.\n\n\nWhen this flag is activated, the non-local operator is applied using an\nalgorithm based on spherical harmonics. Non-local projectors are used with\ntheir usual form:  \n\n\nP  lmn  (r)=Y  lm  (r)*p  ln  (r)\n\n\nWhen \nuseylm\n=0, the sum over Y_lm can be reduced to a Legendre polynomial\nform.\n\n\nwfoptalg\n\u00b6\n\n\nMnemonics: WaveFunction OPTimisation ALGorithm\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \nAUTO_FROM_PSP\n\nComment: 0 when \nusepaw\n=0 (norm-conserving pseudopotentials), 10 when \nusepaw\n=1 (PAW) ; 114 if \nparal_kgb\n=1.  \n\n\nAllows one to choose the algorithm for the optimisation of the wavefunctions.\n\nThe different possibilities are :\n\n\n\n\nwfoptalg\n=0 : standard state-by-state conjugate gradient algorithm, with no possibility to parallelize over the states; \n\n\nwfoptalg\n=2 : minimisation of the residual with respect to different shifts, in order to cover the whole set of occupied bands, with possibility to parallelize over blocks of states (or bands). The number of states in a block is defined in \nnbdblock\n. THIS IS STILL IN DEVELOPMENT. \n\n\nwfoptalg\n=3 : minimisation of the residual with respect to a shift. Available only in the non-self-consistent case \niscf\n=-2, in order to find eigenvalues and wavefunctions close to a prescribed value. \n\n\nwfoptalg\n=4 : (see also \nwfoptalg\n=14), a parallel code based on the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) method of Knyazev. \n Reference : A.V. Knyazev, \u201cToward the Optimal Preconditioned Eigensolver : Locally Optimal Block Preconditioned Conjugate Gradient Method\u201d. SIAM Journal on Scientific Computing 23, pp517-541 (2001) \n . The implementation rests on the \n matlab program by Knyazev \n . \n Reference A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov, Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in hypre and PETSc (2007). SIAM Journal on Scientific Computing (SISC). 25(5): 2224-2239 \n . For more information see \n F. Bottin, S. Leroux, A. Knyazev, G. Zerah, Large scale ab initio calculations based on three levels of parallelization. (2008). Computational Material Science, 42(2), 329-336. \n\n\nwfoptalg\n=10 : (for PAW) standard state-by-state conjugate gradient algorithm, with no possibility to parallelize over the states, but modified scheme described in Kresse, Furthmuller, PRB 54, 11169 (1996) (modified kinetic energy, modified preconditionning, minimal orthogonalization, \u2026) ; \n\n\nwfoptalg\n=14 : the recommended for parallel code, the same as \nwfoptalg\n=4 except that the preconditioning of the block vectors does not depend on the kinetic energy of each band, and the orthogonalization after the LOBPCG algorithm is no longer performed. The first modification increases the convergence and the second one the efficiency. \n\n\nwfoptalg\n=114 : A new version of \nwfoptalg\n=14 which is more efficient for few blocks and can take advantage of OpenMP if abinit is compiled with a multithreaded linear algebra library. With more than 1 thread \nnpfft\n shoud NOT be used for the time being. \n\n\nwfoptalg\n=1 : new algorithm based on Chebyshev filtering, designed for very large number of processors, in the regime where LOBPCG does not scale anymore. It is not able to use preconditionning and therefore might converge slower than other algorithms. By design, it will \n not \n converge the last bands: it is recommended to use slightly more bands than necessary. For usage with \ntolwfr\n, it is imperative to use \nnbdbuf\n. For more performance, try \nuse_gemm_nonlop\n. For more information, see the \n performance guide \n and the \n paper \n by A. Levitt and M. Torrent. Status: experimental but usable. Questions and bug reports should be sent to antoine (dot) levitt (at) gmail.com. \n\n\n\n\nxc_denpos\n\u00b6\n\n\nMnemonics: eXchange-Correlation - DENsity POSitivity value\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1e-14  \n\n\nFor the evaluation of the exchange-correlation functionals, the density cannot\nbe negative, or even too small (e.g. the LDA exchange kernel behaves like the\ndensity at power -(2/3), and the density is used at the denominator of\ndifferent factors in GGAs and metaGGAs. \nxc_denpos\n is the smallest value\nthat the density can assume at the time of the evaluation of a XC functional,\nin ABINIT. When then computed density drops below \nxc_denpos\n before\nattacking the evaluation of the XC functional, then it will be (only for that\npurpose) replaced by \nxc_denpos\n. Note that the evaluation of the gradients\nor other quantities that are density-dependent is performed before this\nreplacement.\n\n\nIt has been observed that the SCF cycle of the Tran-Blaha mGGA can be quite\nhard to make converge, for systems for which there is some vacuum. In this\ncase, setting \nxc_denpos\n to 1.0e-7 \u2026 1.0e-6 has been seen to allow good\nconvergence. Of course, this will affect the numerical results somehow, and\none should play a bit with this value to avoid incorrect calculations.\n\n\nxc_tb09_c\n\u00b6\n\n\nMnemonics: Value of the c parameter in the eXchange-Correlation TB09 functional\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 99.99  \n\n\nThe modified Becke-Johnson exchange-correlation functional by Tran and Blaha\n(Phys. Rev. Lett. 102, 226401 (2009)) reads :\n\n\nV_x(r) = c * V_x^{BR}(r) + (3\nc - 2) * 1/pi * sqrt(5/12) \n\nsqrt(2*kden(r)/den(r))\n\n\nin which V_x^{BR}(r) is the Becke-Roussel potential.\n\n\nIn this equation the parameter c can be evaluated at each SCF step according\nto the following equation :\n\n\nc = alpha + beta * sqrt(1/V_{cell} * \\int_{V_{cell}} |grad(den(r))|/den(r)\nd3r)\n\n\nThe c parameter is evaluated thanks to the previous equation when xc_tb09_c is\nequal to the \u201cmagic\u201d default value 99.99. The c parameter can also be fixed to\nsome (property-optimized or material-optimized) value by using this variable.",
            "title": "Developers"
        },
        {
            "location": "/input_variables/vardev/#builtintest",
            "text": "Mnemonics: BUIT-IN TEST number \nVariable type: integer \nDimensions: scalar \nDefault value: 0    When  builtintest  is non-zero, the input file is a special one, that runs\nvery quickly, and that is accompanied by a specific analysis by ABINIT, at the\nend of the run, against a hard-coded value of total energy (and possibly\nstresses, forces \u2026). The echo of the analysis is done in the STATUS file. In\nparticular, such built-in tests can be used to check quickly whether ABINIT\nfallbacks have been connected or not (bigdft, etsf_io, libxc, wannier90). At\npresent,  builtintest =1 \u2026 7 are allowed. See more information in\ntests/built-in/README .",
            "title": "builtintest"
        },
        {
            "location": "/input_variables/vardev/#cgtyphf",
            "text": "Mnemonics: Conjugate Gradient TYPe used for Hartree Fock exact exchange \nVariable type: integer \nDimensions: scalar \nDefault value: 2 if  usefock  == 1,\n0 otherwise.  Gives how is calculated Fock exact exchange contribution in the conjugate\ngradient, in the SCF case. \nThe value 2 corresponds to calculate the Fock exact exchange contribution each\ntime in the conjugate gradient. The value 1 corresponds to calculate the Fock\nexact exchange contribution only for the initial guess (not for the gradient\ndirection) in the conjugate gradient",
            "title": "cgtyphf"
        },
        {
            "location": "/input_variables/vardev/#densfor_pred",
            "text": "Mnemonics: DENSity and FORces PREDictor \nVariable type: integer \nDimensions: scalar \nDefault value: 6 if  paral_kgb ==1,\n2 otherwise.  Only relevant if  iscf  >0    Used when  iscf >0, to define: \n- the way a change of density is derived from a change of atomic position, \n- the way forces are corrected when the SCF cycle is not converged.    Supported values :   0 => density not changed (fixed charge), forces not corrected   1 => density not changed, forces corrected with rigid ion hypothesis (atomic charge moved with atom)   2 => density changed and forces corrected with rigid ion hypothesis (atomic charge moves with atom)   3 => density changed and forces corrected with a different implementation of the rigid ion hypothesis   4 => density not changed, forces corrected with the use of Harris functional formula (*)   5 => density changed using D. Alfe 2nd-order algorithm (**), forces not corrected   6 => density changed using D. Alfe 2nd-order algorithm (* ) and forces corrected with the use of Harris functional formula ( )    Similar negative values are also allowed (see the meaning later), for\ndevelopment purposes only. No meaning for RF calculations.    For the time being, \n-  densfor_pred =3 must be used with  ionmov =4 and  iscf =5. \n-  densfor_pred =4, 5 or 6 must be used when band-FFT parallelism is\nselected. \nOtherwise, use  densfor_pred =2     (*)   _ Note concerning the correction of forces (use of  densfor_pred =1, 2, 3, 4 or 6) _ :  \nThe force on the atom located at R is corrected by the addition of the\nfollowing term: \n_ F_residual=Int[dr.V_residual.dRho_atomic/dR] _ , where Rho_atomic is an\natomic (spherical) density. \n- When such an atomic density (Rho_atomic) is found in the pseudopotential or\nPAW file, it is used. If not, a gaussian density (defined by  densty \nparameter) is used. \n- When SCF mixing is done on the density ( iscf >=10), the potential\nresidual (V_residual) is obtained from the density residual with the first\norder formula _ V_residual=dV/drho.Rho_residual _ and uses the exchange-\ncorrelation kernel _ dVxc/drho=Kxc _ whose computation is time-consuming for\nGGA functionals. By default (positive values of  densfor_pred ), the local-\ndensity part of the GGA exchange-correlation kernel is used (even for GGA, for\nwhich it seems to give a reasonable accuracy). Using the full GGA exchange\ncorrelation kernel (so, including derivatives with respect to the gradient of\nthe density) is always possible by giving a negative value to densfor_pred . In case of hybrid functionals, a similar correction term is\nadded, although in the density mixing scheme, the related GGA kernel is used\ninstead of the hybrid functional kernel.     ( )   _ Note concerning the use of  densfor_pred =5 or 6 (density prediction) _ :  \nThe algorithm is described in _ Computer Physics Communications   118 **\n(1999) 31-33 _ . It uses an atomic (spherical) density. When such an atomic\ndensity is found in the pseudopotential or PAW file, it is used. If not, a\ngaussian density (defined by  densty  parameter) is used. \nAlso note that, to be efficient, this algorithm requires a minimum convergence\nof the SCF cycle; Typically, vres2 (or nres2) has to be small enough (10  -4\n\u202610  -5  ).",
            "title": "densfor_pred"
        },
        {
            "location": "/input_variables/vardev/#densty",
            "text": "Mnemonics: initial DENSity for each TYpe of atom \nVariable type: real \nDimensions: ( ntypat ) \nDefault value: 0.0    Gives a rough description of the initial GS density, for each type of atom.\nThis value is only used to create the first exchange and correlation\npotential, and is not used anymore afterwards. For the time being, it\ncorresponds to an average radius (a.u.) of the density, and is used to\ngenerate a gaussian density. If set to 0.0d0, an optimized value is used. \nNo meaning for RF calculations.",
            "title": "densty"
        },
        {
            "location": "/input_variables/vardev/#dmft_read_occnd",
            "text": "Mnemonics: Dynamical Mean Fied Theory: READ OCCupations (Non Diagonal) \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Flag to read/write Occupations as computed in DMFT. This flag is useful to\nrestart a DFT+DMFT calculation with self-consistency over electronic density.\nThe occupations are written each time a DMFT loop is finished. So if the\ncalculation stops because the time limit is reached, this option offers the\npossibility to restart the self-consistent loop over density at the point\nwhere it stopped (assuming a restart with the wave functions, see  getwfk ).   0=> Occupations are written but never read.   1=> Occupations are read from I_DMFTOCCND, where I is the root for input files.   2=> Occupations are read from O_DMFTOCCND, where O is the root for output files.    An alternative and more simple way to restart a DFT+DMFT calculation is to use\nthe density file (obtained with  prtden =1 or  prtden =-1) and the self-\nenergy (see  dmft_rslf ).",
            "title": "dmft_read_occnd"
        },
        {
            "location": "/input_variables/vardev/#dmftctqmc_basis",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo BASIS \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  dmft_solv ==5    Choose the basis to perform CTQMC calculation.   0=> Use the local basis in the spherical harmonics basis. Can be useful if the Hamiltonian has weak off diagonal terms and for this reason, one want to keep the original basis for simplicity and for physical insight.   1=> Default value, diagonalize the local Hamiltonian (but only if it is not diagonal). The best choice in general.   2=> Diagonalise the local correlated occupation matrix. Can lead to non diagonal Hamiltonian that cannot be handled by CTQMC. This option should be thus avoided.",
            "title": "dmftctqmc_basis"
        },
        {
            "location": "/input_variables/vardev/#effmass",
            "text": "Mnemonics: EFFective MASS \nVariable type: real \nDimensions: scalar \nDefault value: 1    This parameter allows to change the electron mass, with respect to its\nexperimental value.",
            "title": "effmass"
        },
        {
            "location": "/input_variables/vardev/#eshift",
            "text": "Mnemonics: Energy SHIFT \nVariable type: real \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  wfoptalg ==3    eshift  gives the shift of the energy used in the shifted Hamiltonian\nsquared. The algorithm will determine eigenvalues and eigenvectors centered on eshift . \nCan be specified in Ha (the default), Ry, eV or Kelvin, since   ecut   has\nthe \u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV)",
            "title": "eshift"
        },
        {
            "location": "/input_variables/vardev/#exchmix",
            "text": "Mnemonics: EXCHange MIXing \nVariable type: real \nDimensions: scalar \nDefault value: 0.25 \nOnly relevant if  useexexch  == 1    exchmix  allows to tune the ratio of exact exchange when  useexexch  is\nused. The default value of 0.25 corresponds to PBE0.",
            "title": "exchmix"
        },
        {
            "location": "/input_variables/vardev/#exchn2n3d",
            "text": "Mnemonics: EXCHange N2 and N3 Dimensions \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If  exchn2n3d  is 1, the internal representation of the FFT arrays in\nreciprocal space will be array(n1,n3,n2), where the second and third\ndimensions have been switched. This is to allow to be coherent with the exchn2n3d =4xx FFT treatment.",
            "title": "exchn2n3d"
        },
        {
            "location": "/input_variables/vardev/#extrapwf",
            "text": "Mnemonics: flag - EXTRAPolation of the Wave-Functions \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  densfor_pred ==5 or  densfor_pred ==6    This flag activates the extrapolation of wave-functions from one Molecular\nDynamics (or Structural Relaxation) step to another. The wave functions are\nextrapolated using 2nd-order algorithm of Arias, Payne and Joannopoulos (PRB\n45, 1538 (1992)). \nNote that, when activated, this extrapolation requires non-negligible\nadditional memory resources as the wave functions are stored for the two\nprevious time steps. Also, it can only be activated if a consistent density\nextrapolation is activated (see  densfor_pred ). \nABINIT 7.10: this option is  under development  and might give wrong\nresults.",
            "title": "extrapwf"
        },
        {
            "location": "/input_variables/vardev/#fermie_nest",
            "text": "Mnemonics: FERMI Energy for printing the NESTing function \nVariable type: real \nDimensions: scalar \nDefault value: 0    This input variable is only effective when  prtnest =1. The energy is\nrelative to the calculated fermi energy.",
            "title": "fermie_nest"
        },
        {
            "location": "/input_variables/vardev/#fftalg",
            "text": "Mnemonics: Fast Fourier Transform ALGorithm \nVariable type: integer \nDimensions: scalar \nDefault value: 312 if  FFTW3  and  usedmft ==0,\n401 if  paral_kgb ==1,\n112 otherwise.  This keyword is   irrelevant   when Fast Fourier Transforms are done using  Graphics Processing Units   (GPU), i.e. when  use_gpu_cuda =1 (in that\ncase, it is ignored).    Allows to choose the algorithm for Fast Fourier Transforms. These have to be\nused when applied to wavefunctions (routine fourwf.F90), as well as when\napplied to densities and potentials (routine fourdp.F90). Presently, it is the\nconcatenation of three digits, labelled (A), (B) and (C).    The first digit (A) is to be chosen among 1, 2, 3, 4 or 5 :   1=> use FFT routines written by S. Goedecker.   2=> not available anymore   3=> use serial or multi-threaded FFTW3 fortran routines (   http://www.fftw.org   ). Currently implemented with  fftalg =312.   4=> use FFT routines written by S. Goedecker, 2002 version, that will be suited for MPI and OpenMP parallelism.   5=> use serial or multi-threaded MKL routines Currently implemented with  fftalg =512.    The second digit (B) is related to fourdp.f :   0=> only use Complex-to-complex FFT   1=> real-to-complex is also allowed (only coded for A==1, A==3 and A==5)    The third digit (C) is related to fourwf.f :   0=> no use of zero padding   1=> use of zero padding (only coded for A==1, A==4)   2=> use of zero padding, and also combines actual FFT operations (using 2 routines from S. Goedecker) with important pre- and post-processing operations, in order to maximize cache data reuse. This is very efficient for cache architectures. (coded for A==1 and A==4, but A==4 is not yet sufficiently tested)    Internal representation as  [ngfft] .",
            "title": "fftalg"
        },
        {
            "location": "/input_variables/vardev/#fftcache",
            "text": "Mnemonics: Fast Fourier Transform CACHE size \nVariable type: integer \nDimensions: scalar \nDefault value: 16 \nComment: todo: Not yet machine-dependent    Gives the cache size of the current machine, in Kbytes. \nInternal representation as  [ngfft] .",
            "title": "fftcache"
        },
        {
            "location": "/input_variables/vardev/#getgam_eig2nkq",
            "text": "Mnemonics: GET the GAMma phonon data EIG2NKQ from dataset \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  ieig2rf  != 0 and  qpt  != (0.0,0.0,0.0)    Relevant for second-order eigenvalue calculations using response-functions\n( ieig2rf  != 0), and only for non-zero wavevectors  qpt . \nFrom the electron-phonon matrix elements at some wavevector only, it is not\npossible to determine the Debye-Waller contribution : one has to know also the\nq=Gamma electron-phonon matrix elements. \nThe variable  getgam_eig2nkq  allows to transmit the information about the\nsecond-order derivatives of the eigenvalues for q=Gamma from the dataset where\nthe calculation at Gamma was done, to the datasets for other wavevectors.",
            "title": "getgam_eig2nkq"
        },
        {
            "location": "/input_variables/vardev/#getwfkfine",
            "text": "Mnemonics: GET the fine grid wavefunctions from _WFK file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to  irdwfkfine . One should first\nread the explanations given for these latter variables. \nThe  getwfkfine  variables is typically used to chain the calculations in\nthe multi-dataset mode, since they describe from which dataset the OUTPUT\nwavefunctions are to be taken, as INPUT wavefunctions of the present dataset. \nIf  getwfkfine ==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done. \nIf  getwfkfine  is positive, its value gives the index of the dataset for\nwhich the output wavefunction file appended with _WFK must be used. \nIf  getwfkfine  is -1, the output wf file with _WFK of the previous dataset\nmust be taken, which is a frequently occurring case. \nIf  getwfkfine  is a negative number, it indicates the number of datasets to\ngo backward to find the needed wavefunction file. In this case, if one refers\nto a non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if  getwfkfine =0 for that\ninitialisation. Thanks to this rule, the use of  getwfkfine  -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :   ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized. Response-function\ncalculation :   one and only one of  getwfkfine  or  irdwfkfine  MUST be non-zero   if  getwfkfine  = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   Reading the fine grid wavefunction will trigger the k-points interpolation technique of the temperature dependent calculations.    Bethe-Salpeter calculation :   one and only one of  getwfkfine  or  irdwfkfine  MUST be non-zero   if  getwfkfine  = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   This variable or  irdwfkfine  is mandatory when  bs_interp_mode  == 1     This variable is experimental. In development.",
            "title": "getwfkfine"
        },
        {
            "location": "/input_variables/vardev/#intxc",
            "text": "Mnemonics: INTerpolation for eXchange-Correlation \nVariable type: integer \nDimensions: scalar \nDefault value: 0     0=> do \u201cusual\u201d xc quadrature on fft grid   1=> do higher accuracy xc quadrature using fft grid and additional points at the centers of each cube (doubles number of grid points)\u2013the high accuracy version is only valid for boxcut>=2. If boxcut < 2, the code stops.    For RF calculations only  intxc =0 is allowed yet. Moreover, the GS\npreparation runs (giving the density file and zero-order wavefunctions) must\nbe done with  intxc =0  Prior to ABINITv2.3, the choice  intxc =1 was favoured (it was the default),\nbut the continuation of the development of the code lead to prefer the default intxc =0 . Indeed, the benefit of  intxc =1 is rather small, while making\nit available for all cases is a non-negligible development effort. Other\ntargets are prioritary\u2026 You will notice that many automatic tests use intxc =1. Please, do not follow this historical choice for your production\nruns.",
            "title": "intxc"
        },
        {
            "location": "/input_variables/vardev/#iomode",
            "text": "Mnemonics: Input-Output MODE \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  MPI_IO  and  paral_kgb ==1,\n0 otherwise.  This option selects the format used to produce the output wavefunction files\nand the files containing densities and potentials. It mainly affects the\ncreation of the output files since several parts of Abinit are able to read\ndata from files independently of their format (either binary files or netcdf\nfiles). The possible values are:   0 => Use standard Fortran IO (ok for sequential runs, not suitable for large parallel runs)   1 => Use MPI/IO routines (ok both for sequential and large parallel runs)   3 => Use NetCDF library to produce files according to the ETSF specification (ok for sequential, requires netcdf4 + hdf5 + MPI-IO support for large parallel runs)    By default, Abinit produces Fortran files and uses parallel MPI-IO under the\nhood when these operations cannot be implemented in terms of simple Fortran\nwrite/read statements. For example,  paral_kgb =1 uses the MPI-IO API\nprovided by your MPI library.  In a nutshell, use the default value and make sure that your MPI library\nsupports MPI-IO before embarking yourself in large parallel runs (HAVE_MPI_IO\nshould be set to 1 in ~abinit/config.h). Many MPI libraries, nowadays, support\nthe MPI-2 standard so it\u2019s very likely that your MPI supports parallel IO. If\nyou encounter problems, please ask your sysadmin to install a MPI library with\nMPI-IO capabilities.  There are cases, however, in which you would like to change the default\nbehaviour. For example, you may want to generate WFK or DEN files in etsf-io\nformat because you need data in this format. In this case, you have to use\niomode==3 in the input file to override the default behaviour. Note however\nthat you still need parallel IO capabilities enabled in the netcdf library if\nyou want to produce netcdf files in parallel with  paral_kgb =1 (i.e.\nnetcdf4 + hdf5 + MPI-IO). At present, the internal fallbacks provided by\nAbinit do not support netcdf4 so you have to link against an external netcdf\nlibrary that supports hdf5+MPI-IO and is compatible with the mpif90 used to\ncompile Abinit. See ~abinit/doc/build/config-examples/ubu_gnu_4.9_mpich.ac for\na typical configuration file.  References:   \u201cSpecification of an extensible and portable file format for electronic structure and crystallographic data\u201d, X. Gonze, C.-O. Almbladh, A. Cucca, D. Caliste, C. Freysoldt, M. Marques, V. Olevano, Y. Pouillon, M.J. Verstraete, Comput. Mat. Science 43, 1056 (2008)   \u201cSharing electronic structure and crystallographic data with ETSF_IO\u201d, D. Caliste, Y. Pouillon, M.J. Verstraete, V. Olevano, X. Gonze, Comput. Physics Communications 179, 748 (2008)   see also   http://www.etsf.eu/fileformats   .",
            "title": "iomode"
        },
        {
            "location": "/input_variables/vardev/#iprcfc",
            "text": "Mnemonics: Integer for PReConditioner of Force Constants \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used when  iscf >0, to define the SCF preconditioning scheme. Potential-\nbased preconditioning schemes for the SCF loop are still under development. \nThe present parameter (force constant part) describes the way a change of\nforce is derived from a change of atomic position. \nSupported values :   0 => hessian is the identity matrix   1 => hessian is 0.5 times the identity matrix   2 => hessian is 0.25 times the identity matrix   -1=> hessian is twice the identity matrix   \u2026 (simply corresponding power of 2 times the identity matrix)    No meaning for RF calculations.",
            "title": "iprcfc"
        },
        {
            "location": "/input_variables/vardev/#irandom",
            "text": "Mnemonics: Integer for the choice of the RANDOM number generator \nVariable type: integer \nDimensions: scalar \nDefault value: 3    For the time being, only used when  imgmov =9 (Langevin Path-Integral\nMolecular Dynamics).  irandom  defines the random number generator.    Supported values :   1 => \u201cuniformrandom\u201d, delivered with ABINIT package (initially comes from numerical recipes).   2 => intrinsic Fortran 90 random number generator.   3 => \u201cZBQ\u201d non-deterministic random number generator by R. Chandler and P. Northrop. (Available at [).    irandom =3 is strongly advised when performing Molecular Dynamics restarts\n(avoids bias).",
            "title": "irandom"
        },
        {
            "location": "/input_variables/vardev/#irdwfkfine",
            "text": "Mnemonics: Integer that governs the ReaDing of the grid _WFK file on the FINE grid \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Indicates eventual starting wavefunctions. As alternative, one can use the\ninput variables  getwfkfine .    Ground-state calculation :   only  irdwfkfine  and  getwfkfine  have a meaning   at most one of  irdwfkfine  or  getwfkfine  can be non-zero   if  irdwfkfine  = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state fine grid calculation (see the   section 4   of the  help_abinit ).    Response-function calculation :   one and only one of  irdwfkfine  or  getwfkfine  MUST be non-zero   if  irdwfkfine  = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   Reading the fine grid wavefunction will trigger the k-points interpolation technique of the temperature dependent calculations.    Bethe-Salpeter calculation :   one and only one of  irdwfkfine  or  getwfkfine  MUST be non-zero   if  irdwfkfine  = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   This variable or  getwfkfine  is mandatory when  bs_interp_mode  = 1     This variable is experimental. In development.",
            "title": "irdwfkfine"
        },
        {
            "location": "/input_variables/vardev/#isecur",
            "text": "Mnemonics: Integer for level of SECURity choice \nVariable type: integer \nDimensions: scalar \nDefault value: 0    In the presently used algorithms, there is a compromise between speed and\nrobustness, that can be tuned by using  isecur . \nIf  isecur  =0, an extrapolation of out-of-line data is allowed, and might\nsave one non-SCF calculation every two line minimisation when some stability\nconditions are fulfilled (since there are 2 non-SCF calculations per line\nminimisation, 1 out of 4 is saved) \nUsing  isecur =1 or higher integers will raise gradually the threshold to\nmake extrapolation. \nUsing  isecur =-2 will allow to save 2 non-SCF calculations every three line\nminimisation, but this can make the algorithm unstable. Lower values of isecur  allows for more (tentative) savings. In any case, there must be one\nnon-SCF computation per line minimisation. \nNo meaning for RF calculations yet.",
            "title": "isecur"
        },
        {
            "location": "/input_variables/vardev/#istatr",
            "text": "Mnemonics: Integer for STATus file rate \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nComment: Values lower than 10 may not work on some machines.    Govern the rate of output of the status file. This status file is written when\nthe number of the call to the status subroutine is equal to \u2018   istatshft  \n\u2018 modulo \u2018 istatr \u2019, so that it is written once every \u2018 istatr \u2018 call.\nWhen \u2018 istatr \u2018=0, there is no writing of a status file (which is the\ndefault).",
            "title": "istatr"
        },
        {
            "location": "/input_variables/vardev/#istatshft",
            "text": "Mnemonics: Integer for STATus file SHiFT \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Govern the rate of output of the status file. This status file is written when\nthe number of the call to the status subroutine is equal to \u2018 istatshft \u2018\nmodulo \u2018   istatr   \u2018, so that it is written once every \u2018   istatr   \u2018\ncall. There is also a writing for each of the 5 first calls, and the 10th\ncall.",
            "title": "istatshft"
        },
        {
            "location": "/input_variables/vardev/#istwfk",
            "text": "Mnemonics: Integer for choice of STorage of WaveFunction at each k point \nVariable type: integer \nDimensions: ( nkpt ) \nDefault value: *0 \nComment: For RF calculations, the Default is not used :  istwfk  is forced to be 1 deep inside the code, for all k points. For spin-orbit calculations ( nspinor =2),  istwfk  is also forced to be 1, for all k points.    Control the way the wavefunction for each k-point is stored inside ABINIT, in\nreciprocal space. \nFor the GS calculations, in the \u201ccg\u201d array containing the wavefunction\ncoefficients, there is for each k-point and each band, a segment\ncg(1:2,1:npw). The \u2018full\u2019 number of plane wave is determined by  ecut .\nHowever, if the k-point coordinates are build only from zeroes and halves (see\nlist below), the use of time-reversal symmetry (that connects coefficients)\nhas been implemented, in order to use real-to-complex FFTs (see  fftalg ),\nand to treat explicitly only half of the number of plane waves (this being\nused as \u2018npw\u2019). \nFor the RF calculations, there is not only the \u201ccg\u201d array, but also the \u201ccgq\u201d\nand \u201ccg1\u201d arrays. For the time-reversal symmetry to decrease the number of\nplane waves of these arrays, the q vector MUST be (0 0 0). Then, for each k\npoint, the same rule as for the RF can be applied. \nWARNING (991018) : for the time being, the time-reversal symmetry cannot be\nused in the RF calculations.   1=> do NOT take advantage of the time-reversal symmetry   2=> use time-reversal symmetry for k=( 0 0 0 )   3=> use time-reversal symmetry for k=(1/2 0 0 )   4=> use time-reversal symmetry for k=( 0 0 1/2)   5=> use time-reversal symmetry for k=(1/2 0 1/2)   6=> use time-reversal symmetry for k=( 0 1/2 0 )   7=> use time-reversal symmetry for k=(1/2 1/2 0 )   8=> use time-reversal symmetry for k=( 0 1/2 1/2)   9=> use time-reversal symmetry for k=(1/2 1/2 1/2)   0=> (preprocessed) for each k point, choose automatically the appropriate time-reversal option when it is allowed, and chose  istwfk =1 for all the other k points.",
            "title": "istwfk"
        },
        {
            "location": "/input_variables/vardev/#lotf_classic",
            "text": "Mnemonics: LOTF CLASSIC model for glue model \nVariable type: integer \nDimensions: scalar \nDefault value: 5    Glue model used in LOTF. \nFor the moment it is imposed to be 5.",
            "title": "lotf_classic"
        },
        {
            "location": "/input_variables/vardev/#lotf_nitex",
            "text": "Mnemonics: LOTF Number of ITerations \nVariable type: integer \nDimensions: scalar \nDefault value: 10    Set the number of Molecular Dynamics iterations which are computed by LOTF.",
            "title": "lotf_nitex"
        },
        {
            "location": "/input_variables/vardev/#lotf_nneigx",
            "text": "Mnemonics: LOTF max Number of NEIGhbours \nVariable type: integer \nDimensions: scalar \nDefault value: 5    Set the max number of Neighbours used in the LOTF method. \nFor the moment it is imposed to be 40.",
            "title": "lotf_nneigx"
        },
        {
            "location": "/input_variables/vardev/#lotf_version",
            "text": "Mnemonics: LOTF VERSION of MD algorithm \nVariable type: integer \nDimensions: scalar \nDefault value: 2    Set the MD algorithm in the LOTF method. \nFor the moment it is imposed to be 2.",
            "title": "lotf_version"
        },
        {
            "location": "/input_variables/vardev/#macro_uj",
            "text": "Mnemonics: MACRO variable that activates the determination of the U and J parameter (for the PAW+U calculations) \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Sets proper input values for the determination of U and J i.e. for  pawujat \n(first atom treated with PAW+U),  irdwfk  (=1),  tolvrs  (=10^(-8)), nstep  (=255),  diemix  (=0.45),  atvshift  ( pawujat )  pawujv ).\nDo not overwrite these variables manually unless you know what you do.   macro_uj =1 (and  nsppol =2) Standard procedure to determine U on atom pawujat through a shift of the potential on both spin channels.   macro_uj =1 (and  nsppol =1) Non standard procedure to determine U from potential shift on atom pawujat (experimental).   macro_uj =2 (and  nsppol =2) Non standard procedure to determine U from potential shift on atom pawujat through a shift on spin channel 1 on this atom and the response on this channel (experimental).   macro_uj =3 (and  nsppol =2) Standard procedure to determine J from potential shift on spin channel 1 on atom pawujat and response on spin channel 2 (experimental).    Determination of U and J can be done only if the symmetry of the atomic\narrangement is reduced and the atom pawujat is not connected to any other atom\nby symmetry relations (either input reduced symmetries manually, define\nconcerned atom as a separate atomic species or shift concerned atom from ideal\nposition).",
            "title": "macro_uj"
        },
        {
            "location": "/input_variables/vardev/#maxnsym",
            "text": "Mnemonics: MAXimum Number of SYMetries \nVariable type: integer \nDimensions: scalar \nDefault value: 384    Gives the maximum number of spatial symetries allowed in the memory. \nThe default value is sufficient for most applications; it has to be increase\nin the case of the use of a supercell (unit cell identically repeated).",
            "title": "maxnsym"
        },
        {
            "location": "/input_variables/vardev/#mem_test",
            "text": "Mnemonics: MEMory TEST \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This variable controls the memory test done in the memana routine. Possible\nvalues:   0 no test on the available memory is performed   1 the routine tries to allocate the estimated memory, for testing purposes, and if a failure occurs, the routine stops.   2 like 1, but before stopping, the routine will provide an estimation of the available memory.",
            "title": "mem_test"
        },
        {
            "location": "/input_variables/vardev/#mqgrid",
            "text": "Mnemonics: Maximum number of Q-space GRID points for pseudopotentials \nVariable type: integer \nDimensions: scalar \nDefault value: 3001    Govern the size of the one-dimensional information related to\npseudopotentials, in reciprocal space : potentials, or projector functions.",
            "title": "mqgrid"
        },
        {
            "location": "/input_variables/vardev/#nbdblock",
            "text": "Mnemonics: Number of BanDs in a BLOCK \nVariable type: integer \nDimensions: scalar \nDefault value: 1    In case of non-standard, blocked algorithms for the optimization of the\nwavefunctions (that is, if  wfoptalg =4):   if  wfoptalg =4,  nbdblock  defines the number of blocks (the number of bands in the block is then  nband / nbdblock  ).",
            "title": "nbdblock"
        },
        {
            "location": "/input_variables/vardev/#nc_xccc_gspace",
            "text": "Mnemonics: Norm-Conserving pseudopotentials - use XC Core-Correction in G-SPACE \nVariable type: integer \nDimensions: scalar \nDefault value: 0 if  usepaw ==0,\n1 if  usepaw ==1,\n0 otherwise.  Comment: 0 when  usepaw =0, 1 when  usepaw =1    Historically, Abinit treats the model core charge used for the non-linear core\ncorrection in real space. Alternatively, it is possible to instruct the code\nto compute the core charge in G-space following the same approach used in the\nPAW code. The G-space formalism is more accurate than the interpolation in\nreal space, especially when derivatives of the model core charge are needed,\ne.g. DFPT. Preliminary tests showed that the violation of the acoustic sum\nrule is reduced when  nc_xccc_gspace ==1 , especially for LDA. It is worth\nstressing, however, that  nc_xccc_gspace ==1 should be used only in\nconjunction with NC pseudos whose model core charge that decays quickly in\nG-space. Several NC pseudos available in the Abinit table are not optimized\nfor the G-space formalism and users are strongly invited to perform\nconvergence studies with respect to ecut before using this option.",
            "title": "nc_xccc_gspace"
        },
        {
            "location": "/input_variables/vardev/#nctime",
            "text": "Mnemonics: NetCdf TIME between output of molecular dynamics informations \nVariable type: integer \nDimensions: scalar \nDefault value: 0    When  nctime  is non-zero, the molecular dynamics information is output in\nNetCDF format, every  nctime  time step. Here is the content of an example\nfile :  netcdf   md32 . outH_moldyn1   {  dimensions : \n    time   =   UNLIMITED   ;   //   (11   currently) \n    DimTensor   =   6   ; \n    DimCoord   =   3   ; \n    NbAtoms   =   32   ; \n    DimVector   =   3   ; \n    DimScalar   =   1   ;  variables : \n    double   E_pot ( time )   ; \n       E_pot : units   =   \"hartree\"   ; \n    double   E_kin(time)   ; \n       E_kin : units   =   \"hartree\"   ; \n    double   Stress(time,   DimTensor)   ; \n       Stress : units   =   \"hartree/Bohr^3\"   ; \n    double   Position(time,   DimCoord,   NbAtoms)   ; \n       Position : units   =   \"Bohr\"   ; \n    double   Celerity(time,   DimCoord,   NbAtoms)   ; \n       Celerity : units   =   \"Bohr/(atomic time unit)\"   ; \n    double   PrimitiveVector1(DimVector)   ; \n    double   PrimitiveVector2(DimVector)   ; \n    double   PrimitiveVector3(DimVector)   ; \n    double   Cell_Volume(DimScalar)   ; \n       Cell_Volume : units   =   \"Bohr^3\"   ;  }",
            "title": "nctime"
        },
        {
            "location": "/input_variables/vardev/#nloc_alg",
            "text": "Mnemonics: Non LOCal ALGorithm \nVariable type: integer \nDimensions: scalar \nDefault value: 4    Allows to choose the algorithm for non-local operator application. On super-\nscalar architectures, the default  nloc_alg =4 is the best. \nMore detailed explanations:    -  nloc_alg =2 : Should be efficient on vector machines. It is indeed the\nfastest algorithm for the NEC, but actual tests on Fujitsu machine did not\ngave better performances than the other options. \n-  nloc_alg =3 : same as  nloc_alg ==2, but the loop order is inverted. \n-  nloc_alg =4 : same as  nloc_alg ==3, but maximal use of registers has\nbeen coded. This should be especially efficient on scalar and super-scalar\nmachines. This has been confirmed by tests.    Note: internally,  nloc_alg  is stored in _ nloalg(1) _ . See also nloc_mem  for the tuning of the memory used in the non-local operator\napplication.",
            "title": "nloc_alg"
        },
        {
            "location": "/input_variables/vardev/#nloc_mem",
            "text": "Mnemonics: Non LOCal MEMOry \nVariable type: integer \nDimensions: scalar \nDefault value: 2 if  usepaw ==1,\n1 otherwise.  Controls the memory use for the application of the non-local operator. \nMore detailed explanations:    -  nloc_mem ==1 : (k+G) vectors are not precomputed, in order to save\nmemory space. \n-  nloc_mem ==2 : (k+G) vectors are precomputed, once per k-point. \n-  nloc_mem ==-1 or -2 : Negative values of  nloc_mem  correspond\npositive ones, where the phase precomputation has been suppressed, in order to\nsave memory space, as an array _ double precision :: ph3d(2,npw, natom ) _\nis saved (typically half the space needed for the wavefunctions at 1 k point -\nthis corresponds to the silicon case). However, the computation of phases\ninside nonlop is somehow time-consuming.    Note: internally, sign( nloc_mem ) is stored in _ nloalg(2) _ and\nabs( nloc_mem )-1 is stored in _ nloalg(3) _ . See also  nloc_alg  for the\nalgorithm for the non-local operator application.",
            "title": "nloc_mem"
        },
        {
            "location": "/input_variables/vardev/#nnsclo",
            "text": "Mnemonics: Number of Non-Self Consistent LOops \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the maximum number of non-self-consistent loops of  nline  line\nminimisations, in the SCF case (when  iscf  >0). In the case  iscf \n<=0 , the number of non-self-consistent loops is determined by  nstep . \nThe Default value of 0 \u2013 for standard plane-wave calculations \u2013 corresponds\nto make the two first fixed potential determinations of wavefunctions have 2\nnon-self consistent loops, and the next ones to have only 1 non-self\nconsistent loop. \nThe Default value of 0 \u2013 for wavelets calculations ( usewvl =1) \u2013\ncorresponds to make 2 steps with 3 non-self consistent loops , 2 steps with 2\nnon-self consistent loops, then the next ones with 1 non-self consistent loop.",
            "title": "nnsclo"
        },
        {
            "location": "/input_variables/vardev/#nnsclohf",
            "text": "Mnemonics: Number of Non-Self Consistent LOops for (Hartree)-Fock exact exchange \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  usefock ==1,\n0 otherwise.  Gives the maximum number of loops with non-self-consistent occupied states\nused to calculate Fock exact exchange, in the SCF case. \nThe Default value is 0 when  usefock  = 0. Default value is 1 when usefock  = 1 and correspond to update occupied wavefunctions at each self-\nconsistent loop.",
            "title": "nnsclohf"
        },
        {
            "location": "/input_variables/vardev/#normpawu",
            "text": "Mnemonics: NORMalize atomic PAW+U projector \nVariable type: integer \nDimensions: ( ntypat ) \nDefault value: 0    Defines whether the atomic wave function (used as projectors in PAW+U) should\nbe renormalized to 1 within PAW sphere.   normpawu =0 : leave projector   normpawu =1 : renormalize",
            "title": "normpawu"
        },
        {
            "location": "/input_variables/vardev/#npulayit",
            "text": "Mnemonics: Number of PULAY ITerations for SC mixing \nVariable type: integer \nDimensions: scalar \nDefault value: 7 \nOnly relevant if  iscf  in [7,17]    Gives the number of previous iterations involved in Pulay mixing (mixing\nduring electronic SC iterations).",
            "title": "npulayit"
        },
        {
            "location": "/input_variables/vardev/#nscforder",
            "text": "Mnemonics: Nth - SCaling Function ORDER \nVariable type: integer \nDimensions: scalar \nDefault value: 16    This variable controls the order of used scaling functions when the Hartree\npotential is computed using the Poisson solver (see  icoulomb  imput\nvariable). This variable is of seldom use since the default value is large\nenough. Nonetheless, possible values are 8, 14, 16, 20, 24, 30, 40, 50, 60,\n100. Values greater than 20 are included in ABINIT for test purposes only.",
            "title": "nscforder"
        },
        {
            "location": "/input_variables/vardev/#optforces",
            "text": "Mnemonics: OPTions for the calculation of FORCES \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  toldff  or  tolrff  != 0,\n2 otherwise.  Allows to choose options for the calculation of forces.   optforces =0 : the forces are set to zero, and many steps of the computation of forces are skipped   optforces =1 : calculation of forces at each SCF iteration, allowing to use forces as criterion to stop the SCF cycles   optforces =2 : calculation of forces at the end of the SCF iterations (like the stresses)",
            "title": "optforces"
        },
        {
            "location": "/input_variables/vardev/#optnlxccc",
            "text": "Mnemonics: OPTion for the calculation of Non-Linear eXchange-Correlation Core Correction \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Allows to choose options for the calculation of non-linear XC correction. At\npresent, only relevant for the FHI type of pseudopotentials, with pspcod=6 .   optnlxccc =1 : uses the old psp6cc.f routine, with inconsistent treatment of real-space derivatives of the core function (computed in this routine, while splined in the other parts of the code)   optnlxccc =2 : consistent calculation derivatives, in the psp6cc_dhr.f routine from DHamann.",
            "title": "optnlxccc"
        },
        {
            "location": "/input_variables/vardev/#ortalg",
            "text": "Mnemonics: ORThogonalisation ALGorithm \nVariable type: integer \nDimensions: scalar \nDefault value: -2 if  wfoptalg  >= 10 ,\n2 otherwise.  Allows to choose the algorithm for orthogonalisation. \nPositive or zero values make two projections per line minimisation, one before\nthe preconditioning, one after. This is the clean application of the band-by-\nband CG gradient for finding eigenfunctions. \nNegative values make only one projection per line minimisation. \nThe orthogonalisation step is twice faster, but the convergence is less good.\nThis actually calls to a better understanding of this effect.  ortalg =0, 1 or -1 is the conventional coding.  ortalg =2 or -2 try to make better use of existing registers on the\nparticular machine one is running. \nMore demanding use of registers is provided by  ortalg =3 or -3, and so on. \nThe maximal value is presently 4 and -4. \nTests have shown that  ortalg =2 or -2 is suitable for use on the available\nplatforms.",
            "title": "ortalg"
        },
        {
            "location": "/input_variables/vardev/#papiopt",
            "text": "Mnemonics: PAPI OPTion \nVariable type: integer \nDimensions: scalar \nDefault value: 0     PAPI   aims to provide the tool\ndesigner and application engineer with a consistent interface and methodology\nfor use of the performance counter hardware found in most major\nmicroprocessors. PAPI enables software engineers to see, in near real time,\nthe relation between software performance and processor events. \nThis option can be used only when ABINIT has been compiled with the  --enable-papi  configure option. \nIf  papiopt =1, then PAPI counters are used instead of the usual time()\nroutine. All the timing output of ABINIT is then done with PAPI values. The\nmeasurements are more accurate and give also access to the flops of the\ncalculation.",
            "title": "papiopt"
        },
        {
            "location": "/input_variables/vardev/#pawprt_b",
            "text": "Mnemonics: PAW PRinT band \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Forces the output of the all-electron wavefunction for only a single band. To\nbe used in conjuction with:   pawprtwf =1   and  pawprt_k . The indexing of the bands start with one\nfor the lowest occupied band and goes up from there.",
            "title": "pawprt_b"
        },
        {
            "location": "/input_variables/vardev/#pawprt_k",
            "text": "Mnemonics: PAW PRinT K-point \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Forces the output of the all-electron wavefunction for only a single k-point.\nTo be used in conjuction with:   pawprtwf =1   and  pawprt_b . The indexing follows the order in ouptput\nof the internal variable   kpt   in the beginning of the run.",
            "title": "pawprt_k"
        },
        {
            "location": "/input_variables/vardev/#pawujat",
            "text": "Mnemonics: PAW+macro_UJ, ATom number \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nComment:  i.e. the first atom treated with PAW+U.    Determines the atom for which U (or J) should be determined. See also macro_uj .",
            "title": "pawujat"
        },
        {
            "location": "/input_variables/vardev/#pawujrad",
            "text": "Mnemonics: PAW+macro_UJ, sphere RADius \nVariable type: real \nDimensions: scalar \nDefault value: 20 a.u.    The sphere radius serves to extrapolate the U value calculated at r_paw to a\nlarger sphere radius. See also  macro_uj . As most projector functions are\nlocalized within r_paw to \u224880%, 20 a.u. contains \u2248100% of the wavefunction and\ncorresponds to r_paw -> \u221e.",
            "title": "pawujrad"
        },
        {
            "location": "/input_variables/vardev/#pawujv",
            "text": "Mnemonics: PAW+macro_UJ, potential shift (V) \nVariable type: real \nDimensions: scalar \nDefault value: 0.1 eV    Amplitude of the potential shift for the determination of U (or J). See also macro_uj .",
            "title": "pawujv"
        },
        {
            "location": "/input_variables/vardev/#plowan_bandf",
            "text": "Mnemonics: Projected Local Orbital WANnier functions BAND Final \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the upper band to include in the calculation of Wannier functions",
            "title": "plowan_bandf"
        },
        {
            "location": "/input_variables/vardev/#plowan_bandi",
            "text": "Mnemonics: Projected Local Orbital WANnier functions BAND Initial \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the lower band to include in the calculation of Wannier functions",
            "title": "plowan_bandi"
        },
        {
            "location": "/input_variables/vardev/#plowan_compute",
            "text": "Mnemonics: Projected Local Orbital WANnier functions COMPUTATION \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Activate computation of Projected Local Orbital Wannier functions (PLO\nWannier) and corresponding band structure. Variables  plowan_bandi , plowan_bandf ,  plowan_natom ,  plowan_nbl ,  plowan_iatom , plowan_lcalc ,  plowan_projcalc  are mandatory to precise the nature of\nthe projections.   0=> Default value: do not activate calculation of PLO Wannier.   1=> Compute PLO Wannier and band structure   2=> Compute PLO Wannier and band structure. In this case, the coupling in k-space between blocks of Wannier functions belonging to different angular momenta or atoms is removed.    Other related variables are  plowan_realspace ,  plowan_nt , plowan_it . The implementation is not symetrized over k-point and not\nparallelized. (The calculation of projections is detailed in   Phys. Rev. B\n77, 205112, (2008)  )",
            "title": "plowan_compute"
        },
        {
            "location": "/input_variables/vardev/#plowan_iatom",
            "text": "Mnemonics: Projected Local Orbital WANnier functions, Index of ATOM \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the indices of the  plowan_natom  atoms on which the projections will\nbe done.",
            "title": "plowan_iatom"
        },
        {
            "location": "/input_variables/vardev/#plowan_it",
            "text": "Mnemonics: Projected Local Orbital WANnier functions,  Index of Translation. \nVariable type: integer \nDimensions: (3, plowan_nt ) \nDefault value: 0    Requires  plowan_realspace  to be greater than 0 and  plowan_nt  to be\ngreater than 0. Precise a given set of selected real space translation by\nusing the real space vectors basis. These atoms are used to define Wannier\nfunctions in real space. These real space Wannier functions are used as a\nbasis to compute the Hamiltonian.",
            "title": "plowan_it"
        },
        {
            "location": "/input_variables/vardev/#plowan_lcalc",
            "text": "Mnemonics: Projected Local Orbital WANnier functions,  L values to use for CALCulation \nVariable type: integer \nDimensions: (sum( plowan_nbl )) \nDefault value: -1    Gives the  plowan_nbl  values of angular momenta for each atom, in the order\nof the atoms as given in  plowan_iatom .",
            "title": "plowan_lcalc"
        },
        {
            "location": "/input_variables/vardev/#plowan_natom",
            "text": "Mnemonics: Projected Local Orbital WANnier functions, Number of ATOMs \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of atoms on which the projection will be done",
            "title": "plowan_natom"
        },
        {
            "location": "/input_variables/vardev/#plowan_nbl",
            "text": "Mnemonics: Projected Local Orbital WANnier functions,  NumBer of L values \nVariable type: integer \nDimensions: ( plowan_natom ) \nDefault value: 0    Gives the total number of angular momenta (over all atoms) to compute the\nprojections.",
            "title": "plowan_nbl"
        },
        {
            "location": "/input_variables/vardev/#plowan_nt",
            "text": "Mnemonics: Projected Local Orbital WANnier functions,  Number of Translation on which the real space values of\nenergy are computed \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Requires  plowan_realspace  to be greater than 0. Gives a number of selected\natoms. These atoms are used to define Wannier functions in real space. These\nreal space Wannier functions are used as a basis to compute the Hamiltonian.",
            "title": "plowan_nt"
        },
        {
            "location": "/input_variables/vardev/#plowan_projcalc",
            "text": "Mnemonics: Projected Local Orbital WANnier functions,  PROJectors values to use for CALCulation \nVariable type: integer \nDimensions: (sum( plowan_nbl )) \nDefault value: -1    Gives the  plowan_nbl  values of projectors for each atom, in the order of\nthe atoms as given in  plowan_iatom . The index i for the projectors refers\nto the ith number on line orbitals of the PAW atomic data file.",
            "title": "plowan_projcalc"
        },
        {
            "location": "/input_variables/vardev/#plowan_realspace",
            "text": "Mnemonics: Projected Local Orbital WANnier functions,  activate REAL SPACE calculation. \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Can take the following values:   0=> Default value: do not activate calculation of real space Wannier functions.   1=> Compute PLO Wannier in real space for analysis. These data can also be used in a following dataset to perform a Wannier interpolation.   2=> Do simple Wannier Interpolation for a given k points starting from real space Wannier function Hamiltonian computed in a preceding dataset.",
            "title": "plowan_realspace"
        },
        {
            "location": "/input_variables/vardev/#prepscphon",
            "text": "Mnemonics: PREPare Self-Consistent PHONon calculation \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Print PCINFO, PHFREQ, and PHVEC files, for use with self-consistent phonon\nruns, after a perturbation calculation. Only prints out files for the present\nq-point, and there is presently no tool to symmetrize or merge these files, so\nuse anaddb instead (with prtscphon input variable). The abinit input variable\nis destined to someday bypass the use of anaddb for scphon calculations.",
            "title": "prepscphon"
        },
        {
            "location": "/input_variables/vardev/#prtbltztrp",
            "text": "Mnemonics: PRinT output for BoLTZTRaP code \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Print out geometry (_BLZTRP_GEOM) and eigenenergy (_BLZTRP_EIGEN) files for\nthe   BoltzTraP\ncode \nby Georg Madsen.",
            "title": "prtbltztrp"
        },
        {
            "location": "/input_variables/vardev/#prtcif",
            "text": "Mnemonics: PRinT Crystallographic Information File \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1, a CIF file is output with the crystallographic data for the\npresent run (cell size shape and atomic positions).",
            "title": "prtcif"
        },
        {
            "location": "/input_variables/vardev/#prtdipole",
            "text": "Mnemonics: PRinT DIPOLE \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Print out dipole of unit cell, calculated in real space for the primitive cell\nonly. Under development.",
            "title": "prtdipole"
        },
        {
            "location": "/input_variables/vardev/#prtnest",
            "text": "Mnemonics: PRinT NESTing function \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1, the nesting function for the k-point grid is printed. For the\nmoment the path in q space for the nesting function is fixed, but will become\nan input as well.",
            "title": "prtnest"
        },
        {
            "location": "/input_variables/vardev/#prtposcar",
            "text": "Mnemonics: PRinT POSCAR file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Print out VASP-style POSCAR and FORCES files, for use with PHON or frophon\ncodes for frozen phonon calculations. See the associated script in\n~abinit/extras/post_processing/phondisp2abi.py for further details on\ninterfacing with PHON, PHONOPY, etc\u2026",
            "title": "prtposcar"
        },
        {
            "location": "/input_variables/vardev/#recefermi",
            "text": "Mnemonics: RECursion - initial guess  of the FERMI Energy \nVariable type: real \nDimensions: scalar \nDefault value: 0    Used in Recursion method ( tfkinfunc =2). In the first SCF calculation it\nfixes the initial guess for the Fermi energy.",
            "title": "recefermi"
        },
        {
            "location": "/input_variables/vardev/#recgratio",
            "text": "Mnemonics: RECursion - Grid RATIO \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Used in Recursion method ( tfkinfunc =2). It represents the ratio of the two\ngrid step:  recgratio =fine_step/coarse_step and it is bigger or equal than\n1. It introduces a double-grid system which permits to compute the electronic\ndensity on a coarse grid, using a fine grid (defined by  ngfft ) in the\ndiscretisation of the green kernel (see  recptrott ). Successively the\ndensity and the recursion coefficients are interpolated on the fine grid by\nFFT interpolation. Note that ngfft/recgratio=number of points of the coarse\ngrid has to be compatible with the parallelization parameters.",
            "title": "recgratio"
        },
        {
            "location": "/input_variables/vardev/#recnpath",
            "text": "Mnemonics: RECursion - Number of point for PATH integral calculations \nVariable type: integer \nDimensions: scalar \nDefault value: 500    Used in Recursion method ( tfkinfunc =2). Determine the number of\ndiscretisation points to compute some path integral in the recursion method ;\nthose path integrals are used to compute the entropy and the eigenvalues\nenergy. during the latest SFC cycles.",
            "title": "recnpath"
        },
        {
            "location": "/input_variables/vardev/#recnrec",
            "text": "Mnemonics: RECursion - Number of RECursions \nVariable type: integer \nDimensions: scalar \nDefault value: 10    Used in Recursion method ( tfkinfunc =2). Determine the maximum order of\nrecursion, that is the dimension of the krylov space we use to compute\ndensity. If the precision set by  rectolden  is reached before that order,\nthe recursion method automatically stops.",
            "title": "recnrec"
        },
        {
            "location": "/input_variables/vardev/#recptrott",
            "text": "Mnemonics: RECursion - TROTTer parameter \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used in Recursion method ( tfkinfunc =2). Determine the trotter parameter\nused to compute the exponential of the hamiltonian in the recursion method:\nexp(-beta (-Delta + V)) ~ (exp(-beta/(4 recptrott) V) exp(-beta/(4 recptrott)\nDelta) exp(-beta/(4 recptrott) V))^(2 recptrott). If set to 0, we use\nrecptrott = 1/2 in the above formula. Increasing  recptrott  improve the\naccuracy of the trotter formula, but increase the dicretisation error: it may\nbe necessary to increase  ngfft . The discretisation error is essentially\nthe discretisation error of the green kernel exp((recptrott/beta |r|^2)) on\nthe ngfft grid.",
            "title": "recptrott"
        },
        {
            "location": "/input_variables/vardev/#recrcut",
            "text": "Mnemonics: RECursion - CUTing Radius \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used in Recursion method ( tfkinfunc =2). Used to improve the computational\ntime in the case of the recursion method in a large cell: the density at a\npoint will be computed with taking account only of a sphere of radius recrcut .",
            "title": "recrcut"
        },
        {
            "location": "/input_variables/vardev/#rectesteg",
            "text": "Mnemonics: RECursion - TEST on Electron Gas \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used in Recursion method ( tfkinfunc =2). It is used to test an electron gas\nby putting the ion potential equal to zero.",
            "title": "rectesteg"
        },
        {
            "location": "/input_variables/vardev/#rectolden",
            "text": "Mnemonics: RECursion - TOLerance on the difference of electronic DENsity \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nComment: Default value to be changed.    Used in Recursion method ( tfkinfunc =2). Sets a tolerance for differences\nof electronic density that, reached TWICE successively, will cause one SCF\ncycle to stop. That electronic density difference is computed in the infinity\nnorm (that is, it is computed point-by-point, and then the maximum difference\nis computed).",
            "title": "rectolden"
        },
        {
            "location": "/input_variables/vardev/#symmorphi",
            "text": "Mnemonics: SYMMORPHIc symmetry operation selection \nVariable type: integer \nDimensions: scalar \nDefault value: 1    With  symmorphi =1, symmetry operations with a non-symmorphic vector are\nallowed. With  symmorphi =0, they are not allowed. In the latter case, if\nthe symmetry operations are specified in the input file, the code will stop\nand print an error message if a non-symmorphic vector is encountered. By\ncontrast, if the symmetry operations are to be determined automatically (if nsym =0), then the set of symmetries will not include the non-symmorphic\noperations.  Note : this feature exist because in a previous status of the  GW \ncalculations, non-symmorphic symmetry operations could not be exploited. Thus,\nthe k points were restricted to the IBZ. In order to prepare  GW \ncalculations, and to perform  GW  calculations,  symmorphi =0 was to be\nused, together with  nsym =0.",
            "title": "symmorphi"
        },
        {
            "location": "/input_variables/vardev/#tfkinfunc",
            "text": "Mnemonics: Thomas-Fermi KINetic energy FUNCtional \nVariable type: integer \nDimensions: scalar \nDefault value: 0      tfkinfunc =1 : Thomas-Fermi kinetic functional (explicit functional of the density) is used instead of Kohn-Sham kinetic energy functional (implicit functional of the density through Kohn-Sham wavefunctions). \nSee Perrot F., Phys. Rev. A20,586-594 (1979)).    tfkinfunc =11 : Thomas-Fermi-Weizsacker kinetic functional with Gradient Corrections is used. \nThe convergence of a calculation with this functional needs to be initialized\nfrom a calculation without Gradient Correction. This is automatically done\nwith  tfkinfunc =11. For the initialization steps, the  tfw_toldfe \ncriterion is used. When it is reached, then the Gradient Correction is added\nand the SCF cycle continues. \nNote: to obtain the convergence of a Molecular Dynamics simulation with TFW,\nit is necessary to find the best set of preconditionning parameters\n( diemix ,  diemac ,  dielng ) and the best value of  npulayit  (if\nthe default Pulay mixing is used).    tfkinfunc =12 : same as  tfkinfunc =11, but without the initialization steps. Gradient correction is directly added.    tfkinfunc =2 : the Recursion Method is used in order to compute electronic density, entropy, Fermi energy and eigenvalues energy. This method computes the density without computing any orbital, is efficient at high temperature, with a efficient parallelization (almost perfect scalability). When that option is in use, the  ecut  input variable is no longer a convergence parameter ;  ngfft  becomes the main convergence parameter: you should adapt ecut for the ngfft grid you need (it is not yet automatically computed). Other convergence parameter are for the energetic values:  recnrec ,  recptrott ,  recnpath . \nSince the convergence of the self-consistent cycle is determined directly by\nthe convergence of the density:  toldfe ,  toldff ,  tolrff , tolvrs ,  tolwfr  are not used, and are replaced by  rectolden ; the\nenergetic values, except for the fermi energy, are only computed during the\nlatest SFC cycle : the output file will show a jump of the total energy at the\nend, but it is not because of a bad convergence behavior. Computational speed\ncan be improved by the use of  recrcut  and  recgratio . The recursion\nmethod has not be tested in the case of non cubic cell or with the use of\nsymmetries. \nIn the recursion method the following variables are set to:  useylm =1, userec =1.",
            "title": "tfkinfunc"
        },
        {
            "location": "/input_variables/vardev/#tfw_toldfe",
            "text": "Mnemonics: Thomas-Fermi-Weizsacker: TOLerance on the DiFference of total Energy, for initialization steps \nVariable type: real \nDimensions: scalar \nDefault value: 1.0E-6 or  toldfe  is present \nOnly relevant if  tfkinfunc =11    This input variable has the same definition as  toldfe  and is only relevant\nwhen  tfkinfunc =11. \nIt sets a tolerance for absolute differences of total energy that, reached\nTWICE successively, will cause the initialization steps (without gradient\ncorrection) to stop and the gradient correction to be added. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since it has the\n\u2018ENERGY\u2019 characteristics.",
            "title": "tfw_toldfe"
        },
        {
            "location": "/input_variables/vardev/#tolrde",
            "text": "Mnemonics: TOLerance on the Relative Difference of Eigenenergies \nVariable type: real \nDimensions: scalar \nDefault value: 0.005    Sets a tolerance for the ratio of differences of eigenenergies in the line\nminimisation conjugate-gradient algorithm. It compares the decrease of the\neigenenergy due to the last line minimisation, with the one observed for the\nfirst line minimisation. When the ratio is lower than  tolrde , the next\nline minimisations are skipped. \nThe number of line minimisations is limited by  nline  anyhow. \nThis stopping criterion is present for both GS and RF calculations. In RF\ncalculations,  tolrde  is actually doubled before comparing with the above-\nmentioned ratio, for historical reasons.",
            "title": "tolrde"
        },
        {
            "location": "/input_variables/vardev/#use_gemm_nonlop",
            "text": "Mnemonics: USE the GEMM routine for the application of the NON-Local OPerator \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nComment: because it is not usually worth using it unless bandpp is large and it requires additional memory    This keyword tells abinit to use a BLAS routine to speed up the computation of\nthe non-local operator. This requires the precomputation of a large matrix,\nand has a significant memory overhead. In exchange, it provides improved\nperformance when used on several bands at once (Chebyshev or LOBPCG algorithm\nwith  bandpp  The memory overhead is proportional to the number of atoms, the number of\nplane waves, and the number of projectors per atom. It can be mitigated by\ndistributing the array with  npfft  The performance depends crucially on having a good BLAS installed. Provided\nthe BLAS supports OpenMP, this option also yields very good scaling for the\nnonlocal operator.",
            "title": "use_gemm_nonlop"
        },
        {
            "location": "/input_variables/vardev/#use_nonscf_gkk",
            "text": "Mnemonics: USE NON-SCF calculation of GKK matrix elements (electron phonon) \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nComment: Default is 0 for the moment. Do not use non-scf method.    When this flag is activated during a phonon calculation with abinit, all of\nthe perturbations are cycled through, but only the symmetry-irreducible ones\nare calculated self-consistently. For the others the perturbed density is\nrotated by the appropriate symop and the gkk matrix elements are calculated\nnon-self-consistently. As they do not depend on the perturbed wave functions,\nthey are correct from the first iteration, and nstep is set to 1 for those\nperturbations. Note that the resulting 1DEN files are simply the\nrotate/symmetric ones and that the resulting 1WF files are garbage (completely\nunconverged) except the matrix elements in the header (equivalent to GKK\nfiles, but please use the latter much smaller files for el-ph calculations).\nThe new default behavior with  use_nonscf_gkk  = 1 should be transparent for\nthe user, with the same output files but a much quicker execution.  Caveat: Note that very tight convergence of ground state and phonon\ncalculations is necessary to get good GKK matrix elements!  tolwfr  = 1.e-24\nor so is recommended everywhere. There may be problems using use_nonscf_gkk =\n1 with non-symmorphic symmetries - please check (at least) that lifetimes for\nphonons go to 0 for acoustic modes at Gamma.",
            "title": "use_nonscf_gkk"
        },
        {
            "location": "/input_variables/vardev/#usedmft",
            "text": "Mnemonics: USE Dynamical Mean Field Theory \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1, enable the use of DFT+DMFT, see in particular the important\nvariables  dmft_solv ,  dmftbandi ,  dmftbandf ,  dmft_nwli , dmft_nwlo ,  dmft_tollc ,  dmft_tolfreq , and  dmft_iter .  The current implementation uses Wannier functions obtained from   projected\nlocal orbitals  as\ncorrelated orbitals (see  dmftbandi  and  dmftbandf  input variables to\ndefine them).  The Green functions are computed on a mesh of linear Matsubara frequencies.\nHowever, most of the code uses logarithmic Matsubara grid to lower the\ncomputational cost. Both  dmft_nwli  and  dmft_nwlo  are thus convergence\nparameters.  DMFT is currently available for collinear ( nspinor =1) polarized or\nunpolarized calculations ( nspden = nsppol =2 or  nspden = nsppol =1)\nand for non collinear calculations ( nspinor =2, nspden =4, nsppol =1).\nHowever it is not yet available for collinear antiferromagnetic calculations\n( nspden =2, nsppol =1) and non collinear non magnetic calculations\n( nspden =1,  nsppol =1, nspinor =2). CTQMC calculations\n( dmft_solv =5) are not yet possible if  nspinor =2.  Only static calculations without relaxation or dynamics are possible (forces\nand stress are not computed in the scheme: so the computed values should NOT\nbe trusted).  When correlated density matrices are diagonal, all values of  upawu  and jpawu  are possible. If the correlated density matrices are non diagonal,\nonly  jpawu  = 0 is implemented.  Relevant direct output quantities from converged DMFT calculations are total\nenergy and occupation of correlated orbitals. For Hubbard I calculation\n( dmft_solv =2), total and partial spectral functions can be obtained with\nprtdos=1 and can be found in files OUTSpFunc* (where OUT is the root for\noutput files). For CTQMC calculations ( dmft_solv =5), imaginary time\nimpurity Green function are output of the calculations and can be used to\nproduce spectral function using an external Maximum Entropy Code.  A typical DFT+DMFT calculation involves two runs. First, a DFT calculation is\nfully converged (even unoccupied wavefunctions have to be converged). Then,\nthe DFT+DMFT calculation is started using DFT wavefunctions or density files.\nAs DFT+DMFT calculations (with CTQMC) are computationnally expensive, it is\nconvenient to use prtden=-1, to write DEN file at each DFT iteration, in order\nto be able to restart the calculation easily.  For details of the implementation see,   B. Amadon, F. Lechermann, A. Georges,\nF. Jollet, T. O. Wehling, and A. I. Lichtenstein, Phys. Rev. B 77(20), (2008)  , for\nWannier functions and B. Amadon, J. Phys.: Condens. Matter 24 075604 (2012)\n(doi:10.1088/0953-8984/24/7/075604), for self-consistency and Hubbard I\nimplementation. If  usedmft =1 and  nbandkss /=0, then, the DFT+DMFT\ncalculation is not done and only projections are computed at the end of the\ncalculation. They can be used by an external code or used to compute the\nscreened interaction (see variable  ucrpa ).",
            "title": "usedmft"
        },
        {
            "location": "/input_variables/vardev/#useria",
            "text": "Mnemonics: USER Integer variable A \nVariable type: integer \nDimensions: scalar \nDefault value: 0    These are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards). \nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .",
            "title": "useria"
        },
        {
            "location": "/input_variables/vardev/#userib",
            "text": "Mnemonics: USER Integer variable B \nVariable type: integer \nDimensions: scalar \nDefault value: 0    These are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards). \nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .",
            "title": "userib"
        },
        {
            "location": "/input_variables/vardev/#useric",
            "text": "Mnemonics: USER Integer variable C \nVariable type: integer \nDimensions: scalar \nDefault value: 0    These are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards). \nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .",
            "title": "useric"
        },
        {
            "location": "/input_variables/vardev/#userid",
            "text": "Mnemonics: USER Integer variable D \nVariable type: integer \nDimensions: scalar \nDefault value: 0    These are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards). \nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .",
            "title": "userid"
        },
        {
            "location": "/input_variables/vardev/#userie",
            "text": "Mnemonics: USER Integer variable E \nVariable type: integer \nDimensions: scalar \nDefault value: 0    These are user-definable integers which the user may input and then utilize in\nsubroutines of his/her own design. They are not used in the official versions\nof the ABINIT code, and should ease independent developments (hopefully\nintegrated in the official version afterwards). \nInternally, they are available in the dtset structured datatype, e.g.\ndtset%useria .",
            "title": "userie"
        },
        {
            "location": "/input_variables/vardev/#userra",
            "text": "Mnemonics: USER Real variable A \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    These are user-definable with the same purpose as  useria  and cie.",
            "title": "userra"
        },
        {
            "location": "/input_variables/vardev/#userrb",
            "text": "Mnemonics: USER Real variable B \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    These are user-definable with the same purpose as  useria  and cie.",
            "title": "userrb"
        },
        {
            "location": "/input_variables/vardev/#userrc",
            "text": "Mnemonics: USER Real variable C \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    These are user-definable with the same purpose as  useria  and cie.",
            "title": "userrc"
        },
        {
            "location": "/input_variables/vardev/#userrd",
            "text": "Mnemonics: USER Real variable D \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    These are user-definable with the same purpose as  useria  and cie.",
            "title": "userrd"
        },
        {
            "location": "/input_variables/vardev/#userre",
            "text": "Mnemonics: USER Real variable E \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    These are user-definable with the same purpose as  useria  and cie.",
            "title": "userre"
        },
        {
            "location": "/input_variables/vardev/#useylm",
            "text": "Mnemonics: USE YLM (the spherical harmonics) \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  tfkinfunc ==1,\n1 if  usepaw ==1,\n0 otherwise.  When this flag is activated, the non-local operator is applied using an\nalgorithm based on spherical harmonics. Non-local projectors are used with\ntheir usual form:    P  lmn  (r)=Y  lm  (r)*p  ln  (r)  When  useylm =0, the sum over Y_lm can be reduced to a Legendre polynomial\nform.",
            "title": "useylm"
        },
        {
            "location": "/input_variables/vardev/#wfoptalg",
            "text": "Mnemonics: WaveFunction OPTimisation ALGorithm \nVariable type: integer \nDimensions: scalar \nDefault value:  AUTO_FROM_PSP \nComment: 0 when  usepaw =0 (norm-conserving pseudopotentials), 10 when  usepaw =1 (PAW) ; 114 if  paral_kgb =1.    Allows one to choose the algorithm for the optimisation of the wavefunctions. \nThe different possibilities are :   wfoptalg =0 : standard state-by-state conjugate gradient algorithm, with no possibility to parallelize over the states;   wfoptalg =2 : minimisation of the residual with respect to different shifts, in order to cover the whole set of occupied bands, with possibility to parallelize over blocks of states (or bands). The number of states in a block is defined in  nbdblock . THIS IS STILL IN DEVELOPMENT.   wfoptalg =3 : minimisation of the residual with respect to a shift. Available only in the non-self-consistent case  iscf =-2, in order to find eigenvalues and wavefunctions close to a prescribed value.   wfoptalg =4 : (see also  wfoptalg =14), a parallel code based on the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) method of Knyazev.   Reference : A.V. Knyazev, \u201cToward the Optimal Preconditioned Eigensolver : Locally Optimal Block Preconditioned Conjugate Gradient Method\u201d. SIAM Journal on Scientific Computing 23, pp517-541 (2001)   . The implementation rests on the   matlab program by Knyazev   .   Reference A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov, Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in hypre and PETSc (2007). SIAM Journal on Scientific Computing (SISC). 25(5): 2224-2239   . For more information see   F. Bottin, S. Leroux, A. Knyazev, G. Zerah, Large scale ab initio calculations based on three levels of parallelization. (2008). Computational Material Science, 42(2), 329-336.   wfoptalg =10 : (for PAW) standard state-by-state conjugate gradient algorithm, with no possibility to parallelize over the states, but modified scheme described in Kresse, Furthmuller, PRB 54, 11169 (1996) (modified kinetic energy, modified preconditionning, minimal orthogonalization, \u2026) ;   wfoptalg =14 : the recommended for parallel code, the same as  wfoptalg =4 except that the preconditioning of the block vectors does not depend on the kinetic energy of each band, and the orthogonalization after the LOBPCG algorithm is no longer performed. The first modification increases the convergence and the second one the efficiency.   wfoptalg =114 : A new version of  wfoptalg =14 which is more efficient for few blocks and can take advantage of OpenMP if abinit is compiled with a multithreaded linear algebra library. With more than 1 thread  npfft  shoud NOT be used for the time being.   wfoptalg =1 : new algorithm based on Chebyshev filtering, designed for very large number of processors, in the regime where LOBPCG does not scale anymore. It is not able to use preconditionning and therefore might converge slower than other algorithms. By design, it will   not   converge the last bands: it is recommended to use slightly more bands than necessary. For usage with  tolwfr , it is imperative to use  nbdbuf . For more performance, try  use_gemm_nonlop . For more information, see the   performance guide   and the   paper   by A. Levitt and M. Torrent. Status: experimental but usable. Questions and bug reports should be sent to antoine (dot) levitt (at) gmail.com.",
            "title": "wfoptalg"
        },
        {
            "location": "/input_variables/vardev/#xc_denpos",
            "text": "Mnemonics: eXchange-Correlation - DENsity POSitivity value \nVariable type: real \nDimensions: scalar \nDefault value: 1e-14    For the evaluation of the exchange-correlation functionals, the density cannot\nbe negative, or even too small (e.g. the LDA exchange kernel behaves like the\ndensity at power -(2/3), and the density is used at the denominator of\ndifferent factors in GGAs and metaGGAs.  xc_denpos  is the smallest value\nthat the density can assume at the time of the evaluation of a XC functional,\nin ABINIT. When then computed density drops below  xc_denpos  before\nattacking the evaluation of the XC functional, then it will be (only for that\npurpose) replaced by  xc_denpos . Note that the evaluation of the gradients\nor other quantities that are density-dependent is performed before this\nreplacement.  It has been observed that the SCF cycle of the Tran-Blaha mGGA can be quite\nhard to make converge, for systems for which there is some vacuum. In this\ncase, setting  xc_denpos  to 1.0e-7 \u2026 1.0e-6 has been seen to allow good\nconvergence. Of course, this will affect the numerical results somehow, and\none should play a bit with this value to avoid incorrect calculations.",
            "title": "xc_denpos"
        },
        {
            "location": "/input_variables/vardev/#xc_tb09_c",
            "text": "Mnemonics: Value of the c parameter in the eXchange-Correlation TB09 functional \nVariable type: real \nDimensions: scalar \nDefault value: 99.99    The modified Becke-Johnson exchange-correlation functional by Tran and Blaha\n(Phys. Rev. Lett. 102, 226401 (2009)) reads :  V_x(r) = c * V_x^{BR}(r) + (3 c - 2) * 1/pi * sqrt(5/12)  \nsqrt(2*kden(r)/den(r))  in which V_x^{BR}(r) is the Becke-Roussel potential.  In this equation the parameter c can be evaluated at each SCF step according\nto the following equation :  c = alpha + beta * sqrt(1/V_{cell} * \\int_{V_{cell}} |grad(den(r))|/den(r)\nd3r)  The c parameter is evaluated thanks to the previous equation when xc_tb09_c is\nequal to the \u201cmagic\u201d default value 99.99. The c parameter can also be fixed to\nsome (property-optimized or material-optimized) value by using this variable.",
            "title": "xc_tb09_c"
        },
        {
            "location": "/input_variables/vardmft/",
            "text": "dmft_dc\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Double Counting\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nValue of double counting used for DMFT. Only value 1 is activated for the\nmoment and is the FLL double counting.\n\n\ndmft_entropy\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: ENTROPY\n\nVariable type: integer\n\nDefault value: 0\n\nOnly relevant if \nusedmft\n==1 and \ndmft_solv\n==5  \n\n\nIf 1, enable the calculation of the entropy within the DMFT framework and so\nallows the calculation of the total energy (free energy). In the current\nimplementation, this is only possible with \ndmft_solv\n=5 (Continuous Time\nQuantum Monte Carlo). See also the input variable \ndmft_nlambda\n.\n\n\ndmft_iter\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: number of ITERation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nNumber of iterations for the DMFT inner loop.\n\n\ndmft_mxsf\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: MiXing parameter for the SelF energy\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.3  \n\n\nMixing parameter for the simple mixing of the self-energy.\n\n\ndmft_nlambda\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Number of LAMBDA points\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 6\n\nOnly relevant if \nusedmft\n==1 and \ndmft_entropy\n==1  \n\n\ndmft_nlambda\n gives the number of integration points for the\nthermodynamical integration in case of free energy calculation within DMFT.\nIts value must be greater or equal to 3.\n\n\ndmft_nwli\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Number of frequency omega (W) in the LInear mesh\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nNumber of Matsubara frequencies (linear mesh)\n\n\ndmft_nwlo\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Number of frequency omega (W) in the LOg mesh\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nNumber of frequencies in the log mesh.\n\n\ndmft_rslf\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Read SeLF energy\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nFlag to read/write Self-Energy. If put to one, self-energy is written and read\nat each DFT iteration.\n\n\ndmft_solv\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: choice of SOLVer\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 5  \n\n\nChoice of solver for the Impurity model.\n\n\n\n\n0=> No solver and U=0, J=0 (see \nupawu\n and \njpawu\n). \n\n\n1=> LDA+U self-energy is used (for testing purpose) \n\n\n2=> Hubbard one solver. The Hubbard one solver is an approximation which gives a rough description of correlated Mott insulators. It should not be used for metals. \n\n\n5=> Use the Continuous Time Quantum Monte Carlo (CTQMC) solver CT-Hyb of ABINIT in the density density representation, CTQMC calculations are much more time consuming that Hubbard I calculations. Nevertheless, the calculation is fully parallelised. \n\n\n6=> Continuous Time Quantum Monte Carlo (CTQMC) solver CT-Hyb of TRIQS in the density density representation. \n\n\n7=> Continuous Time Quantum Monte Carlo (CTQMC) solver CT-Hyb of TRIQS with the rotationally invariant formulation. \n\n\n\n\nThe CT Hyb algorithm is described in \n Phys. Rev. Lett 97, 076405, (2006)\n\n. For a\ndiscussion of density-density approximation with respect with the\nrotationnally invariant formulation, see e.g. \n Phys. Rev. B 86, 155107 (2012)\n\n.\n\nThe ABINIT/CT Hyb implementation is discussed in \n\nhttp://dx.doi.org/10.1016/j.cpc.2016.04.003\n\n.\n\nThe TRIQS/CT Hyb implementation is described in \n Comp. Phys. Comm. 200, 274\n(2016) \n. Before using it, it has\nto be installed following instructions at\nhttps://triqs.ipht.cnrs.fr/1.3/applications/cthyb/install.html. The current\ninterface is valid for TRIQS 1.3 and TRIQS/CTHYB 1.3.\n\nSee the useful variables for CT-QMC solver : \ndmftctqmc_basis\n,\n\ndmftctqmc_check\n, \ndmftctqmc_correl\n, \ndmftctqmc_gmove\n,\n\ndmftctqmc_grnns\n, \ndmftctqmc_meas\n, \ndmftctqmc_mrka\n,\n\ndmftctqmc_mov\n, \ndmftctqmc_order\n, \ndmftctqmc_triqs_nleg\n,\n\ndmftqmc_l\n, \ndmftqmc_n\n, \ndmftqmc_seed\n, \ndmftqmc_therm\n\n\ndmft_t2g\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: t2g orbitals\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nCan be set to 1 only if in cubic symmetry. It enables one to carry a DFT+DMFT\ncalculations only on t2g orbitals.\n\n\ndmft_tolfreq\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: TOLerance on DFT correlated electron occupation matrix for the definition of the FREQuency grid\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0001  \n\n\nThe LDA occupation matrix for correlated electrons can be computed directly.\nIt can be compared to the calculation of the same quantity using LDA Green\u2019s\nfunction, a sum over Matsubara frequencies and a projection over correlated\norbitals. Because the Matsubara grid is finite, the two quantities differ. If\nthis difference is larger than dmft_tolfreq, then the code stops and an error\nmessage is given.\n\n\ndmft_tollc\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: TOLerance on Local Charge for convergence of the DMFT loop\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1e-05  \n\n\nTolerance for the variation of Local Charge during iterations of the DMFT\nLoop.\n\nThe default value is good for fast calculations. However, to obtain good\nconvergence of the DFT Loop, the DMFT Loop needs a better convergence\ncriterion.\n\n\ndmftbandf\n\u00b6\n\n\nMnemonics: Dynamical Mean Field Theory: BAND: Final\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\ndmftbandf\n is the last band taken into account in the Projected Local\nOrbitals scheme of DFT+DMFT. With \ndmftbandi\n, they define the energy window\nused to define Wannier Functions. (see Amadon, B., Lechermann, F., Georges,\nA., Jollet, F., Wehling, T. O., and Lichtenstein, A. I. Phys. Rev. B 77(20),\n(2008).)\n\n\ndmftbandi\n\u00b6\n\n\nMnemonics: Dynamical Mean Field Theory: BAND: Initial\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\ndmftbandi\n is the first band taken into account in the Projected Local\nOrbitals scheme of LDA+DMFT. With \ndmftbandf\n, they define the energy window\nused to define Wannier Functions. (see Amadon, B., Lechermann, F., Georges,\nA., Jollet, F., Wehling, T. O., and Lichtenstein, A. I. Phys. Rev. B 77(20),\n(2008).)\n\n\ndmftcheck\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: CHECKs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nOnly for developer purposes. (Introduced by B. Amadon, v6.1.0)\n\n\ndmftctqmc_check\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo CHECK\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nCheck the fast calculations during the Monte Carlo simulation with very slow\nbut robust methods. Should only be used for debugging.\n\n\n\n\n0=> No check. \n\n\n1=> Check the overlap calculations (Impurity operator). \n\n\n2=> Check the update of M matrix calculation (Bath operator). \n\n\n3=> Check both. \n\n\n\n\ndmftctqmc_correl\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo CORRELations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nFlag to compute statistics about segments and anti-segments during the\nsimulation. Slow down the simulation.\n\n\n\n\n0=> Nothing done \n\n\n1=> Calculations performed and written in \u201cCorrelation.dat\u201d file \n\n\n\n\ndmftctqmc_gmove\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo Global MOVEs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nDefault is no global moves. The value of this variable is the modulo used to\ntry a global move. A value of 5000 means that a global move is tried every\n5000 Monte Carlo sweep.\n\n\ndmftctqmc_grnns\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo GReeNs NoiSe\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nCompute the statistical noise for each time slice of each green function. This\nis a good approximation only if there is enough Monte Carlo sweeps per cpu.\n\n\n\n\n0=> Nothing \n\n\n1=> Do it and write the noise in the \u201cGtau.dat\u201d file. \n\n\n\n\ndmftctqmc_meas\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo MEASurements\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nThe modulo used to measure the interaction energy and the number of electrons.\nExample : 2 means the measure is perform every two sweeps.\n\n\ndmftctqmc_mov\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo MOVie\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nPrint a latex file per cpu displaying the full simulation. This option should\nonly be use with very small number (<1000) of Monte Carlo sweeps since it\nrequires a lot of I/O band width.\n\n\n\n\n0=> Nothing \n\n\n1=> Write the \u201cMovie_id.dat\u201d file where id is the MPI rank of each process \n\n\n\n\ndmftctqmc_mrka\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo MARKov Analysis\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nMeasure the time evolution of the number of electrons for each orbital and\nperform a fourier transform. The result can be plotted using the\n\u201cMarkov_id.dat\u201d file\n\n\n\n\n0=> Nothing \n\n\n1=> Do it and write the noise in the \u201cMarkov_id.dat\u201d file where id is the rank of each MPI process. \n\n\n\n\ndmftctqmc_order\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo perturbation ORDER\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nPrint a file containing the statistic distribution of the number of segments\nper orbital. The maximal order taken into account \ndmftctqmc_order\n : 50\nmeans that we have the statistic distribution from 0 to 50 segments. The\nresult is written in the \u201cPerturbation.dat\u201d file.\n\n\ndmftctqmc_triqs_nleg\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo perturbation of TRIQS, Number of LEGendre polynomials\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 30\n\nOnly relevant if \ndmft_solv\n==6 or 7  \n\n\nSpecify the number of Legendre polynomials used for the calculation of Green\u2019s\nfunction in CTQMC code from the library TRIQS. Default is 30. The value of\ncoefficients are given in file whose name ending is\n\u201cLegendre_coefficient.dat\u201d. (see also \n Phys. Rev. B 84, 075145 (2010))\n\n\n\ndmftqmc_l\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Quantum Monte Carlo time sLices\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \ndmft_solv\n>=4  \n\n\nNumber of time slices used to represent the time green function. This value\nshould be carefully chosen according to Niquist frequency and the \ntsmear\n\nvalue.\n\n\ndmftqmc_n\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Quantum Monte Carlo Number of sweeps\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \ndmft_solv\n>=4  \n\n\nNumber of Monte Carlo sweeps. Should be at least 10^6.\n\n\ndmftqmc_seed\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Quantum Monte Carlo SEED\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \njdtset\n\nOnly relevant if \ndmft_solv\n>=4  \n\n\nSeed to initilize the random number generator.\n\nShould not be relevant except for testing purpose.\n\nNOTE : If the CT-QMC (\ndmft_solv\n=5) is used on many CPUs, each CPU\ninitializes its random number generator with dmftqmc_seed+rank where rank is\nthe rank of the cpu in the MPI communicator.\n\n\ndmftqmc_therm\n\u00b6\n\n\nMnemonics: Dynamical Mean Fied Theory: Quantum Monte Carlo THERMalization\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1000\n\nOnly relevant if \ndmft_solv\n==5  \n\n\nNumber of Monte Carlo sweeps for the thermalization",
            "title": "DMFT"
        },
        {
            "location": "/input_variables/vardmft/#dmft_dc",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Double Counting \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Value of double counting used for DMFT. Only value 1 is activated for the\nmoment and is the FLL double counting.",
            "title": "dmft_dc"
        },
        {
            "location": "/input_variables/vardmft/#dmft_entropy",
            "text": "Mnemonics: Dynamical Mean Fied Theory: ENTROPY \nVariable type: integer \nDefault value: 0 \nOnly relevant if  usedmft ==1 and  dmft_solv ==5    If 1, enable the calculation of the entropy within the DMFT framework and so\nallows the calculation of the total energy (free energy). In the current\nimplementation, this is only possible with  dmft_solv =5 (Continuous Time\nQuantum Monte Carlo). See also the input variable  dmft_nlambda .",
            "title": "dmft_entropy"
        },
        {
            "location": "/input_variables/vardmft/#dmft_iter",
            "text": "Mnemonics: Dynamical Mean Fied Theory: number of ITERation \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Number of iterations for the DMFT inner loop.",
            "title": "dmft_iter"
        },
        {
            "location": "/input_variables/vardmft/#dmft_mxsf",
            "text": "Mnemonics: Dynamical Mean Fied Theory: MiXing parameter for the SelF energy \nVariable type: real \nDimensions: scalar \nDefault value: 0.3    Mixing parameter for the simple mixing of the self-energy.",
            "title": "dmft_mxsf"
        },
        {
            "location": "/input_variables/vardmft/#dmft_nlambda",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Number of LAMBDA points \nVariable type: integer \nDimensions: scalar \nDefault value: 6 \nOnly relevant if  usedmft ==1 and  dmft_entropy ==1    dmft_nlambda  gives the number of integration points for the\nthermodynamical integration in case of free energy calculation within DMFT.\nIts value must be greater or equal to 3.",
            "title": "dmft_nlambda"
        },
        {
            "location": "/input_variables/vardmft/#dmft_nwli",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Number of frequency omega (W) in the LInear mesh \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Number of Matsubara frequencies (linear mesh)",
            "title": "dmft_nwli"
        },
        {
            "location": "/input_variables/vardmft/#dmft_nwlo",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Number of frequency omega (W) in the LOg mesh \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Number of frequencies in the log mesh.",
            "title": "dmft_nwlo"
        },
        {
            "location": "/input_variables/vardmft/#dmft_rslf",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Read SeLF energy \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Flag to read/write Self-Energy. If put to one, self-energy is written and read\nat each DFT iteration.",
            "title": "dmft_rslf"
        },
        {
            "location": "/input_variables/vardmft/#dmft_solv",
            "text": "Mnemonics: Dynamical Mean Fied Theory: choice of SOLVer \nVariable type: real \nDimensions: scalar \nDefault value: 5    Choice of solver for the Impurity model.   0=> No solver and U=0, J=0 (see  upawu  and  jpawu ).   1=> LDA+U self-energy is used (for testing purpose)   2=> Hubbard one solver. The Hubbard one solver is an approximation which gives a rough description of correlated Mott insulators. It should not be used for metals.   5=> Use the Continuous Time Quantum Monte Carlo (CTQMC) solver CT-Hyb of ABINIT in the density density representation, CTQMC calculations are much more time consuming that Hubbard I calculations. Nevertheless, the calculation is fully parallelised.   6=> Continuous Time Quantum Monte Carlo (CTQMC) solver CT-Hyb of TRIQS in the density density representation.   7=> Continuous Time Quantum Monte Carlo (CTQMC) solver CT-Hyb of TRIQS with the rotationally invariant formulation.    The CT Hyb algorithm is described in   Phys. Rev. Lett 97, 076405, (2006) . For a\ndiscussion of density-density approximation with respect with the\nrotationnally invariant formulation, see e.g.   Phys. Rev. B 86, 155107 (2012) . \nThe ABINIT/CT Hyb implementation is discussed in  \nhttp://dx.doi.org/10.1016/j.cpc.2016.04.003 . \nThe TRIQS/CT Hyb implementation is described in   Comp. Phys. Comm. 200, 274\n(2016)  . Before using it, it has\nto be installed following instructions at\nhttps://triqs.ipht.cnrs.fr/1.3/applications/cthyb/install.html. The current\ninterface is valid for TRIQS 1.3 and TRIQS/CTHYB 1.3. \nSee the useful variables for CT-QMC solver :  dmftctqmc_basis , dmftctqmc_check ,  dmftctqmc_correl ,  dmftctqmc_gmove , dmftctqmc_grnns ,  dmftctqmc_meas ,  dmftctqmc_mrka , dmftctqmc_mov ,  dmftctqmc_order ,  dmftctqmc_triqs_nleg , dmftqmc_l ,  dmftqmc_n ,  dmftqmc_seed ,  dmftqmc_therm",
            "title": "dmft_solv"
        },
        {
            "location": "/input_variables/vardmft/#dmft_t2g",
            "text": "Mnemonics: Dynamical Mean Fied Theory: t2g orbitals \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Can be set to 1 only if in cubic symmetry. It enables one to carry a DFT+DMFT\ncalculations only on t2g orbitals.",
            "title": "dmft_t2g"
        },
        {
            "location": "/input_variables/vardmft/#dmft_tolfreq",
            "text": "Mnemonics: Dynamical Mean Fied Theory: TOLerance on DFT correlated electron occupation matrix for the definition of the FREQuency grid \nVariable type: real \nDimensions: scalar \nDefault value: 0.0001    The LDA occupation matrix for correlated electrons can be computed directly.\nIt can be compared to the calculation of the same quantity using LDA Green\u2019s\nfunction, a sum over Matsubara frequencies and a projection over correlated\norbitals. Because the Matsubara grid is finite, the two quantities differ. If\nthis difference is larger than dmft_tolfreq, then the code stops and an error\nmessage is given.",
            "title": "dmft_tolfreq"
        },
        {
            "location": "/input_variables/vardmft/#dmft_tollc",
            "text": "Mnemonics: Dynamical Mean Fied Theory: TOLerance on Local Charge for convergence of the DMFT loop \nVariable type: real \nDimensions: scalar \nDefault value: 1e-05    Tolerance for the variation of Local Charge during iterations of the DMFT\nLoop. \nThe default value is good for fast calculations. However, to obtain good\nconvergence of the DFT Loop, the DMFT Loop needs a better convergence\ncriterion.",
            "title": "dmft_tollc"
        },
        {
            "location": "/input_variables/vardmft/#dmftbandf",
            "text": "Mnemonics: Dynamical Mean Field Theory: BAND: Final \nVariable type: integer \nDimensions: scalar \nDefault value: 0    dmftbandf  is the last band taken into account in the Projected Local\nOrbitals scheme of DFT+DMFT. With  dmftbandi , they define the energy window\nused to define Wannier Functions. (see Amadon, B., Lechermann, F., Georges,\nA., Jollet, F., Wehling, T. O., and Lichtenstein, A. I. Phys. Rev. B 77(20),\n(2008).)",
            "title": "dmftbandf"
        },
        {
            "location": "/input_variables/vardmft/#dmftbandi",
            "text": "Mnemonics: Dynamical Mean Field Theory: BAND: Initial \nVariable type: integer \nDimensions: scalar \nDefault value: 0    dmftbandi  is the first band taken into account in the Projected Local\nOrbitals scheme of LDA+DMFT. With  dmftbandf , they define the energy window\nused to define Wannier Functions. (see Amadon, B., Lechermann, F., Georges,\nA., Jollet, F., Wehling, T. O., and Lichtenstein, A. I. Phys. Rev. B 77(20),\n(2008).)",
            "title": "dmftbandi"
        },
        {
            "location": "/input_variables/vardmft/#dmftcheck",
            "text": "Mnemonics: Dynamical Mean Fied Theory: CHECKs \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Only for developer purposes. (Introduced by B. Amadon, v6.1.0)",
            "title": "dmftcheck"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_check",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo CHECK \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  dmft_solv ==5    Check the fast calculations during the Monte Carlo simulation with very slow\nbut robust methods. Should only be used for debugging.   0=> No check.   1=> Check the overlap calculations (Impurity operator).   2=> Check the update of M matrix calculation (Bath operator).   3=> Check both.",
            "title": "dmftctqmc_check"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_correl",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo CORRELations \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  dmft_solv ==5    Flag to compute statistics about segments and anti-segments during the\nsimulation. Slow down the simulation.   0=> Nothing done   1=> Calculations performed and written in \u201cCorrelation.dat\u201d file",
            "title": "dmftctqmc_correl"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_gmove",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo Global MOVEs \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  dmft_solv ==5    Default is no global moves. The value of this variable is the modulo used to\ntry a global move. A value of 5000 means that a global move is tried every\n5000 Monte Carlo sweep.",
            "title": "dmftctqmc_gmove"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_grnns",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo GReeNs NoiSe \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  dmft_solv ==5    Compute the statistical noise for each time slice of each green function. This\nis a good approximation only if there is enough Monte Carlo sweeps per cpu.   0=> Nothing   1=> Do it and write the noise in the \u201cGtau.dat\u201d file.",
            "title": "dmftctqmc_grnns"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_meas",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo MEASurements \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  dmft_solv ==5    The modulo used to measure the interaction energy and the number of electrons.\nExample : 2 means the measure is perform every two sweeps.",
            "title": "dmftctqmc_meas"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_mov",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo MOVie \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  dmft_solv ==5    Print a latex file per cpu displaying the full simulation. This option should\nonly be use with very small number (<1000) of Monte Carlo sweeps since it\nrequires a lot of I/O band width.   0=> Nothing   1=> Write the \u201cMovie_id.dat\u201d file where id is the MPI rank of each process",
            "title": "dmftctqmc_mov"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_mrka",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo MARKov Analysis \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  dmft_solv ==5    Measure the time evolution of the number of electrons for each orbital and\nperform a fourier transform. The result can be plotted using the\n\u201cMarkov_id.dat\u201d file   0=> Nothing   1=> Do it and write the noise in the \u201cMarkov_id.dat\u201d file where id is the rank of each MPI process.",
            "title": "dmftctqmc_mrka"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_order",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo perturbation ORDER \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  dmft_solv ==5    Print a file containing the statistic distribution of the number of segments\nper orbital. The maximal order taken into account  dmftctqmc_order  : 50\nmeans that we have the statistic distribution from 0 to 50 segments. The\nresult is written in the \u201cPerturbation.dat\u201d file.",
            "title": "dmftctqmc_order"
        },
        {
            "location": "/input_variables/vardmft/#dmftctqmc_triqs_nleg",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Continuous Time Quantum Monte Carlo perturbation of TRIQS, Number of LEGendre polynomials \nVariable type: integer \nDimensions: scalar \nDefault value: 30 \nOnly relevant if  dmft_solv ==6 or 7    Specify the number of Legendre polynomials used for the calculation of Green\u2019s\nfunction in CTQMC code from the library TRIQS. Default is 30. The value of\ncoefficients are given in file whose name ending is\n\u201cLegendre_coefficient.dat\u201d. (see also   Phys. Rev. B 84, 075145 (2010))",
            "title": "dmftctqmc_triqs_nleg"
        },
        {
            "location": "/input_variables/vardmft/#dmftqmc_l",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Quantum Monte Carlo time sLices \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  dmft_solv >=4    Number of time slices used to represent the time green function. This value\nshould be carefully chosen according to Niquist frequency and the  tsmear \nvalue.",
            "title": "dmftqmc_l"
        },
        {
            "location": "/input_variables/vardmft/#dmftqmc_n",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Quantum Monte Carlo Number of sweeps \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  dmft_solv >=4    Number of Monte Carlo sweeps. Should be at least 10^6.",
            "title": "dmftqmc_n"
        },
        {
            "location": "/input_variables/vardmft/#dmftqmc_seed",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Quantum Monte Carlo SEED \nVariable type: integer \nDimensions: scalar \nDefault value:  jdtset \nOnly relevant if  dmft_solv >=4    Seed to initilize the random number generator. \nShould not be relevant except for testing purpose. \nNOTE : If the CT-QMC ( dmft_solv =5) is used on many CPUs, each CPU\ninitializes its random number generator with dmftqmc_seed+rank where rank is\nthe rank of the cpu in the MPI communicator.",
            "title": "dmftqmc_seed"
        },
        {
            "location": "/input_variables/vardmft/#dmftqmc_therm",
            "text": "Mnemonics: Dynamical Mean Fied Theory: Quantum Monte Carlo THERMalization \nVariable type: integer \nDimensions: scalar \nDefault value: 1000 \nOnly relevant if  dmft_solv ==5    Number of Monte Carlo sweeps for the thermalization",
            "title": "dmftqmc_therm"
        },
        {
            "location": "/input_variables/vareph/",
            "text": "asr\n\u00b6\n\n\nMnemonics: Acoustic Sum Rule\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nGovern the imposition of the Acoustic Sum Rule (ASR) in phonon calculations.\nSame meaning as the corresponding anaddb variable.\n\n\nchneut\n\u00b6\n\n\nMnemonics: CHarge NEUTrality treatment \n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nSet the treatment of the Charge Neutrality requirement for the effective\ncharges. Same meaning as the corresponding anaddb variable.\n\n\nddb_ngqpt\n\u00b6\n\n\nMnemonics: Derivative DatabBase: Number of Grid points for Q-PoinTs\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]  \n\n\nThis variable is mandatory when \noptdriver\n==7. It defines the number of\ndivisions in the (homogeneous) q-mesh used to generate the DDB file. See also\nthe description of the \ngetddb\n input variable.\n\n\nddb_shiftq\n\u00b6\n\n\nMnemonics: Derivative DataBase: SHIFT of the Q-points \n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: [0.0, 0.0, 0.0]  \n\n\nOnly relevant when \noptdriver\n==7. It defines the shift in the q-mesh used\nto generate the DDB file, which is defined by the \nddb_ngqpt\n input\nvariable. See \nshiftk\n for more information on the definition.\n\n\ndipdip\n\u00b6\n\n\nMnemonics: DIPole-DIPole interaction \n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis variable defines the treatment of the dipole-dipole interaction. Same\nmeaning as the corresponding anaddb variable\n\n\neph_extrael\n\u00b6\n\n\nMnemonics: Electron-PHonon: EXTRA ELectrons\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\neph_fermie\n\u00b6\n\n\nMnemonics: Electron-PHonon: FERMI Energy\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nThis variable can be used to change the value of the Fermi level when\nperforming electron-phonon calculations with \noptdriver\n==7. This variable\nhas effect only if set to a non-zero value. See also \neph_extrael\n.\n\n\neph_fsewin\n\u00b6\n\n\nMnemonics: Electron-Phonon: Fermi Surface Energy WINdow\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.01 Hartree  \n\n\nThis variable defines the energy window around the Fermi level used for e-ph\ncalculations (\noptdriver\n = 7). Only the states located in the energy range\n[efermi - eph_fsewin, efermi + eph_fsewin] are included in the e-ph\ncalculation.\n\n\nRelated input variables: \neph_intmeth\n, \neph_fsmear\n, \neph_extrael\n and\n\neph_fermie\n.\n\n\neph_fsmear\n\u00b6\n\n\nMnemonics: Electron-PHonon: Fermi surface SMEARing\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.01 Hartree\n\nOnly relevant if \neph_intmeth\n == 1  \n\n\nThis variable defines the gaussian broadening used for the integration over\nthe Fermi surface when \neph_intmeth\n == 1.\n\n\neph_intmeth\n\u00b6\n\n\nMnemonics: Electron-Phonon: INTegration METHod\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2  \n\n\nThis variable defines the technique for the integration on the Fermi surface\nof electron-phonon quantities.\n\n\n1 for Gaussian technique with broadening factor \neph_fsmear\n. 2 for\ntetrahedron method.\n\n\nSee also \neph_fsewin\n, \neph_extrael\n and \neph_fermie\n.\n\n\neph_mustar\n\u00b6\n\n\nMnemonics: Electron-PHonon : MU STAR (electron-electron interaction strength)\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.1  \n\n\nAverage electron-electron interaction strength, for the computation of the\nsuperconducting Tc using Mc-Millan\u2019s formula.\n\n\neph_ngqpt_fine\n\u00b6\n\n\nMnemonics: Electron-PHonon : Number of Grid Q-PoinTs in FINE grid.\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]  \n\n\nThis variable activates the interpolation of the first-order variation of the\nself-consistent potential in the electron-phonon code. If eph_nqgpt_fine\ndiffers from [0, 0, 0], the code will use the Fourier transform to interpolate\nthe DFPT potentials on this fine q-mesh starting from the irreducible set of\nq-points read from the DDB file. This approach is similar to the one used to\ninterpolate the interatomic force constants in q-space. If eph_ngqpt_fine is\nnot given, the EPH code uses the list of irreducible q-points reported in the\nDDB file (default behavior).\n\n\neph_transport\n\u00b6\n\n\nMnemonics: Electron-PHonon: TRANSPORT flag\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nNB - this does not work yet. This variable can be used to turn on the\ncalculation of transport quantities in the eph module of abinit. Value of 1\ncorresponds to elastic LOVA as in the PRB by Savrasov and Savrasov\n\n\nph_intmeth\n\u00b6\n\n\nMnemonics: PHonons: INTegration METHod\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2  \n\n\nSelect the integration technique for computing the phonon DOS and the\nEliashberg function a2fF(w).\n\n\n1 for Gaussian scheme (see also \nph_smear\n).  \n\n\n2 for tetrahedron method (no other input is needed but requires at least 4\nq-points in the BZ)\n\n\nph_ndivsm\n\u00b6\n\n\nMnemonics: PHonons: Number of DIVisions for sampling the SMallest segment\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 20  \n\n\nThis variable is used in conjunction with \nph_nqpath\n and \nph_qpath\n to\ndefine the q-path used for phonon band structures and phonon linewidths. It\ngives the number of points used to sample the smallest segment in the q-path\nspecified by \nph_qpath\n.\n\n\nph_nqpath\n\u00b6\n\n\nMnemonics: PHonons: Number of Q-points defining the PATH\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis integer defines the number of points in the \nph_qpath\n array.\n\n\nph_nqshift\n\u00b6\n\n\nMnemonics: PHonons: Number of Q-SHIFTs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis variable defines the number of shifts in the q-mesh used for the phonon\nDOS and for the Eliashberg functions (see \nph_ngqpt\n). If not given, the\ncode assumes a Gamma-centered mesh. The shifts are specified by \nph_qshift\n.\n\n\nph_qshift\n\u00b6\n\n\nMnemonics: PHonons: Q-SHIFTs for mesh.\n\nVariable type: real\n\nDimensions: (3,ph_nqshift)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \nph_nqshift\n  \n\n\nThis array gives the shifts to be used to construct the q-mesh for computing\nthe phonon DOS and the Eliashberg functions (see also \nph_nqshift\n. If not\ngiven, a Gamma-centered mesh is used.\n\n\nph_smear\n\u00b6\n\n\nMnemonics: PHonons: SMEARing factor\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.00002 Hartree\n\nOnly relevant if \nph_intmeth\n==1  \n\n\nThe gaussian broadening used for the integration of the phonon DOS and the\nEliashberg function. See also \nph_intmeth\n and \nph_ngqpt\n.\n\n\nph_wstep\n\u00b6\n\n\nMnemonics: PHonons: frequency(W)  STEP.\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.1 meV  \n\n\nThe step used to generate the (linear) frequency mesh for the phonon DOS and\nthe Eliashberg function. The extrema of the mesh are automatically computed by\nthe code.\n\n\nprtphbands\n\u00b6\n\n\nMnemonics: PRinT PHonon BANDS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis option activates the output of the phonon frequencies in the EPH code.\nPossible values:\n\n\n\n\n0 Disable the output of the phonon frequencies.\n\n\n1 Write frequencies in xmgrace format. A file with extension \nPHBANDS.agr\n is produced. Use \nxmgrace file_PHBANDS.agr\n to visualize the data\n\n\n2 Write frequencies in gnuplot format. The code produces a \nPHBANDS.dat\n file with the eigenvalues and a \nPHBANDS.gnuplot\n script. Use \ngnuplot file_PHBANDS.gnuplot\n to visualize the phonon band structure.\n\n\n\n\nprtphdos\n\u00b6\n\n\nMnemonics: PRinT the PHonon Density Of States\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nPrint the phonon density of states. It is activated by default when\n\noptdriver\n==7.\n\n\nprtphsurf\n\u00b6\n\n\nMnemonics: PRinT PHonon iso-SURFace\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nPrint a bxsf file (Xcrysden format) with the (interpolated) phonon frequencies\ncomputed of the q-mesh determined by \nph_ngqpt\n. The file can be use to\nvisualize isosurfaces with Xcrysden or other similar tools supporting the bxsf\nformat. Note that the (dense) q-mesh must be Gamma-centered, shifted meshs are\nnot supported by Xcrysden. This variable requires \noptdriver\n==7.\n\n\nsymdynmat\n\u00b6\n\n\nMnemonics: SYMmetrize the DYNamical MATrix\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nIf symdynmat is equal to 1, the dynamical matrix is symmetrized before the\ndiagonalization (same meaning as the corresponding anaddb variable). Note that\nsymdynmat==1 will automatically enable the symmetrization of the electron-\nphonon linewidths.",
            "title": "Electron-Phonon"
        },
        {
            "location": "/input_variables/vareph/#asr",
            "text": "Mnemonics: Acoustic Sum Rule \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Govern the imposition of the Acoustic Sum Rule (ASR) in phonon calculations.\nSame meaning as the corresponding anaddb variable.",
            "title": "asr"
        },
        {
            "location": "/input_variables/vareph/#chneut",
            "text": "Mnemonics: CHarge NEUTrality treatment  \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Set the treatment of the Charge Neutrality requirement for the effective\ncharges. Same meaning as the corresponding anaddb variable.",
            "title": "chneut"
        },
        {
            "location": "/input_variables/vareph/#ddb_ngqpt",
            "text": "Mnemonics: Derivative DatabBase: Number of Grid points for Q-PoinTs \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0]    This variable is mandatory when  optdriver ==7. It defines the number of\ndivisions in the (homogeneous) q-mesh used to generate the DDB file. See also\nthe description of the  getddb  input variable.",
            "title": "ddb_ngqpt"
        },
        {
            "location": "/input_variables/vareph/#ddb_shiftq",
            "text": "Mnemonics: Derivative DataBase: SHIFT of the Q-points  \nVariable type: real \nDimensions: (3) \nDefault value: [0.0, 0.0, 0.0]    Only relevant when  optdriver ==7. It defines the shift in the q-mesh used\nto generate the DDB file, which is defined by the  ddb_ngqpt  input\nvariable. See  shiftk  for more information on the definition.",
            "title": "ddb_shiftq"
        },
        {
            "location": "/input_variables/vareph/#dipdip",
            "text": "Mnemonics: DIPole-DIPole interaction  \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This variable defines the treatment of the dipole-dipole interaction. Same\nmeaning as the corresponding anaddb variable",
            "title": "dipdip"
        },
        {
            "location": "/input_variables/vareph/#eph_extrael",
            "text": "Mnemonics: Electron-PHonon: EXTRA ELectrons \nVariable type: real \nDimensions: scalar \nDefault value: 0.0",
            "title": "eph_extrael"
        },
        {
            "location": "/input_variables/vareph/#eph_fermie",
            "text": "Mnemonics: Electron-PHonon: FERMI Energy \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    This variable can be used to change the value of the Fermi level when\nperforming electron-phonon calculations with  optdriver ==7. This variable\nhas effect only if set to a non-zero value. See also  eph_extrael .",
            "title": "eph_fermie"
        },
        {
            "location": "/input_variables/vareph/#eph_fsewin",
            "text": "Mnemonics: Electron-Phonon: Fermi Surface Energy WINdow \nVariable type: real \nDimensions: scalar \nDefault value: 0.01 Hartree    This variable defines the energy window around the Fermi level used for e-ph\ncalculations ( optdriver  = 7). Only the states located in the energy range\n[efermi - eph_fsewin, efermi + eph_fsewin] are included in the e-ph\ncalculation.  Related input variables:  eph_intmeth ,  eph_fsmear ,  eph_extrael  and eph_fermie .",
            "title": "eph_fsewin"
        },
        {
            "location": "/input_variables/vareph/#eph_fsmear",
            "text": "Mnemonics: Electron-PHonon: Fermi surface SMEARing \nVariable type: real \nDimensions: scalar \nDefault value: 0.01 Hartree \nOnly relevant if  eph_intmeth  == 1    This variable defines the gaussian broadening used for the integration over\nthe Fermi surface when  eph_intmeth  == 1.",
            "title": "eph_fsmear"
        },
        {
            "location": "/input_variables/vareph/#eph_intmeth",
            "text": "Mnemonics: Electron-Phonon: INTegration METHod \nVariable type: integer \nDimensions: scalar \nDefault value: 2    This variable defines the technique for the integration on the Fermi surface\nof electron-phonon quantities.  1 for Gaussian technique with broadening factor  eph_fsmear . 2 for\ntetrahedron method.  See also  eph_fsewin ,  eph_extrael  and  eph_fermie .",
            "title": "eph_intmeth"
        },
        {
            "location": "/input_variables/vareph/#eph_mustar",
            "text": "Mnemonics: Electron-PHonon : MU STAR (electron-electron interaction strength) \nVariable type: real \nDimensions: scalar \nDefault value: 0.1    Average electron-electron interaction strength, for the computation of the\nsuperconducting Tc using Mc-Millan\u2019s formula.",
            "title": "eph_mustar"
        },
        {
            "location": "/input_variables/vareph/#eph_ngqpt_fine",
            "text": "Mnemonics: Electron-PHonon : Number of Grid Q-PoinTs in FINE grid. \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0]    This variable activates the interpolation of the first-order variation of the\nself-consistent potential in the electron-phonon code. If eph_nqgpt_fine\ndiffers from [0, 0, 0], the code will use the Fourier transform to interpolate\nthe DFPT potentials on this fine q-mesh starting from the irreducible set of\nq-points read from the DDB file. This approach is similar to the one used to\ninterpolate the interatomic force constants in q-space. If eph_ngqpt_fine is\nnot given, the EPH code uses the list of irreducible q-points reported in the\nDDB file (default behavior).",
            "title": "eph_ngqpt_fine"
        },
        {
            "location": "/input_variables/vareph/#eph_transport",
            "text": "Mnemonics: Electron-PHonon: TRANSPORT flag \nVariable type: integer \nDimensions: scalar \nDefault value: 0    NB - this does not work yet. This variable can be used to turn on the\ncalculation of transport quantities in the eph module of abinit. Value of 1\ncorresponds to elastic LOVA as in the PRB by Savrasov and Savrasov",
            "title": "eph_transport"
        },
        {
            "location": "/input_variables/vareph/#ph_intmeth",
            "text": "Mnemonics: PHonons: INTegration METHod \nVariable type: integer \nDimensions: scalar \nDefault value: 2    Select the integration technique for computing the phonon DOS and the\nEliashberg function a2fF(w).  1 for Gaussian scheme (see also  ph_smear ).    2 for tetrahedron method (no other input is needed but requires at least 4\nq-points in the BZ)",
            "title": "ph_intmeth"
        },
        {
            "location": "/input_variables/vareph/#ph_ndivsm",
            "text": "Mnemonics: PHonons: Number of DIVisions for sampling the SMallest segment \nVariable type: integer \nDimensions: scalar \nDefault value: 20    This variable is used in conjunction with  ph_nqpath  and  ph_qpath  to\ndefine the q-path used for phonon band structures and phonon linewidths. It\ngives the number of points used to sample the smallest segment in the q-path\nspecified by  ph_qpath .",
            "title": "ph_ndivsm"
        },
        {
            "location": "/input_variables/vareph/#ph_nqpath",
            "text": "Mnemonics: PHonons: Number of Q-points defining the PATH \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This integer defines the number of points in the  ph_qpath  array.",
            "title": "ph_nqpath"
        },
        {
            "location": "/input_variables/vareph/#ph_nqshift",
            "text": "Mnemonics: PHonons: Number of Q-SHIFTs \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This variable defines the number of shifts in the q-mesh used for the phonon\nDOS and for the Eliashberg functions (see  ph_ngqpt ). If not given, the\ncode assumes a Gamma-centered mesh. The shifts are specified by  ph_qshift .",
            "title": "ph_nqshift"
        },
        {
            "location": "/input_variables/vareph/#ph_qshift",
            "text": "Mnemonics: PHonons: Q-SHIFTs for mesh. \nVariable type: real \nDimensions: (3,ph_nqshift) \nDefault value: [0, 0, 0] \nOnly relevant if  ph_nqshift     This array gives the shifts to be used to construct the q-mesh for computing\nthe phonon DOS and the Eliashberg functions (see also  ph_nqshift . If not\ngiven, a Gamma-centered mesh is used.",
            "title": "ph_qshift"
        },
        {
            "location": "/input_variables/vareph/#ph_smear",
            "text": "Mnemonics: PHonons: SMEARing factor \nVariable type: real \nDimensions: scalar \nDefault value: 0.00002 Hartree \nOnly relevant if  ph_intmeth ==1    The gaussian broadening used for the integration of the phonon DOS and the\nEliashberg function. See also  ph_intmeth  and  ph_ngqpt .",
            "title": "ph_smear"
        },
        {
            "location": "/input_variables/vareph/#ph_wstep",
            "text": "Mnemonics: PHonons: frequency(W)  STEP. \nVariable type: real \nDimensions: scalar \nDefault value: 0.1 meV    The step used to generate the (linear) frequency mesh for the phonon DOS and\nthe Eliashberg function. The extrema of the mesh are automatically computed by\nthe code.",
            "title": "ph_wstep"
        },
        {
            "location": "/input_variables/vareph/#prtphbands",
            "text": "Mnemonics: PRinT PHonon BANDS \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This option activates the output of the phonon frequencies in the EPH code.\nPossible values:   0 Disable the output of the phonon frequencies.  1 Write frequencies in xmgrace format. A file with extension  PHBANDS.agr  is produced. Use  xmgrace file_PHBANDS.agr  to visualize the data  2 Write frequencies in gnuplot format. The code produces a  PHBANDS.dat  file with the eigenvalues and a  PHBANDS.gnuplot  script. Use  gnuplot file_PHBANDS.gnuplot  to visualize the phonon band structure.",
            "title": "prtphbands"
        },
        {
            "location": "/input_variables/vareph/#prtphdos",
            "text": "Mnemonics: PRinT the PHonon Density Of States \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Print the phonon density of states. It is activated by default when optdriver ==7.",
            "title": "prtphdos"
        },
        {
            "location": "/input_variables/vareph/#prtphsurf",
            "text": "Mnemonics: PRinT PHonon iso-SURFace \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Print a bxsf file (Xcrysden format) with the (interpolated) phonon frequencies\ncomputed of the q-mesh determined by  ph_ngqpt . The file can be use to\nvisualize isosurfaces with Xcrysden or other similar tools supporting the bxsf\nformat. Note that the (dense) q-mesh must be Gamma-centered, shifted meshs are\nnot supported by Xcrysden. This variable requires  optdriver ==7.",
            "title": "prtphsurf"
        },
        {
            "location": "/input_variables/vareph/#symdynmat",
            "text": "Mnemonics: SYMmetrize the DYNamical MATrix \nVariable type: integer \nDimensions: scalar \nDefault value: 1    If symdynmat is equal to 1, the dynamical matrix is symmetrized before the\ndiagonalization (same meaning as the corresponding anaddb variable). Note that\nsymdynmat==1 will automatically enable the symmetrization of the electron-\nphonon linewidths.",
            "title": "symdynmat"
        },
        {
            "location": "/input_variables/varff/",
            "text": "atvshift\n\u00b6\n\n\nMnemonics: ATomic potential (V) energy SHIFTs\n\nVariable type: real\n\nDimensions: (\nnatvshift\n,\nnsppol\n,\nnatom\n)\n\nDefault value: *0.0d0\n\nOnly relevant if \nusepawu\n /= 0 and \nnatvshift\n in [5,7]  \n\n\nDefines for each atom and each spin channel (at present, can only be used with\n\nnsppol\n=1 or 2, like the +U scheme), a possible potential shift, for the d\n(with \nlpawu\n=2, \nnatvshift\n=5), or f states (with \nlpawu\n=3,\n\nnatvshift\n=7). In the case of d states, and 2 spin channels, a set of 10\nnumbers for each atom must be defined. The first set of 5 numbers corresponds\nto real spherical harmonics m=-2 to m=+2 for the spin-up channel, the second\nset of 5 numbers corresponds to real spherical harmonics m=-2 to m=+2 for the\nspin-down channel. In the case of f states, the same ordering applies, for\nsets of 7 numbers, corresponding to m=-3 to m=+3.\n\n\nusepawu\n should be non-zero, \nlpawu\n should be 2 or 3.\n\n\nbdberry\n\u00b6\n\n\nMnemonics: BanD limits for BERRY phase\n\nVariable type: integer\n\nDimensions: (4)\n\nDefault value: 4*0\n\nOnly relevant if \nberryopt\n in [1, 2, 3] and \nnberry\n > 0  \n\n\nGive the lower band and the upper band of the set of bands for which the Berry\nphase must be computed. Irrelevant if \nnberry\n is not positive. When\n\nnsppol\n is 1 (no spin-polarisation), only the two first numbers, giving the\nlower and highest bands, are significant. Their occupation number is assumed\nto be 2. When \nnsppol\n is 2 (spin-polarized calculation), the two first\nnumbers give the lowest and highest bands for spin up, and the third and\nfourth numbers give the lowest and highest bands for spin down. Their\noccupation number is assumed to be 1 .\n\n\nPresently, \nbdberry\n MUST be initialized by the user in case of a Berry\nphase calculation with \nberryopt\n = 1, 2, or 3: the above-mentioned default\nwill cause an early exit.\n\n\nberryopt\n\u00b6\n\n\nMnemonics: BERRY phase OPTions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nSpecifies the use of Berry phase for the computation of either the\npolarization, the derivatives with respect to the wavevector, or finite\nelectric field calculations.\n\n\n\n\n0 => no computation of expressions relying on a Berry phase (default) \n\n\n1 => the computation of Berry phases is activated (berryphase routine) \n\n\n2 => the computation of derivatives with respect to the wavevector, thanks to the Berry phase finite-difference formula, is activated (uderiv routine) \n\n\n3 => same as option 1 and 2 together \n\nNote that options 1 to 3 require the use of a serial build of Abinit.\n\n\n-1 => alternative computation of Berry phases (berryphase_new routine) \n\n\n-2 => alternative computation of derivatives with respect to the wavevector, thanks to the Berry phase finite-difference formula (berryphase_new routine) \n\n\n-3 => same as option -1 and -2 together \n\nOptions -1 to -3 permit use of a parallel build and will be preferred by most users.\n\n\n4 => finite electric field calculation (unreduced E-field) \n\n\n6 => finite electric displacement field calculation (unreduced D-field) \n\n\n14 => finite reduced electric field calculation \n\n\n16 => finite electric displacement field calculation \n\n\n17 => mixed electric boundary condition: finite reduced electric field in some directions, finite reduced electric displacement field along other directions. See variable \njfielddir\n for more details. \n\n\n\n\nOther related input variables are :\n\n\n\n\nin case of \nberryopt\n=1,2, or 3 : \nbdberry\n and \nkberry\n; also, \nnberry\n must be larger than 0; \n\n\nin case of \nberryopt\n=-1,-2, or -3 : the variable \nrfdir\n must be used to specify the primitive vector along which the projection of the polarization or the ddk will be computed. For example if \nberryopt\n=-1 and \nrfdir\n=1 0 0, the projection of the polarization along the reciprocal lattice vector G_1 is computed. In case \nrfdir\n=1 1 1, ABINIT computes the projection of P along G_1, G_2 and G_3 and transforms the results to cartesian coordinates; \n\n\nin cases where \nberryopt\n is negative, \nberrystep\n allow a computation of multiple-step Berry phase in order to accelerate the convergence. \n\n\nefield\n and \nrfdir\n in case of \nberryopt\n=4 ; \n\n\n\n\nThe cases \nberryopt\n=-1,-2,-3, 4, 6, 7, 14, 16, and 17 have to be used with\n\noccopt\n=1.\n\n\nThe cases \nberryopt\n=-1 and 4, 6, 7, 14, 16, 17 are compatible with PAW,\nhowevever, if in these cases one uses \nkptopt\n/=3, one must also use only\nsymmorphic symmetries (either because the space group is symmorphic or the\nvariable \nsymmorphi\n is set to zero).\n\n\nFor a phonon calculation under a finite electric field, respect the following\nprocedure.\n\n\n\n\n1. Run a scf ground-state calculation at zero electric field to get wavefunctions to initialize the ground-state calculation in finite electric fields. \n\n\n2. Run a scf ground-state calculation in finite electric field. The electric field is controlled by the input variable \nefield\n. \nberryopt\n should be 4. The input variable \nkptopt\n should be set to be 2. \n\n\n3. Based on the wave functions obtained in step (2), perform phonon calculation by setting \nberryopt\n=4, \nkptopt\n=3 and The same value of \nefield\n than in step 2. \nnsym\n should be set to 1 currently but this restriction may be removed later . The other parameters are the same as phonon calculation at zero electric field. \n\n\nNote : the choice of k-point sampling N x N x N should be the same in the three runs and N should be an even number. \n\n\n\n\nIn case of finite electric and displacement field calculations\n(\nberryopt\n=4,6,7,14,16,17), see also the input variables \nberrysav\n,\n\ndfield\n, \nred_dfield\n, \nred_efield\n, \nddamp\n\n\nberrysav\n\u00b6\n\n\nMnemonics: BERRY SAVe\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\n\n\n0 => for finite electric field calculation (\nberryopt\n=4/14), the polarization branch will be chosen on each iteration from (-pi, pi); for finite electric displacement field calculation(\nberryopt\n=6/7/16/17), the polarization will be chosen to minimize the internal energy. \n\n\n1 => the polarization will be kept in the same branch on each iteration. At the end of the run, a file \u201cPOLSAVE\u201d will be saved containing the reduced polarization in atomic units. Note: Make sure that \u201cPOLSAVE\u201d is empty or it does not exist before the calculation, or else that it specifies the desired polarization branch. \n\n\n\n\nberrystep\n\u00b6\n\n\nMnemonics: BERRY phase : multiple STEP\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if 0 > \nberryopt\n  \n\n\nIf \nberryopt\n is negative, this variable is used to compute berry phases\nusing multiple discrete steps, in order to accelerate convergence. The single-\nstep berry phase is the standard calculation using strings of k-points based\non overlap of Bloch function separated by dk, while the two-step berry phase\nuse strings use overlaps based on dk and 2\ndk, the three-step use overlaps\nbased on dk, 2\ndk and 3*dk\u2026\n\n\nThe default value of this variable is 1, meaning that only the single-step\nberry phase calculation is done. If a larger value is set, ABINIT will compute\nall the multiple-step berry phase from the single-step to the\n\nberrystep\n-step, and use the large-step values of berry phase to correct\nthe single-step berry phase. Use with care: while experience is still to be\ngained with this procedure, the outlook is promising.\n\n\nbfield\n\u00b6\n\n\nMnemonics: finite B FIELD calculation\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0.0  \n\n\nPerform finite magnetic field calculation.\n\n\nTHIS CODE IS UNDER DEVELOPMENT AND IS NOT READY FOR USE.\n\n\nddamp\n\u00b6\n\n\nMnemonics: electric Displacement field DAMPing parameter\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.1\n\nOnly relevant if \nberryopt\n = 6 or 16  \n\n\nIn case \nberryopt\n=6, the electric field is updated after each SCF iteration\naccording to E_{n+1}= \nddamp\n(D - 4\npi\nP_{n}) + (1-\nddamp\n)\nE_{n} where\nP_{n} and E_{n} are the polarization and electric field after nth SCF\niteration. \nddamp\n is a damping parameter used to control the convergence\nspeed.\n\nIn case \nberryopt\n=16, the electric field is updated after each SCF\niteration according to e_{n+1}= \nddamp\n(d - p_{n}) + (1-\nddamp\n)\ne_{n}\n\nIf you have difficulty getting convergence, try to reduce this value or reduce\nmaxestep. This parameter is used in finite electric displacement field\ncalculations (berryopt=6,16,17).\n\n\ndfield\n\u00b6\n\n\nMnemonics: Displacement FIELD\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0.0\n\nOnly relevant if \nberryopt\n = 6, \nefield\n  \n\n\nIn case \nberryopt\n=6, \ndfield\n specifies the (unreduced) finite electric\ndisplacement field vector, in atomic units, that is to be imposed as a\nconstraint during the calculation.\n\n\nefield\n\u00b6\n\n\nMnemonics: Electric FIELD\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0.0\n\nOnly relevant if \nberryopt\n = 4 or 6  \n\n\nIn case \nberryopt\n=4, a finite electric field calculation is performed. The\nvalue of this electric field, and its direction is determined by \nefield\n.\nIt must be given in atomic units (1 a.u. of electric field= 514220624373.482\nV/m, see note below), in cartesian coordinates.\n\n\nReferences for the calculation under electric field (based on multi k point\nBerry phase) :\n\n\n\n\nNunes and Vanderbilt, PRL 73, 712 (1994) : real-space version of the finite-field Hamiltonian \n\n\nNunes and Gonze, PRB 63, 155107 (2001) : reciprocal-space version of the finite-field Hamiltonian (the one presently implemented), and extensive theoretical analysis \n\n\nSouza, Iniguez and Vanderbilt, PRL 89, 117602 (2003) : implementation of the finite-field Hamiltonian (reciprocal-space version) \n\n\nZwanziger, Galbraith, Kipouros, Torrent, Giantomassi and Gonze, Comp. Mater. Sci. 58, 113 (2012) : extension to PAW formalism \n\n\n\n\nSee also Umari, Gonze, Pasquarello, PRL 90, 027401 (2003).\n\n\nThe atomic unit of electric field strength is : e_Cb/(4 pi eps0 a0**2), where\ne_Cb is the electronic charge in Coulomb (1.60217653e-19), eps0 is the\nelectric constant (8.854187817d-12 F/m), and a0 is the Bohr radius in meter\n(0.5291772108e-10).\n\n\njfielddir\n\u00b6\n\n\nMnemonics: electric/displacement FIELD DIRection\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: 3*0\n\nOnly relevant if \nberryopt\n = 17  \n\n\nWhen specifying mixed electric field boundary conditions ( \nberryopt\n=17),\njfielddir controls whether reduced electric field (\njfielddir\n=1) or reduced\nelectric displacement field (\njfielddir\n=2) is chosen to be fixed, in each\nof the three lattice directions (i.e., in the reduced, not the Cartesian,\nframe). For example, \njfielddir\n=(1 1 2) tells the code to use fixed ebar_1\nand ebar_2 along the first two lattice directions and fixed d_3 along the\nthird.\n\nFor the case of mixed electric field boundary conditions, \nred_efieldbar\n\nand \nred_dfield\n are used to control ebar and d, respectively. For example,\nfor electric boundary conditions corresponding to a material in a parallel-\nplate capacitor, if you want to control d_3=d0, while fixing ebar_1=ebar_2=0,\nthen the input files should have \nberryopt\n=17, \njfielddir\n=(1 1 2),\n\nred_efieldbar\n=(0.0 0.0 a), and \nred_dfield\n=(b c d0). Here a, b, and c\nare the starting values. They can be chosen in this way: do a single run for\nfixed d calculation (\nred_dfield\n=0,0,d0), from the final results you will\nhave ebar_3, which is a good guess for a. Then do another single run for fixed\nebar calculation (\nred_efieldbar\n=(0 0 0)), from the final results you will\nhave d_1,d_2, these are good guesses for b, c.\n\n\nkberry\n\u00b6\n\n\nMnemonics: K wavevectors for BERRY phase computation\n\nVariable type: integer\n\nDimensions: (3,\nnberry\n)\n\nDefault value: *0\n\nOnly relevant if \nberryopt\n = 1, 2, or 3  \n\n\nUsed for values of \nberryopt\n = 1, 2, or 3.\n\n\nThis array defines, for each Berry phase calculation (the number of such\ncalculations is defined by \nnberry\n), the difference of wavevector between k\npoints for which the overlap matrix must be computed. The polarisation vector\nwill be projected on the direction of that wavevector, and the result of the\ncomputation will be the magnitude of this projection. Doing more than one\nwavevector, with different independent direction, allows to find the full\npolarisation vector. However, note that converged results need oriented grids,\ndenser along the difference wavevector than usual Monkhorst-Pack grids.\n\n\nThe difference of wavevector is computed in the coordinate system defined by\nthe k-points grid (see \nngkpt\n and \nkptrlatt\n), so that the values of\n\nkberry\n are integers. Of course, such a k point grid must exist, and all\nthe corresponding wavefunctions must be available, so that the computation is\nallowed only when \nkptopt\n is equal to 3. In order to save computing time,\nit is suggested to make a preliminary calculation of the wavefunctions on the\nirreducible part of the grid, with \nkptopt\n equal to 1, and then use these\nconverged wavefunctions in the entire Brillouin zone, by reading them to\ninitialize the \nkptopt\n=3 computation.\n\n\nmaxestep\n\u00b6\n\n\nMnemonics: MAXimum Electric field STEP\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.005\n\nOnly relevant if \nberryopt\n = 6, 16, or 17  \n\n\nThis variable controls the maximum change of electric field when updating the\nelectric field after each SCF iteration. When the calculation is difficult to\nconverge, try reducing this value or reducing \nddamp\n. This variable is used\nin finite electric displacement field calculations (\nberryopt\n=6,16,17).\n\n\nnatvshift\n\u00b6\n\n\nMnemonics: Number of ATomic potential (V) energy SHIFTs (per atom)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepawu\n /= 0, \natvshift\n  \n\n\nNumber of atomic potential energy shifts (per atom), to be used to define the\narray \natvshift\n. If non-zero, only two possibilities exist : 5 for d states\n(with \nlpawu\n=2), and 7 for f states (with \nlpawu\n=3). If non-zero, one\nshould define \nusepawu\n, \nlpawu\n and \natvshift\n.\n\n\nnberry\n\u00b6\n\n\nMnemonics: Number of BERRY phase computations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nberryopt\n = 1, 2, or 3  \n\n\nGives the number of Berry phase computations of polarisation, or finite-\ndifference estimations of the derivative of wavefunctions with respect to the\nwavevector, each of which might be characterized by a different change of\nwavevector \nkberry\n.\n\n\nWhen equal to 0, no Berry phase calculation of polarisation is performed. The\nmaximal value of \nnberry\n is 20.\n\n\nNote that the computation of the polarisation for a set of bands having\ndifferent occupation numbers is meaningless (although in the case of spin-\npolarized calculations, the spin up bands might have an identical occupation\nnumber, that might differ from the identical occupation number of spin down\nbands). Although meaningless, ABINIT will perform such computation, if\nrequired by the user. The input variable \nbdberry\n governs the set of bands\nfor which a Berry phase is computed.\n\n\nFor the \nberryopt\n = 1, 2, and 3 cases, spinor wavefunctions are not\nallowed, nor are parallel computations.\n\n\npolcen\n\u00b6\n\n\nMnemonics: POLarization for CENtrosymmetric geometry\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0  \n\n\nWhen doing a finite electric displacement field calculation, if the structure\nis centrosymmetric but the polarization is non-zero (such as for AlAs), this\nnon-zero polarization should be specified as \npolcen\n (in REDUCED\ncoordinates, in atomic units) in the input file. See Eq.(24) in the Suppl. of\nNat. Phys. (M. Stengel, N.A. Spaldin and D. Vanderbilt, Nat. Phys. 5,304\n(2009))\n\n\nqprtrb\n\u00b6\n\n\nMnemonics: Q-wavevector of the PERTurbation\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \nvprtrb\n  \n\n\nGives the wavevector, in units of reciprocal lattice primitive translations,\nof a perturbing potential of strength \nvprtrb\n. See \nvprtrb\n for more\nexplanation.\n\n\nred_dfield\n\u00b6\n\n\nMnemonics: REDuced Displacement FIELD\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0.0\n\nOnly relevant if \nberryopt\n = 16, \nred_efield\n  \n\n\nIn case \nberryopt\n=16, a reduced finite electric displacement field\ncalculation is performed. The value of this displacement field, and its\ndirection is determined by \nred_dfield\n. It must be given in atomic units.\n\n\nred_dfield\n is defined via Eq.(26) in the Supplement of M. Stengel, N.A.\nSpaldin and D. Vanderbilt, Nat. Phys. 5,304 (2009).\n\n\nred_efield\n\u00b6\n\n\nMnemonics: REDuced Electric FIELD\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0.0\n\nOnly relevant if \nberryopt\n = 16  \n\n\nIn case \nberryopt\n=16, a reduced finite electric displacement field\ncalculation is performed. In this case, the parameter red_efield specifies the\ninitial electric field used on the first iteration, in atomic units.\n\n\nred_efield\n is defined via Eq.(25) in the Supplement of M. Stengel, N.A.\nSpaldin and D. Vanderbilt, Nat. Phys. 5,304 (2009).\n\n\nred_efieldbar\n\u00b6\n\n\nMnemonics: REDuced Electric FIELD BAR\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0.0\n\nOnly relevant if \nberryopt\n = 14  \n\n\nIn case \nberryopt\n=14, a reduced finite electric field calculation is\nperformed. The magnitude and direction of this electric field are determined\nby red_efieldbar. It must be given in atomic units.\n\n\nred_efieldbar\n is defined via Eq.(28) in the Supplement of M. Stengel, N.A.\nSpaldin and D. Vanderbilt, Nat. Phys. 5,304 (2009).\n\n\nspinmagntarget\n\u00b6\n\n\nMnemonics: SPIN-MAGNetization TARGET\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: -99.99  \n\n\nThis input variable is active only in the \nnsppol\n=2 case. If\n\nspinmagntarget\n is not the \u201cmagic\u201d value of -99.99d0, the spin-\nmagnetization of the primitive cell will be fixed (or optimized, if it is not\npossible to impose it) to the value of \nspinmagntarget\n, in Bohr magneton\nunits, e.g. for an Hydrogen atom, it is 1.\n\nIf \noccopt\n is a metallic one, the Fermi energies for spin up and spin down\nare adjusted to give the target spin-polarisation (this is equivalent to an\nexchange splitting). If \noccopt\n=1 and \nnsppol\n=2, the occupation numbers\nfor spin up and spin down will be adjusted to give the required spin-\nmagnetization (occupation numbers are identical for all k-points, with\n\noccopt\n=1). The definition of \nspinmagntarget\n is actually requested in\nthis case, except for the single isolated Hydrogen atom.\n\nIf \nspinmagntarget\n is the default one, the spin-magnetization will not be\nconstrained, and will be determined self-consistently, by having the same spin\nup and spin down Fermi energy in the metallic case, while for the other cases,\nthere will be no spin-magnetization, except for an odd number of electrons if\n\noccopt\n=1 and \nnsppol\n=2.\n\n\nNote : for the time being, only the spin down Fermi energy is written out in\nthe main output file. In the fixed magnetic moment case, it differs from the\nspin up Fermi energy.\n\n\nvprtrb\n\u00b6\n\n\nMnemonics: potential -V- for the PeRTuRBation\n\nVariable type: real\n\nDimensions: (2)\n\nDefault value: [0.0, 0.0]\n\nOnly relevant if \nqprtrb\n  \n\n\nGives the real and imaginary parts of a scalar potential perturbation. Can be\nspecified in Ha (the default), Ry, eV or Kelvin, since \nvprtrb\n has the\n\u2018\nENERGY\n\u2018 characteristics.\n\nThis is made available for testing responses to such perturbations. The form\nof the perturbation, which is added to the local potential, is:\n\n\n\n\n(\n[vprtrb]\n+I*\n[vprtrb]\n)/2 at G=\nqprtrb\n and \n\n\n(\n[vprtrb]\n-I*\n[vprtrb]\n)/2 at G=-\nqprtrb\n (see \nqprtrb\n also). \n\n\n\n\nzeemanfield\n\u00b6\n\n\nMnemonics: ZEEMAN FIELD\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 0  \n\n\nGive the value of the Zeeman field, H, acting on the spinorial wavefunctions.\nNote that Tesla are admitted. This sets the magnitude of mu_0*H, in Tesla,\nwith H in Amperes/metre.",
            "title": "Varff"
        },
        {
            "location": "/input_variables/varff/#atvshift",
            "text": "Mnemonics: ATomic potential (V) energy SHIFTs \nVariable type: real \nDimensions: ( natvshift , nsppol , natom ) \nDefault value: *0.0d0 \nOnly relevant if  usepawu  /= 0 and  natvshift  in [5,7]    Defines for each atom and each spin channel (at present, can only be used with nsppol =1 or 2, like the +U scheme), a possible potential shift, for the d\n(with  lpawu =2,  natvshift =5), or f states (with  lpawu =3, natvshift =7). In the case of d states, and 2 spin channels, a set of 10\nnumbers for each atom must be defined. The first set of 5 numbers corresponds\nto real spherical harmonics m=-2 to m=+2 for the spin-up channel, the second\nset of 5 numbers corresponds to real spherical harmonics m=-2 to m=+2 for the\nspin-down channel. In the case of f states, the same ordering applies, for\nsets of 7 numbers, corresponding to m=-3 to m=+3.  usepawu  should be non-zero,  lpawu  should be 2 or 3.",
            "title": "atvshift"
        },
        {
            "location": "/input_variables/varff/#bdberry",
            "text": "Mnemonics: BanD limits for BERRY phase \nVariable type: integer \nDimensions: (4) \nDefault value: 4*0 \nOnly relevant if  berryopt  in [1, 2, 3] and  nberry  > 0    Give the lower band and the upper band of the set of bands for which the Berry\nphase must be computed. Irrelevant if  nberry  is not positive. When nsppol  is 1 (no spin-polarisation), only the two first numbers, giving the\nlower and highest bands, are significant. Their occupation number is assumed\nto be 2. When  nsppol  is 2 (spin-polarized calculation), the two first\nnumbers give the lowest and highest bands for spin up, and the third and\nfourth numbers give the lowest and highest bands for spin down. Their\noccupation number is assumed to be 1 .  Presently,  bdberry  MUST be initialized by the user in case of a Berry\nphase calculation with  berryopt  = 1, 2, or 3: the above-mentioned default\nwill cause an early exit.",
            "title": "bdberry"
        },
        {
            "location": "/input_variables/varff/#berryopt",
            "text": "Mnemonics: BERRY phase OPTions \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Specifies the use of Berry phase for the computation of either the\npolarization, the derivatives with respect to the wavevector, or finite\nelectric field calculations.   0 => no computation of expressions relying on a Berry phase (default)   1 => the computation of Berry phases is activated (berryphase routine)   2 => the computation of derivatives with respect to the wavevector, thanks to the Berry phase finite-difference formula, is activated (uderiv routine)   3 => same as option 1 and 2 together  Note that options 1 to 3 require the use of a serial build of Abinit.  -1 => alternative computation of Berry phases (berryphase_new routine)   -2 => alternative computation of derivatives with respect to the wavevector, thanks to the Berry phase finite-difference formula (berryphase_new routine)   -3 => same as option -1 and -2 together  Options -1 to -3 permit use of a parallel build and will be preferred by most users.  4 => finite electric field calculation (unreduced E-field)   6 => finite electric displacement field calculation (unreduced D-field)   14 => finite reduced electric field calculation   16 => finite electric displacement field calculation   17 => mixed electric boundary condition: finite reduced electric field in some directions, finite reduced electric displacement field along other directions. See variable  jfielddir  for more details.    Other related input variables are :   in case of  berryopt =1,2, or 3 :  bdberry  and  kberry ; also,  nberry  must be larger than 0;   in case of  berryopt =-1,-2, or -3 : the variable  rfdir  must be used to specify the primitive vector along which the projection of the polarization or the ddk will be computed. For example if  berryopt =-1 and  rfdir =1 0 0, the projection of the polarization along the reciprocal lattice vector G_1 is computed. In case  rfdir =1 1 1, ABINIT computes the projection of P along G_1, G_2 and G_3 and transforms the results to cartesian coordinates;   in cases where  berryopt  is negative,  berrystep  allow a computation of multiple-step Berry phase in order to accelerate the convergence.   efield  and  rfdir  in case of  berryopt =4 ;    The cases  berryopt =-1,-2,-3, 4, 6, 7, 14, 16, and 17 have to be used with occopt =1.  The cases  berryopt =-1 and 4, 6, 7, 14, 16, 17 are compatible with PAW,\nhowevever, if in these cases one uses  kptopt /=3, one must also use only\nsymmorphic symmetries (either because the space group is symmorphic or the\nvariable  symmorphi  is set to zero).  For a phonon calculation under a finite electric field, respect the following\nprocedure.   1. Run a scf ground-state calculation at zero electric field to get wavefunctions to initialize the ground-state calculation in finite electric fields.   2. Run a scf ground-state calculation in finite electric field. The electric field is controlled by the input variable  efield .  berryopt  should be 4. The input variable  kptopt  should be set to be 2.   3. Based on the wave functions obtained in step (2), perform phonon calculation by setting  berryopt =4,  kptopt =3 and The same value of  efield  than in step 2.  nsym  should be set to 1 currently but this restriction may be removed later . The other parameters are the same as phonon calculation at zero electric field.   Note : the choice of k-point sampling N x N x N should be the same in the three runs and N should be an even number.    In case of finite electric and displacement field calculations\n( berryopt =4,6,7,14,16,17), see also the input variables  berrysav , dfield ,  red_dfield ,  red_efield ,  ddamp",
            "title": "berryopt"
        },
        {
            "location": "/input_variables/varff/#berrysav",
            "text": "Mnemonics: BERRY SAVe \nVariable type: integer \nDimensions: scalar \nDefault value: 0     0 => for finite electric field calculation ( berryopt =4/14), the polarization branch will be chosen on each iteration from (-pi, pi); for finite electric displacement field calculation( berryopt =6/7/16/17), the polarization will be chosen to minimize the internal energy.   1 => the polarization will be kept in the same branch on each iteration. At the end of the run, a file \u201cPOLSAVE\u201d will be saved containing the reduced polarization in atomic units. Note: Make sure that \u201cPOLSAVE\u201d is empty or it does not exist before the calculation, or else that it specifies the desired polarization branch.",
            "title": "berrysav"
        },
        {
            "location": "/input_variables/varff/#berrystep",
            "text": "Mnemonics: BERRY phase : multiple STEP \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if 0 >  berryopt     If  berryopt  is negative, this variable is used to compute berry phases\nusing multiple discrete steps, in order to accelerate convergence. The single-\nstep berry phase is the standard calculation using strings of k-points based\non overlap of Bloch function separated by dk, while the two-step berry phase\nuse strings use overlaps based on dk and 2 dk, the three-step use overlaps\nbased on dk, 2 dk and 3*dk\u2026  The default value of this variable is 1, meaning that only the single-step\nberry phase calculation is done. If a larger value is set, ABINIT will compute\nall the multiple-step berry phase from the single-step to the berrystep -step, and use the large-step values of berry phase to correct\nthe single-step berry phase. Use with care: while experience is still to be\ngained with this procedure, the outlook is promising.",
            "title": "berrystep"
        },
        {
            "location": "/input_variables/varff/#bfield",
            "text": "Mnemonics: finite B FIELD calculation \nVariable type: real \nDimensions: (3) \nDefault value: 3*0.0    Perform finite magnetic field calculation.  THIS CODE IS UNDER DEVELOPMENT AND IS NOT READY FOR USE.",
            "title": "bfield"
        },
        {
            "location": "/input_variables/varff/#ddamp",
            "text": "Mnemonics: electric Displacement field DAMPing parameter \nVariable type: real \nDimensions: scalar \nDefault value: 0.1 \nOnly relevant if  berryopt  = 6 or 16    In case  berryopt =6, the electric field is updated after each SCF iteration\naccording to E_{n+1}=  ddamp (D - 4 pi P_{n}) + (1- ddamp ) E_{n} where\nP_{n} and E_{n} are the polarization and electric field after nth SCF\niteration.  ddamp  is a damping parameter used to control the convergence\nspeed. \nIn case  berryopt =16, the electric field is updated after each SCF\niteration according to e_{n+1}=  ddamp (d - p_{n}) + (1- ddamp ) e_{n} \nIf you have difficulty getting convergence, try to reduce this value or reduce\nmaxestep. This parameter is used in finite electric displacement field\ncalculations (berryopt=6,16,17).",
            "title": "ddamp"
        },
        {
            "location": "/input_variables/varff/#dfield",
            "text": "Mnemonics: Displacement FIELD \nVariable type: real \nDimensions: (3) \nDefault value: 3*0.0 \nOnly relevant if  berryopt  = 6,  efield     In case  berryopt =6,  dfield  specifies the (unreduced) finite electric\ndisplacement field vector, in atomic units, that is to be imposed as a\nconstraint during the calculation.",
            "title": "dfield"
        },
        {
            "location": "/input_variables/varff/#efield",
            "text": "Mnemonics: Electric FIELD \nVariable type: real \nDimensions: (3) \nDefault value: 3*0.0 \nOnly relevant if  berryopt  = 4 or 6    In case  berryopt =4, a finite electric field calculation is performed. The\nvalue of this electric field, and its direction is determined by  efield .\nIt must be given in atomic units (1 a.u. of electric field= 514220624373.482\nV/m, see note below), in cartesian coordinates.  References for the calculation under electric field (based on multi k point\nBerry phase) :   Nunes and Vanderbilt, PRL 73, 712 (1994) : real-space version of the finite-field Hamiltonian   Nunes and Gonze, PRB 63, 155107 (2001) : reciprocal-space version of the finite-field Hamiltonian (the one presently implemented), and extensive theoretical analysis   Souza, Iniguez and Vanderbilt, PRL 89, 117602 (2003) : implementation of the finite-field Hamiltonian (reciprocal-space version)   Zwanziger, Galbraith, Kipouros, Torrent, Giantomassi and Gonze, Comp. Mater. Sci. 58, 113 (2012) : extension to PAW formalism    See also Umari, Gonze, Pasquarello, PRL 90, 027401 (2003).  The atomic unit of electric field strength is : e_Cb/(4 pi eps0 a0**2), where\ne_Cb is the electronic charge in Coulomb (1.60217653e-19), eps0 is the\nelectric constant (8.854187817d-12 F/m), and a0 is the Bohr radius in meter\n(0.5291772108e-10).",
            "title": "efield"
        },
        {
            "location": "/input_variables/varff/#jfielddir",
            "text": "Mnemonics: electric/displacement FIELD DIRection \nVariable type: integer \nDimensions: (3) \nDefault value: 3*0 \nOnly relevant if  berryopt  = 17    When specifying mixed electric field boundary conditions (  berryopt =17),\njfielddir controls whether reduced electric field ( jfielddir =1) or reduced\nelectric displacement field ( jfielddir =2) is chosen to be fixed, in each\nof the three lattice directions (i.e., in the reduced, not the Cartesian,\nframe). For example,  jfielddir =(1 1 2) tells the code to use fixed ebar_1\nand ebar_2 along the first two lattice directions and fixed d_3 along the\nthird. \nFor the case of mixed electric field boundary conditions,  red_efieldbar \nand  red_dfield  are used to control ebar and d, respectively. For example,\nfor electric boundary conditions corresponding to a material in a parallel-\nplate capacitor, if you want to control d_3=d0, while fixing ebar_1=ebar_2=0,\nthen the input files should have  berryopt =17,  jfielddir =(1 1 2), red_efieldbar =(0.0 0.0 a), and  red_dfield =(b c d0). Here a, b, and c\nare the starting values. They can be chosen in this way: do a single run for\nfixed d calculation ( red_dfield =0,0,d0), from the final results you will\nhave ebar_3, which is a good guess for a. Then do another single run for fixed\nebar calculation ( red_efieldbar =(0 0 0)), from the final results you will\nhave d_1,d_2, these are good guesses for b, c.",
            "title": "jfielddir"
        },
        {
            "location": "/input_variables/varff/#kberry",
            "text": "Mnemonics: K wavevectors for BERRY phase computation \nVariable type: integer \nDimensions: (3, nberry ) \nDefault value: *0 \nOnly relevant if  berryopt  = 1, 2, or 3    Used for values of  berryopt  = 1, 2, or 3.  This array defines, for each Berry phase calculation (the number of such\ncalculations is defined by  nberry ), the difference of wavevector between k\npoints for which the overlap matrix must be computed. The polarisation vector\nwill be projected on the direction of that wavevector, and the result of the\ncomputation will be the magnitude of this projection. Doing more than one\nwavevector, with different independent direction, allows to find the full\npolarisation vector. However, note that converged results need oriented grids,\ndenser along the difference wavevector than usual Monkhorst-Pack grids.  The difference of wavevector is computed in the coordinate system defined by\nthe k-points grid (see  ngkpt  and  kptrlatt ), so that the values of kberry  are integers. Of course, such a k point grid must exist, and all\nthe corresponding wavefunctions must be available, so that the computation is\nallowed only when  kptopt  is equal to 3. In order to save computing time,\nit is suggested to make a preliminary calculation of the wavefunctions on the\nirreducible part of the grid, with  kptopt  equal to 1, and then use these\nconverged wavefunctions in the entire Brillouin zone, by reading them to\ninitialize the  kptopt =3 computation.",
            "title": "kberry"
        },
        {
            "location": "/input_variables/varff/#maxestep",
            "text": "Mnemonics: MAXimum Electric field STEP \nVariable type: real \nDimensions: scalar \nDefault value: 0.005 \nOnly relevant if  berryopt  = 6, 16, or 17    This variable controls the maximum change of electric field when updating the\nelectric field after each SCF iteration. When the calculation is difficult to\nconverge, try reducing this value or reducing  ddamp . This variable is used\nin finite electric displacement field calculations ( berryopt =6,16,17).",
            "title": "maxestep"
        },
        {
            "location": "/input_variables/varff/#natvshift",
            "text": "Mnemonics: Number of ATomic potential (V) energy SHIFTs (per atom) \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepawu  /= 0,  atvshift     Number of atomic potential energy shifts (per atom), to be used to define the\narray  atvshift . If non-zero, only two possibilities exist : 5 for d states\n(with  lpawu =2), and 7 for f states (with  lpawu =3). If non-zero, one\nshould define  usepawu ,  lpawu  and  atvshift .",
            "title": "natvshift"
        },
        {
            "location": "/input_variables/varff/#nberry",
            "text": "Mnemonics: Number of BERRY phase computations \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  berryopt  = 1, 2, or 3    Gives the number of Berry phase computations of polarisation, or finite-\ndifference estimations of the derivative of wavefunctions with respect to the\nwavevector, each of which might be characterized by a different change of\nwavevector  kberry .  When equal to 0, no Berry phase calculation of polarisation is performed. The\nmaximal value of  nberry  is 20.  Note that the computation of the polarisation for a set of bands having\ndifferent occupation numbers is meaningless (although in the case of spin-\npolarized calculations, the spin up bands might have an identical occupation\nnumber, that might differ from the identical occupation number of spin down\nbands). Although meaningless, ABINIT will perform such computation, if\nrequired by the user. The input variable  bdberry  governs the set of bands\nfor which a Berry phase is computed.  For the  berryopt  = 1, 2, and 3 cases, spinor wavefunctions are not\nallowed, nor are parallel computations.",
            "title": "nberry"
        },
        {
            "location": "/input_variables/varff/#polcen",
            "text": "Mnemonics: POLarization for CENtrosymmetric geometry \nVariable type: real \nDimensions: (3) \nDefault value: 3*0    When doing a finite electric displacement field calculation, if the structure\nis centrosymmetric but the polarization is non-zero (such as for AlAs), this\nnon-zero polarization should be specified as  polcen  (in REDUCED\ncoordinates, in atomic units) in the input file. See Eq.(24) in the Suppl. of\nNat. Phys. (M. Stengel, N.A. Spaldin and D. Vanderbilt, Nat. Phys. 5,304\n(2009))",
            "title": "polcen"
        },
        {
            "location": "/input_variables/varff/#qprtrb",
            "text": "Mnemonics: Q-wavevector of the PERTurbation \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  vprtrb     Gives the wavevector, in units of reciprocal lattice primitive translations,\nof a perturbing potential of strength  vprtrb . See  vprtrb  for more\nexplanation.",
            "title": "qprtrb"
        },
        {
            "location": "/input_variables/varff/#red_dfield",
            "text": "Mnemonics: REDuced Displacement FIELD \nVariable type: real \nDimensions: (3) \nDefault value: 3*0.0 \nOnly relevant if  berryopt  = 16,  red_efield     In case  berryopt =16, a reduced finite electric displacement field\ncalculation is performed. The value of this displacement field, and its\ndirection is determined by  red_dfield . It must be given in atomic units.  red_dfield  is defined via Eq.(26) in the Supplement of M. Stengel, N.A.\nSpaldin and D. Vanderbilt, Nat. Phys. 5,304 (2009).",
            "title": "red_dfield"
        },
        {
            "location": "/input_variables/varff/#red_efield",
            "text": "Mnemonics: REDuced Electric FIELD \nVariable type: real \nDimensions: (3) \nDefault value: 3*0.0 \nOnly relevant if  berryopt  = 16    In case  berryopt =16, a reduced finite electric displacement field\ncalculation is performed. In this case, the parameter red_efield specifies the\ninitial electric field used on the first iteration, in atomic units.  red_efield  is defined via Eq.(25) in the Supplement of M. Stengel, N.A.\nSpaldin and D. Vanderbilt, Nat. Phys. 5,304 (2009).",
            "title": "red_efield"
        },
        {
            "location": "/input_variables/varff/#red_efieldbar",
            "text": "Mnemonics: REDuced Electric FIELD BAR \nVariable type: real \nDimensions: (3) \nDefault value: 3*0.0 \nOnly relevant if  berryopt  = 14    In case  berryopt =14, a reduced finite electric field calculation is\nperformed. The magnitude and direction of this electric field are determined\nby red_efieldbar. It must be given in atomic units.  red_efieldbar  is defined via Eq.(28) in the Supplement of M. Stengel, N.A.\nSpaldin and D. Vanderbilt, Nat. Phys. 5,304 (2009).",
            "title": "red_efieldbar"
        },
        {
            "location": "/input_variables/varff/#spinmagntarget",
            "text": "Mnemonics: SPIN-MAGNetization TARGET \nVariable type: real \nDimensions: scalar \nDefault value: -99.99    This input variable is active only in the  nsppol =2 case. If spinmagntarget  is not the \u201cmagic\u201d value of -99.99d0, the spin-\nmagnetization of the primitive cell will be fixed (or optimized, if it is not\npossible to impose it) to the value of  spinmagntarget , in Bohr magneton\nunits, e.g. for an Hydrogen atom, it is 1. \nIf  occopt  is a metallic one, the Fermi energies for spin up and spin down\nare adjusted to give the target spin-polarisation (this is equivalent to an\nexchange splitting). If  occopt =1 and  nsppol =2, the occupation numbers\nfor spin up and spin down will be adjusted to give the required spin-\nmagnetization (occupation numbers are identical for all k-points, with occopt =1). The definition of  spinmagntarget  is actually requested in\nthis case, except for the single isolated Hydrogen atom. \nIf  spinmagntarget  is the default one, the spin-magnetization will not be\nconstrained, and will be determined self-consistently, by having the same spin\nup and spin down Fermi energy in the metallic case, while for the other cases,\nthere will be no spin-magnetization, except for an odd number of electrons if occopt =1 and  nsppol =2.  Note : for the time being, only the spin down Fermi energy is written out in\nthe main output file. In the fixed magnetic moment case, it differs from the\nspin up Fermi energy.",
            "title": "spinmagntarget"
        },
        {
            "location": "/input_variables/varff/#vprtrb",
            "text": "Mnemonics: potential -V- for the PeRTuRBation \nVariable type: real \nDimensions: (2) \nDefault value: [0.0, 0.0] \nOnly relevant if  qprtrb     Gives the real and imaginary parts of a scalar potential perturbation. Can be\nspecified in Ha (the default), Ry, eV or Kelvin, since  vprtrb  has the\n\u2018 ENERGY \u2018 characteristics. \nThis is made available for testing responses to such perturbations. The form\nof the perturbation, which is added to the local potential, is:   ( [vprtrb] +I* [vprtrb] )/2 at G= qprtrb  and   ( [vprtrb] -I* [vprtrb] )/2 at G=- qprtrb  (see  qprtrb  also).",
            "title": "vprtrb"
        },
        {
            "location": "/input_variables/varff/#zeemanfield",
            "text": "Mnemonics: ZEEMAN FIELD \nVariable type: real \nDimensions: (3) \nDefault value: 0    Give the value of the Zeeman field, H, acting on the spinorial wavefunctions.\nNote that Tesla are admitted. This sets the magnitude of mu_0*H, in Tesla,\nwith H in Amperes/metre.",
            "title": "zeemanfield"
        },
        {
            "location": "/input_variables/varfil/",
            "text": "get1den\n\u00b6\n\n\nMnemonics: GET the first-order density from _1DEN file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nRelevant only for non self consistent RF calculations (e.g. to get electron\nphonon matrix elements) or for non linear RF calculations (to get mixed higher\norder derivatives you need several perturbed densities and wave functions).\nIndicate the files from which first-order densities must be obtained, in\nmulti-dataset mode (in single dataset mode, use \nird1den\n).\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\nget1wf\n\u00b6\n\n\nMnemonics: GET the first-order wavefunctions from _1WF file \n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to \nirdwfk\n, \nirdwfq\n,\n\nird1wf\n, \nirdddk\n. One should first read the explanations given for these\nlatter variables.\n\nThe \n getwfk \n , \n getwfq \n , \nget1wf\n and \n getddk \n variables are\ntypically used to chain the calculations in the multi-dataset mode, since they\ndescribe from which dataset the OUTPUT wavefunctions are to be taken, as INPUT\nwavefunctions of the present dataset.  \n\n\nWe now focus on the \n getwfk \n input variable (the only one used in ground-\nstate calculations), but the rules for \n getwfq \n and \nget1wf\n are\nsimilar, with _WFK replaced by _WFQ or _1WF.\n\nIf \n getwfk \n ==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done.\n\nIf \n getwfk \n is positive, its value gives the index of the dataset for\nwhich the output wavefunction file appended with _WFK must be used.\n\nIf \n getwfk \n is -1, the output wf file with _WFK of the previous dataset\nmust be taken, which is a frequently occurring case.\n\nIf \n getwfk \n is a negative number, it indicates the number of datasets to\ngo backward to find the needed wavefunction file. In this case, if one refers\nto a non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if \n getwfk \n =0 for that\ninitialisation. Thanks to this rule, the use of \n getwfk \n -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one.\n\nIn the case of a ddk calculation in a multi dataset run, in order to compute\ncorrectly the localisation tensor, it is mandatory to declare give getddk the\nvalue of the current dataset (i.e. getddk3 3 ) - this is a bit strange and\nshould be changed in the future.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngetbscoup\n\u00b6\n\n\nMnemonics: GET the Bethe-Salpeter COUPling block from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (multi-dataset mode) and, in the case of\na Bethe-Salpeter calculation to indicate that the starting coupling block of\nthe excitonic Hamiltonian will be taken from the output of a previous dataset.\nIt is used to chain the calculations, since it describes from which dataset\nthe OUTPUT coupling block is to be taken, as INPUT of the present dataset.\n\nIf \ngetbscoup\n==0, no such use of previously computed coupling block file is\ndone.\n\nIf \ngetbscoup\n is positive, its value gives the index of the dataset to be\nused as input.\n\nIf \ngetbscoup\n is -1, the output of the previous dataset must be taken,\nwhich is a frequently occuring case.\n\nIf \ngetbscoup\n is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the coupling block is not initialised\nfrom a disk file, so that it is as if \ngetbscoup\n=0 for that initialisation.\n\n\ngetbseig\n\u00b6\n\n\nMnemonics: GET the Bethe-Salpeter EIGenstates from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (multi-dataset mode) and, in the case of\na Bethe-Salpeter calculation to indicate that the starting excitonic\neigenstates are to be taken from the output of a previous dataset. It is used\nto chain the calculations, since it describes from which dataset the OUTPUT\neigenstates are to be taken, as INPUT eigenstates of the present dataset.\n\nIf \ngetbseig\n==0, no such use of previously computed output eigenstates file\nis done.\n\nIf \ngetbseig\n is positive, its value gives the index of the dataset from\nwhich the output states is to be used as input.\n\nIf \ngetbseig\n is -1, the output eigenstates of the previous dataset must be\ntaken, which is a frequently occurring case.\n\nIf \ngetbseig\n is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the eigenstates are not initialised\nfrom a disk file, so that it is as if \ngetbseig\n=0 for that initialisation.\n\n\ngetbsreso\n\u00b6\n\n\nMnemonics: GET the Bethe-Salpeter RESOnant block from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (multi-dataset mode) and, in the case of\na Bethe-Salpeter calculation to indicate that the starting resonant block of\nthe excitonic Hamiltonian will be taken from the output of a previous dataset.\nIt is used to chain the calculations, since it describes from which dataset\nthe OUTPUT resonant block is to be taken, as INPUT of the present dataset.\n\nIf \ngetbsreso\n==0, no such use of previously computed resonant block file is\ndone.\n\nIf \ngetbsreso\n is positive, its value gives the index of the dataset to be\nused as input.\n\nIf \ngetbsreso\n is -1, the output of the previous dataset must be taken,\nwhich is a frequently occurring case.\n\nIf \ngetbsreso\n is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the resonant block is not initialised\nfrom a disk file, so that it is as if \ngetbsreso\n=0 for that initialisation.\n\n\ngetddb\n\u00b6\n\n\nMnemonics: GET the DDB from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis variable should be used when performing electron-phonon or temperature-\ndependence calculations. The Born effective charge as well as the dielectric\ntensor will be read from a previous DFPT calculations of the electric field at\nq=Gamma. The use of this variable will trigger the cancellation of a residual\ndipole that leads to an unphysical divergence of the GKK with vanishing\nq-points. The use of this variable greatly improves the k-point convergence\nspeed as the density of the k-point grid required to obtain the fulfillment of\nthe charge neutrality sum rule is usually prohibitively large.\n\nIf \ngetddb\n==0, no such use of previously computed Born effective charge and\ndielectric tensor is done.\n\nIf \ngetddb\n is positive, its value gives the index of the dataset from which\nthe output density is to be used as input.\n\nIf \ngetddb\n is -1, the output density of the previous dataset must be taken,\nwhich is a frequently occurring case.\n\nIf \ngetddb\n is a negative number, it indicates the number of datasets to go\nbackward to find the needed file.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngetddk\n\u00b6\n\n\nMnemonics: GET the DDK wavefunctions from _1WF file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to\n\nirdwfk\n,\nirdwfq\n,\nird1wf\n,\nirdddk\n. One should first read the\nexplanations given for these latter variables.\n\nThe \n getwfk \n , \n getwfq \n , \n get1wf \n and \ngetddk\n variables are\ntypically used to chain the calculations in the multi-dataset mode, since they\ndescribe from which dataset the OUTPUT wavefunctions are to be taken, as INPUT\nwavefunctions of the present dataset.  \n\n\nWe now focus on the \n getwfk \n input variable (the only one used in ground-\nstate calculations), but the rules for \n getwfq \n and \n get1wf \n are\nsimilar, with _WFK replaced by _WFQ or _1WF.\n\nIf \n getwfk \n ==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done.\n\nIf \n getwfk \n is positive, its value gives the index of the dataset for\nwhich the output wavefunction file appended with _WFK must be used.\n\nIf \n getwfk \n is -1, the output wf file with _WFK of the previous dataset\nmust be taken, which is a frequently occurring case.\n\nIf \n getwfk \n is a negative number, it indicates the number of datasets to\ngo backward to find the needed wavefunction file. In this case, if one refers\nto a non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if \n getwfk \n =0 for that\ninitialisation. Thanks to this rule, the use of \n getwfk \n -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one.\n\nIn the case of a ddk calculation in a multi dataset run, in order to compute\ncorrectly the localisation tensor, it is mandatory to declare give getddk the\nvalue of the current dataset (i.e. getddk3 3 ) - this is a bit strange and\nshould be changed in the future.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngetden\n\u00b6\n\n\nMnemonics: GET the DENsity from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (multi-dataset mode) and, in the case of\na ground-state calculation, if \niscf\n<0 (non-SCF calculation), to\nindicate that the starting density is to be taken from the output of a\nprevious dataset. It is used to chain the calculations, since it describes\nfrom which dataset the OUTPUT density are to be taken, as INPUT density of the\npresent dataset.\n\nIf \ngetden\n==0, no such use of previously computed output density file is\ndone.\n\nIf \ngetden\n is positive, its value gives the index of the dataset from which\nthe output density is to be used as input.\n\nIf \ngetden\n is -1, the output density of the previous dataset must be taken,\nwhich is a frequently occurring case.\n\nIf \ngetden\n is a negative number, it indicates the number of datasets to go\nbackward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the density is not initialised from a\ndisk file, so that it is as if \ngetden\n=0 for that initialisation. Thanks to\nthis rule, the use of \ngetden\n -1 is rather straightforward : except for the\nfirst density, that is not initialized by reading a disk file, the output\ndensity of one dataset is input of the next one.\n\nBe careful : the output density file of a run with non-zero \nionmov\n does\nnot have the proper name (it has a \u201cTIM\u201d indication) for use as an input of an\n\niscf\n<0 calculation.\n\nOne should use the output density of a \nionmov\n==0 run.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngethaydock\n\u00b6\n\n\nMnemonics: GET the HAYDOCK restart file from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (multi-dataset mode) and, in the case of\na Bethe-Salpeter calculation to indicate that the Haydock iterative technique\nwill be restarted from the output of a previous dataset.\n\nIf \ngethaydock\n==0, no such use of previously computed coupling block file\nis done.\n\nIf \ngethaydock\n is positive, its value gives the index of the dataset to be\nused as input.\n\nIf \ngethaydock\n is -1, the output of the previous dataset must be taken,\nwhich is a frequently occuring case.\n\nIf \ngethaydock\n is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the coupling block is not initialised\nfrom a disk file, so that it is as if \ngethaydock\n=0 for that\ninitialisation.\n\n\ngetocc\n\u00b6\n\n\nMnemonics: GET OCC parameters from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis variable is typically used to chain the calculations, in the multi-\ndataset mode (\nndtset\n>0), since it describes from which dataset the\narray \nocc\n is to be taken, as input of the present dataset. The occupation\nnumbers are \nEVOLVING\n variables, for which such a chain of calculations is\nuseful.\n\nIf \ngetocc\n==0, no such use of previously computed output occupations is\ndone.\n\nIf \ngetocc\n is positive, its value gives the index of the dataset from which\nthe data are to be used as input data. It must be the index of a dataset\nalready computed in the SAME run.\n\nIf \ngetocc\n is -1, the output data of the previous dataset must be taken,\nwhich is a frequently occurring case.\n\nIf \ngetocc\n is a negative number, it indicates the number of datasets to go\nbackward to find the needed data. In this case, if one refers to a non\nexistent data set (prior to the first), the date is not initialised from a\ndisk file, so that it is as if \ngetocc\n==0 for that initialisation.\n\nNOTE that a non-zero \ngetocc\n MUST be used with \noccopt\n==2, so that the\nnumber of bands has to be initialized for each k point. Of course, these\nnumbers of bands must be identical to the numbers of bands of the dataset from\nwhich \nocc\n will be copied. The same is true for the number of k points.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngetqps\n\u00b6\n\n\nMnemonics: GET QuasiParticle Structure\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed when \nndtset\n>0 (multi-dataset mode) and \noptdriver\n=3, or 4\n(screening or sigma step of a \nGW\n calculation), to indicate that the\neigenvalues and possibly the wavefunctions have to be taken from a previous\nquasiparticle calculation (instead of the usual LDA starting point). This is\nto achieve quasiparticle self-consistency. See also \nirdqps\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngetscr\n\u00b6\n\n\nMnemonics: GET SCReening (the inverse dielectric matrix) from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed when \nndtset\n>0 (multi-dataset mode) and \noptdriver\n=4 (sigma step\nof a \nGW\n calculation), to indicate that the dielectric matrix (_SCR file)\nis to be taken from the output of a previous dataset. It is used to chain the\ncalculations, since it describes from which dataset the OUTPUT dielectric\nmatrix is to be taken, as INPUT of the present dataset.\n\nIf \ngetscr\n==0, no such use of previously computed output _SCR file is done.\n\nIf \ngetscr\n is positive, its value gives the index of the dataset from which\nthe output _SCR file is to be used as input.\n\nIf \ngetscr\n is -1, the output _SCR file of the previous dataset must be\ntaken, which is a frequently occurring case.\n\nIf \ngetscr\n is a negative number, it indicates the number of datasets to go\nbackward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the _SCR file is not initialised from\na disk file, so that it is as if \ngetscr\n=0 for that initialisation.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngetsuscep\n\u00b6\n\n\nMnemonics: GET SUSCEPtibility (the irreducible polarizability) from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed when \nndtset\n>0 (multi-dataset mode) and \noptdriver\n=4 (sigma step\nof a \nGW\n calculation), to indicate that the irreducible polarizability\n(_SUSC file) is to be taken from the output of a previous dataset. It is used\nto chain the calculations, since it describes from which dataset the OUTPUT\nsusceptibility is to be taken, as INPUT of the present dataset. Performing a\n\nGW\n calculations starting from the _SUSC file instead of the _SCR file\npresents the advantage that starting from the irreducible polarizability, one\ncan calculate the screened interaction using different expressions without\nhaving to perform a screening calculation from scratch. For example, it is\npossible to apply a cutoff to the Coulomb interaction in order to facilitate\nthe convergence of the \nGW\n correction with respect to the size of the\nsupercell (see \nvcutgeo\n and \nicutcoul\n)\n\nIf \ngetsuscep\n==0, no such use of previously computed output _SUSC file is\ndone.\n\nIf \ngetsuscep\n is positive, its value gives the index of the dataset from\nwhich the output _SUSC file is to be used as input.\n\nIf \ngetsuscep\n is -1, the output _SUSC file of the previous dataset must be\ntaken, which is a frequently occurring case.\n\nIf \ngetsuscep\n is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the _SUSC file is not initialised from\na disk file, so that it is as if \ngetsuscep\n=0 for that initialisation.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngetwfk\n\u00b6\n\n\nMnemonics: GET the wavefunctions from _WFK file \n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to \nirdwfk\n,\nirdwfq\n,\nird1wf\n,\nor \nirdddk\n. One should first read the explanations given for these latter\nvariables.\n\nThe \ngetwfk\n, \n getwfq \n , \n get1wf \n and \n getddk \n variables are\ntypically used to chain the calculations in the multi-dataset mode, since they\ndescribe from which dataset the OUTPUT wavefunctions are to be taken, as INPUT\nwavefunctions of the present dataset.  \n\n\nWe now focus on the \ngetwfk\n input variable (the only one used in ground-\nstate calculations), but the rules for \n getwfq \n and \n get1wf \n are\nsimilar, with _WFK replaced by _WFQ or _1WF.\n\nIf \ngetwfk\n==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done.\n\nIf \ngetwfk\n is positive, its value gives the index of the dataset for which\nthe output wavefunction file appended with _WFK must be used.\n\nIf \ngetwfk\n is -1, the output wf file with _WFK of the previous dataset must\nbe taken, which is a frequently occurring case.\n\nIf \ngetwfk\n is a negative number, it indicates the number of datasets to go\nbackward to find the needed wavefunction file. In this case, if one refers to\na non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if \ngetwfk\n=0 for that\ninitialisation. Thanks to this rule, the use of \ngetwfk\n -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one.\n\nIn the case of a ddk calculation in a multi dataset run, in order to compute\ncorrectly the localisation tensor, it is mandatory to declare give getddk the\nvalue of the current dataset (i.e. getddk3 3 ) - this is a bit strange and\nshould be changed in the future.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\ngetwfq\n\u00b6\n\n\nMnemonics: GET the wavefunctions from _WFQ file \n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nEventually used when \nndtset\n>0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to \nirdwfk\n,\nirdwfq\n,\nird1wf\n\nor \nirdddk\n. One should first read the explanations given for these latter\nvariables.\n\nThe \n getwfk \n , \ngetwfq\n, \n get1wf \n and \n getddk \n variables are\ntypically used to chain the calculations in the multi-dataset mode, since they\ndescribe from which dataset the OUTPUT wavefunctions are to be taken, as INPUT\nwavefunctions of the present dataset.  \n\n\nWe now focus on the \n getwfk \n input variable (the only one used in ground-\nstate calculations), but the rules for \ngetwfq\n and \n get1wf \n are\nsimilar, with _WFK replaced by _WFQ or _1WF.\n\nIf \n getwfk \n ==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done.\n\nIf \n getwfk \n is positive, its value gives the index of the dataset for\nwhich the output wavefunction file appended with _WFK must be used.\n\nIf \n getwfk \n is -1, the output wf file with _WFK of the previous dataset\nmust be taken, which is a frequently occurring case.\n\nIf \n getwfk \n is a negative number, it indicates the number of datasets to\ngo backward to find the needed wavefunction file. In this case, if one refers\nto a non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if \n getwfk \n =0 for that\ninitialisation. Thanks to this rule, the use of \n getwfk \n -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one.\n\nIn the case of a ddk calculation in a multi dataset run, in order to compute\ncorrectly the localisation tensor, it is mandatory to declare give getddk the\nvalue of the current dataset (i.e. getddk3 3 ) - this is a bit strange and\nshould be changed in the future.\n\nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :\n\n\n  ndtset 3   jdtset 1 2 4  getXXX -1\n\n\n\n\n\nrefers to dataset 2 when dataset 4 is initialized.\n\n\nird1den\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of 1st-order DEN file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \niscf\n < 0,\n0 otherwise.\n\n\nIf first order density is needed in single dataset mode (for example in\nnonlinear optical response), use \nird1den\n=1 to read first-order densities\nfrom _DENx files produced in other calculations. In multi-dataset mode use\n\nget1den\n.\n\n\nWhen iscf < 0, the reading of a DEN file is always enforced.\n\n\nA non-zero value of \n ird1den \n is treated in the same way as other \u201cird\u201d\nvariables, see the \n section 4\n\n of the \nhelp_abinit\n.  \n\n\nird1wf\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of _1WF files \n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIndicates eventual starting wavefunctions. As alternative, one can use the\ninput variables \ngetwfk\n, \ngetwfq\n, \nget1wf\n or \ngetddk\n.  \n\n\nGround-state calculation :\n\n\n\n\nonly \n irdwfk \n and \ngetwfk\n have a meaning \n\n\nat most one of \n irdwfk \n or \ngetwfk\n can be non-zero \n\n\nif \n irdwfk \n and \ngetwfk\n are both zero, initialize wavefunctions with random numbers for ground state calculation. \n\n\nif \n irdwfk \n = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nResponse-function calculation :\n\n\n\n\none and only one of \n irdwfk \n or \ngetwfk\n MUST be non-zero \n\n\nif \n irdwfk \n = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nonly one of \n irdwfq \n or \ngetwfq\n can be non-zero, if both of them are non-zero, use as k + q file the one defined by \n irdwfk \n and/or \ngetwfk\n \n\n\nif \n irdwfq \n = 1 : read ground state k+q -wavefunctions from a disk file appended with _WFQ , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nat most one of \nird1wf\n or \nget1wf\n can be non-zero \n\n\nif both are zero, initialize first order wavefunctions to zeroes \n\n\nif \nird1wf\n = 1 : read first-order wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nat most one of \n irdddk \n or \ngetddk\n can be non-zero \n\n\none of them must be non-zero if an homogeneous electric field calculation is done (presently, a ddk calculation in the same dataset is not allowed) \n\n\nif \n irdddk \n = 1 : read first-order ddk wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nirdbscoup\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of COUPling block\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nStart the Bethe-Salpeter calculation from the BSC file containing the coupling\nblock produced in a previous run.\n\n\nirdbseig\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of BS_EIG file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nStart the Bethe-Salpeter calculation from the BS_EIG contining the exciton\neigenvectors produced in a previous run.\n\n\nirdbsreso\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of RESOnant block\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nStart the Bethe-Salpeter calculation from the BSR file containing the resonat\nblock produced in a previous run.\n\n\nirdddb\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of DDB file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \niscf\n < 0,\n0 otherwise.\n\n\nThis variable should be used when performing electron-phonon or temperature-\ndependence calculations. The Born effective charge as well as the dielectric\ntensor will be read from a previous DFPT calculations of the electric field at\nq=Gamma. The use of this variable will trigger the cancellation of a residual\ndipole that leads to an unphysical divergence of the GKK with vanishing\nq-points. The use of this variable greatly improves the k-point convergence\nspeed as the density of the k-point grid required to obtain the fulfillment of\nthe charge neutrality sum rule is usually prohibitively large.\n\n\nA non-zero value of \nirdddb\n is treated in the same way as other \u201cird\u201d\nvariables, see the \n section 4\n\n of the \nhelp_abinit\n.  \n\n\nirdddk\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of DDK wavefunctions, in _1WF files\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIndicates eventual starting wavefunctions. As alternative, one can use the\ninput variables \ngetwfk\n, \ngetwfq\n, \nget1wf\n or \ngetddk\n.  \n\n\nGround-state calculation :\n\n\n\n\nonly \n irdwfk \n and \ngetwfk\n have a meaning \n\n\nat most one of \n irdwfk \n or \ngetwfk\n can be non-zero \n\n\nif \n irdwfk \n and \ngetwfk\n are both zero, initialize wavefunctions with random numbers for ground state calculation. \n\n\nif \n irdwfk \n = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nResponse-function calculation :\n\n\n\n\none and only one of \n irdwfk \n or \ngetwfk\n MUST be non-zero \n\n\nif \n irdwfk \n = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nonly one of \n irdwfq \n or \ngetwfq\n can be non-zero, if both of them are non-zero, use as k + q file the one defined by \n irdwfk \n and/or \ngetwfk\n \n\n\nif \n irdwfq \n = 1 : read ground state k+q -wavefunctions from a disk file appended with _WFQ , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nat most one of \n ird1wf \n or \nget1wf\n can be non-zero \n\n\nif both are zero, initialize first order wavefunctions to zeroes \n\n\nif \n ird1wf \n = 1 : read first-order wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nat most one of \nirdddk\n or \ngetddk\n can be non-zero \n\n\none of them must be non-zero if an homogeneous electric field calculation is done (presently, a ddk calculation in the same dataset is not allowed) \n\n\nif \nirdddk\n = 1 : read first-order ddk wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nirdden\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of DEN file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \niscf\n < 0,\n0 otherwise.\n\n\nStart the ground-state calculation from the density file of a previous run.\nWhen iscf < 0, the reading of a DEN file is always enforced.\n\n\nA non-zero value of \nirdden\n is treated in the same way as other \u201cird\u201d\nvariables, see the \n section 4\n\n of the \nhelp_abinit\n.  \n\n\nirdhaydock\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of the HAYDOCK restart file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed to re-start the Haydock iterative technique from the HAYDR_SAVE file\nproduced in a previous run.\n\n\nirdqps\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of QuasiParticle Structure\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nRelevant only when \noptdriver\n=3 or 4. Indicate the file from which the\neigenvalues and possibly the wavefunctions must be obtained, in order to\nachieve a self-consistent quasiparticle calculations. See also \ngetqps\n\n\nirdscr\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of the SCReening\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nRelevant only when \noptdriver\n=4. Indicate the file from which the\ndielectric matrix must be obtained. As alternative, one can use the input\nvariable \ngetscr\n.\n\nWhen \noptdriver\n=4, at least one of \nirdscr\n or \ngetscr\n (alternatively,\n\nirdsuscep\n or \ngetsuscep\n) must be non-zero.\n\n\nA non-zero value of \nirdscr\n is treated in the same way as other \u201cird\u201d\nvariables, see the \n section 4\n\n of the \nhelp_abinit\n.\n\n\nirdsuscep\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of the SUSCEPtibility\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nRelevant only when \noptdriver\n=4. Indicate the file from which the\nirreducible polarizability must be obtained. As alternative, one can use the\ninput variable \ngetsuscep\n.\n\nWhen \noptdriver\n=4, at least one of \nirdsuscep\n or \ngetsuscep\n\n(alternatively, \nirdscr\n or \ngetscr\n) must be non-zero.\n\n\nA non-zero value of \nirdsuscep\n is treated in the same way as other \u201cird\u201d\nvariables, see the \n section 4\n\n of the \nhelp_abinit\n.\n\n\nirdwfk\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of _WFK files\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIndicates eventual starting wavefunctions. As alternative, one can use the\ninput variables \ngetwfk\n, \ngetwfq\n, \nget1wf\n or \ngetddk\n.  \n\n\nGround-state calculation :\n\n\n\n\nonly \nirdwfk\n and \ngetwfk\n have a meaning \n\n\nat most one of \nirdwfk\n or \ngetwfk\n can be non-zero \n\n\nif \nirdwfk\n and \ngetwfk\n are both zero, initialize wavefunctions with random numbers for ground state calculation. \n\n\nif \nirdwfk\n = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nResponse-function calculation :\n\n\n\n\none and only one of \nirdwfk\n or \ngetwfk\n MUST be non-zero \n\n\nif \nirdwfk\n = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nonly one of \n irdwfq \n or \ngetwfq\n can be non-zero, if both of them are non-zero, use as k + q file the one defined by \nirdwfk\n and/or \ngetwfk\n \n\n\nif \n irdwfq \n = 1 : read ground state k+q -wavefunctions from a disk file appended with _WFQ , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nat most one of \n ird1wf \n or \nget1wf\n can be non-zero \n\n\nif both are zero, initialize first order wavefunctions to 0\u2019s. \n\n\nif \n ird1wf \n = 1 : read first-order wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nat most one of \n irdddk \n or \ngetddk\n can be non-zero \n\n\none of them must be non-zero if an homogeneous electric field calculation is done (presently, a ddk calculation in the same dataset is not allowed) \n\n\nif \n irdddk \n = 1 : read first-order ddk wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nirdwfq\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of _WFQ files\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIndicates eventual starting wavefunctions. As alternative, one can use the\ninput variables \ngetwfk\n, \ngetwfq\n, \nget1wf\n or \ngetddk\n.  \n\n\nGround-state calculation :\n\n\n\n\nonly \n irdwfk \n and \ngetwfk\n have a meaning \n\n\nat most one of \n irdwfk \n or \ngetwfk\n can be non-zero \n\n\nif \n irdwfk \n and \ngetwfk\n are both zero, initialize wavefunctions with random numbers for ground state calculation. \n\n\nif \n irdwfk \n = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nResponse-function calculation :\n\n\n\n\none and only one of \n irdwfk \n or \ngetwfk\n MUST be non-zero \n\n\nif \n irdwfk \n = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nonly one of \nirdwfq\n or \ngetwfq\n can be non-zero, if both of them are non-zero, use as k + q file the one defined by \n irdwfk \n and/or \ngetwfk\n \n\n\nif \nirdwfq\n = 1 : read ground state k+q -wavefunctions from a disk file appended with _WFQ , produced in a previous ground state calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nat most one of \n ird1wf \n or \nget1wf\n can be non-zero \n\n\nif both are zero, initialize first order wavefunctions to 0\u2019s. \n\n\nif \n ird1wf \n = 1 : read first-order wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\nat most one of \n irdddk \n or \ngetddk\n can be non-zero \n\n\none of them must be non-zero if an homogeneous electric field calculation is done (presently, a ddk calculation in the same dataset is not allowed) \n\n\nif \n irdddk \n = 1 : read first-order ddk wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the \n section 4 \n of the \nhelp_abinit\n). \n\n\n\n\nkssform\n\u00b6\n\n\nMnemonics: Kohn Sham Structure file FORMat\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nGoverns the choice of the format for the file that contains the Kohn-Sham\nelectronic structure information, for use in \nGW\n calculations, see the\ninput variables \noptdriver\n and \nnbandkss\n.\n\n\n\n\nkssform\n=1, a single file .kss (double precision) containing complete information on the Kohn Sham Structure (eigenstates and the pseudopotentials used) will be generated through full diagonalization of the complete Hamiltonian matrix. The file has at the beginning the standard abinit header. \n\n\nkssform\n=3, a single file .kss (double precision) containing complete information on the Kohn Sham Structure (eigenstates and the pseudopotentials used) will be generated through the usual conjugate gradient algorithm (so, a restricted number of states). The file has at the beginning the standard abinit header. \n\n\n\n\nVery important : for the time being, \nistwfk\n must be 1 for all the\nk-points.\n\n\nprt1dm\n\u00b6\n\n\nMnemonics: PRinT 1-DiMensional potential and density\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set >= 1, provide one-dimensional projection of potential and density,\nfor each of the three axis. This corresponds to averaging the potential or the\ndensity on bi-dimensional slices of the FFT grid.\n\n\nprtden\n\u00b6\n\n\nMnemonics: PRinT the DENsity\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0 if \nnimage\n>1,\n1 otherwise.\n\n\nIf set to 1 or a larger value , provide output of electron density in real\nspace rho(r), in units of electrons/Bohr^3.\n\nIf \nionmov\n==0, the name of the density file will be the root output name,\nfollowed by _DEN .\n\nIf \nionmov\n==1 or 2, density files will be output at each time step, with\nthe name being made of\n\n\n\n\nthe root output name, \n\n\nfollowed by _TIMx , where x is related to the timestep (see later) \n\n\nthen followed by _DEN \n\n\n\n\nThe file structure of the unformatted output file is described below, see\nsection 6).\n\nIf \nprtden\n is lower than 0, two files will be printed for restart every\n\nprtden\n step, with the names being made of\n\n\n\n\nthe root temporary name, \n\n\nfollowed by _DEN_x , where x is 0000 or 0001 alternatively. \n\n\nThe most recent of the two files should be used for restart, and copied to root input name_DS2_DEN \n\n\nTo perform a restart, in a multidataset mode, use ndtset 2 and jdtset 2 3 (that is 2 datasets, numbered 2 and 3) \n\n\nIn the dataset 2, get the density you just copied (getden2 -1), perform a non selfconsistent calculation and print the wave function (prtwf2 1) \n\n\nIn the dataset 3, get the previous wf(getwfk3 -1), and continue the calculation \n\n\nThis complicated procedure is due to the fact that reading the density is only allowed for a non sc calculation, and also for a dataset different of 0 or the previous one, the option we choose here. \n\n\n\n\nPlease note that in the case of PAW (\nusepaw\n=1) calculations, the _DEN\ndensity output is not the full physical electron density. If what is wanted is\nthe full physical electron density, say for post-processing with \n AIM\n\n or visualization, prtden > 1\nwill produce physical electron density or other interesting quantities (see\nbelow). Nevertheless, even in the PAW case, when chaining together\ncalculations where the density from one calculation is to be used in a\nsubsequent calculation, it is necessary to use the _DEN files and \n not \n\none of the other files produced with prtden > 1, i.e. _PAWDEN, ATMDEN_xxx\nor else. Note that the usual _DEN file is always generated as soon as prtden\n>= 1. Options 2 to 6 for prtden are relevant only for \nusepaw\n=1 and\ncontrol the output of the full electron density in the PAW case :  \n\n\n prtden=2 \n causes generation of a file _PAWDEN that contains the bulk \n valence \n charge density together with the PAW on-site contributions, and has the same format as the other density files. \n\n\n prtden=3 \n causes generation of a file _PAWDEN that contains the bulk \n full \n charge density (valence+core) \n\n\n prtden=4 \n causes generation of three files _ATMDEN_CORE, _ATMDEN_VAL and _ATMDEN_FULL which respectively contain the core, valence and full atomic protodensity (the density of the individual component atoms in vacuum superposed at the bulk atomic positions). This can be used to generate various visualizations of the bonding density. \n\n\n prtden=5 \n options 2 and 4 taken together. \n\n\n prtden=6 \n options 3 and 4 taken together. \n\n\n prtden=7 \n causes the generation of all the individual contributions to the bulk \n valence \n charge density : n_tilde-n_hat (_N_TILDE), n_onsite (_N_ONE) and n_tilde_onsite (_NT_ONE). This is for diagnosis purposes only.   \n\n\nOptions 3 to 6 currently require the user to supply the atomic core and\nvalence density in external files in the working directory. The files must be\nnamed properly; for example, the files for an atom of type 1 should be named:\n\u201ccore_density_atom_type1.dat\u201d and \u201cvalence_density_atom_type1.dat\u201d. The file\nshould be a text file, where the first line is assumed to be a comment, and\nthe subsequent lines contain two values each, where the first one is a radial\ncoordinate and the second the value of the density n(r). Please note that it\nis n(r) which should be supplied, \n not \n n(r)/r^2. The first coordinate\npoint must be the origin, i.e. \n _ r = 0 _ \n . The atomic densities are\nspherically averaged, so assumed to be completely spherically symmetric, even\nfor open shells.  \n\n\nNOTE: in the PAW case, \n DO NOT \n use _PAWDEN or _ATMDEN_xxx files produced\nby prtden > 1 to chain the density output from one calculation as the input\nto another, use the _DEN file for that.\n\n\nprtdos\n\u00b6\n\n\nMnemonics: PRinT the Density Of States\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nProvide output of Density of States if set to 1, 2 or 3. Can either use a\nsmearing technique (\nprtdos\n=1), or the tetrahedron method (\nprtdos\n=2).\nIf \nprtdos\n=3, provide output of Local Density of States inside a sphere\ncentered on an atom, as well as the angular-momentum projected DOS, in the\nsame sphere. The resolution of the linear grid of energies for which the DOS\nis computed can be tuned thanks to \ndosdeltae\n.\n\n\nIf \nprtdos\n=1, the smeared density of states is obtained from the\neigenvalues, properly weighted at each k point using \nwtk\n, and smeared\naccording to \noccopt\n and \ntsmear\n. All levels that are present in the\ncalculation are taken into account (occupied and unoccupied). Note that\n\noccopt\n must be between 3 and 7 . Also note that the sampling of the\nBrillouin Zone that is needed to get a converged DOS is usually much finer\nthan the sampling needed to converge the total energy or the geometry of the\nsystem, unless \ntsmear\n is very large (hence the DOS is not obtained\nproperly).. A separate convergence study is needed.\n\nIn order to compute the DOS of an insulator with \nprtdos\n=1, compute its\ndensity thanks to a self-consistent calculation (with a non-metallic\n\noccopt\n value, 0, 1 or 2), then use \nprtdos\n=1, together with\n\niscf\n=-3, and a metallic \noccopt\n, between 3 and 7, providing the needed\nsmearing. If \nprtdos\n=1, the name of the DOS file is the root name for the\noutput files, followed by \u201c_DOS\u201d .\n\n\nIf \nprtdos\n=2, the DOS is computed using the tetrahedron method. As in the\ncase of \nprtdos\n=1, all levels that are present in the calculation are taken\ninto account (occupied and unoccupied). In this case, the k-points must have\nbeen defined using the input variable \nngkpt\n or the input variable\n\nkptrlatt\n. There must be at least two non-equivalent points in the\nIrreducible Brillouin Zone to use \nprtdos\n=2. It is strongly advised to use\na non-shifted k-point grid (\nshiftk\n 0 0 0): such grids contain naturally\nmore extremal points (band minima and maxima at Gamma or at the zone-\nboundaries) than shifted grids, and lead to more non-equivalent points than\nshifted grids, for the same grid spacing. There is no need to take care of the\n\noccopt\n or \ntsmear\n input variables, and there is no subtlety to be taken\ninto account for insulators. The computation can be done in the self-\nconsistent case as well as in the non-self-consistent case, using \niscf\n=-3.\nThis allows to refine the DOS at fixed starting density.\n\nIn that case, if \nionmov\n==0, the name of the potential file will be the\nroot output name, followed by _DOS (like in the \nprtdos\n=1 case).\n\nHowever, if \nionmov\n==1 or 2, potential files will be output at each time\nstep, with the name being made of\n\n\n\n\nthe root output name, \n\n\nfollowed by _TIMx , where x is related to the timestep (see later) \n\n\nthen followed by _DOS. \n\n\n\n\nIf \nprtdos\n=3, the same tetrahedron method as for \nprtdos\n=2 is used, but\nthe DOS inside a sphere centered on some atom is delivered, as well as the\nangular-momentum projected (l=0,1,2,3,4) DOS in the same sphere. The\npreparation of this case, the parameters under which the computation is to be\ndone, and the file denomination is similar to the \nprtdos\n=2 case. However,\nthree additional input variables might be provided, describing the atoms that\nare the center of the sphere (input variables \nnatsph\n and \niatsph\n), as\nwell as the radius of this sphere (input variable \nratsph\n).\n\nIn case of PAW, \nratsph\n radius has to be greater or equal to largest PAW\nradius of the atom types considered (which is read from the PAW atomic data\nfile; see rc_sph or r_paw). Additional printing and/or approximations in PAW\nmode can be controlled with \npawprtdos\n keyword (in\nparticular,\npawprtdos\n=2 can be used to compute quickly a very good\napproximation of the DOS).  \n\n\nNote 1: when \nprtdos\n=3, it is possible to output m-decomposed LDOS in _DOS\nfile; simply use \nprtdosm\n keyword.\n\nNote 2: the integrated total DOS in spheres around atoms can be obtained when\n\nprtdensph\n flag is activated. It can be compared to the integrated DOS\nprovided in _DOS file when \nprtdos\n=3.\n\n\nprtdos\n=4 delivers the sphere-projected DOS (like \nprtdos\n=3), on the\nbasis of a smearing approach (like \nprtdos\n=1)\n\n\nprtdos\n=5 delivers the spin-spin DOS in the \nnspinor\n==2 case, using the\ntetrahedron method (as \nprtdos\n=2).\n\n\nprtdosm\n\u00b6\n\n\nMnemonics: PRinT the Density Of States with M decomposition\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nRelevant only when \nprtdos\n=3.\n\nIf set to 1, the m-decomposed LDOS is delivered in DOS file.\n\nNote that \nprtdosm\n computes the M-resolved partial dos for complex\nspherical harmonics,giving e.g. DOS(L,M) == DOS(L,-M) (without spin-orbit). In\nthe contrary, the LDA+U occupation matrix, see \ndmatpawu\n is in the real\nspherical harmonics basis.\n\nIf set to 2, the m-decomposed LDOS is delivered in DOS file.\n\nIn this case, \nprtdosm\n computes the M-resolved partial dos for real\nspherical harmonics in the same basis as the LDA+U occupation matrix.\n\n\nprteig\n\u00b6\n\n\nMnemonics: PRinT EIGenenergies\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0 if \nnimage\n > 1,\n1 otherwise.\n\n\nIf set to 1, a file *_EIG, containing the k-points and one-electron\neigenvalues is printed.\n\n\nprtelf\n\u00b6\n\n\nMnemonics: PRinT Electron Localization Function (ELF)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1 or a larger value, provide output of ELF in real space elf(r).\nThis is a dimensionless quantity bounded between 0 and 1.\n\nThe name of the ELF file will be the root output name, followed by _ELF.\n\nLike a _DEN file, it can be analyzed by cut3d. However unlike densities, in\ncase of spin polarized calculations, the spin down component can not be\nobtained by subtracting the spin up component to the total ELF. Hence when\nspin polarized calculations are performed the code produces also output files\nwith _ELF_UP and _ELF_DOWN extensions. (For technical reasons these files\ncontain also two components but the second is zero. So to perform analysis of\n_ELF_UP and _ELF_DOWN files with cut3d you have to answer \u201cispden= 0 ==>\nTotal density\u201d when cut3d ask you which ispden to choose. Also remember that\nspin down component can not be obtained by using cut3d on the _ELF file. Sorry\nfor the inconvenience, this will be fixed in the next release.)\n\nELF is not yet implemented in non collinear spin case.\n\nIf prtelf is set to 2, in the case of spin polarized calculation, the total\nELF is computed from an alternative approach which should better take into\naccount the existence of spin dependent densities (see the documentation in\n/doc/theory/ELF of your ABINIT repository)  \n\n\nPlease note that ELF is \n not \n yet implemented in the case of PAW\n(\nusepaw\n=1) calculations.\n\n\nprtfsurf\n\u00b6\n\n\nMnemonics: PRinT Fermi SURFace file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1, provide Fermi surface file in the BXSF format (Xcrysden) If\n\nprtfsurf\n=1, a _BXSF file readable by \n XCrySDen \n\nwill be produced at the end of the calculation. The file contains information\non the band structure of the system and can be used to visualize the Fermi\nsurface or any other energy isosurface. \nprtfsurf\n=1 is compatible only with\nSCF calculations (\niscf\n > 1) or NSCF runs in which the occupation\nfactors and Fermi level are recalculated once convergence is achieved\n(\niscf\n = -3). The two methods should produce the same Fermi surface\nprovided that the k-meshes are sufficiently dense. The k-mesh used for the\nsampling of the Fermi surface can be specified using the standard variables\n\nngkpt\n, (\nshiftk\n, and \nnshiftk\n. Note, however, that the mesh must be\nhomogeneous and centered on gamma (multiple shifts are not supported by\nXcrysden)\n\n\nprtgden\n\u00b6\n\n\nMnemonics: PRinT the Gradient of electron DENsity\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1 or a larger value, provide output of gradient of electron density\nin real space grho(r), in units of Bohr^-(5/2).\n\nThe names of the gradient of electron density files will be the root output\nname, followed by _GDEN1, _GDEN2, GDEN3 for each principal direction (indeed\nit is a vector).\n\nLike a _DEN file, it can be analyzed by cut3d. The file structure of the\nunformatted output file is described below, see section 6).\n\n\nprtgeo\n\u00b6\n\n\nMnemonics: PRinT the GEOmetry analysis\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1 or a larger value, provide output of geometrical analysis (bond\nlengths and bond angles). The value of \nprtgeo\n is taken by the code to be\nthe maximum coordination number of atoms in the system.\n\nIt will deduce a maximum number of \u201cnearest\u201d and \u201cnext-nearest\u201d neighbors\naccordingly , and compute corresponding bond lengths.\n\nIt will compute bond angles for the \u201cnearest\u201d neighbours only.\n\nIf \nionmov\n==0, the name of the file will be the root output name, followed\nby _GEO .\n\nIf \nionmov\n==1 or 2, one file will be output at each time step, with the\nname being made of\n\n\n\n\nthe root output name, \n\n\nfollowed by _TIMx , where x is related to the timestep (see later) \n\n\nthen followed by _GEO \n\n\n\n\nThe content of the file should be rather self-explanatory.\n\nNo output is provided by \nprtgeo\n is lower than or equal to 0.\n\nIf \nprtgeo\n>0, the maximum number of atoms (\nnatom\n) is 9999.\n\n\nprtgkk\n\u00b6\n\n\nMnemonics: PRinT the GKK matrix elements file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1, provide output of electron-phonon \u201cgkk\u201d matrix elements, for\nfurther treatment by mrggkk utility or anaddb utility. Note that symmetry will\nbe disabled for the calculation of the perturbation, forcing the inclusion of\nall k-points and all perturbation directions. Additional information on\nelectron-phonon treatment in ABINIT is given in the tutorial\n~abinit/doc/tutorial/lesson_eph.html and in ~abinit/doc/users/elphon_manual.ps\n\n\nprtgsr\n\u00b6\n\n\nMnemonics: PRinT the GSR file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: prtgsr = 0  \n\n\nIf set to 1, ABINIT will produce a GSR file at the end of the GS calculation.\nThe GSR file contains the most important GS results (band structure, forces,\nstresses, electronic density). The GSR file can be read by AbiPy and used for\nfuther postprocessing.\n\nNote that, by default, the GSR file contains the electronic density unless\n\nprtden\n is set to 0.\n\n\nprtkden\n\u00b6\n\n\nMnemonics: PRinT the Kinetic energy DENsity\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1 or a larger value , provide output of kinetic energy density in\nreal space tau(r), in units of Bohr^-5.\n\nThe name of the kinetic energy density file will be the root output name,\nfollowed by _KDEN.\n\nLike a _DEN file, it can be analyzed by cut3d. The file structure of the\nunformatted output file is described below (see \n section 6\n\n).\n\nNote that the computation of the kinetic energy density must be activate,\nthanks to the input variable \nusekden\n.\n\nPlease note that kinetic energy density is \n not \n yet implemented in the\ncase of PAW (\nusepaw\n=1) calculations.\n\n\nprtkpt\n\u00b6\n\n\nMnemonics: PRinT the K-PoinTs sets\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set /= 0 , proceeds to a detailed analysis of different k point grids.\nWorks only if \nkptopt\n is positive, and neither \nkptrlatt\n nor \nngkpt\n\nare defined. ABINIT will stop after this analysis.\n\n\nDifferent sets of k point grids are defined, with common values of \nshiftk\n.\nIn each set, ABINIT increases the length of vectors of the supercell (see\n\nkptrlatt\n) by integer steps. The different sets are labelled by \u201ciset\u201d. For\neach k point grid, \nkptrlen\n and \nnkpt\n are computed (the latter always\ninvoking \nkptopt\n=1, that is, full use of symmetries). A series is finished\nwhen the computed \nkptrlen\n is twice larger than the input variable\n\nkptrlen\n. After the examination of the different sets, ABINIT summarizes,\nfor each \nnkpt\n, the best possible grid, that is, the one with the largest\ncomputed \nkptrlen\n.\n\n\nNote that this analysis is also performed when \nprtkpt\n=0, as soon as\nneither \nkptrlatt\n nor \nngkpt\n are defined. But, in this case, no analysis\nreport is given, and the code selects the grid with the smaller \nngkpt\n for\nthe desired \nkptrlen\n. However, this analysis takes some times (well\nsometimes, it is only a few seconds - it depends on the value of the input\n\nkptrlen\n), and it is better to examine the full analysis for a given cell\nand set of symmetries, \nshiftk\n for all the production runs.\n\n\nif set to -2, the code stops in invars1 after the computation of the\nirreducible set and a file named kpts.nc with the list of the k-points and the\ncorresponding weights is produced\n\n\nprtlden\n\u00b6\n\n\nMnemonics: PRinT the Laplacian of electron DENsity\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1 or a larger value, provide output of Laplacian of electron density\nin real space grho(r), in units of Bohr^-(7/2).\n\nThe name of the Laplacian of electron density file will be the root output\nname, followed by _LDEN.\n\nLike a _DEN file, it can be analyzed by cut3d. The file structure of the\nunformatted output file is described below (see \n section 6\n\n).\n\n\nprtpot\n\u00b6\n\n\nMnemonics: PRinT total POTential\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set >=1 , provide output of the total (Kohn-Sham) potential (sum of\nlocal pseudo-potential, Hartree potential, and xc potential).\n\n\nIf \nionmov\n==0, the name of the potential file will be the root output name,\nfollowed by _POT.\n\nIf \nionmov\n==1 or 2, potential file will be output at each time step, with\nthe name being made of\n\n\n\n\nthe root output name, \n\n\nfollowed by _TIMx , where x is related to the timestep (see later) \n\n\nthen followed by _POT. \n\n\n\n\nThe file structure of this unformatted output file is described in \n section\n6.6 \n of the\n\nhelp_abinit\n. No output is provided by a negative value of this variable.\n\n\nprtpsps\n\u00b6\n\n\nMnemonics: PRint the PSPS file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1, the code produces a netcdf file (PSPS.nc) with the internal\ntables used by Abinit to apply the pseudopotential part of the KS Hamiltonian.\nThe data can be visualized with AbiPy. if prtpsps is set to -1, the code will\nexit after the output of the PSPS.nc file.\n\n\nprtspcur\n\u00b6\n\n\nMnemonics: PRinT the SPin CURrent density\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1 or a larger value, provide output of the current density of\ndifferent direction spins (x,y,z) in the whole unit cell. Should require\nspinorial wave functions \nnspinor\n = 2. Experimental: this does not work\nyet.\n\n\nprtstm\n\u00b6\n\n\nMnemonics: PRinT the STM density\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1 or a larger value, provide output of the electron density in real\nspace rho(r), made only from the electrons close to the Fermi energy, in a\nrange of energy (positive or negative), determined by the (positive or\nnegative, but non-zero) value of the STM bias \nstmbias\n.\n\nThis is a very approximate way to obtain STM profiles : one can choose an\nequidensity surface, and consider that the STM tip will follow this surface.\nSuch equidensity surface might be determined with the help of Cut3D, and\nfurther post-processing of it (to be implemented). The big approximations of\nthis technique are : neglect of the finite size of the tip, and position-\nindependent transfer matrix elements between the tip and the surface.\n\nThe charge density is provided in units of electrons/Bohr^3. The name of the\nSTM density file will be the root output name, followed by _STM . Like a _DEN\nfile, it can be analyzed by cut3d. The file structure of this unformatted\noutput file is described in \n section 6.5\n\n of the\n\nhelp_abinit\n.\n\nFor the STM charge density to be generated, one must give, as an input file,\nthe converged wavefunctions obtained from a previous run, at exactly the same\nk-points and cut-off energy, self-consistently determined, using the\noccupation numbers from \noccopt\n=7.\n\nIn the run with positive \nprtstm\n, one has to use :\n\n\n\n\npositive \niscf\n \n\n\noccopt\n=7, with specification of \ntsmear\n \n\n\nnstep\n=1 \n\n\nthe \ntolwfr\n convergence criterion \n\n\nionmov\n=0 (this is the default value) \n\n\noptdriver\n=0 (this is the default value) \n\n\n\n\nNote that you might have to adjust the value of \nnband\n as well, for the\ntreatment of unoccupied states, because the automatic determination of\n\nnband\n will often not include enough unoccupied states.\n\nWhen \nprtstm\n is non-zero, the stress tensor is set to zero.\n\nNo output of _STM file is provided by \nprtstm\n lower or equal to 0.\n\nNo other printing variables for density or potentials should be activated\n(e.g. \nprtden\n has to be set to zero).\n\n\nprtsuscep\n\u00b6\n\n\nMnemonics: PRinT the SUSCEPtibility file (the irreducible polarizability)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 0, no _SUSC file will be produced after the screening calculation,\nonly the _SCR file will be output.\n\n\nprtvclmb\n\u00b6\n\n\nMnemonics: PRinT V CouLoMB\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set >= 0 outputs a file with the Coulomb potential, defined as Hartree +\nlocal Pseudopotential.\n\n\nIf \nprtvclmb=1\n and in case of PAW (\nusepaw\n > 0), the full core potential\nis added for the Hartree part, with the on-site corrections vh1 - vht1.\n\n\nIf \nprtvclmb=2\n, only the smooth part of the Coulomb potential is output.\n\n\nprtvha\n\u00b6\n\n\nMnemonics: PRinT V_HArtree\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set >=1 , provide output of the Hartree potential.  \n\n\nIf \nionmov\n==0, the name of the potential file will be the root output name,\nfollowed by _VHA.\n\nIf \nionmov\n==1 or 2, potential files will be output at each time step, with\nthe name being made of\n\n\n\n\nthe root output name, \n\n\nfollowed by _TIMx , where x is related to the timestep (see later) \n\n\nthen followed by _VHA. \n\n\n\n\nThe file structure of this unformatted output file is described in \n section\n6.6 \n of the\n\nhelp_abinit\n. No output is provided by a negative value of this variable.\n\n\nprtvhxc\n\u00b6\n\n\nMnemonics: PRinT V_HXC\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set >=1 , provide output of the sum of the Hartree potential and xc\npotential.\n\n\nIf \nionmov\n==0, the name of the potential file will be the root output name,\nfollowed by _VHXC.\n\nIf \nionmov\n==1 or 2, potential files will be output at each time step, with\nthe name being made of\n\n\n\n\nthe root output name, \n\n\nfollowed by _TIMx , where x is related to the timestep (see later) \n\n\nthen followed by _VHXC. \n\n\n\n\nThe file structure of this unformatted output file is described in \n section\n6.6 \n of the\n\nhelp_abinit\n. No output is provided by a negative value of this variable.\n\n\nprtvol\n\u00b6\n\n\nMnemonics: PRinT VOLume\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nControl the volume of printed output. In particular, this concerns the\nexplicit echo of eigenenergies and residuals for all bands and k points in the\nmain output file. Also, the analysis of the value and location of the maximal\ndensity (and magnetization).\n\nStandard choice is 0. Positive values print more in the output and log files,\nwhile negative values are for debugging (or preprocessing only), and cause the\ncode to stop at some point.\n\n\n\n\n0 => The eigenenergies and residuals for all bands and k points are not echoed in the main output file. There are exceptions: the eigenvalues of the first k point are printed at the end of the SCF loop, and also, if \niscf\n=-2 and \nkptopt\n<=0, the eigenvalues for all the k points are printed anyway, for a maximum of 50 k-points. Due to some subtlety, if for \nsome\n dataset \nprtvol\n is non-zero, the limit for input and output echoes cannot be enforced, so it is like if \nprtvol\n=1 for \nall\n the datasets for which \nprtvol\n was set to 0.\n\n\n1 => the eigenvalues for the first 50 k-points are printed in all cases, at the end of the SCF loop.\n\n\n2 => all the eigenvalues and the residuals are printed at the end of the SCF loop. Also, the analysis of the value and location of the maximal density (and magnetization) is printed.\n\n\n3 => Print memory information for lobpcg \n\n\n4 => Like 3 and prints information of lobpcg algorithm convergence\n\n\n10 => the eigenvalues are printed for every SCF iteration, as well as other additions (to be specified in the future\u2026) \n\n\n\n\nDebugging options :\n\n\n\n\n= -1 => stop in abinit (main program), before call driver. Useful to see the effect of the preprocessing of input variables (memory needed, effect of symmetries, k points \u2026) without going further. Run very fast, on the order of the second.\n\n\n=-2 => same as -1, except that print only the first dataset. All the non default input variables associated to all datasets are printed in the output file, but only for the first dataset. Also all the input variables are written in the NetCDF file \"OUT.nc\", even if the value is the default.\n\n\n= -3 => stop in gstate, before call scfcv, move or brdmin. Useful to debug pseudopotentials\n\n\n= -4 => stop in move, after completion of all loops\n\n\n= -5 => stop in brdmin, after completion of all loops\n\n\n= -6 => stop in scfcv, after completion of all loops \n\n\n= -7 => stop in vtorho, after the first rho is obtained\n\n\n= -8 => stop in vtowfk, after the first k point is treated\n\n\n= -9 => stop in cgwf, after the first wf is optimized\n\n\n= -10 => stop in getghc, after the Hamiltonian is applied once\n\n\n\n\nThis debugging feature is not yet activated in the RF routines. Note that\n\nfftalg\n offers another option for debugging.\n\n\nprtvolimg\n\u00b6\n\n\nMnemonics: PRinT VOLume for IMaGes\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nControl the volume of printed output when an algorithm using images of the\ncell is used (\nnimage\n>1).\n\nWhen such an algorithm is activated, the printing volume (in output file) can\nbe large and difficult to read.\n\nUsing \n prtvolimg=1 \n , the printing volume, for each image, is reduced to\nunit cell, atomic positions, total energy, forces, stresses, velocities and\nconvergence residuals.\n\nUsing \n prtvolimg=2 \n , the printing volume, for each image, is reduced to\ntotal energy and convergence residuals only.\n\n\nprtvpsp\n\u00b6\n\n\nMnemonics: PRinT V_PSeudoPotential\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set >=1 , provide output of the local pseudo potential.  \n\n\nIf \nionmov\n==0, the name of the potential file will be the root output name,\nfollowed by _VPSP.\n\nIf \nionmov\n==1 or 2, potential files will be output at each time step, with\nthe name being made of\n\n\n\n\nthe root output name, \n\n\nfollowed by _TIMx , where x is related to the timestep (see later) \n\n\nthen followed by _VPSP. \n\n\n\n\nThe file structure of this unformatted output file is described in \n section\n6.6 \n of the\n\nhelp_abinit\n. No output is provided by a negative value of this variable.\n\n\nprtvxc\n\u00b6\n\n\nMnemonics: PRinT V_XC\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set >=1 , provide output of the exchange-correlation potential.\n\n\nIf \nionmov\n==0, the name of the potential file will be the root output name,\nfollowed by _VXC.\n\nIf \nionmov\n==1 or 2, potential files will be output at each time step, with\nthe name being made of\n\n\n\n\nthe root output name, \n\n\nfollowed by _TIMx , where x is related to the timestep (see later) \n\n\nthen followed by _VXC. \n\n\n\n\nThe file structure of this unformatted output file is described in \n section\n6.6 \n of the\n\nhelp_abinit\n. No output is provided by a negative value of this variable.\n\n\nprtwant\n\u00b6\n\n\nMnemonics: PRinT WANT file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nFlag used to indicate that either the Wannier90 or the WanT interfaces will be\nused.\n\n\n\n\nprtwant\n=1 => Use the \n ABINIT- WanT \n interface. \n\n\n\n\nProvide an output file that can be used by the WanT postprocessing program\n(see http://www.wannier-transport.org). The value of the prtwant indicates the\nversion of the WanT code that can read it. Currently only the value\n\nprtwant\n=1 is implemented, corresponding to WanT version 1.0.1, available\nsince Oct. 22, 2004.\n\n\nNotes : Several requirements must be fulfilled by the wavefunction. Among\nthem, two are mandatory:  \n\n\n* 1\\. An uniform grid of k-points, including the GAMMA point must be used. \n* 2\\. The use of time reversal symmetry is not allowed (istwfk=1) \n* 3\\. The list of k-points must be ordered, such that the coordinates, namely three-components vectors has the third index varying the most rapidly, then the second index, then the first index\n\n\n\n\n\nIf these requirement are not fulfilled, the program will stop and an error\nmessage is returned.\n\n\nAs an example of k-point grid in case of systems that have some 3D character\n(1D systems are easy) :\n\n\n         nkpt 8\nkpt  0   0   0\n0   0   1/2\n0   1/2 0\n0   1/2 1/2\n1/2 0   0\n1/2 0   1/2\n1/2 1/2 0\n1/2 1/2 1/2\nistwfk 8*1\n\n\n\n\n\nAlso, in order to use WanT as a postprocessing program for ABINIT you might\nhave to recompile it with the appropriate flags (see ABINIT makefile). Up to\nnow only the -convert big-endian was found to be mandatory, for machines with\nlittle-endian default choice.\n\n\n\n\nprtwant\n=2 => Use the \n ABINIT- Wannier90 \n interface. \n\n\n\n\nABINIT will produce the input files required by Wannier90 and it will run\nWannier90 to produce the Maximally-locallized Wannier functions (see \n\nhttp://www.wannier.org \n ).\n\n\nNotes:\n\n\n* The files that are created can also be used by Wannier90 in stand-alone mode. \n* In order to use Wannier90 as a postprocessing program for ABINIT you might have to recompile it with the appropriate flags (see ABINIT makefile). You might use ./configure --enable-wannier90 \n* There are some other variables related to the interface of Wannier90 and ABINIT. See, [ VARW90 ](varw90.html) .\n\n\n\n\n\n\n\nprtwant\n=3 => Use the \n ABINIT- Wannier90 \n interface after converting the input wavefunctions to \n \nGW\n quasiparticle \n wavefunctions. \n\n\n\n\nABINIT will produce the input files required by Wannier90 and it will run\nWannier90 to produce the Maximally-localized Wannier functions (see \n\nhttp://www.wannier.org \n ).\n\n\nAdditional Notes:\n\n\n* An input file of LDA wave functions is required which is completely consistent with the _KSS file used in the self-consistent [[GW]] calculation. This means that [[kssform]] 3 must be used to create the _KSS file and the output _WFK file from the same run must be used as input here. \n* Wannier90 requires [[nshiftk]]=1, and [[shiftk]]= 0 0 0 is recommended. The k-point set used for the [[GW]] calculation, typically the irreducible BZ set created using [[kptopt]]=1, and that for the Abinit- Wannier90 interface must be consistent. \n* Full-BZ wavefunctions should be generated in the run calling the interface by setting [[kptopt]]=3, [[iscf]]=-2, and [[nstep]]=3. This will simply use symmetry to transform the input IBZ wavefunctions to the full BZ set, still consistent with the [[GW]] _KSS input. \n* The final _QPS file created by the self-consistent [[GW]] run is required as input. \n* Any value of [[gwcalctyp]] between between 20 and 29 should be suitable, so, for example, Hartree-Fock maximally-localized Wannier functions could be generated setting [[gwcalctyp]]=25.\n\n\n\n\n\nprtwf\n\u00b6\n\n\nMnemonics: PRinT the WaveFunction\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0 if \nnimage\n > 1,\n1 otherwise.\n\n\nIf \nprtwf\n=1 , provide output of wavefunction and eigenvalue file, as\ndescribed in \n section 6.7\n\n of the main\n\nhelp_abinit\n.\n\nFor a standard ground-state calculation, the name of the wavefunction file\nwill be the root output name, followed by _WFK. If \nnqpt\n=1, the root name\nwill be followed by _WFQ. For response-function calculations, the root name\nwill be followed by _1WFx, where x is the number of the perturbation. The\ndataset information will be added as well, if relevant.\n\nNo wavefunction output is provided by \nprtwf\n=0.\n\nIf \nprtwf\n=-1, the code writes the wavefunction file only if convergence is\nnot achieved in the self-consistent cycle.\n\n\nIf \nprtwf\n=2, a file pwfn.data is produced, to be used as input for the\nCASINO QMC code. See more explanation at the end of this section.\n\nIf \nprtwf\n=3, the file that is created is nearly the same as with\n\nprtwf\n=1, except that the records that should contain the wavefunction is\nempty (so, such records exist, but store nothing). This is useful to generate\nsize-reduced DDK files, to perform an optic run. Indeed, in the latter case,\nonly matrix elements are needed [so, no wavefunction], but possibly a large\nnumber of conduction bands, so that the DDK file might be huge if it contains\nthe wavefunctions.\n\n\nFurther explanation for the \nprtwf\n=2 case. To produce a wave function\nsuitable for use as a CASINO trial wave function, certain ABINIT parameters\nmust be set correctly. Primarily, CASINO (and QMC methods generally) can only\ntake advantage of time-reversal symmetry, and not the full set of symmetries\nof the crystal structure. Therefore, ABINIT must be instructed to generate\nk-points not just in the Irreducible Brillouin Zone, but in a full half of the\nBrillouin Zone (using time-reversal symmetry to generate the other half).\nAdditionally, unless instructed otherwise, Abinit avoids the need for internal\nstorage of many of the coefficients of its wave functions for k-points that\nhave the property 2k=G_latt, where G_latt is a reciprocal lattice vector, by\nmaking use of the property that c_k(G)=c^*_k(-G-G_latt). Abinit must be\ninstructed not to do this in order to output the full set of coefficients for\nuse in CASINO. See the ABINIT theoretical background documents\nABINIT/Infos/Theory/geometry.pdf and ABINIT/Infos/Theory/1WF.pdf for more\ninformation.\n\nThe first of these requirements is met by setting the ABINIT input variable\nkptopt to 2 (see ABINIT/Infos/varbas.html#kptopt) and the second by setting\nistwfk to 1 for all the k points (see ABINIT/Infos/vardev.html#istwfk). Since\nCASINO is typically run with relatively small numbers of k-points, this is\neasily done by defining an array of \u201c1\u201d in the input file.\n\nFor example, for the 8 k-points generated with ngkpt 2 2 2, we add the\nfollowing lines to the input file:\n\n\n  # Turn off special storage mode for time-reversal k-points\nistwfk 1 1 1 1 1 1 1 1\n# Use only time reversal symmetry, not full set of symmetries.\nkptopt 2\n\n\n\n\n\nOther useful input variables of relevance to the plane waves ABINIT will\nproduce include ecut, nshiftk, shiftk, nband, occopt, occ, spinat and nsppol\n(see relevant input variable documents in ABINIT/Infos/). If ABINIT is run in\nmultiple dataset mode, the different wave functions for the various datasets\nare exported as pwfn1.data, pwfn2.data, \u2026, pwfnn.data where the numbers are\nthe contents of the contents of the input array jdtset (defaults to\n1,2,\u2026,ndtset).\n\nOnce the routine is incorporated into the ABINIT package it is anticipated\nthat there will be an input variable to control whether or not a CASINO\npwfn.data file is written.\n\n\nOther issues related to \nprtwf\n=2.\n\nThe exporter does not currently work when ABINIT is used in parallel mode on\nmultiple processors if k-point parallelism is chosen. ABINIT does not store\nthe full wave function on each processor but rather splits the k-points\nbetween the processors, so no one processor could write out the whole file.\nClearly this could be fixed but we have not done it yet. The sort of plane\nwave DFT calculations usually required to generate QMC trial wave functions\nexecute very rapidly anyway and will generally not require a parallel\nmachines. The outqmc routine currently bails out with an error if this\ncombination of modes is selected - this will hopefully be fixed later.\n\nThere has not been very extensive testing of less common situations such as\ndifferent numbers of bands for different k-points, and more complicated spin\npolarized systems, so care should be taken when using the output in these\ncircumstances.\n\nIf there is any doubt about the output of this routine, the first place to\nlook is the log file produced by ABINIT: if there are any warnings about\nincorrectly normalized orbitals or non-integer occupation numbers there is\nprobably something set wrong in the input file.\n\n\nprtwf_full\n\u00b6\n\n\nMnemonics: PRinT Wavefunction file on the FULL mesh\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nprtwf\n == 1  \n\n\nIf set to 1 in a ground-state calculation, the code will output another WFK\nfile (with extension FULL_WFK) containing the wavefunctions in the full BZ as\nwell as a text file with the tables used for the tetrahedron method. Note that\nprtwf_full requires \nprtwf\n == 1 and a ground-state calculation done on a\nhomogeneous k-mesh (see \nngkpt\n and \nshiftk\n). The tetrahedron table is\nproduced only if the number of k-points in the irreducible zone (\nnkpt\n) is\ngreater than 3.\n\n\nprtxml\n\u00b6\n\n\nMnemonics: PRinT an XML output\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nCreate an XML output with common values. The corresponding DTD is distributed\nin sources as extras/post_processing/abinitRun.dtd. All the DTD is not yet\nimplemented and this one is currently restricted to ground-state computations\n(and derivative such as geometry optimisation).",
            "title": "File-handling"
        },
        {
            "location": "/input_variables/varfil/#get1den",
            "text": "Mnemonics: GET the first-order density from _1DEN file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Relevant only for non self consistent RF calculations (e.g. to get electron\nphonon matrix elements) or for non linear RF calculations (to get mixed higher\norder derivatives you need several perturbed densities and wave functions).\nIndicate the files from which first-order densities must be obtained, in\nmulti-dataset mode (in single dataset mode, use  ird1den ). \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "get1den"
        },
        {
            "location": "/input_variables/varfil/#get1wf",
            "text": "Mnemonics: GET the first-order wavefunctions from _1WF file  \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to  irdwfk ,  irdwfq , ird1wf ,  irdddk . One should first read the explanations given for these\nlatter variables. \nThe   getwfk   ,   getwfq   ,  get1wf  and   getddk   variables are\ntypically used to chain the calculations in the multi-dataset mode, since they\ndescribe from which dataset the OUTPUT wavefunctions are to be taken, as INPUT\nwavefunctions of the present dataset.    We now focus on the   getwfk   input variable (the only one used in ground-\nstate calculations), but the rules for   getwfq   and  get1wf  are\nsimilar, with _WFK replaced by _WFQ or _1WF. \nIf   getwfk   ==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done. \nIf   getwfk   is positive, its value gives the index of the dataset for\nwhich the output wavefunction file appended with _WFK must be used. \nIf   getwfk   is -1, the output wf file with _WFK of the previous dataset\nmust be taken, which is a frequently occurring case. \nIf   getwfk   is a negative number, it indicates the number of datasets to\ngo backward to find the needed wavefunction file. In this case, if one refers\nto a non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if   getwfk   =0 for that\ninitialisation. Thanks to this rule, the use of   getwfk   -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one. \nIn the case of a ddk calculation in a multi dataset run, in order to compute\ncorrectly the localisation tensor, it is mandatory to declare give getddk the\nvalue of the current dataset (i.e. getddk3 3 ) - this is a bit strange and\nshould be changed in the future. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "get1wf"
        },
        {
            "location": "/input_variables/varfil/#getbscoup",
            "text": "Mnemonics: GET the Bethe-Salpeter COUPling block from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (multi-dataset mode) and, in the case of\na Bethe-Salpeter calculation to indicate that the starting coupling block of\nthe excitonic Hamiltonian will be taken from the output of a previous dataset.\nIt is used to chain the calculations, since it describes from which dataset\nthe OUTPUT coupling block is to be taken, as INPUT of the present dataset. \nIf  getbscoup ==0, no such use of previously computed coupling block file is\ndone. \nIf  getbscoup  is positive, its value gives the index of the dataset to be\nused as input. \nIf  getbscoup  is -1, the output of the previous dataset must be taken,\nwhich is a frequently occuring case. \nIf  getbscoup  is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the coupling block is not initialised\nfrom a disk file, so that it is as if  getbscoup =0 for that initialisation.",
            "title": "getbscoup"
        },
        {
            "location": "/input_variables/varfil/#getbseig",
            "text": "Mnemonics: GET the Bethe-Salpeter EIGenstates from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (multi-dataset mode) and, in the case of\na Bethe-Salpeter calculation to indicate that the starting excitonic\neigenstates are to be taken from the output of a previous dataset. It is used\nto chain the calculations, since it describes from which dataset the OUTPUT\neigenstates are to be taken, as INPUT eigenstates of the present dataset. \nIf  getbseig ==0, no such use of previously computed output eigenstates file\nis done. \nIf  getbseig  is positive, its value gives the index of the dataset from\nwhich the output states is to be used as input. \nIf  getbseig  is -1, the output eigenstates of the previous dataset must be\ntaken, which is a frequently occurring case. \nIf  getbseig  is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the eigenstates are not initialised\nfrom a disk file, so that it is as if  getbseig =0 for that initialisation.",
            "title": "getbseig"
        },
        {
            "location": "/input_variables/varfil/#getbsreso",
            "text": "Mnemonics: GET the Bethe-Salpeter RESOnant block from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (multi-dataset mode) and, in the case of\na Bethe-Salpeter calculation to indicate that the starting resonant block of\nthe excitonic Hamiltonian will be taken from the output of a previous dataset.\nIt is used to chain the calculations, since it describes from which dataset\nthe OUTPUT resonant block is to be taken, as INPUT of the present dataset. \nIf  getbsreso ==0, no such use of previously computed resonant block file is\ndone. \nIf  getbsreso  is positive, its value gives the index of the dataset to be\nused as input. \nIf  getbsreso  is -1, the output of the previous dataset must be taken,\nwhich is a frequently occurring case. \nIf  getbsreso  is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the resonant block is not initialised\nfrom a disk file, so that it is as if  getbsreso =0 for that initialisation.",
            "title": "getbsreso"
        },
        {
            "location": "/input_variables/varfil/#getddb",
            "text": "Mnemonics: GET the DDB from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This variable should be used when performing electron-phonon or temperature-\ndependence calculations. The Born effective charge as well as the dielectric\ntensor will be read from a previous DFPT calculations of the electric field at\nq=Gamma. The use of this variable will trigger the cancellation of a residual\ndipole that leads to an unphysical divergence of the GKK with vanishing\nq-points. The use of this variable greatly improves the k-point convergence\nspeed as the density of the k-point grid required to obtain the fulfillment of\nthe charge neutrality sum rule is usually prohibitively large. \nIf  getddb ==0, no such use of previously computed Born effective charge and\ndielectric tensor is done. \nIf  getddb  is positive, its value gives the index of the dataset from which\nthe output density is to be used as input. \nIf  getddb  is -1, the output density of the previous dataset must be taken,\nwhich is a frequently occurring case. \nIf  getddb  is a negative number, it indicates the number of datasets to go\nbackward to find the needed file. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getddb"
        },
        {
            "location": "/input_variables/varfil/#getddk",
            "text": "Mnemonics: GET the DDK wavefunctions from _1WF file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to irdwfk , irdwfq , ird1wf , irdddk . One should first read the\nexplanations given for these latter variables. \nThe   getwfk   ,   getwfq   ,   get1wf   and  getddk  variables are\ntypically used to chain the calculations in the multi-dataset mode, since they\ndescribe from which dataset the OUTPUT wavefunctions are to be taken, as INPUT\nwavefunctions of the present dataset.    We now focus on the   getwfk   input variable (the only one used in ground-\nstate calculations), but the rules for   getwfq   and   get1wf   are\nsimilar, with _WFK replaced by _WFQ or _1WF. \nIf   getwfk   ==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done. \nIf   getwfk   is positive, its value gives the index of the dataset for\nwhich the output wavefunction file appended with _WFK must be used. \nIf   getwfk   is -1, the output wf file with _WFK of the previous dataset\nmust be taken, which is a frequently occurring case. \nIf   getwfk   is a negative number, it indicates the number of datasets to\ngo backward to find the needed wavefunction file. In this case, if one refers\nto a non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if   getwfk   =0 for that\ninitialisation. Thanks to this rule, the use of   getwfk   -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one. \nIn the case of a ddk calculation in a multi dataset run, in order to compute\ncorrectly the localisation tensor, it is mandatory to declare give getddk the\nvalue of the current dataset (i.e. getddk3 3 ) - this is a bit strange and\nshould be changed in the future. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getddk"
        },
        {
            "location": "/input_variables/varfil/#getden",
            "text": "Mnemonics: GET the DENsity from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (multi-dataset mode) and, in the case of\na ground-state calculation, if  iscf <0 (non-SCF calculation), to\nindicate that the starting density is to be taken from the output of a\nprevious dataset. It is used to chain the calculations, since it describes\nfrom which dataset the OUTPUT density are to be taken, as INPUT density of the\npresent dataset. \nIf  getden ==0, no such use of previously computed output density file is\ndone. \nIf  getden  is positive, its value gives the index of the dataset from which\nthe output density is to be used as input. \nIf  getden  is -1, the output density of the previous dataset must be taken,\nwhich is a frequently occurring case. \nIf  getden  is a negative number, it indicates the number of datasets to go\nbackward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the density is not initialised from a\ndisk file, so that it is as if  getden =0 for that initialisation. Thanks to\nthis rule, the use of  getden  -1 is rather straightforward : except for the\nfirst density, that is not initialized by reading a disk file, the output\ndensity of one dataset is input of the next one. \nBe careful : the output density file of a run with non-zero  ionmov  does\nnot have the proper name (it has a \u201cTIM\u201d indication) for use as an input of an iscf <0 calculation. \nOne should use the output density of a  ionmov ==0 run. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getden"
        },
        {
            "location": "/input_variables/varfil/#gethaydock",
            "text": "Mnemonics: GET the HAYDOCK restart file from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (multi-dataset mode) and, in the case of\na Bethe-Salpeter calculation to indicate that the Haydock iterative technique\nwill be restarted from the output of a previous dataset. \nIf  gethaydock ==0, no such use of previously computed coupling block file\nis done. \nIf  gethaydock  is positive, its value gives the index of the dataset to be\nused as input. \nIf  gethaydock  is -1, the output of the previous dataset must be taken,\nwhich is a frequently occuring case. \nIf  gethaydock  is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the coupling block is not initialised\nfrom a disk file, so that it is as if  gethaydock =0 for that\ninitialisation.",
            "title": "gethaydock"
        },
        {
            "location": "/input_variables/varfil/#getocc",
            "text": "Mnemonics: GET OCC parameters from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This variable is typically used to chain the calculations, in the multi-\ndataset mode ( ndtset >0), since it describes from which dataset the\narray  occ  is to be taken, as input of the present dataset. The occupation\nnumbers are  EVOLVING  variables, for which such a chain of calculations is\nuseful. \nIf  getocc ==0, no such use of previously computed output occupations is\ndone. \nIf  getocc  is positive, its value gives the index of the dataset from which\nthe data are to be used as input data. It must be the index of a dataset\nalready computed in the SAME run. \nIf  getocc  is -1, the output data of the previous dataset must be taken,\nwhich is a frequently occurring case. \nIf  getocc  is a negative number, it indicates the number of datasets to go\nbackward to find the needed data. In this case, if one refers to a non\nexistent data set (prior to the first), the date is not initialised from a\ndisk file, so that it is as if  getocc ==0 for that initialisation. \nNOTE that a non-zero  getocc  MUST be used with  occopt ==2, so that the\nnumber of bands has to be initialized for each k point. Of course, these\nnumbers of bands must be identical to the numbers of bands of the dataset from\nwhich  occ  will be copied. The same is true for the number of k points. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getocc"
        },
        {
            "location": "/input_variables/varfil/#getqps",
            "text": "Mnemonics: GET QuasiParticle Structure \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used when  ndtset >0 (multi-dataset mode) and  optdriver =3, or 4\n(screening or sigma step of a  GW  calculation), to indicate that the\neigenvalues and possibly the wavefunctions have to be taken from a previous\nquasiparticle calculation (instead of the usual LDA starting point). This is\nto achieve quasiparticle self-consistency. See also  irdqps \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getqps"
        },
        {
            "location": "/input_variables/varfil/#getscr",
            "text": "Mnemonics: GET SCReening (the inverse dielectric matrix) from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used when  ndtset >0 (multi-dataset mode) and  optdriver =4 (sigma step\nof a  GW  calculation), to indicate that the dielectric matrix (_SCR file)\nis to be taken from the output of a previous dataset. It is used to chain the\ncalculations, since it describes from which dataset the OUTPUT dielectric\nmatrix is to be taken, as INPUT of the present dataset. \nIf  getscr ==0, no such use of previously computed output _SCR file is done. \nIf  getscr  is positive, its value gives the index of the dataset from which\nthe output _SCR file is to be used as input. \nIf  getscr  is -1, the output _SCR file of the previous dataset must be\ntaken, which is a frequently occurring case. \nIf  getscr  is a negative number, it indicates the number of datasets to go\nbackward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the _SCR file is not initialised from\na disk file, so that it is as if  getscr =0 for that initialisation. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getscr"
        },
        {
            "location": "/input_variables/varfil/#getsuscep",
            "text": "Mnemonics: GET SUSCEPtibility (the irreducible polarizability) from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used when  ndtset >0 (multi-dataset mode) and  optdriver =4 (sigma step\nof a  GW  calculation), to indicate that the irreducible polarizability\n(_SUSC file) is to be taken from the output of a previous dataset. It is used\nto chain the calculations, since it describes from which dataset the OUTPUT\nsusceptibility is to be taken, as INPUT of the present dataset. Performing a GW  calculations starting from the _SUSC file instead of the _SCR file\npresents the advantage that starting from the irreducible polarizability, one\ncan calculate the screened interaction using different expressions without\nhaving to perform a screening calculation from scratch. For example, it is\npossible to apply a cutoff to the Coulomb interaction in order to facilitate\nthe convergence of the  GW  correction with respect to the size of the\nsupercell (see  vcutgeo  and  icutcoul ) \nIf  getsuscep ==0, no such use of previously computed output _SUSC file is\ndone. \nIf  getsuscep  is positive, its value gives the index of the dataset from\nwhich the output _SUSC file is to be used as input. \nIf  getsuscep  is -1, the output _SUSC file of the previous dataset must be\ntaken, which is a frequently occurring case. \nIf  getsuscep  is a negative number, it indicates the number of datasets to\ngo backward to find the needed file. In this case, if one refers to a non\nexistent data set (prior to the first), the _SUSC file is not initialised from\na disk file, so that it is as if  getsuscep =0 for that initialisation. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getsuscep"
        },
        {
            "location": "/input_variables/varfil/#getwfk",
            "text": "Mnemonics: GET the wavefunctions from _WFK file  \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to  irdwfk , irdwfq , ird1wf ,\nor  irdddk . One should first read the explanations given for these latter\nvariables. \nThe  getwfk ,   getwfq   ,   get1wf   and   getddk   variables are\ntypically used to chain the calculations in the multi-dataset mode, since they\ndescribe from which dataset the OUTPUT wavefunctions are to be taken, as INPUT\nwavefunctions of the present dataset.    We now focus on the  getwfk  input variable (the only one used in ground-\nstate calculations), but the rules for   getwfq   and   get1wf   are\nsimilar, with _WFK replaced by _WFQ or _1WF. \nIf  getwfk ==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done. \nIf  getwfk  is positive, its value gives the index of the dataset for which\nthe output wavefunction file appended with _WFK must be used. \nIf  getwfk  is -1, the output wf file with _WFK of the previous dataset must\nbe taken, which is a frequently occurring case. \nIf  getwfk  is a negative number, it indicates the number of datasets to go\nbackward to find the needed wavefunction file. In this case, if one refers to\na non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if  getwfk =0 for that\ninitialisation. Thanks to this rule, the use of  getwfk  -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one. \nIn the case of a ddk calculation in a multi dataset run, in order to compute\ncorrectly the localisation tensor, it is mandatory to declare give getddk the\nvalue of the current dataset (i.e. getddk3 3 ) - this is a bit strange and\nshould be changed in the future. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getwfk"
        },
        {
            "location": "/input_variables/varfil/#getwfq",
            "text": "Mnemonics: GET the wavefunctions from _WFQ file  \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Eventually used when  ndtset >0 (in the multi-dataset mode), to indicate\nstarting wavefunctions, as an alternative to  irdwfk , irdwfq , ird1wf \nor  irdddk . One should first read the explanations given for these latter\nvariables. \nThe   getwfk   ,  getwfq ,   get1wf   and   getddk   variables are\ntypically used to chain the calculations in the multi-dataset mode, since they\ndescribe from which dataset the OUTPUT wavefunctions are to be taken, as INPUT\nwavefunctions of the present dataset.    We now focus on the   getwfk   input variable (the only one used in ground-\nstate calculations), but the rules for  getwfq  and   get1wf   are\nsimilar, with _WFK replaced by _WFQ or _1WF. \nIf   getwfk   ==0, no use of previously computed output wavefunction file\nappended with _DSx_WFK is done. \nIf   getwfk   is positive, its value gives the index of the dataset for\nwhich the output wavefunction file appended with _WFK must be used. \nIf   getwfk   is -1, the output wf file with _WFK of the previous dataset\nmust be taken, which is a frequently occurring case. \nIf   getwfk   is a negative number, it indicates the number of datasets to\ngo backward to find the needed wavefunction file. In this case, if one refers\nto a non existent data set (prior to the first), the wavefunctions are not\ninitialised from a disk file, so that it is as if   getwfk   =0 for that\ninitialisation. Thanks to this rule, the use of   getwfk   -1 is rather\nstraightforward : except for the first wavefunctions, that are not initialized\nby reading a disk file, the output wavefunction of one dataset is input of the\nnext one. \nIn the case of a ddk calculation in a multi dataset run, in order to compute\ncorrectly the localisation tensor, it is mandatory to declare give getddk the\nvalue of the current dataset (i.e. getddk3 3 ) - this is a bit strange and\nshould be changed in the future. \nNOTE : a negative value of a \u201cget\u201d variable indicates the number of datasets\nto go backwards; it is not the number to be subtracted from the current\ndataset to find the proper dataset. As an example :    ndtset 3   jdtset 1 2 4  getXXX -1  refers to dataset 2 when dataset 4 is initialized.",
            "title": "getwfq"
        },
        {
            "location": "/input_variables/varfil/#ird1den",
            "text": "Mnemonics: Integer that governs the ReaDing of 1st-order DEN file \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  iscf  < 0,\n0 otherwise.  If first order density is needed in single dataset mode (for example in\nnonlinear optical response), use  ird1den =1 to read first-order densities\nfrom _DENx files produced in other calculations. In multi-dataset mode use get1den .  When iscf < 0, the reading of a DEN file is always enforced.  A non-zero value of   ird1den   is treated in the same way as other \u201cird\u201d\nvariables, see the   section 4  of the  help_abinit .",
            "title": "ird1den"
        },
        {
            "location": "/input_variables/varfil/#ird1wf",
            "text": "Mnemonics: Integer that governs the ReaDing of _1WF files  \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Indicates eventual starting wavefunctions. As alternative, one can use the\ninput variables  getwfk ,  getwfq ,  get1wf  or  getddk .    Ground-state calculation :   only   irdwfk   and  getwfk  have a meaning   at most one of   irdwfk   or  getwfk  can be non-zero   if   irdwfk   and  getwfk  are both zero, initialize wavefunctions with random numbers for ground state calculation.   if   irdwfk   = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).    Response-function calculation :   one and only one of   irdwfk   or  getwfk  MUST be non-zero   if   irdwfk   = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   only one of   irdwfq   or  getwfq  can be non-zero, if both of them are non-zero, use as k + q file the one defined by   irdwfk   and/or  getwfk    if   irdwfq   = 1 : read ground state k+q -wavefunctions from a disk file appended with _WFQ , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   at most one of  ird1wf  or  get1wf  can be non-zero   if both are zero, initialize first order wavefunctions to zeroes   if  ird1wf  = 1 : read first-order wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the   section 4   of the  help_abinit ).   at most one of   irdddk   or  getddk  can be non-zero   one of them must be non-zero if an homogeneous electric field calculation is done (presently, a ddk calculation in the same dataset is not allowed)   if   irdddk   = 1 : read first-order ddk wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the   section 4   of the  help_abinit ).",
            "title": "ird1wf"
        },
        {
            "location": "/input_variables/varfil/#irdbscoup",
            "text": "Mnemonics: Integer that governs the ReaDing of COUPling block \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Start the Bethe-Salpeter calculation from the BSC file containing the coupling\nblock produced in a previous run.",
            "title": "irdbscoup"
        },
        {
            "location": "/input_variables/varfil/#irdbseig",
            "text": "Mnemonics: Integer that governs the ReaDing of BS_EIG file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Start the Bethe-Salpeter calculation from the BS_EIG contining the exciton\neigenvectors produced in a previous run.",
            "title": "irdbseig"
        },
        {
            "location": "/input_variables/varfil/#irdbsreso",
            "text": "Mnemonics: Integer that governs the ReaDing of RESOnant block \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Start the Bethe-Salpeter calculation from the BSR file containing the resonat\nblock produced in a previous run.",
            "title": "irdbsreso"
        },
        {
            "location": "/input_variables/varfil/#irdddb",
            "text": "Mnemonics: Integer that governs the ReaDing of DDB file \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  iscf  < 0,\n0 otherwise.  This variable should be used when performing electron-phonon or temperature-\ndependence calculations. The Born effective charge as well as the dielectric\ntensor will be read from a previous DFPT calculations of the electric field at\nq=Gamma. The use of this variable will trigger the cancellation of a residual\ndipole that leads to an unphysical divergence of the GKK with vanishing\nq-points. The use of this variable greatly improves the k-point convergence\nspeed as the density of the k-point grid required to obtain the fulfillment of\nthe charge neutrality sum rule is usually prohibitively large.  A non-zero value of  irdddb  is treated in the same way as other \u201cird\u201d\nvariables, see the   section 4  of the  help_abinit .",
            "title": "irdddb"
        },
        {
            "location": "/input_variables/varfil/#irdddk",
            "text": "Mnemonics: Integer that governs the ReaDing of DDK wavefunctions, in _1WF files \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Indicates eventual starting wavefunctions. As alternative, one can use the\ninput variables  getwfk ,  getwfq ,  get1wf  or  getddk .    Ground-state calculation :   only   irdwfk   and  getwfk  have a meaning   at most one of   irdwfk   or  getwfk  can be non-zero   if   irdwfk   and  getwfk  are both zero, initialize wavefunctions with random numbers for ground state calculation.   if   irdwfk   = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).    Response-function calculation :   one and only one of   irdwfk   or  getwfk  MUST be non-zero   if   irdwfk   = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   only one of   irdwfq   or  getwfq  can be non-zero, if both of them are non-zero, use as k + q file the one defined by   irdwfk   and/or  getwfk    if   irdwfq   = 1 : read ground state k+q -wavefunctions from a disk file appended with _WFQ , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   at most one of   ird1wf   or  get1wf  can be non-zero   if both are zero, initialize first order wavefunctions to zeroes   if   ird1wf   = 1 : read first-order wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the   section 4   of the  help_abinit ).   at most one of  irdddk  or  getddk  can be non-zero   one of them must be non-zero if an homogeneous electric field calculation is done (presently, a ddk calculation in the same dataset is not allowed)   if  irdddk  = 1 : read first-order ddk wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the   section 4   of the  help_abinit ).",
            "title": "irdddk"
        },
        {
            "location": "/input_variables/varfil/#irdden",
            "text": "Mnemonics: Integer that governs the ReaDing of DEN file \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  iscf  < 0,\n0 otherwise.  Start the ground-state calculation from the density file of a previous run.\nWhen iscf < 0, the reading of a DEN file is always enforced.  A non-zero value of  irdden  is treated in the same way as other \u201cird\u201d\nvariables, see the   section 4  of the  help_abinit .",
            "title": "irdden"
        },
        {
            "location": "/input_variables/varfil/#irdhaydock",
            "text": "Mnemonics: Integer that governs the ReaDing of the HAYDOCK restart file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used to re-start the Haydock iterative technique from the HAYDR_SAVE file\nproduced in a previous run.",
            "title": "irdhaydock"
        },
        {
            "location": "/input_variables/varfil/#irdqps",
            "text": "Mnemonics: Integer that governs the ReaDing of QuasiParticle Structure \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Relevant only when  optdriver =3 or 4. Indicate the file from which the\neigenvalues and possibly the wavefunctions must be obtained, in order to\nachieve a self-consistent quasiparticle calculations. See also  getqps",
            "title": "irdqps"
        },
        {
            "location": "/input_variables/varfil/#irdscr",
            "text": "Mnemonics: Integer that governs the ReaDing of the SCReening \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Relevant only when  optdriver =4. Indicate the file from which the\ndielectric matrix must be obtained. As alternative, one can use the input\nvariable  getscr . \nWhen  optdriver =4, at least one of  irdscr  or  getscr  (alternatively, irdsuscep  or  getsuscep ) must be non-zero.  A non-zero value of  irdscr  is treated in the same way as other \u201cird\u201d\nvariables, see the   section 4  of the  help_abinit .",
            "title": "irdscr"
        },
        {
            "location": "/input_variables/varfil/#irdsuscep",
            "text": "Mnemonics: Integer that governs the ReaDing of the SUSCEPtibility \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Relevant only when  optdriver =4. Indicate the file from which the\nirreducible polarizability must be obtained. As alternative, one can use the\ninput variable  getsuscep . \nWhen  optdriver =4, at least one of  irdsuscep  or  getsuscep \n(alternatively,  irdscr  or  getscr ) must be non-zero.  A non-zero value of  irdsuscep  is treated in the same way as other \u201cird\u201d\nvariables, see the   section 4  of the  help_abinit .",
            "title": "irdsuscep"
        },
        {
            "location": "/input_variables/varfil/#irdwfk",
            "text": "Mnemonics: Integer that governs the ReaDing of _WFK files \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Indicates eventual starting wavefunctions. As alternative, one can use the\ninput variables  getwfk ,  getwfq ,  get1wf  or  getddk .    Ground-state calculation :   only  irdwfk  and  getwfk  have a meaning   at most one of  irdwfk  or  getwfk  can be non-zero   if  irdwfk  and  getwfk  are both zero, initialize wavefunctions with random numbers for ground state calculation.   if  irdwfk  = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).    Response-function calculation :   one and only one of  irdwfk  or  getwfk  MUST be non-zero   if  irdwfk  = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   only one of   irdwfq   or  getwfq  can be non-zero, if both of them are non-zero, use as k + q file the one defined by  irdwfk  and/or  getwfk    if   irdwfq   = 1 : read ground state k+q -wavefunctions from a disk file appended with _WFQ , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   at most one of   ird1wf   or  get1wf  can be non-zero   if both are zero, initialize first order wavefunctions to 0\u2019s.   if   ird1wf   = 1 : read first-order wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the   section 4   of the  help_abinit ).   at most one of   irdddk   or  getddk  can be non-zero   one of them must be non-zero if an homogeneous electric field calculation is done (presently, a ddk calculation in the same dataset is not allowed)   if   irdddk   = 1 : read first-order ddk wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the   section 4   of the  help_abinit ).",
            "title": "irdwfk"
        },
        {
            "location": "/input_variables/varfil/#irdwfq",
            "text": "Mnemonics: Integer that governs the ReaDing of _WFQ files \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Indicates eventual starting wavefunctions. As alternative, one can use the\ninput variables  getwfk ,  getwfq ,  get1wf  or  getddk .    Ground-state calculation :   only   irdwfk   and  getwfk  have a meaning   at most one of   irdwfk   or  getwfk  can be non-zero   if   irdwfk   and  getwfk  are both zero, initialize wavefunctions with random numbers for ground state calculation.   if   irdwfk   = 1 : read ground state wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).    Response-function calculation :   one and only one of   irdwfk   or  getwfk  MUST be non-zero   if   irdwfk   = 1 : read ground state k -wavefunctions from a disk file appended with _WFK , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   only one of  irdwfq  or  getwfq  can be non-zero, if both of them are non-zero, use as k + q file the one defined by   irdwfk   and/or  getwfk    if  irdwfq  = 1 : read ground state k+q -wavefunctions from a disk file appended with _WFQ , produced in a previous ground state calculation (see the   section 4   of the  help_abinit ).   at most one of   ird1wf   or  get1wf  can be non-zero   if both are zero, initialize first order wavefunctions to 0\u2019s.   if   ird1wf   = 1 : read first-order wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the   section 4   of the  help_abinit ).   at most one of   irdddk   or  getddk  can be non-zero   one of them must be non-zero if an homogeneous electric field calculation is done (presently, a ddk calculation in the same dataset is not allowed)   if   irdddk   = 1 : read first-order ddk wavefunctions from a disk file appended with _1WFx , produced in a previous response function calculation (see the   section 4   of the  help_abinit ).",
            "title": "irdwfq"
        },
        {
            "location": "/input_variables/varfil/#kssform",
            "text": "Mnemonics: Kohn Sham Structure file FORMat \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Governs the choice of the format for the file that contains the Kohn-Sham\nelectronic structure information, for use in  GW  calculations, see the\ninput variables  optdriver  and  nbandkss .   kssform =1, a single file .kss (double precision) containing complete information on the Kohn Sham Structure (eigenstates and the pseudopotentials used) will be generated through full diagonalization of the complete Hamiltonian matrix. The file has at the beginning the standard abinit header.   kssform =3, a single file .kss (double precision) containing complete information on the Kohn Sham Structure (eigenstates and the pseudopotentials used) will be generated through the usual conjugate gradient algorithm (so, a restricted number of states). The file has at the beginning the standard abinit header.    Very important : for the time being,  istwfk  must be 1 for all the\nk-points.",
            "title": "kssform"
        },
        {
            "location": "/input_variables/varfil/#prt1dm",
            "text": "Mnemonics: PRinT 1-DiMensional potential and density \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set >= 1, provide one-dimensional projection of potential and density,\nfor each of the three axis. This corresponds to averaging the potential or the\ndensity on bi-dimensional slices of the FFT grid.",
            "title": "prt1dm"
        },
        {
            "location": "/input_variables/varfil/#prtden",
            "text": "Mnemonics: PRinT the DENsity \nVariable type: integer \nDimensions: scalar \nDefault value: 0 if  nimage >1,\n1 otherwise.  If set to 1 or a larger value , provide output of electron density in real\nspace rho(r), in units of electrons/Bohr^3. \nIf  ionmov ==0, the name of the density file will be the root output name,\nfollowed by _DEN . \nIf  ionmov ==1 or 2, density files will be output at each time step, with\nthe name being made of   the root output name,   followed by _TIMx , where x is related to the timestep (see later)   then followed by _DEN    The file structure of the unformatted output file is described below, see\nsection 6). \nIf  prtden  is lower than 0, two files will be printed for restart every prtden  step, with the names being made of   the root temporary name,   followed by _DEN_x , where x is 0000 or 0001 alternatively.   The most recent of the two files should be used for restart, and copied to root input name_DS2_DEN   To perform a restart, in a multidataset mode, use ndtset 2 and jdtset 2 3 (that is 2 datasets, numbered 2 and 3)   In the dataset 2, get the density you just copied (getden2 -1), perform a non selfconsistent calculation and print the wave function (prtwf2 1)   In the dataset 3, get the previous wf(getwfk3 -1), and continue the calculation   This complicated procedure is due to the fact that reading the density is only allowed for a non sc calculation, and also for a dataset different of 0 or the previous one, the option we choose here.    Please note that in the case of PAW ( usepaw =1) calculations, the _DEN\ndensity output is not the full physical electron density. If what is wanted is\nthe full physical electron density, say for post-processing with   AIM  or visualization, prtden > 1\nwill produce physical electron density or other interesting quantities (see\nbelow). Nevertheless, even in the PAW case, when chaining together\ncalculations where the density from one calculation is to be used in a\nsubsequent calculation, it is necessary to use the _DEN files and   not  \none of the other files produced with prtden > 1, i.e. _PAWDEN, ATMDEN_xxx\nor else. Note that the usual _DEN file is always generated as soon as prtden\n>= 1. Options 2 to 6 for prtden are relevant only for  usepaw =1 and\ncontrol the output of the full electron density in the PAW case :     prtden=2   causes generation of a file _PAWDEN that contains the bulk   valence   charge density together with the PAW on-site contributions, and has the same format as the other density files.    prtden=3   causes generation of a file _PAWDEN that contains the bulk   full   charge density (valence+core)    prtden=4   causes generation of three files _ATMDEN_CORE, _ATMDEN_VAL and _ATMDEN_FULL which respectively contain the core, valence and full atomic protodensity (the density of the individual component atoms in vacuum superposed at the bulk atomic positions). This can be used to generate various visualizations of the bonding density.    prtden=5   options 2 and 4 taken together.    prtden=6   options 3 and 4 taken together.    prtden=7   causes the generation of all the individual contributions to the bulk   valence   charge density : n_tilde-n_hat (_N_TILDE), n_onsite (_N_ONE) and n_tilde_onsite (_NT_ONE). This is for diagnosis purposes only.     Options 3 to 6 currently require the user to supply the atomic core and\nvalence density in external files in the working directory. The files must be\nnamed properly; for example, the files for an atom of type 1 should be named:\n\u201ccore_density_atom_type1.dat\u201d and \u201cvalence_density_atom_type1.dat\u201d. The file\nshould be a text file, where the first line is assumed to be a comment, and\nthe subsequent lines contain two values each, where the first one is a radial\ncoordinate and the second the value of the density n(r). Please note that it\nis n(r) which should be supplied,   not   n(r)/r^2. The first coordinate\npoint must be the origin, i.e.   _ r = 0 _   . The atomic densities are\nspherically averaged, so assumed to be completely spherically symmetric, even\nfor open shells.    NOTE: in the PAW case,   DO NOT   use _PAWDEN or _ATMDEN_xxx files produced\nby prtden > 1 to chain the density output from one calculation as the input\nto another, use the _DEN file for that.",
            "title": "prtden"
        },
        {
            "location": "/input_variables/varfil/#prtdos",
            "text": "Mnemonics: PRinT the Density Of States \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Provide output of Density of States if set to 1, 2 or 3. Can either use a\nsmearing technique ( prtdos =1), or the tetrahedron method ( prtdos =2).\nIf  prtdos =3, provide output of Local Density of States inside a sphere\ncentered on an atom, as well as the angular-momentum projected DOS, in the\nsame sphere. The resolution of the linear grid of energies for which the DOS\nis computed can be tuned thanks to  dosdeltae .  If  prtdos =1, the smeared density of states is obtained from the\neigenvalues, properly weighted at each k point using  wtk , and smeared\naccording to  occopt  and  tsmear . All levels that are present in the\ncalculation are taken into account (occupied and unoccupied). Note that occopt  must be between 3 and 7 . Also note that the sampling of the\nBrillouin Zone that is needed to get a converged DOS is usually much finer\nthan the sampling needed to converge the total energy or the geometry of the\nsystem, unless  tsmear  is very large (hence the DOS is not obtained\nproperly).. A separate convergence study is needed. \nIn order to compute the DOS of an insulator with  prtdos =1, compute its\ndensity thanks to a self-consistent calculation (with a non-metallic occopt  value, 0, 1 or 2), then use  prtdos =1, together with iscf =-3, and a metallic  occopt , between 3 and 7, providing the needed\nsmearing. If  prtdos =1, the name of the DOS file is the root name for the\noutput files, followed by \u201c_DOS\u201d .  If  prtdos =2, the DOS is computed using the tetrahedron method. As in the\ncase of  prtdos =1, all levels that are present in the calculation are taken\ninto account (occupied and unoccupied). In this case, the k-points must have\nbeen defined using the input variable  ngkpt  or the input variable kptrlatt . There must be at least two non-equivalent points in the\nIrreducible Brillouin Zone to use  prtdos =2. It is strongly advised to use\na non-shifted k-point grid ( shiftk  0 0 0): such grids contain naturally\nmore extremal points (band minima and maxima at Gamma or at the zone-\nboundaries) than shifted grids, and lead to more non-equivalent points than\nshifted grids, for the same grid spacing. There is no need to take care of the occopt  or  tsmear  input variables, and there is no subtlety to be taken\ninto account for insulators. The computation can be done in the self-\nconsistent case as well as in the non-self-consistent case, using  iscf =-3.\nThis allows to refine the DOS at fixed starting density. \nIn that case, if  ionmov ==0, the name of the potential file will be the\nroot output name, followed by _DOS (like in the  prtdos =1 case). \nHowever, if  ionmov ==1 or 2, potential files will be output at each time\nstep, with the name being made of   the root output name,   followed by _TIMx , where x is related to the timestep (see later)   then followed by _DOS.    If  prtdos =3, the same tetrahedron method as for  prtdos =2 is used, but\nthe DOS inside a sphere centered on some atom is delivered, as well as the\nangular-momentum projected (l=0,1,2,3,4) DOS in the same sphere. The\npreparation of this case, the parameters under which the computation is to be\ndone, and the file denomination is similar to the  prtdos =2 case. However,\nthree additional input variables might be provided, describing the atoms that\nare the center of the sphere (input variables  natsph  and  iatsph ), as\nwell as the radius of this sphere (input variable  ratsph ). \nIn case of PAW,  ratsph  radius has to be greater or equal to largest PAW\nradius of the atom types considered (which is read from the PAW atomic data\nfile; see rc_sph or r_paw). Additional printing and/or approximations in PAW\nmode can be controlled with  pawprtdos  keyword (in\nparticular, pawprtdos =2 can be used to compute quickly a very good\napproximation of the DOS).    Note 1: when  prtdos =3, it is possible to output m-decomposed LDOS in _DOS\nfile; simply use  prtdosm  keyword. \nNote 2: the integrated total DOS in spheres around atoms can be obtained when prtdensph  flag is activated. It can be compared to the integrated DOS\nprovided in _DOS file when  prtdos =3.  prtdos =4 delivers the sphere-projected DOS (like  prtdos =3), on the\nbasis of a smearing approach (like  prtdos =1)  prtdos =5 delivers the spin-spin DOS in the  nspinor ==2 case, using the\ntetrahedron method (as  prtdos =2).",
            "title": "prtdos"
        },
        {
            "location": "/input_variables/varfil/#prtdosm",
            "text": "Mnemonics: PRinT the Density Of States with M decomposition \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Relevant only when  prtdos =3. \nIf set to 1, the m-decomposed LDOS is delivered in DOS file. \nNote that  prtdosm  computes the M-resolved partial dos for complex\nspherical harmonics,giving e.g. DOS(L,M) == DOS(L,-M) (without spin-orbit). In\nthe contrary, the LDA+U occupation matrix, see  dmatpawu  is in the real\nspherical harmonics basis. \nIf set to 2, the m-decomposed LDOS is delivered in DOS file. \nIn this case,  prtdosm  computes the M-resolved partial dos for real\nspherical harmonics in the same basis as the LDA+U occupation matrix.",
            "title": "prtdosm"
        },
        {
            "location": "/input_variables/varfil/#prteig",
            "text": "Mnemonics: PRinT EIGenenergies \nVariable type: integer \nDimensions: scalar \nDefault value: 0 if  nimage  > 1,\n1 otherwise.  If set to 1, a file *_EIG, containing the k-points and one-electron\neigenvalues is printed.",
            "title": "prteig"
        },
        {
            "location": "/input_variables/varfil/#prtelf",
            "text": "Mnemonics: PRinT Electron Localization Function (ELF) \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1 or a larger value, provide output of ELF in real space elf(r).\nThis is a dimensionless quantity bounded between 0 and 1. \nThe name of the ELF file will be the root output name, followed by _ELF. \nLike a _DEN file, it can be analyzed by cut3d. However unlike densities, in\ncase of spin polarized calculations, the spin down component can not be\nobtained by subtracting the spin up component to the total ELF. Hence when\nspin polarized calculations are performed the code produces also output files\nwith _ELF_UP and _ELF_DOWN extensions. (For technical reasons these files\ncontain also two components but the second is zero. So to perform analysis of\n_ELF_UP and _ELF_DOWN files with cut3d you have to answer \u201cispden= 0 ==>\nTotal density\u201d when cut3d ask you which ispden to choose. Also remember that\nspin down component can not be obtained by using cut3d on the _ELF file. Sorry\nfor the inconvenience, this will be fixed in the next release.) \nELF is not yet implemented in non collinear spin case. \nIf prtelf is set to 2, in the case of spin polarized calculation, the total\nELF is computed from an alternative approach which should better take into\naccount the existence of spin dependent densities (see the documentation in\n/doc/theory/ELF of your ABINIT repository)    Please note that ELF is   not   yet implemented in the case of PAW\n( usepaw =1) calculations.",
            "title": "prtelf"
        },
        {
            "location": "/input_variables/varfil/#prtfsurf",
            "text": "Mnemonics: PRinT Fermi SURFace file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1, provide Fermi surface file in the BXSF format (Xcrysden) If prtfsurf =1, a _BXSF file readable by   XCrySDen  \nwill be produced at the end of the calculation. The file contains information\non the band structure of the system and can be used to visualize the Fermi\nsurface or any other energy isosurface.  prtfsurf =1 is compatible only with\nSCF calculations ( iscf  > 1) or NSCF runs in which the occupation\nfactors and Fermi level are recalculated once convergence is achieved\n( iscf  = -3). The two methods should produce the same Fermi surface\nprovided that the k-meshes are sufficiently dense. The k-mesh used for the\nsampling of the Fermi surface can be specified using the standard variables ngkpt , ( shiftk , and  nshiftk . Note, however, that the mesh must be\nhomogeneous and centered on gamma (multiple shifts are not supported by\nXcrysden)",
            "title": "prtfsurf"
        },
        {
            "location": "/input_variables/varfil/#prtgden",
            "text": "Mnemonics: PRinT the Gradient of electron DENsity \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1 or a larger value, provide output of gradient of electron density\nin real space grho(r), in units of Bohr^-(5/2). \nThe names of the gradient of electron density files will be the root output\nname, followed by _GDEN1, _GDEN2, GDEN3 for each principal direction (indeed\nit is a vector). \nLike a _DEN file, it can be analyzed by cut3d. The file structure of the\nunformatted output file is described below, see section 6).",
            "title": "prtgden"
        },
        {
            "location": "/input_variables/varfil/#prtgeo",
            "text": "Mnemonics: PRinT the GEOmetry analysis \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1 or a larger value, provide output of geometrical analysis (bond\nlengths and bond angles). The value of  prtgeo  is taken by the code to be\nthe maximum coordination number of atoms in the system. \nIt will deduce a maximum number of \u201cnearest\u201d and \u201cnext-nearest\u201d neighbors\naccordingly , and compute corresponding bond lengths. \nIt will compute bond angles for the \u201cnearest\u201d neighbours only. \nIf  ionmov ==0, the name of the file will be the root output name, followed\nby _GEO . \nIf  ionmov ==1 or 2, one file will be output at each time step, with the\nname being made of   the root output name,   followed by _TIMx , where x is related to the timestep (see later)   then followed by _GEO    The content of the file should be rather self-explanatory. \nNo output is provided by  prtgeo  is lower than or equal to 0. \nIf  prtgeo >0, the maximum number of atoms ( natom ) is 9999.",
            "title": "prtgeo"
        },
        {
            "location": "/input_variables/varfil/#prtgkk",
            "text": "Mnemonics: PRinT the GKK matrix elements file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1, provide output of electron-phonon \u201cgkk\u201d matrix elements, for\nfurther treatment by mrggkk utility or anaddb utility. Note that symmetry will\nbe disabled for the calculation of the perturbation, forcing the inclusion of\nall k-points and all perturbation directions. Additional information on\nelectron-phonon treatment in ABINIT is given in the tutorial\n~abinit/doc/tutorial/lesson_eph.html and in ~abinit/doc/users/elphon_manual.ps",
            "title": "prtgkk"
        },
        {
            "location": "/input_variables/varfil/#prtgsr",
            "text": "Mnemonics: PRinT the GSR file \nVariable type: integer \nDimensions: scalar \nDefault value: prtgsr = 0    If set to 1, ABINIT will produce a GSR file at the end of the GS calculation.\nThe GSR file contains the most important GS results (band structure, forces,\nstresses, electronic density). The GSR file can be read by AbiPy and used for\nfuther postprocessing. \nNote that, by default, the GSR file contains the electronic density unless prtden  is set to 0.",
            "title": "prtgsr"
        },
        {
            "location": "/input_variables/varfil/#prtkden",
            "text": "Mnemonics: PRinT the Kinetic energy DENsity \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1 or a larger value , provide output of kinetic energy density in\nreal space tau(r), in units of Bohr^-5. \nThe name of the kinetic energy density file will be the root output name,\nfollowed by _KDEN. \nLike a _DEN file, it can be analyzed by cut3d. The file structure of the\nunformatted output file is described below (see   section 6 ). \nNote that the computation of the kinetic energy density must be activate,\nthanks to the input variable  usekden . \nPlease note that kinetic energy density is   not   yet implemented in the\ncase of PAW ( usepaw =1) calculations.",
            "title": "prtkden"
        },
        {
            "location": "/input_variables/varfil/#prtkpt",
            "text": "Mnemonics: PRinT the K-PoinTs sets \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set /= 0 , proceeds to a detailed analysis of different k point grids.\nWorks only if  kptopt  is positive, and neither  kptrlatt  nor  ngkpt \nare defined. ABINIT will stop after this analysis.  Different sets of k point grids are defined, with common values of  shiftk .\nIn each set, ABINIT increases the length of vectors of the supercell (see kptrlatt ) by integer steps. The different sets are labelled by \u201ciset\u201d. For\neach k point grid,  kptrlen  and  nkpt  are computed (the latter always\ninvoking  kptopt =1, that is, full use of symmetries). A series is finished\nwhen the computed  kptrlen  is twice larger than the input variable kptrlen . After the examination of the different sets, ABINIT summarizes,\nfor each  nkpt , the best possible grid, that is, the one with the largest\ncomputed  kptrlen .  Note that this analysis is also performed when  prtkpt =0, as soon as\nneither  kptrlatt  nor  ngkpt  are defined. But, in this case, no analysis\nreport is given, and the code selects the grid with the smaller  ngkpt  for\nthe desired  kptrlen . However, this analysis takes some times (well\nsometimes, it is only a few seconds - it depends on the value of the input kptrlen ), and it is better to examine the full analysis for a given cell\nand set of symmetries,  shiftk  for all the production runs.  if set to -2, the code stops in invars1 after the computation of the\nirreducible set and a file named kpts.nc with the list of the k-points and the\ncorresponding weights is produced",
            "title": "prtkpt"
        },
        {
            "location": "/input_variables/varfil/#prtlden",
            "text": "Mnemonics: PRinT the Laplacian of electron DENsity \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1 or a larger value, provide output of Laplacian of electron density\nin real space grho(r), in units of Bohr^-(7/2). \nThe name of the Laplacian of electron density file will be the root output\nname, followed by _LDEN. \nLike a _DEN file, it can be analyzed by cut3d. The file structure of the\nunformatted output file is described below (see   section 6 ).",
            "title": "prtlden"
        },
        {
            "location": "/input_variables/varfil/#prtpot",
            "text": "Mnemonics: PRinT total POTential \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set >=1 , provide output of the total (Kohn-Sham) potential (sum of\nlocal pseudo-potential, Hartree potential, and xc potential).  If  ionmov ==0, the name of the potential file will be the root output name,\nfollowed by _POT. \nIf  ionmov ==1 or 2, potential file will be output at each time step, with\nthe name being made of   the root output name,   followed by _TIMx , where x is related to the timestep (see later)   then followed by _POT.    The file structure of this unformatted output file is described in   section\n6.6   of the help_abinit . No output is provided by a negative value of this variable.",
            "title": "prtpot"
        },
        {
            "location": "/input_variables/varfil/#prtpsps",
            "text": "Mnemonics: PRint the PSPS file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1, the code produces a netcdf file (PSPS.nc) with the internal\ntables used by Abinit to apply the pseudopotential part of the KS Hamiltonian.\nThe data can be visualized with AbiPy. if prtpsps is set to -1, the code will\nexit after the output of the PSPS.nc file.",
            "title": "prtpsps"
        },
        {
            "location": "/input_variables/varfil/#prtspcur",
            "text": "Mnemonics: PRinT the SPin CURrent density \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1 or a larger value, provide output of the current density of\ndifferent direction spins (x,y,z) in the whole unit cell. Should require\nspinorial wave functions  nspinor  = 2. Experimental: this does not work\nyet.",
            "title": "prtspcur"
        },
        {
            "location": "/input_variables/varfil/#prtstm",
            "text": "Mnemonics: PRinT the STM density \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1 or a larger value, provide output of the electron density in real\nspace rho(r), made only from the electrons close to the Fermi energy, in a\nrange of energy (positive or negative), determined by the (positive or\nnegative, but non-zero) value of the STM bias  stmbias . \nThis is a very approximate way to obtain STM profiles : one can choose an\nequidensity surface, and consider that the STM tip will follow this surface.\nSuch equidensity surface might be determined with the help of Cut3D, and\nfurther post-processing of it (to be implemented). The big approximations of\nthis technique are : neglect of the finite size of the tip, and position-\nindependent transfer matrix elements between the tip and the surface. \nThe charge density is provided in units of electrons/Bohr^3. The name of the\nSTM density file will be the root output name, followed by _STM . Like a _DEN\nfile, it can be analyzed by cut3d. The file structure of this unformatted\noutput file is described in   section 6.5  of the help_abinit . \nFor the STM charge density to be generated, one must give, as an input file,\nthe converged wavefunctions obtained from a previous run, at exactly the same\nk-points and cut-off energy, self-consistently determined, using the\noccupation numbers from  occopt =7. \nIn the run with positive  prtstm , one has to use :   positive  iscf    occopt =7, with specification of  tsmear    nstep =1   the  tolwfr  convergence criterion   ionmov =0 (this is the default value)   optdriver =0 (this is the default value)    Note that you might have to adjust the value of  nband  as well, for the\ntreatment of unoccupied states, because the automatic determination of nband  will often not include enough unoccupied states. \nWhen  prtstm  is non-zero, the stress tensor is set to zero. \nNo output of _STM file is provided by  prtstm  lower or equal to 0. \nNo other printing variables for density or potentials should be activated\n(e.g.  prtden  has to be set to zero).",
            "title": "prtstm"
        },
        {
            "location": "/input_variables/varfil/#prtsuscep",
            "text": "Mnemonics: PRinT the SUSCEPtibility file (the irreducible polarizability) \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 0, no _SUSC file will be produced after the screening calculation,\nonly the _SCR file will be output.",
            "title": "prtsuscep"
        },
        {
            "location": "/input_variables/varfil/#prtvclmb",
            "text": "Mnemonics: PRinT V CouLoMB \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set >= 0 outputs a file with the Coulomb potential, defined as Hartree +\nlocal Pseudopotential.  If  prtvclmb=1  and in case of PAW ( usepaw  > 0), the full core potential\nis added for the Hartree part, with the on-site corrections vh1 - vht1.  If  prtvclmb=2 , only the smooth part of the Coulomb potential is output.",
            "title": "prtvclmb"
        },
        {
            "location": "/input_variables/varfil/#prtvha",
            "text": "Mnemonics: PRinT V_HArtree \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set >=1 , provide output of the Hartree potential.    If  ionmov ==0, the name of the potential file will be the root output name,\nfollowed by _VHA. \nIf  ionmov ==1 or 2, potential files will be output at each time step, with\nthe name being made of   the root output name,   followed by _TIMx , where x is related to the timestep (see later)   then followed by _VHA.    The file structure of this unformatted output file is described in   section\n6.6   of the help_abinit . No output is provided by a negative value of this variable.",
            "title": "prtvha"
        },
        {
            "location": "/input_variables/varfil/#prtvhxc",
            "text": "Mnemonics: PRinT V_HXC \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set >=1 , provide output of the sum of the Hartree potential and xc\npotential.  If  ionmov ==0, the name of the potential file will be the root output name,\nfollowed by _VHXC. \nIf  ionmov ==1 or 2, potential files will be output at each time step, with\nthe name being made of   the root output name,   followed by _TIMx , where x is related to the timestep (see later)   then followed by _VHXC.    The file structure of this unformatted output file is described in   section\n6.6   of the help_abinit . No output is provided by a negative value of this variable.",
            "title": "prtvhxc"
        },
        {
            "location": "/input_variables/varfil/#prtvol",
            "text": "Mnemonics: PRinT VOLume \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Control the volume of printed output. In particular, this concerns the\nexplicit echo of eigenenergies and residuals for all bands and k points in the\nmain output file. Also, the analysis of the value and location of the maximal\ndensity (and magnetization). \nStandard choice is 0. Positive values print more in the output and log files,\nwhile negative values are for debugging (or preprocessing only), and cause the\ncode to stop at some point.   0 => The eigenenergies and residuals for all bands and k points are not echoed in the main output file. There are exceptions: the eigenvalues of the first k point are printed at the end of the SCF loop, and also, if  iscf =-2 and  kptopt <=0, the eigenvalues for all the k points are printed anyway, for a maximum of 50 k-points. Due to some subtlety, if for  some  dataset  prtvol  is non-zero, the limit for input and output echoes cannot be enforced, so it is like if  prtvol =1 for  all  the datasets for which  prtvol  was set to 0.  1 => the eigenvalues for the first 50 k-points are printed in all cases, at the end of the SCF loop.  2 => all the eigenvalues and the residuals are printed at the end of the SCF loop. Also, the analysis of the value and location of the maximal density (and magnetization) is printed.  3 => Print memory information for lobpcg   4 => Like 3 and prints information of lobpcg algorithm convergence  10 => the eigenvalues are printed for every SCF iteration, as well as other additions (to be specified in the future\u2026)    Debugging options :   = -1 => stop in abinit (main program), before call driver. Useful to see the effect of the preprocessing of input variables (memory needed, effect of symmetries, k points \u2026) without going further. Run very fast, on the order of the second.  =-2 => same as -1, except that print only the first dataset. All the non default input variables associated to all datasets are printed in the output file, but only for the first dataset. Also all the input variables are written in the NetCDF file \"OUT.nc\", even if the value is the default.  = -3 => stop in gstate, before call scfcv, move or brdmin. Useful to debug pseudopotentials  = -4 => stop in move, after completion of all loops  = -5 => stop in brdmin, after completion of all loops  = -6 => stop in scfcv, after completion of all loops   = -7 => stop in vtorho, after the first rho is obtained  = -8 => stop in vtowfk, after the first k point is treated  = -9 => stop in cgwf, after the first wf is optimized  = -10 => stop in getghc, after the Hamiltonian is applied once   This debugging feature is not yet activated in the RF routines. Note that fftalg  offers another option for debugging.",
            "title": "prtvol"
        },
        {
            "location": "/input_variables/varfil/#prtvolimg",
            "text": "Mnemonics: PRinT VOLume for IMaGes \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Control the volume of printed output when an algorithm using images of the\ncell is used ( nimage >1). \nWhen such an algorithm is activated, the printing volume (in output file) can\nbe large and difficult to read. \nUsing   prtvolimg=1   , the printing volume, for each image, is reduced to\nunit cell, atomic positions, total energy, forces, stresses, velocities and\nconvergence residuals. \nUsing   prtvolimg=2   , the printing volume, for each image, is reduced to\ntotal energy and convergence residuals only.",
            "title": "prtvolimg"
        },
        {
            "location": "/input_variables/varfil/#prtvpsp",
            "text": "Mnemonics: PRinT V_PSeudoPotential \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set >=1 , provide output of the local pseudo potential.    If  ionmov ==0, the name of the potential file will be the root output name,\nfollowed by _VPSP. \nIf  ionmov ==1 or 2, potential files will be output at each time step, with\nthe name being made of   the root output name,   followed by _TIMx , where x is related to the timestep (see later)   then followed by _VPSP.    The file structure of this unformatted output file is described in   section\n6.6   of the help_abinit . No output is provided by a negative value of this variable.",
            "title": "prtvpsp"
        },
        {
            "location": "/input_variables/varfil/#prtvxc",
            "text": "Mnemonics: PRinT V_XC \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set >=1 , provide output of the exchange-correlation potential.  If  ionmov ==0, the name of the potential file will be the root output name,\nfollowed by _VXC. \nIf  ionmov ==1 or 2, potential files will be output at each time step, with\nthe name being made of   the root output name,   followed by _TIMx , where x is related to the timestep (see later)   then followed by _VXC.    The file structure of this unformatted output file is described in   section\n6.6   of the help_abinit . No output is provided by a negative value of this variable.",
            "title": "prtvxc"
        },
        {
            "location": "/input_variables/varfil/#prtwant",
            "text": "Mnemonics: PRinT WANT file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Flag used to indicate that either the Wannier90 or the WanT interfaces will be\nused.   prtwant =1 => Use the   ABINIT- WanT   interface.    Provide an output file that can be used by the WanT postprocessing program\n(see http://www.wannier-transport.org). The value of the prtwant indicates the\nversion of the WanT code that can read it. Currently only the value prtwant =1 is implemented, corresponding to WanT version 1.0.1, available\nsince Oct. 22, 2004.  Notes : Several requirements must be fulfilled by the wavefunction. Among\nthem, two are mandatory:    * 1\\. An uniform grid of k-points, including the GAMMA point must be used. \n* 2\\. The use of time reversal symmetry is not allowed (istwfk=1) \n* 3\\. The list of k-points must be ordered, such that the coordinates, namely three-components vectors has the third index varying the most rapidly, then the second index, then the first index  If these requirement are not fulfilled, the program will stop and an error\nmessage is returned.  As an example of k-point grid in case of systems that have some 3D character\n(1D systems are easy) :           nkpt 8\nkpt  0   0   0\n0   0   1/2\n0   1/2 0\n0   1/2 1/2\n1/2 0   0\n1/2 0   1/2\n1/2 1/2 0\n1/2 1/2 1/2\nistwfk 8*1  Also, in order to use WanT as a postprocessing program for ABINIT you might\nhave to recompile it with the appropriate flags (see ABINIT makefile). Up to\nnow only the -convert big-endian was found to be mandatory, for machines with\nlittle-endian default choice.   prtwant =2 => Use the   ABINIT- Wannier90   interface.    ABINIT will produce the input files required by Wannier90 and it will run\nWannier90 to produce the Maximally-locallized Wannier functions (see  \nhttp://www.wannier.org   ).  Notes:  * The files that are created can also be used by Wannier90 in stand-alone mode. \n* In order to use Wannier90 as a postprocessing program for ABINIT you might have to recompile it with the appropriate flags (see ABINIT makefile). You might use ./configure --enable-wannier90 \n* There are some other variables related to the interface of Wannier90 and ABINIT. See, [ VARW90 ](varw90.html) .   prtwant =3 => Use the   ABINIT- Wannier90   interface after converting the input wavefunctions to    GW  quasiparticle   wavefunctions.    ABINIT will produce the input files required by Wannier90 and it will run\nWannier90 to produce the Maximally-localized Wannier functions (see  \nhttp://www.wannier.org   ).  Additional Notes:  * An input file of LDA wave functions is required which is completely consistent with the _KSS file used in the self-consistent [[GW]] calculation. This means that [[kssform]] 3 must be used to create the _KSS file and the output _WFK file from the same run must be used as input here. \n* Wannier90 requires [[nshiftk]]=1, and [[shiftk]]= 0 0 0 is recommended. The k-point set used for the [[GW]] calculation, typically the irreducible BZ set created using [[kptopt]]=1, and that for the Abinit- Wannier90 interface must be consistent. \n* Full-BZ wavefunctions should be generated in the run calling the interface by setting [[kptopt]]=3, [[iscf]]=-2, and [[nstep]]=3. This will simply use symmetry to transform the input IBZ wavefunctions to the full BZ set, still consistent with the [[GW]] _KSS input. \n* The final _QPS file created by the self-consistent [[GW]] run is required as input. \n* Any value of [[gwcalctyp]] between between 20 and 29 should be suitable, so, for example, Hartree-Fock maximally-localized Wannier functions could be generated setting [[gwcalctyp]]=25.",
            "title": "prtwant"
        },
        {
            "location": "/input_variables/varfil/#prtwf",
            "text": "Mnemonics: PRinT the WaveFunction \nVariable type: integer \nDimensions: scalar \nDefault value: 0 if  nimage  > 1,\n1 otherwise.  If  prtwf =1 , provide output of wavefunction and eigenvalue file, as\ndescribed in   section 6.7  of the main help_abinit . \nFor a standard ground-state calculation, the name of the wavefunction file\nwill be the root output name, followed by _WFK. If  nqpt =1, the root name\nwill be followed by _WFQ. For response-function calculations, the root name\nwill be followed by _1WFx, where x is the number of the perturbation. The\ndataset information will be added as well, if relevant. \nNo wavefunction output is provided by  prtwf =0. \nIf  prtwf =-1, the code writes the wavefunction file only if convergence is\nnot achieved in the self-consistent cycle.  If  prtwf =2, a file pwfn.data is produced, to be used as input for the\nCASINO QMC code. See more explanation at the end of this section. \nIf  prtwf =3, the file that is created is nearly the same as with prtwf =1, except that the records that should contain the wavefunction is\nempty (so, such records exist, but store nothing). This is useful to generate\nsize-reduced DDK files, to perform an optic run. Indeed, in the latter case,\nonly matrix elements are needed [so, no wavefunction], but possibly a large\nnumber of conduction bands, so that the DDK file might be huge if it contains\nthe wavefunctions.  Further explanation for the  prtwf =2 case. To produce a wave function\nsuitable for use as a CASINO trial wave function, certain ABINIT parameters\nmust be set correctly. Primarily, CASINO (and QMC methods generally) can only\ntake advantage of time-reversal symmetry, and not the full set of symmetries\nof the crystal structure. Therefore, ABINIT must be instructed to generate\nk-points not just in the Irreducible Brillouin Zone, but in a full half of the\nBrillouin Zone (using time-reversal symmetry to generate the other half).\nAdditionally, unless instructed otherwise, Abinit avoids the need for internal\nstorage of many of the coefficients of its wave functions for k-points that\nhave the property 2k=G_latt, where G_latt is a reciprocal lattice vector, by\nmaking use of the property that c_k(G)=c^*_k(-G-G_latt). Abinit must be\ninstructed not to do this in order to output the full set of coefficients for\nuse in CASINO. See the ABINIT theoretical background documents\nABINIT/Infos/Theory/geometry.pdf and ABINIT/Infos/Theory/1WF.pdf for more\ninformation. \nThe first of these requirements is met by setting the ABINIT input variable\nkptopt to 2 (see ABINIT/Infos/varbas.html#kptopt) and the second by setting\nistwfk to 1 for all the k points (see ABINIT/Infos/vardev.html#istwfk). Since\nCASINO is typically run with relatively small numbers of k-points, this is\neasily done by defining an array of \u201c1\u201d in the input file. \nFor example, for the 8 k-points generated with ngkpt 2 2 2, we add the\nfollowing lines to the input file:    # Turn off special storage mode for time-reversal k-points\nistwfk 1 1 1 1 1 1 1 1\n# Use only time reversal symmetry, not full set of symmetries.\nkptopt 2  Other useful input variables of relevance to the plane waves ABINIT will\nproduce include ecut, nshiftk, shiftk, nband, occopt, occ, spinat and nsppol\n(see relevant input variable documents in ABINIT/Infos/). If ABINIT is run in\nmultiple dataset mode, the different wave functions for the various datasets\nare exported as pwfn1.data, pwfn2.data, \u2026, pwfnn.data where the numbers are\nthe contents of the contents of the input array jdtset (defaults to\n1,2,\u2026,ndtset). \nOnce the routine is incorporated into the ABINIT package it is anticipated\nthat there will be an input variable to control whether or not a CASINO\npwfn.data file is written.  Other issues related to  prtwf =2. \nThe exporter does not currently work when ABINIT is used in parallel mode on\nmultiple processors if k-point parallelism is chosen. ABINIT does not store\nthe full wave function on each processor but rather splits the k-points\nbetween the processors, so no one processor could write out the whole file.\nClearly this could be fixed but we have not done it yet. The sort of plane\nwave DFT calculations usually required to generate QMC trial wave functions\nexecute very rapidly anyway and will generally not require a parallel\nmachines. The outqmc routine currently bails out with an error if this\ncombination of modes is selected - this will hopefully be fixed later. \nThere has not been very extensive testing of less common situations such as\ndifferent numbers of bands for different k-points, and more complicated spin\npolarized systems, so care should be taken when using the output in these\ncircumstances. \nIf there is any doubt about the output of this routine, the first place to\nlook is the log file produced by ABINIT: if there are any warnings about\nincorrectly normalized orbitals or non-integer occupation numbers there is\nprobably something set wrong in the input file.",
            "title": "prtwf"
        },
        {
            "location": "/input_variables/varfil/#prtwf_full",
            "text": "Mnemonics: PRinT Wavefunction file on the FULL mesh \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  prtwf  == 1    If set to 1 in a ground-state calculation, the code will output another WFK\nfile (with extension FULL_WFK) containing the wavefunctions in the full BZ as\nwell as a text file with the tables used for the tetrahedron method. Note that\nprtwf_full requires  prtwf  == 1 and a ground-state calculation done on a\nhomogeneous k-mesh (see  ngkpt  and  shiftk ). The tetrahedron table is\nproduced only if the number of k-points in the irreducible zone ( nkpt ) is\ngreater than 3.",
            "title": "prtwf_full"
        },
        {
            "location": "/input_variables/varfil/#prtxml",
            "text": "Mnemonics: PRinT an XML output \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Create an XML output with common values. The corresponding DTD is distributed\nin sources as extras/post_processing/abinitRun.dtd. All the DTD is not yet\nimplemented and this one is currently restricted to ground-state computations\n(and derivative such as geometry optimisation).",
            "title": "prtxml"
        },
        {
            "location": "/input_variables/vargeo/",
            "text": "brvltt\n\u00b6\n\n\nMnemonics: BRaVais LaTTice type\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nspgroup\n != 0  \n\n\nSet the type of Bravais lattice. The cell defined by \nacell\n and \nrprim\n\nor \nangdeg\n should be the CONVENTIONAL cell.\n\n\nIf brvltt=0, the code will assign brvltt from the space group information\n\nspgroup\n, and produce the symmetry operations for the conventional unit\ncell. If the conventional cell is not primitive, the user should set\n\nchkprim\n=0.\n\n\nIf brvltt=-1, the code will assign brvltt from the space group information,\nthen reduce the unit cell to a primitive unit cell. The echo of \nacell\n and\n\nrprim\n might thus differ from those derived directly from the input\nvariables. Also, the input variable \nxred\n will refer to the CONVENTIONAL\nunit cell, but its echo will refer to the preprocessed PRIMITIVE unit cell.\nThere is of course no problem with \nxangst\n and \nxcart\n, as they are\nindependent of the unit cell.\n\n\nThe echo of \nbrvltt\n in the output file will be one of the following Bravais\nlattices:  \n\n\n\n\n1 = Primitive with no associated translations \n\n\n2 = Inner centered with (a/2 + b/2 + c/2) associated translation \n\n\n3 = Face centered with (a/2 + b/2; b/2 + c/2; c/2 + a/2) associated translations \n\n\n4 = C - centered with (a/2 + b/2) associated translation \n\n\n5 = A - centered with (b/2 + c/2) associated translation \n\n\n6 = B - centered with (c/2 + a/2) associated translation \n\n\n7 = Rhombohedral lattice. \n\n\n\n\nThe user might also input directly these values, although they might not be\nconsistent with \nspgroup\n.\n\n\nThe space groups 146, 148, 155, 160, 161, 166, 167, when used with\n\nspgaxor\n=1 (hexagonal axes) will have \nbrvltt\n=7 and two associated\ntranslations: (2/3, 1/3, 1/3) and (1/3, 2/3, 2/3).\n\nFor more details see the space group \n help file\n\n .\n\n\nchempot\n\u00b6\n\n\nMnemonics: spatially varying CHEMical POTential\n\nVariable type: real\n\nDimensions: (3,[[\u2018nzchempot\u2019]],[[\u2018ntype\u2019]])\n\nDefault value: 0.0\n\nOnly relevant if \nnzchempot\n/=0  \n\n\nFor each type of atoms, from 1 to \nntypat\n, specifies the spatially varying\nchemical potential, through the specification of \nnzchempot\n triplets of\nreal numbers. They give data for \nnzchempot\n delimiting planes, all parallel\nto each other, each determined by its z reduced coordinate. The first real\nnumber is the z reduced coordinate of the delimiting plane. The second real\nnumber is the value of the chemical potential for this type of atom on this\nplane. The third real number is the derivative of the chemical potential fior\nthis type of atom with respect to the z reduced coordinate, evaluated on this\nplane. In the space between delimiting planes, a piecewise cubic polynomial\ninterpolation is determined : the cubic polynomial between two delimiting\nplanes will have the imposed chemical potentials and derivatives on the two\ndelimiting planes. The z reduced coordinates must be ordered in increasing\nvalues, and cannot span more than 1.0 . There is an automatic periodic\nboundary condition imposed. Specifying two identical z reduced coordinates is\nallowed, and means that the first one applies to the adjacent space with lower\nvalues of z, while the second applies to the adjacent space with higher values\nof z. When the spatial chemical potential is defined only for one type of atom\n(and no chemical potential is present for the other atoms), simply set the\nrelated values to *0.0 in the \nchempot\n array. In the present input array,\nreduced positions, energies and derivatives of energies are mixed. Hence,\nalthough the chemical potential is an energy, one cannot use the usual energy\ndefinitions (i.e. the chemical potential is always to be input in Hartree\natomic units).\n\n\ngenafm\n\u00b6\n\n\nMnemonics: GENerator of the translation for Anti-FerroMagnetic space group\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0  \n\n\nThis input variable might be used to define a Shubnikov type IV magnetic space\ngroup (anti-ferromagnetic space group). The user is advised to consult \u201cThe\nmathematical theory of symmetry in solids, Representation theory for point\ngroups and space groups, 1972, C.J. Bradley and A.P. Cracknell, Clarendon\nPress, Oxford.\u201d\n\nA Shubnikov type IV magnetic space group might be defined by its Fedorov space\ngroup (set of spatial symmetries, that do not change the magnetization), and\none translation associated with a change of magnetization. \ngenafm\n is\nprecisely this translation, in reduced coordinates (like \nxred\n)\n\nThus, one way to specify a Shubnikov IV magnetic space group, is to define\nboth \nspgroup\n and \ngenafm\n. Alternatively, one might define \nspgroup\n\nand \nspgroupma\n, or define by hand the set of symmetries, using \nsymrel\n,\n\ntnons\n and \nsymafm\n\n\nnatrd\n\u00b6\n\n\nMnemonics: Number of AToms ReaD\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \nnatom\n  \n\n\nGives the number of atoms to be read from the input file, in the case the\ngeometry builder or the symmetriser is used. In this case, \nnatrd\n is also\nused to dimension the array \ntypat\n, and the arrays \nxred\n, \nxangst\n and\n\nxcart\n.\n\nMust take into account the vacancies (see \nvacnum\n and \nvaclst\n).\n\nDespite possible vacancies, cannot be bigger than \nnatom\n.\n\n\nnobj\n\u00b6\n\n\nMnemonics: Number of OBJects\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nComment: (no use of the geometry builder)  \n\n\nGives the number of \u2018objects\u2019 to be used by the geometry builder in order to\nfind the full set of atoms. At present, only one or two objects can be\ndefined, identified as objects \u2018a\u2019 and \u2018b\u2019.\n\nRelated variables for object \u2018a\u2019 are : \nobjan\n, \nobjaat\n, \nobjarf\n,\n\nobjatr\n, \nobjaro\n, \nobjaax\n. Related variables for object \u2018b\u2019 are :\n\nobjbn\n , \nobjbat\n , \nobjbrf\n , \nobjbtr\n , \nobjbro\n , \nobjbax\n .\n\nMore detailed explanation : when the geometry builder is used (i.e. when\n\nnobj\n==1 or \nnobj\n==2), the code will be given a primitive set of atoms,\nfrom which it will have to deduce the full set of atoms.\n\nAn object will be specified by the number of atoms it includes (\nobjan\n or\n\nobjbn\n ), and the list of these atoms (\nobjaat\n or \nobjbat\n ).\n\nExamples of physical realisation of an object can be a molecule, or a group of\natom to be repeated, or a part of a molecule to be rotated. The geometry\nbuilder can indeed repeat these objects (\nobjarf\n or \nobjbrf\n ), rotate\nthem (\nobjaro\n or \nobjbro\n ) with respect to an axis (\nobjaax\n or\n\nobjbax\n ), and translate them (\nobjatr\n or \nobjbtr\n ). After having\ngenerated a geometry thanks to rotation, translation and repetition of\nobjects, it is possible to remove some atoms, in order to create vacancies\n(\nvacnum\n and \nvaclst\n). The number of atoms in the primitive set, those\nthat will be read from the input file, is specified by the variable \nnatrd\n.\nIt will be always smaller than the final number of atoms, given by the\nvariable \nnatom\n. The code checks whether the primitive number of atoms plus\nthose obtained by the repetition operation is coherent with the variable\n\nnatom\n, taking into account possible vacancies.\n\nYou should look at the other variables for more information. Go to \nobjan\n,\nfor example.  \n\n\nnzchempot\n\u00b6\n\n\nMnemonics: Number of Z reduced coordinates that define the spatial CHEMical POTential\n\nVariable type: integer\n\nDefault value: None  \n\n\nDefines the number of z reduced coordinates that defines the spatially varying\nchemical potential. See the input variable \nchempot\n, of which \nnzchempot\n\nis the second dimension.\n\n\nobjaat\n\u00b6\n\n\nMnemonics: OBJect A : list of AToms\n\nVariable type: integer\n\nDimensions: (\nobjan\n)\n\nDefault value: None\n\nOnly relevant if \u2018\nnobj\n==1\u2019\n\n\nGives the list of atoms in object a. This list is specified by giving, for\neach atom, its index in the list of coordinates (\nxred\n, \nxangst\n or\n\nxcart\n), that also corresponds to a type of atom (given by the array type).\nThese objects can be thought as molecules, or groups of atoms, or parts of\nmolecules, to be repeated, rotated and translated to generate the full set of\natoms.\n\nLook at \nobjarf\n for further explanations.  \n\n\nobjaax\n\u00b6\n\n\nMnemonics: OBJect A : AXis\n\nVariable type: real\n\nDefault value: None\n\nComment: \nobjaax\n must be provided if (\nnobj\n==1 and one component of \nobjaro\n != 0). Moreover,\n\nobjaax\n AND \nobjbax\n must be provided if ( \nnobj\n == 2 and one component of \nobjbro\n != 0 ).  \n\n\nGives, for each object, the cartesian coordinates of two points (first point :\n\n[objaax]\n second point : \n[objaax]\n. By default, given in Bohr\natomic units (1 Bohr=0.5291772108 Angstroms), although Angstrom can be\nspecified, if preferred, since these variables have the \u2018\nLENGTH\n\u2018\ncharacteristics.\n\nThe two points define an axis of rotation of the corresponding object.\n\nNote that the rotation of the object is done BEFORE the object is translated.\n\nThe sign of the rotation angle is positive if the object is to be rotated\nclockwise when looking to it along the axis, from point 1 (coordinates 1:3)\ntoward point 2 (coordinates 4:6).  \n\n\nobjan\n\u00b6\n\n\nMnemonics: OBJect A : Number of atoms\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None\n\nComment:  \nobjan\n MUST be provided if \nnobj\n==1.\n \nobjan\n and \nobjbn\n MUST be provided if \nnobj\n==2.  \n\n\nGives the number of atoms in object a. The list of atoms is given by the\nvariables \nobjaat\n.  \n\n\nobjarf\n\u00b6\n\n\nMnemonics: OBJect A : Repetition Factors\n\nVariable type: integer\n\nDefault value: [1, 1, 1]  \n\n\nGives three repetition factors of the objects a.\n\nThis gives the opportunity to generate a three-dimensional set of repeated\nobjects, although a simple one-dimensional repetition will be easily obtained\nthrough the specification of\n\n\u2018nrep\u2019 1 1\n\nwhere \u2018nrep\u2019 is the 1D repetition factor.\n\nThe initial rotation and translation of the object, as well as the increment\nof rotation or translation from one object to the next are specified by the\nvariables \nobjaro\n and \nobjatr\n, for object a,\n\nNote that the geometry builder will generate the full set of atoms from the\nprimitive set of atoms using the following order : it will process each atom\nin the primitive list one by one, determine whether it belongs to either\nobject a or object b, and then repeat it taking into account the proper\nrotation and translation, with the fastest varying repetition factor being the\nfirst, then the second, then the third.\n\nIn the final list of atoms, one will first find the atoms generated from atom\n1 in the primitive list, then those generated from atom 2 in the primitive\nlist, and so on.\n\nIf the geometry builder is only used to rotate or translate an object, without\nrepeating it, simply use 1 1 1, which is also the Default value.  \n\n\nobjaro\n\u00b6\n\n\nMnemonics: OBJect A : ROtations\n\nVariable type: real\n\nDefault value: 4*0.0d0\n\nComment: (no rotation)  \n\n\nGive, for each object, the angles of rotation in degrees to be applied to the\ncorresponding object.\n\nThe rotation is applied before the translation, and the axis is defined by the\nvariables \nobjaax\n and \nobjbax\n. See the latter variables for the\ndefinition of the sign of the rotation.\n\nThe first component \n[objaro]\n and \n objbro \n (1) gives the angle of\nrotation to be applied to the first instance of the object. The second, third\nor fourth component (resp.) gives the increment of rotation angle from one\ninstance to the next instance, defined by the first, second or third\nrepetition factor (resp.) . This allows to generate 3D arrays of molecules\nwith different rotation angles.  \n\n\nobjatr\n\u00b6\n\n\nMnemonics: OBJect A : TRanslations\n\nVariable type: real\n\nDefault value: 12*0.0d0\n\nComment: (no translation)  \n\n\nGive, for each object, the vectors of translations, in cartesian coordinates,\nto be applied to the corresponding object. By default, given in Bohr atomic\nunits (1 Bohr=0.5291772108 Angstroms), although Angstrom can be specified, if\npreferred, since these variables have the \u2018\nLENGTH\n\u2018 characteristics.\n\nThe translation is applied after the rotation.\n\nThe first vector \n[objatr]\n and \n[objbtr]\n gives the translation to\nbe applied to the first instance of the object. The second, third or fourth\ncomponent (resp.) gives the increment of translation from one instance to the\nnext instance, defined by the first, second or third repetition factor (resp.)\n. This allows to generate 3D arrays of molecules.\n\nIn general, when the objects are repeated, a translation vector must be given,\nsince otherwise, the repeated objects pack in the same region of space. As an\nexception, one can have a set of molecules regularly spaced on a circle, in\nwhich case, only rotations are needed.\n\nNot present in the dtset array (no internal).\n\n\nobjbat\n\u00b6\n\n\nMnemonics: OBJect B : list of AToms\n\nVariable type: integer\n\nDefault value: None\n\nOnly relevant if \nnobj\n==2  \n\n\nGives the list of atoms in object b. This list is specified by giving, for\neach atom, its index in the list of coordinates (\nxred\n, \nxangst\n or\n\nxcart\n), that also corresponds to a type of atom (given by the array type).\nThese objects can be thought as molecules, or groups of atoms, or parts of\nmolecules, to be repeated, rotated and translated to generate the full set of\natoms.\n\nLook at \nobjbrf\n for further explanations.  \n\n\nobjbax\n\u00b6\n\n\nMnemonics: OBJect B : AXis\n\nVariable type: real\n\nDefault value: None\n\nComment: \nobjbax\n must be provided if (\nnobj\n==1 and one component of \nobjaro\n != 0). Moreover,\n\nobjaax\n AND \nobjbax\n must be provided if ( \nnobj\n == 2 and one component of \nobjbro\n != 0 ).  \n\n\nGives, for each object, the cartesian coordinates of two points (first point :\n\n[objbax]\n second point : \n[objbax]\n. By default, given in Bohr\natomic units (1 Bohr=0.5291772108 Angstroms), although Angstrom can be\nspecified, if preferred, since these variables have the \u2018\nLENGTH\n\u2018\ncharacteristics.\n\nThe two points define an axis of rotation of the corresponding object.\n\nNote that the rotation of the object is done BEFORE the object is translated.\n\nThe sign of the rotation angle is positive if the object is to be rotated\nclockwise when looking to it along the axis, from point 1 (coordinates 1:3)\ntoward point 2 (coordinates 4:6).  \n\n\nobjbn\n\u00b6\n\n\nMnemonics: OBJect B : Number of atoms\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None\n\nComment:  \nobjan\n and \nobjbn\n MUST be provided if \nnobj\n==2.  \n\n\nGives the number of atoms in either object b. The list of atoms is given by\nthe variables \nobjbat\n.  \n\n\nobjbrf\n\u00b6\n\n\nMnemonics: OBJect B : Repetition Factors\n\nVariable type: integer\n\nDefault value: [1, 1, 1]  \n\n\nGives three repetition factors of the objects a or b.\n\nThis gives the opportunity to generate a three-dimensional set of repeated\nobjects, although a simple one-dimensional repetition will be easily obtained\nthrough the specification of\n\nnrep 1 1 <r> where nrep is the 1D repetition factor.\n\nThe initial rotation and translation of the object, as well as the increment\nof rotation or translation from one object to the next are specified by the\nvariables \nobjbro\n and \nobjbtr\n, for object b.\n\nNote that the geometry builder will generate the full set of atoms from the\nprimitive set of atoms using the following order : it will process each atom\nin the primitive list one by one, determine whether it belongs to either\nobject a or object b, and then repeat it taking into account the proper\nrotation and translation, with the fastest varying repetition factor being the\nfirst, then the second, then the third.\n\nIn the final list of atoms, one will first find the atoms generated from atom\n1 in the primitive list, then those generated from atom 2 in the primitive\nlist, and so on.\n\nIf the geometry builder is only used to rotate or translate an object, without\nrepeating it, simply use 1 1 1, which is also the Default value.  \n\n\nobjbro\n\u00b6\n\n\nMnemonics: OBJect B : ROtations\n\nVariable type: real\n\nDefault value: 4*0.0d0\n\nComment: (no rotation)  \n\n\nGive, for each object, the angles of rotation in degrees to be applied to the\ncorresponding object.\n\nThe rotation is applied before the translation, and the axis is defined by the\nvariables \nobjaax\n and \nobjbax\n. See the latter variables for the\ndefinition of the sign of the rotation.\n\nThe first component \n[objaro]\n and \n objbro \n (1) gives the angle of\nrotation to be applied to the first instance of the object. The second, third\nor fourth component (resp.) gives the increment of rotation angle from one\ninstance to the next instance, defined by the first, second or third\nrepetition factor (resp.) . This allows to generate 3D arrays of molecules\nwith different rotation angles.  \n\n\nobjbtr\n\u00b6\n\n\nMnemonics: OBJect B : TRanslations\n\nVariable type: real\n\nDefault value: 12*0.0d0\n\nComment: (no translation)  \n\n\nGive, for each object, the vectors of translations, in cartesian coordinates,\nto be applied to the corresponding object. By default, given in Bohr atomic\nunits (1 Bohr=0.5291772108 Angstroms), although Angstrom can be specified, if\npreferred, since these variables have the \u2018\nLENGTH\n\u2018 characteristics.\n\nThe translation is applied after the rotation.\n\nThe first vector \n[objatr]\n and \n[objbtr]\n gives the translation to\nbe applied to the first instance of the object. The second, third or fourth\ncomponent (resp.) gives the increment of translation from one instance to the\nnext instance, defined by the first, second or third repetition factor (resp.)\n. This allows to generate 3D arrays of molecules.\n\nIn general, when the objects are repeated, a translation vector must be given,\nsince otherwise, the repeated objects pack in the same region of space. As an\nexception, one can have a set of molecules regularly spaced on a circle, in\nwhich case, only rotations are needed.  \n\n\nptgroupma\n\u00b6\n\n\nMnemonics: PoinT GROUP number for the MAgnetic space group\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis internal variable characterizes a Shubnikov type III magnetic space group\n(anti-ferromagnetic space group). The user is advised to consult \u201cThe\nmathematical theory of symmetry in solids, Representation theory for point\ngroups and space groups, 1972, C.J. Bradley and A.P. Cracknell, Clarendon\nPress, Oxford.\u201d\n\nA Shubnikov type III magnetic space group might be defined by its Fedorov\nspace group (set of all spatial symmetries, irrespective of their magnetic\naction), and the halving space group (only the symmetries that do not change\nthe magnetization).\n\nThe specification of the halving space group might be done by specifying, for\neach point symmetry, the magnetic action. See Table 7.1 of the above-mentioned\nreference. Magnetic point groups are numbered from 1 to 58.\n\n\nRelated input variables : \nspgroup\n, \nspgroupma\n, \ngenafm\n\n\nspgaxor\n\u00b6\n\n\nMnemonics: SPace Group : AXes ORientation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nIt is taken into account only when \nspgroup\n/=0; it allows one to define the\naxes orientation for the specific space groups for which this is needed.\nTrigonal groups (number 146,148,155,160,161,166,167):\n\n\n\n\n1 represents the hexagonal axes \n\n\n2 represents the rhombohedral axes \n\n\n\n\nOrthorhombic space groups : there are six possibilities corresponding to the\npossible axes permutations\n\n\n\n\n1 abc -> abc \n\n\n2 abc -> cab \n\n\n3 abc -> bca \n\n\n4 abc -> acb \n\n\n5 abc -> bac \n\n\n6 abc -> cba \n\n\n\n\nMonoclinic : there are 3 or 9 possibilities depending on the space group. See\nthe space group \n help file \n for\ndetails. In the log/output file the notation used to describe the monoclinic\ngroups is for example:\n\n15:c1, A2/a_c = C2/c\n\nwhere,\n\n\n\n\n15 represents the space group number, \n\n\nc1 the orientation as it appears on the web page, \n\n\nA is the real Bravais type lattice, \n\n\n2/a the existent symmetry elements, \n\n\n_c marks the orientation of the two-fold axis or of the mirror plane, \n\n\nC2/c represents the parent space group. \n\n\n\n\nHow to determine which spgaxor you need:\n\n\n\n\ncheck the reduced positions you have, for more symmetric positions, e.g. 1/2 1/4 3/4 etc\u2026 Let us say your symmetric positions are in the first coordinate (a axis) and you are using spgroup 62. \n\n\nlook up the raw space group Wyckoff positions on \n the Bilbao server \n to see where they put the corresponding symmetric positions. For spgroup 62 Bilbao puts the 1/4 3/4 in the second coordinate, ie along the b axis. \n\n\nin this case you need to swap the axes from the original abc order to a new order where the Bilbao axis (b) is in the first position. In this case you have 2 possibilities, spgaxor 3 or 5. If you have more than one highly symmetric coordinate you may have only a single possibility. \n\n\n\n\nspgorig\n\u00b6\n\n\nMnemonics: SPace Group : ORIGin\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nspgroup\n!=0  \n\n\nGives the choice of origin for the axes system.\n\nIt is defined according to the origin choice in the International Tables of\nCrystallography.\n\nIt applies only to the space groups 48, 50, 59, 70, 85, 86, 88, 125, 126, 129,\n130, 133, 134, 137, 141, 142, 201, 203, 222, 224, 227, 228.\n\nFor details see the space group \n help file\n\n .\n\n\nspgroup\n\u00b6\n\n\nMnemonics: SPace GROUP number\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of the space group.\n\nIf \nspgroup\n is 0, the code assumes that all the symmetries are input\nthrough the \nsymrel\n matrices and the \ntnons\n vectors, or obtained from\nthe symmetry finder (the default when \nnsym\n==0).\n\nIt should be between 1 and 230. This option can be used to obtain all the\natoms in the unit cell, starting from the asymmetric unit cell.\n\nThe references for computing the symmetry corresponding to the space groups\nare :\n\n\n\n\nInternational Tables for Crystallography, 1983, Ed. Theo Hahn, D. Reidel Publishing Company \n\n\nThe mathematical theory of symmetry in solids, Representation theory for point groups and space groups, 1972, C.J. Bradley and A.P. Cracknell, Clarendon Press, Oxford. \n\n\n\n\nFor details see the space group \n help file\n\n .\n\n\nspgroupma\n\u00b6\n\n\nMnemonics: SPace GROUP number defining a MAgnetic space group\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis input variable might be used to define a Shubnikov magnetic space group\n(anti-ferromagnetic space group). The user is advised to consult \u201cThe\nmathematical theory of symmetry in solids, Representation theory for point\ngroups and space groups, 1972, C.J. Bradley and A.P. Cracknell, Clarendon\nPress, Oxford.\u201d\n\nA Shubnikov type IV magnetic space group might be defined by its Fedorov space\ngroup (set of spatial symmetries that do not change the magnetization), and an\nadditional magnetic space group number \nspgroupma\n.\n\nA Shubnikov type III magnetic space group might be defined by its Fedorov\nspace group (set of all spatial symmetries, irrespective of their magnetic\naction), and an additional magnetic space group number \nspgroupma\n.\n\nFor the additional number \nspgroupma\n, we follow the definition of Table 7.4\nof the above-mentioned Bradley and Cracknell textbook.\n\nThus, one way to specify a Shubnikov IV magnetic space group, is to define\nboth \nspgroup\n and \nspgroupma\n.\n\nFor example, the group P2_1/c_prime has \nspgroup\n=14 and \nspgroupma\n=78.\n\nAlternatively, for Shubnikov IV magnetic groups, one might define \nspgroup\n\nand \ngenafm\n. For both the type III and IV, one might define by hand the set\nof symmetries, using \nsymrel\n, \ntnons\n and \nsymafm\n.\n\n\ntolsym\n\u00b6\n\n\nMnemonics: TOLERANCE for SYMmetries\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1e-08  \n\n\nGives the tolerance on the atomic positions (reduced coordinates), primitive\nvectors, or magnetization, to be considered equivalent, thanks to symmetry\noperations. This is used in the recognition of the set of symmetries of the\nsystem, or the application of the symmetry operations to generate from a\nreduced set of atoms, the full set of atoms. Note that a value larger than\n0.01 is considered to be unacceptable.\n\nNote : ABINIT needs the atomic positions to be symmmetric to each others\nwithin 1.e-8 . If \ntolsym\n is set to a larger value than 1.e-8, then the\ninput atomic coordinates will be automatically symmetrized by the symmetry\noperations that will have been found.\n\n\nvaclst\n\u00b6\n\n\nMnemonics: VACancies LiST\n\nVariable type: integer\n\nDimensions: (\nvacnum\n)\n\nDefault value: None  \n\n\nGives the identification number(s) of atoms to be subtracted from the set of\natoms that are obtained after having rotated, translated and repeated the\nobjects.\n\nUseful to created vacancies.\n\n\nvacnum\n\u00b6\n\n\nMnemonics: VACancies NUMber\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of atoms to be subtracted from the list of atoms after the\nrotations, translations and repetitions have been done. The list of these\natoms is contained in \nvaclst\n.\n\n\nxyzfile\n\u00b6\n\n\nMnemonics: XYZ FILE input for geometry\n\nVariable type: string\n\nDimensions: scalar\n\nDefault value: None  \n\n\nGives the name of a xyz format file, to take \nnatom\n, \nntypat\n, \ntypat\n,\n\nznucl\n, and \nxangst\n from. This input can not be mixed with normal atom\nspecifications for other datasets.\n\n\nNotes: do not quote the file name in the abinit input file, simply leave a\nspace after xyzfile. The xyz format is the number of atoms on the first line,\na comment line, then one line per atom, with the element as a 2 letter symbol\n(\u201cAs\u201d \u201cO\u201d or \u201cPu\u201d) and the three cartesian coordinates in Angstrom.",
            "title": "Geometry"
        },
        {
            "location": "/input_variables/vargeo/#brvltt",
            "text": "Mnemonics: BRaVais LaTTice type \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  spgroup  != 0    Set the type of Bravais lattice. The cell defined by  acell  and  rprim \nor  angdeg  should be the CONVENTIONAL cell.  If brvltt=0, the code will assign brvltt from the space group information spgroup , and produce the symmetry operations for the conventional unit\ncell. If the conventional cell is not primitive, the user should set chkprim =0.  If brvltt=-1, the code will assign brvltt from the space group information,\nthen reduce the unit cell to a primitive unit cell. The echo of  acell  and rprim  might thus differ from those derived directly from the input\nvariables. Also, the input variable  xred  will refer to the CONVENTIONAL\nunit cell, but its echo will refer to the preprocessed PRIMITIVE unit cell.\nThere is of course no problem with  xangst  and  xcart , as they are\nindependent of the unit cell.  The echo of  brvltt  in the output file will be one of the following Bravais\nlattices:     1 = Primitive with no associated translations   2 = Inner centered with (a/2 + b/2 + c/2) associated translation   3 = Face centered with (a/2 + b/2; b/2 + c/2; c/2 + a/2) associated translations   4 = C - centered with (a/2 + b/2) associated translation   5 = A - centered with (b/2 + c/2) associated translation   6 = B - centered with (c/2 + a/2) associated translation   7 = Rhombohedral lattice.    The user might also input directly these values, although they might not be\nconsistent with  spgroup .  The space groups 146, 148, 155, 160, 161, 166, 167, when used with spgaxor =1 (hexagonal axes) will have  brvltt =7 and two associated\ntranslations: (2/3, 1/3, 1/3) and (1/3, 2/3, 2/3). \nFor more details see the space group   help file  .",
            "title": "brvltt"
        },
        {
            "location": "/input_variables/vargeo/#chempot",
            "text": "Mnemonics: spatially varying CHEMical POTential \nVariable type: real \nDimensions: (3,[[\u2018nzchempot\u2019]],[[\u2018ntype\u2019]]) \nDefault value: 0.0 \nOnly relevant if  nzchempot /=0    For each type of atoms, from 1 to  ntypat , specifies the spatially varying\nchemical potential, through the specification of  nzchempot  triplets of\nreal numbers. They give data for  nzchempot  delimiting planes, all parallel\nto each other, each determined by its z reduced coordinate. The first real\nnumber is the z reduced coordinate of the delimiting plane. The second real\nnumber is the value of the chemical potential for this type of atom on this\nplane. The third real number is the derivative of the chemical potential fior\nthis type of atom with respect to the z reduced coordinate, evaluated on this\nplane. In the space between delimiting planes, a piecewise cubic polynomial\ninterpolation is determined : the cubic polynomial between two delimiting\nplanes will have the imposed chemical potentials and derivatives on the two\ndelimiting planes. The z reduced coordinates must be ordered in increasing\nvalues, and cannot span more than 1.0 . There is an automatic periodic\nboundary condition imposed. Specifying two identical z reduced coordinates is\nallowed, and means that the first one applies to the adjacent space with lower\nvalues of z, while the second applies to the adjacent space with higher values\nof z. When the spatial chemical potential is defined only for one type of atom\n(and no chemical potential is present for the other atoms), simply set the\nrelated values to *0.0 in the  chempot  array. In the present input array,\nreduced positions, energies and derivatives of energies are mixed. Hence,\nalthough the chemical potential is an energy, one cannot use the usual energy\ndefinitions (i.e. the chemical potential is always to be input in Hartree\natomic units).",
            "title": "chempot"
        },
        {
            "location": "/input_variables/vargeo/#genafm",
            "text": "Mnemonics: GENerator of the translation for Anti-FerroMagnetic space group \nVariable type: real \nDimensions: (3) \nDefault value: 3*0    This input variable might be used to define a Shubnikov type IV magnetic space\ngroup (anti-ferromagnetic space group). The user is advised to consult \u201cThe\nmathematical theory of symmetry in solids, Representation theory for point\ngroups and space groups, 1972, C.J. Bradley and A.P. Cracknell, Clarendon\nPress, Oxford.\u201d \nA Shubnikov type IV magnetic space group might be defined by its Fedorov space\ngroup (set of spatial symmetries, that do not change the magnetization), and\none translation associated with a change of magnetization.  genafm  is\nprecisely this translation, in reduced coordinates (like  xred ) \nThus, one way to specify a Shubnikov IV magnetic space group, is to define\nboth  spgroup  and  genafm . Alternatively, one might define  spgroup \nand  spgroupma , or define by hand the set of symmetries, using  symrel , tnons  and  symafm",
            "title": "genafm"
        },
        {
            "location": "/input_variables/vargeo/#natrd",
            "text": "Mnemonics: Number of AToms ReaD \nVariable type: integer \nDimensions: scalar \nDefault value:  natom     Gives the number of atoms to be read from the input file, in the case the\ngeometry builder or the symmetriser is used. In this case,  natrd  is also\nused to dimension the array  typat , and the arrays  xred ,  xangst  and xcart . \nMust take into account the vacancies (see  vacnum  and  vaclst ). \nDespite possible vacancies, cannot be bigger than  natom .",
            "title": "natrd"
        },
        {
            "location": "/input_variables/vargeo/#nobj",
            "text": "Mnemonics: Number of OBJects \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nComment: (no use of the geometry builder)    Gives the number of \u2018objects\u2019 to be used by the geometry builder in order to\nfind the full set of atoms. At present, only one or two objects can be\ndefined, identified as objects \u2018a\u2019 and \u2018b\u2019. \nRelated variables for object \u2018a\u2019 are :  objan ,  objaat ,  objarf , objatr ,  objaro ,  objaax . Related variables for object \u2018b\u2019 are : objbn  ,  objbat  ,  objbrf  ,  objbtr  ,  objbro  ,  objbax  . \nMore detailed explanation : when the geometry builder is used (i.e. when nobj ==1 or  nobj ==2), the code will be given a primitive set of atoms,\nfrom which it will have to deduce the full set of atoms. \nAn object will be specified by the number of atoms it includes ( objan  or objbn  ), and the list of these atoms ( objaat  or  objbat  ). \nExamples of physical realisation of an object can be a molecule, or a group of\natom to be repeated, or a part of a molecule to be rotated. The geometry\nbuilder can indeed repeat these objects ( objarf  or  objbrf  ), rotate\nthem ( objaro  or  objbro  ) with respect to an axis ( objaax  or objbax  ), and translate them ( objatr  or  objbtr  ). After having\ngenerated a geometry thanks to rotation, translation and repetition of\nobjects, it is possible to remove some atoms, in order to create vacancies\n( vacnum  and  vaclst ). The number of atoms in the primitive set, those\nthat will be read from the input file, is specified by the variable  natrd .\nIt will be always smaller than the final number of atoms, given by the\nvariable  natom . The code checks whether the primitive number of atoms plus\nthose obtained by the repetition operation is coherent with the variable natom , taking into account possible vacancies. \nYou should look at the other variables for more information. Go to  objan ,\nfor example.",
            "title": "nobj"
        },
        {
            "location": "/input_variables/vargeo/#nzchempot",
            "text": "Mnemonics: Number of Z reduced coordinates that define the spatial CHEMical POTential \nVariable type: integer \nDefault value: None    Defines the number of z reduced coordinates that defines the spatially varying\nchemical potential. See the input variable  chempot , of which  nzchempot \nis the second dimension.",
            "title": "nzchempot"
        },
        {
            "location": "/input_variables/vargeo/#objaat",
            "text": "Mnemonics: OBJect A : list of AToms \nVariable type: integer \nDimensions: ( objan ) \nDefault value: None \nOnly relevant if \u2018 nobj ==1\u2019  Gives the list of atoms in object a. This list is specified by giving, for\neach atom, its index in the list of coordinates ( xred ,  xangst  or xcart ), that also corresponds to a type of atom (given by the array type).\nThese objects can be thought as molecules, or groups of atoms, or parts of\nmolecules, to be repeated, rotated and translated to generate the full set of\natoms. \nLook at  objarf  for further explanations.",
            "title": "objaat"
        },
        {
            "location": "/input_variables/vargeo/#objaax",
            "text": "Mnemonics: OBJect A : AXis \nVariable type: real \nDefault value: None \nComment:  objaax  must be provided if ( nobj ==1 and one component of  objaro  != 0). Moreover, objaax  AND  objbax  must be provided if (  nobj  == 2 and one component of  objbro  != 0 ).    Gives, for each object, the cartesian coordinates of two points (first point : [objaax]  second point :  [objaax] . By default, given in Bohr\natomic units (1 Bohr=0.5291772108 Angstroms), although Angstrom can be\nspecified, if preferred, since these variables have the \u2018 LENGTH \u2018\ncharacteristics. \nThe two points define an axis of rotation of the corresponding object. \nNote that the rotation of the object is done BEFORE the object is translated. \nThe sign of the rotation angle is positive if the object is to be rotated\nclockwise when looking to it along the axis, from point 1 (coordinates 1:3)\ntoward point 2 (coordinates 4:6).",
            "title": "objaax"
        },
        {
            "location": "/input_variables/vargeo/#objan",
            "text": "Mnemonics: OBJect A : Number of atoms \nVariable type: integer \nDimensions: scalar \nDefault value: None \nComment:   objan  MUST be provided if  nobj ==1.\n  objan  and  objbn  MUST be provided if  nobj ==2.    Gives the number of atoms in object a. The list of atoms is given by the\nvariables  objaat .",
            "title": "objan"
        },
        {
            "location": "/input_variables/vargeo/#objarf",
            "text": "Mnemonics: OBJect A : Repetition Factors \nVariable type: integer \nDefault value: [1, 1, 1]    Gives three repetition factors of the objects a. \nThis gives the opportunity to generate a three-dimensional set of repeated\nobjects, although a simple one-dimensional repetition will be easily obtained\nthrough the specification of \n\u2018nrep\u2019 1 1 \nwhere \u2018nrep\u2019 is the 1D repetition factor. \nThe initial rotation and translation of the object, as well as the increment\nof rotation or translation from one object to the next are specified by the\nvariables  objaro  and  objatr , for object a, \nNote that the geometry builder will generate the full set of atoms from the\nprimitive set of atoms using the following order : it will process each atom\nin the primitive list one by one, determine whether it belongs to either\nobject a or object b, and then repeat it taking into account the proper\nrotation and translation, with the fastest varying repetition factor being the\nfirst, then the second, then the third. \nIn the final list of atoms, one will first find the atoms generated from atom\n1 in the primitive list, then those generated from atom 2 in the primitive\nlist, and so on. \nIf the geometry builder is only used to rotate or translate an object, without\nrepeating it, simply use 1 1 1, which is also the Default value.",
            "title": "objarf"
        },
        {
            "location": "/input_variables/vargeo/#objaro",
            "text": "Mnemonics: OBJect A : ROtations \nVariable type: real \nDefault value: 4*0.0d0 \nComment: (no rotation)    Give, for each object, the angles of rotation in degrees to be applied to the\ncorresponding object. \nThe rotation is applied before the translation, and the axis is defined by the\nvariables  objaax  and  objbax . See the latter variables for the\ndefinition of the sign of the rotation. \nThe first component  [objaro]  and   objbro   (1) gives the angle of\nrotation to be applied to the first instance of the object. The second, third\nor fourth component (resp.) gives the increment of rotation angle from one\ninstance to the next instance, defined by the first, second or third\nrepetition factor (resp.) . This allows to generate 3D arrays of molecules\nwith different rotation angles.",
            "title": "objaro"
        },
        {
            "location": "/input_variables/vargeo/#objatr",
            "text": "Mnemonics: OBJect A : TRanslations \nVariable type: real \nDefault value: 12*0.0d0 \nComment: (no translation)    Give, for each object, the vectors of translations, in cartesian coordinates,\nto be applied to the corresponding object. By default, given in Bohr atomic\nunits (1 Bohr=0.5291772108 Angstroms), although Angstrom can be specified, if\npreferred, since these variables have the \u2018 LENGTH \u2018 characteristics. \nThe translation is applied after the rotation. \nThe first vector  [objatr]  and  [objbtr]  gives the translation to\nbe applied to the first instance of the object. The second, third or fourth\ncomponent (resp.) gives the increment of translation from one instance to the\nnext instance, defined by the first, second or third repetition factor (resp.)\n. This allows to generate 3D arrays of molecules. \nIn general, when the objects are repeated, a translation vector must be given,\nsince otherwise, the repeated objects pack in the same region of space. As an\nexception, one can have a set of molecules regularly spaced on a circle, in\nwhich case, only rotations are needed. \nNot present in the dtset array (no internal).",
            "title": "objatr"
        },
        {
            "location": "/input_variables/vargeo/#objbat",
            "text": "Mnemonics: OBJect B : list of AToms \nVariable type: integer \nDefault value: None \nOnly relevant if  nobj ==2    Gives the list of atoms in object b. This list is specified by giving, for\neach atom, its index in the list of coordinates ( xred ,  xangst  or xcart ), that also corresponds to a type of atom (given by the array type).\nThese objects can be thought as molecules, or groups of atoms, or parts of\nmolecules, to be repeated, rotated and translated to generate the full set of\natoms. \nLook at  objbrf  for further explanations.",
            "title": "objbat"
        },
        {
            "location": "/input_variables/vargeo/#objbax",
            "text": "Mnemonics: OBJect B : AXis \nVariable type: real \nDefault value: None \nComment:  objbax  must be provided if ( nobj ==1 and one component of  objaro  != 0). Moreover, objaax  AND  objbax  must be provided if (  nobj  == 2 and one component of  objbro  != 0 ).    Gives, for each object, the cartesian coordinates of two points (first point : [objbax]  second point :  [objbax] . By default, given in Bohr\natomic units (1 Bohr=0.5291772108 Angstroms), although Angstrom can be\nspecified, if preferred, since these variables have the \u2018 LENGTH \u2018\ncharacteristics. \nThe two points define an axis of rotation of the corresponding object. \nNote that the rotation of the object is done BEFORE the object is translated. \nThe sign of the rotation angle is positive if the object is to be rotated\nclockwise when looking to it along the axis, from point 1 (coordinates 1:3)\ntoward point 2 (coordinates 4:6).",
            "title": "objbax"
        },
        {
            "location": "/input_variables/vargeo/#objbn",
            "text": "Mnemonics: OBJect B : Number of atoms \nVariable type: integer \nDimensions: scalar \nDefault value: None \nComment:   objan  and  objbn  MUST be provided if  nobj ==2.    Gives the number of atoms in either object b. The list of atoms is given by\nthe variables  objbat .",
            "title": "objbn"
        },
        {
            "location": "/input_variables/vargeo/#objbrf",
            "text": "Mnemonics: OBJect B : Repetition Factors \nVariable type: integer \nDefault value: [1, 1, 1]    Gives three repetition factors of the objects a or b. \nThis gives the opportunity to generate a three-dimensional set of repeated\nobjects, although a simple one-dimensional repetition will be easily obtained\nthrough the specification of \nnrep 1 1 <r> where nrep is the 1D repetition factor. \nThe initial rotation and translation of the object, as well as the increment\nof rotation or translation from one object to the next are specified by the\nvariables  objbro  and  objbtr , for object b. \nNote that the geometry builder will generate the full set of atoms from the\nprimitive set of atoms using the following order : it will process each atom\nin the primitive list one by one, determine whether it belongs to either\nobject a or object b, and then repeat it taking into account the proper\nrotation and translation, with the fastest varying repetition factor being the\nfirst, then the second, then the third. \nIn the final list of atoms, one will first find the atoms generated from atom\n1 in the primitive list, then those generated from atom 2 in the primitive\nlist, and so on. \nIf the geometry builder is only used to rotate or translate an object, without\nrepeating it, simply use 1 1 1, which is also the Default value.",
            "title": "objbrf"
        },
        {
            "location": "/input_variables/vargeo/#objbro",
            "text": "Mnemonics: OBJect B : ROtations \nVariable type: real \nDefault value: 4*0.0d0 \nComment: (no rotation)    Give, for each object, the angles of rotation in degrees to be applied to the\ncorresponding object. \nThe rotation is applied before the translation, and the axis is defined by the\nvariables  objaax  and  objbax . See the latter variables for the\ndefinition of the sign of the rotation. \nThe first component  [objaro]  and   objbro   (1) gives the angle of\nrotation to be applied to the first instance of the object. The second, third\nor fourth component (resp.) gives the increment of rotation angle from one\ninstance to the next instance, defined by the first, second or third\nrepetition factor (resp.) . This allows to generate 3D arrays of molecules\nwith different rotation angles.",
            "title": "objbro"
        },
        {
            "location": "/input_variables/vargeo/#objbtr",
            "text": "Mnemonics: OBJect B : TRanslations \nVariable type: real \nDefault value: 12*0.0d0 \nComment: (no translation)    Give, for each object, the vectors of translations, in cartesian coordinates,\nto be applied to the corresponding object. By default, given in Bohr atomic\nunits (1 Bohr=0.5291772108 Angstroms), although Angstrom can be specified, if\npreferred, since these variables have the \u2018 LENGTH \u2018 characteristics. \nThe translation is applied after the rotation. \nThe first vector  [objatr]  and  [objbtr]  gives the translation to\nbe applied to the first instance of the object. The second, third or fourth\ncomponent (resp.) gives the increment of translation from one instance to the\nnext instance, defined by the first, second or third repetition factor (resp.)\n. This allows to generate 3D arrays of molecules. \nIn general, when the objects are repeated, a translation vector must be given,\nsince otherwise, the repeated objects pack in the same region of space. As an\nexception, one can have a set of molecules regularly spaced on a circle, in\nwhich case, only rotations are needed.",
            "title": "objbtr"
        },
        {
            "location": "/input_variables/vargeo/#ptgroupma",
            "text": "Mnemonics: PoinT GROUP number for the MAgnetic space group \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This internal variable characterizes a Shubnikov type III magnetic space group\n(anti-ferromagnetic space group). The user is advised to consult \u201cThe\nmathematical theory of symmetry in solids, Representation theory for point\ngroups and space groups, 1972, C.J. Bradley and A.P. Cracknell, Clarendon\nPress, Oxford.\u201d \nA Shubnikov type III magnetic space group might be defined by its Fedorov\nspace group (set of all spatial symmetries, irrespective of their magnetic\naction), and the halving space group (only the symmetries that do not change\nthe magnetization). \nThe specification of the halving space group might be done by specifying, for\neach point symmetry, the magnetic action. See Table 7.1 of the above-mentioned\nreference. Magnetic point groups are numbered from 1 to 58.  Related input variables :  spgroup ,  spgroupma ,  genafm",
            "title": "ptgroupma"
        },
        {
            "location": "/input_variables/vargeo/#spgaxor",
            "text": "Mnemonics: SPace Group : AXes ORientation \nVariable type: integer \nDimensions: scalar \nDefault value: 1    It is taken into account only when  spgroup /=0; it allows one to define the\naxes orientation for the specific space groups for which this is needed.\nTrigonal groups (number 146,148,155,160,161,166,167):   1 represents the hexagonal axes   2 represents the rhombohedral axes    Orthorhombic space groups : there are six possibilities corresponding to the\npossible axes permutations   1 abc -> abc   2 abc -> cab   3 abc -> bca   4 abc -> acb   5 abc -> bac   6 abc -> cba    Monoclinic : there are 3 or 9 possibilities depending on the space group. See\nthe space group   help file   for\ndetails. In the log/output file the notation used to describe the monoclinic\ngroups is for example: \n15:c1, A2/a_c = C2/c \nwhere,   15 represents the space group number,   c1 the orientation as it appears on the web page,   A is the real Bravais type lattice,   2/a the existent symmetry elements,   _c marks the orientation of the two-fold axis or of the mirror plane,   C2/c represents the parent space group.    How to determine which spgaxor you need:   check the reduced positions you have, for more symmetric positions, e.g. 1/2 1/4 3/4 etc\u2026 Let us say your symmetric positions are in the first coordinate (a axis) and you are using spgroup 62.   look up the raw space group Wyckoff positions on   the Bilbao server   to see where they put the corresponding symmetric positions. For spgroup 62 Bilbao puts the 1/4 3/4 in the second coordinate, ie along the b axis.   in this case you need to swap the axes from the original abc order to a new order where the Bilbao axis (b) is in the first position. In this case you have 2 possibilities, spgaxor 3 or 5. If you have more than one highly symmetric coordinate you may have only a single possibility.",
            "title": "spgaxor"
        },
        {
            "location": "/input_variables/vargeo/#spgorig",
            "text": "Mnemonics: SPace Group : ORIGin \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  spgroup !=0    Gives the choice of origin for the axes system. \nIt is defined according to the origin choice in the International Tables of\nCrystallography. \nIt applies only to the space groups 48, 50, 59, 70, 85, 86, 88, 125, 126, 129,\n130, 133, 134, 137, 141, 142, 201, 203, 222, 224, 227, 228. \nFor details see the space group   help file  .",
            "title": "spgorig"
        },
        {
            "location": "/input_variables/vargeo/#spgroup",
            "text": "Mnemonics: SPace GROUP number \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of the space group. \nIf  spgroup  is 0, the code assumes that all the symmetries are input\nthrough the  symrel  matrices and the  tnons  vectors, or obtained from\nthe symmetry finder (the default when  nsym ==0). \nIt should be between 1 and 230. This option can be used to obtain all the\natoms in the unit cell, starting from the asymmetric unit cell. \nThe references for computing the symmetry corresponding to the space groups\nare :   International Tables for Crystallography, 1983, Ed. Theo Hahn, D. Reidel Publishing Company   The mathematical theory of symmetry in solids, Representation theory for point groups and space groups, 1972, C.J. Bradley and A.P. Cracknell, Clarendon Press, Oxford.    For details see the space group   help file  .",
            "title": "spgroup"
        },
        {
            "location": "/input_variables/vargeo/#spgroupma",
            "text": "Mnemonics: SPace GROUP number defining a MAgnetic space group \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This input variable might be used to define a Shubnikov magnetic space group\n(anti-ferromagnetic space group). The user is advised to consult \u201cThe\nmathematical theory of symmetry in solids, Representation theory for point\ngroups and space groups, 1972, C.J. Bradley and A.P. Cracknell, Clarendon\nPress, Oxford.\u201d \nA Shubnikov type IV magnetic space group might be defined by its Fedorov space\ngroup (set of spatial symmetries that do not change the magnetization), and an\nadditional magnetic space group number  spgroupma . \nA Shubnikov type III magnetic space group might be defined by its Fedorov\nspace group (set of all spatial symmetries, irrespective of their magnetic\naction), and an additional magnetic space group number  spgroupma . \nFor the additional number  spgroupma , we follow the definition of Table 7.4\nof the above-mentioned Bradley and Cracknell textbook. \nThus, one way to specify a Shubnikov IV magnetic space group, is to define\nboth  spgroup  and  spgroupma . \nFor example, the group P2_1/c_prime has  spgroup =14 and  spgroupma =78. \nAlternatively, for Shubnikov IV magnetic groups, one might define  spgroup \nand  genafm . For both the type III and IV, one might define by hand the set\nof symmetries, using  symrel ,  tnons  and  symafm .",
            "title": "spgroupma"
        },
        {
            "location": "/input_variables/vargeo/#tolsym",
            "text": "Mnemonics: TOLERANCE for SYMmetries \nVariable type: real \nDimensions: scalar \nDefault value: 1e-08    Gives the tolerance on the atomic positions (reduced coordinates), primitive\nvectors, or magnetization, to be considered equivalent, thanks to symmetry\noperations. This is used in the recognition of the set of symmetries of the\nsystem, or the application of the symmetry operations to generate from a\nreduced set of atoms, the full set of atoms. Note that a value larger than\n0.01 is considered to be unacceptable. \nNote : ABINIT needs the atomic positions to be symmmetric to each others\nwithin 1.e-8 . If  tolsym  is set to a larger value than 1.e-8, then the\ninput atomic coordinates will be automatically symmetrized by the symmetry\noperations that will have been found.",
            "title": "tolsym"
        },
        {
            "location": "/input_variables/vargeo/#vaclst",
            "text": "Mnemonics: VACancies LiST \nVariable type: integer \nDimensions: ( vacnum ) \nDefault value: None    Gives the identification number(s) of atoms to be subtracted from the set of\natoms that are obtained after having rotated, translated and repeated the\nobjects. \nUseful to created vacancies.",
            "title": "vaclst"
        },
        {
            "location": "/input_variables/vargeo/#vacnum",
            "text": "Mnemonics: VACancies NUMber \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of atoms to be subtracted from the list of atoms after the\nrotations, translations and repetitions have been done. The list of these\natoms is contained in  vaclst .",
            "title": "vacnum"
        },
        {
            "location": "/input_variables/vargeo/#xyzfile",
            "text": "Mnemonics: XYZ FILE input for geometry \nVariable type: string \nDimensions: scalar \nDefault value: None    Gives the name of a xyz format file, to take  natom ,  ntypat ,  typat , znucl , and  xangst  from. This input can not be mixed with normal atom\nspecifications for other datasets.  Notes: do not quote the file name in the abinit input file, simply leave a\nspace after xyzfile. The xyz format is the number of atoms on the first line,\na comment line, then one line per atom, with the element as a 2 letter symbol\n(\u201cAs\u201d \u201cO\u201d or \u201cPu\u201d) and the three cartesian coordinates in Angstrom.",
            "title": "xyzfile"
        },
        {
            "location": "/input_variables/vargs/",
            "text": "algalch\n\u00b6\n\n\nMnemonics: ALGorithm for generating ALCHemical pseudopotentials\n\nVariable type: integer\n\nDimensions: (\nntypalch\n)\n\nDefault value: *1  \n\n\nUsed for the generation of alchemical pseudopotentials, that is, when\n\nntypalch\n is non-zero.\n\n\nGive the algorithm to be used to generate the \nntypalch\n alchemical\npotentials from the different \nnpspalch\n pseudopotentials dedicated to this\nuse.\n\n\nPresently, \nalgalch\n can only have the value 1, that is :\n\n\n\n\nthe local potentials are mixed, thanks to the \nmixalch\n mixing coefficients \n\n\nthe form factors of the non-local projectors are all preserved, and all considered to generate the alchemical potential \n\n\nthe scalar coefficients of the non-local projectors are multiplied by the proportion of the corresponding type of atom that is present in \nmixalch\n \n\n\nthe characteristic radius for the core charge is a linear combination of the characteristic radii of the core charges, build with the \nmixalch\n mixing coefficients \n\n\nthe core charge function f(r/rc) is a linear combination of the core charge functions, build with the \nmixalch\n mixing coefficients \n\n\n\n\nLater, other algorithms for the mixing might be included.\n\n\nNote that alchemical mixing cannot be used with PAW.\n\n\nboxcenter\n\u00b6\n\n\nMnemonics: BOX CENTER\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: [0.5, 0.5, 0.5]  \n\n\nDefines the center of the box, in reduced coordinates. At present, this\ninformation is only used in the case of Time-Dependent DFT computation of the\noscillator strength. One must take boxcenter such as to be roughly the center\nof the cluster or molecule. The default is sensible when the vacuum\nsurrounding the cluster or molecule has xred 0 or 1. On the contrary, when the\ncluster or molecule is close to the origin, it is better to take\n\nboxcenter\n=(0 0 0).\n\n\nboxcutmin\n\u00b6\n\n\nMnemonics: BOX CUT-off MINimum\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 2.0  \n\n\nThe box cut-off ratio is the ratio between the wavefunction plane wave sphere\nradius, and the radius of the sphere that can be inserted in the FFT box, in\nreciprocal space. In order for the density to be exact (in the case of plane\nwave, not PAW), this ratio should be at least two. If one uses a smaller\nratio, one will gain speed, at the expense of accuracy. In case of pure ground\nstate calculation (e.g. for the determination of geometries), this is\nsensible. However, the wavefunctions that are obtained CANNOT be used for\nstarting response function calculation.\n\n\ncharge\n\u00b6\n\n\nMnemonics: CHARGE\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed to establish charge balance between the number of electrons filling the\nbands and the nominal \ncharge\n associated with the atomic cores.\n\nThe code adds up the number of valence electrons provided by the\npseudopotentials of each type (call this \u201czval\u201d), then add \ncharge\n, to get\nthe number of electrons per unit cell, \nnelect\n.\n\nThen, if \niscf\n is positive, the code adds up the band occupancies (given in\narray \nocc\n) for all bands at each k point, then multiplies by the k point\nweight \nwtk\n at each k point. Call this sum \u201cnelect_occ\u201d (for the number of\nelectrons from occupation numbers). It is then required that:\n\nnelect_occ = nelect\n\nTo treat a neutral system, which is desired in nearly all cases, one must use\n\ncharge\n=0. To treat a system missing one electron per unit cell, set\n\ncharge\n=+1.\n\n\nchkexit\n\u00b6\n\n\nMnemonics: CHecK whether the user want to EXIT\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf \nchkexit\n is 1 or 2, ABINIT will check whether the user wants to\ninterrupt the run (using the keyword \u201cexit\u201d on the top of the input file or\ncreating a file named \u201cabinit.exit\u201d: see the \n end of section 3.2\n\n of the\n\nhelp_abinit\n).\n\n\nIf \nchkexit\n=0, the check is not performed at all\n\n\nIf \nchkexit\n=1, the check is not performed frequently (after each SCF step)\n\n\nIf \nchkexit\n=2, the check is performed frequently (after a few bands, at\neach k point)\n\n\nIn all cases, the check is performed at most every 2 seconds of CPU time.\n\n\nchkprim\n\u00b6\n\n\nMnemonics: CHecK whether the cell is PRIMitive\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nIf the symmetry finder is used (see \nnsym\n), a non-zero value of \nchkprim\n\nwill make the code stop if a non-primitive cell is used. If \nchkprim\n=0, a\nwarning is issued, but the run does not stop.\n\n\nIf you are generating the atomic and cell geometry using \nspgroup\n, you\nmight generate a PRIMITIVE cell using \nbrvltt\n=-1 .\n\n\nchksymbreak\n\u00b6\n\n\nMnemonics: CHecK SYMmetry BREAKing\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis variable governs the behaviour of the code when there are potential\nsource of symmetry breaking, related e.g. to the k point grid or the presence\nof non-symmorphic translations which might not be coherent with the exchange-\ncorrelation grid.\n\n\nWhen \nchksymbreak\n=1, the code stops (or issue a warning) if :\n\n\n\n\n(1) The k point grid is non-symmetric, in case \nkptopt\n =1, 2, or 4 ; \n\n\n(2) The non-symmorphic translation part of the symmetry operations has components that are not zero, or simple fractions, with 2, 3, 4, 6, 8 or 12 as denominators. \n\n\n\n\nWhen \nchksymbreak\n is zero, there is no such check.\n\nWhen \nchksymbreak\n is minus 1, the code stops if the condition (1) is met,\nbut in case the condition (2) is met, there will be a trial to shift the\natomic coordinates such as to obtain symmetry operations with the adequate\nnon-symmorphic part.\n\n\nExplanation :\n\nIn the ground-state calculation, such breaking of the symmetry is usually\nharmless. However, if the user is doing a calculation of phonons using DFPT\n(\nrfphon\n=1), the convergence with respect to the number of k points will be\nmuch worse with a non-symmetric grid than with a symmetric one. Also, if the\nuser is doing a \nGW\n calculation, the presence of non-symmorphic\ntranslations that are not coherent with the FFT grid might cause problems. In\nthe \nGW\n part, indeed, one needs to reconstruct the wavefunctions in the\nfull Brillouin zone for calculating both the polarizability and the self-\nenergy. The wavefunctions in the full Brillouin zone are obtained from the\nirreducible wedge by applying the symmetry operations of the space group of\nthe crystal. In the present implementation, the symmetrization of the\nwavefunctions is done in real space on the FFT mesh that, therefore, has to be\ncoherent both with the rotational part as well as with the fractional\ntranslation of each symmetry operation. If the condition (2) is met, the\n\nGW\n code will not be able to find a symmetry-preserving FFT mesh.\n\nSo, it was decided to warn the user about these possible problems already at\nthe level of the ground state calculations, although such warning might be\nirrelevant.\n\nIf you encounter a problem outlined above, you have two choices : change your\natomic positions (translate them) such that the origin appears as the most\nsymmetric point ; or ignore the problem, and set \nchksymbreak\n=0 .\n\n\ncpuh\n\u00b6\n\n\nMnemonics: CPU time limit in Hours\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nThe use of this variable forbids the use of specified(\ncpum\n) or specified(\ncpus\n)  \n\n\nOnly one of the three real parameters \ncpus\n, \ncpum\n and \ncpuh\n can be\ndefined in the input file to set up a CPU time limit. When the job reaches\nthat limit, it will try to end smoothly. However, note that this might still\ntake some time. If the user want a firm CPU time limit, the present parameter\nmust be reduced sufficiently. Intuition about the actual margin to be taken\ninto account should come with experience \u2026\n\nA zero value has no action of the job.\n\n\ncpum\n\u00b6\n\n\nMnemonics: CPU time limit in Minutes\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nThe use of this variable forbids the use of specified(\ncpum\n) or specified(\ncpus\n)  \n\n\nOnly one of the three real parameters \ncpus\n, \ncpum\n and \ncpuh\n can be\ndefined in the input file to set up a CPU time limit. When the job reaches\nthat limit, it will try to end smoothly. However, note that this might still\ntake some time. If the user want a firm CPU time limit, the present parameter\nmust be reduced sufficiently. Intuition about the actual margin to be taken\ninto account should come with experience \u2026\n\nA zero value has no action of the job.\n\n\ncpus\n\u00b6\n\n\nMnemonics: CPU time limit in seconds\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nThe use of this variable forbids the use of specified(\ncpum\n) or specified(\ncpus\n)  \n\n\nOnly one of the three real parameters \ncpus\n, \ncpum\n and \ncpuh\n can be\ndefined in the input file to set up a CPU time limit. When the job reaches\nthat limit, it will try to end smoothly. However, note that this might still\ntake some time. If the user want a firm CPU time limit, the present parameter\nmust be reduced sufficiently. Intuition about the actual margin to be taken\ninto account should come with experience \u2026\n\nA zero value has no action of the job.\n\n\ndiecut\n\u00b6\n\n\nMnemonics: DIElectric matrix energy CUToff\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 2.2  \n\n\nKinetic energy cutoff that controls the number of planewaves used to represent\nthe dielectric matrix:\n\n(1/2)[(2 Pi)*(Gmax)]  2  =\necut\n for Gmax.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \ndiecut\n has\nthe \u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV)\n\nAll planewaves inside this \u201cbasis sphere\u201d centered at G=0 are included in the\nbasis. This is useful only when \niprcel\n>=21, which means that a\npreconditioning scheme based on the dielectric matrix is used.\n\nNOTE : a negative \ndiecut\n will define the same dielectric basis sphere as\nthe corresponding positive value, but the FFT grid will be identical to the\none used for the wavefunctions. The much smaller FFT grid, used when\n\ndiecut\n is positive, gives exactly the same results.\n\nNo meaning for RF calculations yet.\n\n\ndiegap\n\u00b6\n\n\nMnemonics: DIElectric matrix GAP\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.1  \n\n\nGives a rough estimation of the dielectric gap between the highest energy\nlevel computed in the run, and the set of bands not represented. Used to\nextrapolate dielectric matrix when \niprcel\n >= 21.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \ndiegap\n has\nthe \u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV)\n\nNo meaning for RF calculations yet.\n\n\ndielam\n\u00b6\n\n\nMnemonics: DIElectric matrix LAMbda\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.5\n\nOnly relevant if \niprcel\n >= 21  \n\n\nGives the amount of occupied states with mean energy given by the highest\nlevel computed in the run, included in the extrapolation of the dielectric\nmatrix.\n\nNo meaning for RF calculations yet.\n\n\ndielng\n\u00b6\n\n\nMnemonics: model DIElectric screening LeNGth\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0774841d0  \n\n\nUsed for screening length (in Bohr) of the model dielectric function, diagonal\nin reciprocal space. By default, given in Bohr atomic units (1\nBohr=0.5291772108 Angstrom), although Angstrom can be specified, if preferred,\nsince \ndielng\n has the \u2018\nLENGTH\n\u2018 characteristics.\n\nThis model dielectric function is as follows (K being a wavevector) :\n\n\n         (     1        +     [[dielng]]2* K2   )\ndiel(K)= ------------------------------------\n         ( 1/[[diemac]] + [[dielng]]2 * K2 ) * [[diemix]]\n\n\n\n\n\nThe inverse of this model dielectric function will be applied to the residual,\nto give the preconditioned change of potential. Right at K=0, diel(K) is\nimposed to be 1.\n\n\nIf the preconditioning were perfect, the change of potential would lead to an\nexceedingly fast solution of the self-consistency problem (two or three\nsteps). The present model dielectric function is excellent for rather\nhomogeneous unit cells.\n\nWhen K->0 , it tends to the macroscopic dielectric constant, eventually\ndivided by the mixing factor \ndiemix\n (or \ndiemixmag\n  for magnetization).\n\nFor metals, simply put \ndiemac\n to a very large value (10^6 is OK)\n\nThe screening length \ndielng\n governs the length scale to go from the\nmacroscopic regime to the microscopic regime, where it is known that the\ndielectric function should tend to 1. It is on the order of 1 Bohr for metals\nwith medium density of states at the Fermi level, like Molybdenum, and for\nSilicon. For metals with a larger DOS at the Fermi level (like Iron), the\nscreening will be more effective, so that \ndielng\n has to be decreased by a\nfactor of 2-4.\n\nThis works for GS and RF calculations.\n\n\ndiemac\n\u00b6\n\n\nMnemonics: model DIElectric MACroscopic constant\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1000000.0  \n\n\nA rough knowledge of the macroscopic dielectric constant \ndiemac\n of the\nsystem is a useful help to speed-up the SCF procedure: a model dielectric\nfunction, see the keyword \ndielng\n, is used for that purpose. It is\nespecially useful for speeding up the treatment of rather homogeneous unit\ncells.\n\n\nSome hint :\n\nThe value of \ndiemac\n should usually be bigger than 1.0d0, on physical\ngrounds.\n\nFor metals, simply put \ndiemac\n to a very large value (the default 10  6  is\nOK)\n\nFor silicon, use 12.0 . A similar value is likely to work well for other\nsemiconductors\n\nFor wider gap insulators, use 2.0 \u2026 4.0\n\nFor molecules in an otherwise empty big box, try 1.5 \u2026 3.0\n\nSystems that combine a highly polarisable part and some vacuum are rather\nbadly treated by the model dielectric function. One has to use the\n\u201cextrapolar\u201d technique, activated by the input variable \niprcel\n.\n\nIn sufficiently homogeneous systems, you might have to experiment a bit to\nfind the best \ndiemac\n. If you let \ndiemac\n to its default value, you\nmight even never obtain the self-consistent convergence !\n\nFor response function calculations, use the same values as for GS. The\nimprovement in speed can be considerable for small (but non-zero) values of\nthe wavevector.\n\n\ndiemix\n\u00b6\n\n\nMnemonics: model DIElectric MIXing factor\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0 if \nusepaw\n==0 or \niprcel\n !=0,\n0.7 if \nusepaw\n==1 or \niprcel\n==0,\nNone otherwise.\n\n\nOnly relevant if \ndiemix\n >= 0.0 and \ndiemix\n <=  1.0  \n\n\nGives overall factor of the preconditioned residual density/potential to be\ntransferred in the SCF cycle.\n\nIt should be between 0.0 and 1.0 .\n\nIf the model dielectric function were perfect, \ndiemix\n should be 1.0 . By\ncontrast, if the model dielectric function does nothing (when \ndiemac\n=1.0d0\nor \ndielng\n is larger than the size of the cell), \ndiemix\n can be used to\ndamp the amplifying factor inherent to the SCF loop.\n\nFor molecules, a value on the order 0.5 or 0.33 is rather usual.\n\nWhen mod(\niscf\n,10)=3, 4 ,5 or 7, \ndiemix\n is only important at the few\nfirst iterations when anharmonic effects are important, since these schemes\ncompute their own mixing factor for self-consistency.\n\nAlso note that a different value of diemix can be used for the magnetization\n(see \ndiemixmag\n).\n\n\ndiemixmag\n\u00b6\n\n\nMnemonics: model DIElectric MIXing factor for the MAGgnetization\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: \ndiemix\n if 70 < \niprcel\n and \niprcel\n < 80,\n\ndiemix\n if \niprcel\n==0,\n\ndiemix\n if \niscf\n<10,\n-\ndiemix\n otherwise.\n\n\nGives overall factor of the preconditioned residual magnetization/magnetic\nfield to be transferred in the SCF cycle (see \ndiemix\n for further\ninformation).\n\nFor the time being, apply only when the SCF mixing is done on the density\n(\niscf\n>=10).  \n\n\nA negative value of diemixmag means that magnetization is only preconditionned\nby ABS(diemixmag), without the use of any preconditionner.  \n\n\nWhen SCF cycle has some difficulties to converge, changing the value of\n\ndiemixmag\n can have a positive effect.\n\nIn particular \ndiemixmag\n=-4 is a good choice (i.e. diemixmag=4, no other\npreconditionner on magnetization).\n\n\ndosdeltae\n\u00b6\n\n\nMnemonics: DOS DELTA in Energy\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nDefines the linear grid resolution (energy increment) to be used for the\ncomputation of the Density-Of-States, when \nprtdos\n is non-zero.\n\nIf \ndosdeltae\n is set to zero (the default value), the actual increment is\n0.001 Ha if \nprtdos\n=1, and the much smaller value 0.00005 Ha if\n\nprtdos\n=2. This different default value arises because the \nprtdos\n=1\ncase, based on a smearing technique, gives a quite smooth DOS, while the DOS\nfrom the tetrahedron method, \nprtdos\n=2, is rapidly varying.\n\n\nenunit\n\u00b6\n\n\nMnemonics: ENergy UNITs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGoverns the units to be used for output of eigenvalues (and eventual phonon\nfrequencies)\n\n\n\n\n0=>print eigenvalues in hartree; \n\n\n1=>print eigenvalues in eV; \n\n\n2=>print eigenvalues in both hartree and eV. \n\n\n\n\nIf phonon frequencies are to be computed :\n\n\n\n\n0=> phonon frequencies in Hartree and cm-1; \n\n\n1=> phonon frequencies in eV and THz; \n\n\n2=> phonon frequencies in hartree, eV, cm-1, Thz and Kelvin. \n\n\n\n\nfband\n\u00b6\n\n\nMnemonics: Factor for the number of BANDs\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.125 if \noccopt\n==1,\n0.5 if \noccopt\n>2,\n0.0 if \nusewvl\n==1,\n0.0 otherwise.\n\n\nGoverns the number of bands to be used in the code in the case the parameter\n\nnband\n is not defined in the input file (which means that \noccopt\n is not\nequal to 0 or 2).\n\n\nIn case \nfband\n is 0.0d0, the code computes from the pseudopotential files\nand the geometry data contained in the input file, the number of electrons\npresent in the system. Then, it computes the minimum number of bands that can\naccommodate them, and use that value for \nnband\n.\n\nIn case \nfband\n differs from zero, other bands will be added, just larger\nthan \nfband\n times the number of atoms. This parameter is not echoed in the\ntop of the main output file, but only the parameter \nnband\n that it allowed\nto compute. It is also not present in the dtset array (no internal).\n\nThe default values are chosen such as to give naturally some conduction bands.\nThis improves the robustness of the code, since this allows to identify lack\nof convergence coming from (near-)degeneracies at the Fermi level. In the\nmetallic case, the number of bands generated might be too small if the\nsmearing factor is large. The occupation numbers of the higher bands should be\nsmall enough such as to neglect higher bands. It is difficult to automate\nthis, so a fixed default value has been chosen.\n\n\niatsph\n\u00b6\n\n\nMnemonics: Index for the ATomic SPHeres of the atom-projected density-of-states\n\nVariable type: integer\n\nDimensions: (\nnatsph\n)\n\nDefault value: [1 .. \nnatsph\n]\n\nOnly relevant if \nprtdos\n == 3 or \npawfatbnd\n in [1,2]  \n\n\niatsph\n gives the number of the \nnatsph\n atoms around which the sphere\nfor atom-projected density-of-states will be build, in the \nprtdos\n=3 case.\nThe radius of these spheres is given by \nratsph\n.\n\nIf \npawfatbnd\n=1 or 2, it gives the number of the \nnatsph\n atoms around\nwhich atom-projected band structure will be built.\n\n\nicoulomb\n\u00b6\n\n\nMnemonics: Index for the Coulomb TReaTMenT\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nDefines the type of computation used for Hartree potential, local part of\npseudo-potential and ion-ion interaction:\n\n\n\n\nicoulomb\n=0 : usual reciprocal space computation, using 1 / g^2 for the Hartree potential and using Ewald correction. \n\n\nicoulomb\n=1 : free boundary conditions are used when the Hartree potential is computed, real space expressions of pseudo-potentials are involved (restricted to GTH pseudo-potentials) and simple coulomb interaction gives the ion-ion energy. \n\n\n\n\niprcel\n\u00b6\n\n\nMnemonics: Integer for PReConditioning of ELectron response\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed when \niscf\n>0, to define the SCF preconditioning scheme. Potential-\nbased preconditioning schemes for the SCF loop (electronic part) are still a\nsubject of active research. The present parameter (electronic part) describes\nthe way the change of potential is derived from the residual.\n\nThe possible values of \niprcel\n correspond to :\n\n\n\n\n0 => model dielectric function described by \ndiemac\n, \ndielng\n and \ndiemix\n. \n\n\nlarger or equal to 21 => will compute the dielectric matrix according to \ndiecut\n, \ndielam\n, \ndiegap\n. This methodology is described in P.-M. Anglade, X. Gonze, Phys. Rev. B 78, 045126 (2008). \n\n\nBetween 21 and 29 => for the first few steps uses the same as option 0 then compute RPA dielectric function, and use it as such. \n\n\nBetween 31 and 39 => for the first few steps uses the same as option 0 then compute RPA dielectric function, and use it, with the mixing factor \ndiemix\n. \n\n\nBetween 41 and 49 => compute the RPA dielectric matrix at the first step, and recompute it at a later step, and take into account the mixing factor \ndiemix\n. \n\n\nBetween 51 and 59 => same as between 41 and 49, but compute the RPA dielectric matrix by another mean \n\n\nBetween 61 and 69 => same as between 41 and 49, but compute the electronic dielectric matrix instead of the RPA one. \n\n\nBetween 71 and 78 => STILL UNDER DEVELOPMENT \u2013 NOT USABLE ; Use the modified Kerker preconditioner with a real-space formulation (basic formulation is shown at \ndielng\n). The dielectric matrix is approximated thanks to \ndiemac\n and \ndielng\n. Note that \ndiemix\n is also used. \n\n\n79 => STILL UNDER DEVELOPMENT \u2013 NOT USABLE ; same as previous but with an alternate algorithm. \n\n\n141 to 169 => same as Between 41 and 69 (but, the dielectric matrix is also recomputed every iprcel modulo 10 step). \n\n\n\n\nThe computation of the dielectric matrix (for 0 [100]< \niprcel\n < 70\n[100]) is based on the \n extrapolar \n approximation. This approximation can\nbe tuned with \ndiecut\n, \ndielam\n, and \ndiegap\n. Yet its accuracy mainly\ndepends on the number of conduction bands included in the system. Having 2 to\n10 empty bands in the calculation is usually enough (use \nnband\n).  \n\n\nNOTES:\n\n\n\n\nThe step at which the dielectric matrix is computed or recomputed is determined by modulo(\niprcel\n,10). The recomputation happens just once in the calculation for \niprcel\n < 100. \n\n\nFor non-homogeneous relatively large cells \niprcel\n=45 will likely give a large improvement over \niprcel\n=0. \n\n\nIn case of PAW and \niprcel\n>0, see \npawsushat\n input variable. By default, an approximation (which can be suppressed) is done for the computation of susceptibility matrix. \n\n\nFor extremely large inhomogeneous cells where computation of the full dielectric matrix takes too many weeks, 70 < \niprcel\n < 80 is advised. \n\n\nFor \nnsppol\n=2 or \nnspinor\n=2 with metallic \noccopt\n, only \n mod(iprcel,100) \n <50 is allowed. \n\n\nNo meaning for RF calculations yet. \n\n\nThe exchange term in the full dielectric matrix diverges for vanishing densities. Therefore the values of \niprcel\n beyond 60 must not be used for cells containing vacuum, unless ones computes this matrix for every step (\niprcel\n=161). \n\n\n\n\niqpt\n\u00b6\n\n\nMnemonics: Index for QPoinT generation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nOnly used if \nnqpt\n=1, and \nqptopt\n=1 to 4.\n\n\nDefines the index of the Q point to be selected in the list of q points\ngenerated by \nngqpt\n, \nqptrlatt\n, \nnshiftq\n, and \nshiftq\n.\n\n\nIf \niqpt\n=0, then the q point is Gamma (0 0 0).\n\n\nThe usual working mode is to define a series of values for \niqpt\n, starting\nwith \niqpt\n=0 or 1 (so through the definition of \n iqpt: \n ), and\nincreasing it by one for each dataset (thanks to \n iqpt+ \n ).\n\n\nixcpositron\n\u00b6\n\n\nMnemonics: Integer for the eXchange-Correlation applied to the electron-POSITRON interaction\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nComment: (Teter parameterization). However, if all the pseudopotentials have the same value of pspxc, the initial value of ixc will be that common value  \n\n\nRelevant only when \npositron\n/=0.\n\nDefine the type of electron-positron correlation that is used in case of a\nelectron-positron two-component DFT calculation.\n\nDefine also the analytical formula of the enhancement factor used to compute\nthe electron-positron annhilation rate:  \n\n\nElectron-positron correlation functional:  \n\n\n ixcpositron=1 \n : LDA zero positron density limit parametrized by Arponen & Pajanne and provided by Boronski & Nieminen [1,2] \n\n\n ixcpositron=11 \n : LDA zero positron density limit parametrized by Arponen & Pajanne and fitted by Sterne & Kaiser [1,3] \n\n\n ixcpositron=2 \n : LDA electron-positron correlation provided by Puska, Seitsonen, and Nieminen [1,4] \n\n\n ixcpositron=3 \n : GGA zero positron density limit parametrized by Arponen & Pajanne and provided by Boronski & Nieminen [1,2,5] \n\n\n ixcpositron=31 \n : GGA zero positron density limit parametrized by Arponen & Pajanne and fitted by Sterne & Kaiser [1,3,5] \nAnnihilation rate enhancement factor:  \n\n\n ixcpositron=1 \n : Boronski and Nieminen full modelisation and RPA limit [1] \n\n\n ixcpositron=11 \n : Sterne and Kaiser [2] \n\n\n ixcpositron=2 \n : Puska, Seitsonen and Nieminen [3] \n\n\n ixcpositron=3 \n : Boronski and Nieminen full modelisation and RPA limit [1], with GGA corrections \n\n\n ixcpositron=31 \n : Sterne and Kaiser [2], with GGA corrections   \n\n\nReferences:  \n [1] \n J. Arponen and E. Pajanne, Ann. Phys. (N.Y.) 121, 343\n(1979).\n\n\n [2] \n Boronski and R.M. Nieminen, Phys. Rev. B 34, 3820 (1986). \n\n\n [3] \n P.A. Sterne and J.H. Kaiser, Phys. Rev. B 43, 13892 (1991). \n\n\n [4] \n M.J. Puska, A.P. Seitsonen and R.M. Nieminen, Phys. Rev. B 52, 10947 (1994). \n\n\n [5] \n B. Barbiellini, M.J. Puska, T. Torsti and R.M.Nieminen, Phys. Rev. B 51, 7341 (1994)   \n\n\njellslab\n\u00b6\n\n\nMnemonics: include a JELLium SLAB in the cell\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1, a slab of uniform positive background charge density, that is, a\njellium slab, is included in the calculation cell. A portion of the unit cell\nis filled with such positive charge density distribution which is equal to a\nbulk-mean value n  bulk  between two edges and zero in the vacuum region if\npresent.\n\nFor the sake of convenience the unit cell is supposed to have the third\ncrystal primitive lattice vector orthogonal to the other ones so that the\nportion of the cell filled by the jellium slab can be defined through its\nedges along z.\n\nThe bulk-mean positive charge density is fixed by the input variable\n\nslabwsrad\n, while the position of the slab edges along z is defined through\nthe input variables \nslabzbeg\n and \nslabzend\n.\n\n\nkptbounds\n\u00b6\n\n\nMnemonics: K PoinT BOUNDarieS\n\nVariable type: real\n\nDimensions: (3,abs(\nkptopt\n)+1))\n\nDefault value: None  \n\n\nIt is used to generate the circuit to be followed by the band structure, when\n\nkptopt\n is negative (it is not read if \nkptopt\n is zero or positive).\n\n\nThere are abs(\nkptopt\n) segments to be defined, each of which starting from\nthe end point of the preceeding one. Thus, the number of points to be input is\nabs(\nkptopt\n)+1. They form a circuit starting at\n\n[kptbounds]\n/\nkptnrm\n and ending at\n\n[kptbounds]\n/\nkptnrm\n. The number of divisions of\neach segment can be defined either using the array \nndivk\n or the variable\n\nndivsm\n that just defines the number of divisions for the smallest segment\n\n\nAs for \nkpt\n, \nkptbounds\n is specified using the primitive vectors in\nreciprocal space. If your Bravais lattice is simple, then it should be quite\neasy to find the coordinates of the end points. On the other hand, for\ncentered, body-centered, face-centered, hexagonal, and rhombohedral Bravais\nlattice, the conversion might be more difficult. See the description of\n\nkpt\n for an explanation of how to convert data from the \u201cconventional\u201d\ncartesian coordinates to the primitive vectors in the reciprocal space. In\norder to help a bit, we list below a series of typical values, for the FCC,\nBCC, hexagonal and rhombohedral Bravais lattices. Note : all the data below\nare given in dimensionless units ; they have to be rescaled by the actual\nlengths defined by the \nacell\n values. However, \nkptbounds\n values can be\nused as such, if the values of \nrprim\n given below are adopted.\n\n\nA. \n FCC lattice \n\n\nSuppose the primitive vectors in real space are given by  \n\n\n  rprim   0 1 1    1 0 1    1 1 0\n\n\n\n\n\nor\n\n\n  rprim   0 1/2 1/2    1/2 0 1/2    1/2 1/2 0\n\n\n\n\n\n(these two possibilities only differ by a scaling factor, irrelevant for the\ndefinition of the k points in the primitive vectors in reciprocal space).\nThen, the reciprocal primitive vectors (in conventional cartesian coordinates)\nare\n\n\n  (-1/2 1/2 1/2), (1/2 -1/2 1/2), (1/2 1/2 -1/2)\n\n\n\n\n\nor\n\n\n  (-1 1 1), (1 -1 1), (1 1 -1)\n\n\n\n\n\nand, in both cases, the coordinates of several special points with respect to\nprimitive vectors in reciprocal space are\n\n\n  X (0   1/2 1/2)   (conventional cartesian coordinate 1/2 0 0)\n  X'(1/2 1/2 1  )   (conventional cartesian coordinate 1/2 1/2 0)  (an other instance of X, in another Brillouin zone)\n  L (1/2 1/2 1/2)   (conventional cartesian coordinate  1/4 1/4 1/4)\n  L'(1/2 0   0  )   (conventional cartesian coordinate -1/4 1/4 1/4) (an other instance of L, on another face of the BZ)\n  W (1/4 1/2 3/4)   (conventional cartesian coordinate 1/2 1/4 0)\n  U (1/4 5/8 5/8)   (conventional cartesian coordinate 1/2 1/8 1/8)\n  K (3/8 3/8 3/4)   (conventional cartesian coordinate 3/8 3/8 0)\n\n\n\n\n\nNote that K is actually equivalent to U, by spatial and translational\nsymmetry. So, if you want to specify a typical circuit, the following might do\nthe work : L-Gamma-X-W-K,U-L-W-X-K,U-Gamma with  \n\n\n  kptbounds  1/2 0 0  0 0 0  0 1/2 1/2  1/4 1/2 3/4  3/8 3/8 3/4  1/2 1/2 1/2  1/4 1/2 3/4  1/2 1/2 1  3/8 3/8 3/4  0 0 0\n\n\n\n\n\nThe lengths of segments (this information is useful to draw the band\nstructure, with the correct relative scale between special points) can be\nfound using the conventional cartesian coordinates :\nl(L-Gamma)=sqrt(3)/4=0.433\u2026 ; l(Gamma-X)=1/2=0.5 ; l(X-W)=1/4=0.25 ;\nl(W-K)=sqrt(2)/8=0.177\u2026 ; l(K-L)=sqrt(6)/8=0.306\u2026 ;\nl(L-W)=sqrt(2)/4=0.354\u2026 ; l(W-X)=1/4=0.25 ; l(X-K)=sqrt(2)/8=0.177\u2026 ;\nl(K-Gamma)=sqrt(2).3/8=0.530\u2026\n\n\nB. \n BCC lattice \n\n\nSuppose the primitive vectors in real space are given by  \n\n\n  rprim  -1 1 1    1 -1 1    1 1 -1\n\n\n\n\n\n(as for the FCC lattice, there is a scale invariance). Then, the reciprocal\nprimitive vectors (in conventional cartesian coordinates) are (0 1/2 1/2),\n(1/2 0 1/2), and (1/2 1/2 0) and the coordinates of several special points\nwith respect to primitive vectors in reciprocal space are\n\n\n  H (-1/2 1/2 1/2)   (conventional cartesian coordinate 1/2 0 0)\n  N ( 0   0   1/2)   (conventional cartesian coordinate 1/4 1/4 0)\n  P ( 1/4 1/4 1/4)   (conventional cartesian coordinate 1/4 1/4 1/4)\n\n\n\n\n\n\n\nSo, if you want to specify a typical circuit, the following might do the work\n\n\n\n\nGamma-H-N-Gamma-P-N-P-H  \n\n\nkptbounds  0 0 0  -1/2 1/2 1/2  0 0 1/2  0 0 0   1/4 1/4 1/4  0 0 1/2  1/4 1/4 1/4  -1/2 1/2 1/2\n\n\n\n\n\n\nThe lengths of segments (this information is useful to draw the band\nstructure, with the correct relative scale between special points) can be\nfound using the conventional cartesian coordinates : l(Gamma-H)=1/2=0.5 ;\nl(H-N)=sqrt(2)/4=0.354\u2026 ; l(N-Gamma)=sqrt(2)/4=0.354\u2026 ;\nl(Gamma-P)=sqrt(3)/4=0.433\u2026 ; l(P-N)=1/4=0.25 ; l(N-P)=1/4=0.25 ;\nl(P-H)=sqrt(3)/4=0.433\u2026\n\n\nC. \n Hexagonal lattices \n\n\nSuppose the primitive vectors in real space are given by  \n\n\n  rprim  1 0 0    -1/2 sqrt(0.75) 0    0 0 1\n\n\n\n\n\nThe coordinates of several special points with respect to primitive vectors in\nreciprocal space are\n\n\n  M (1/2 0 0) or (0 1/2 0) or (-1/2 1/2 0)\n  L (1/2 0 1/2) or (0 1/2 1/2) or (-1/2 1/2 1/2)\n  K (1/3 1/3 0) or (2/3 -1/3 0) or (-1/3 2/3 0)\n  H (1/3 1/3 1/2) or (2/3 -1/3 1/2) or (-1/3 2/3 1/2)\n  A (0 0 1/2)\n\n\n\n\n\n\n\nSo, if you want to specify a typical circuit, the following might do the work\n\n\n\n\nK-Gamma-M-K-H-A-L-H-L-M-Gamma-A  \n\n\nkptbounds  1/3 1/3 0  0 0 0  1/2 0 0  1/3 1/3 0  1/3 1/3 1/2  0 0 1/2  1/2 0 1/2  1/3 1/3 1/2  1/2 0 1/2  1/2 0 0  0 0 0  0 0 1/2\n\n\n\n\n\n\nIn order to find the lengths of segments (this information is useful to draw\nthe band structure, with the correct relative scale between special points)\none needs to know the a and c lattice parameters. Also, in what follows, we\nomit the 2\npi factor sometimes present in the definition of the reciprocal\nspace vectors. The reciprocal vectors are (1/a 1/(sqrt(3)\na) 0) , (0\n2/(sqrt(3)\na) 0), (0 0 1/c). The lengths of the above-mentioned segments can\nbe computed as : l(K-Gamma)=2/(3\na)=0.666\u2026/a ;\nl(Gamma-M)=1/(sqrt(3)\na)=0.577\u2026/a ; l(M-K)=1/(3\na)=0.333\u2026/a ;\nl(K-H)=1/(2\nc)=0.5\u2026/c ; l(H-A)=2/(3\na)=0.666\u2026/a ;\nl(A-L)=1/(sqrt(3)\na)=0.577\u2026/a ; l(L-H)=1/(3\na)=0.333\u2026/a ;\nl(H-L)=1/(3\na)=0.333\u2026/a ; l(L-M)=1/(2\nc)=0.5\u2026/c ;\nl(M-Gamma)=-1/(sqrt(3)\na)=0.577\u2026/a ; l(Gamma-A)=1/(2\nc)=0.5\u2026/c\n\n\nD. \n Rhombohedral lattices \n\n\nRhombohedral lattices are characterised by two parameters, the length of the\nprimitive vectors, that we will denote a0, and the angle they form, alpha.\nThese can be directly input of ABINIT, as \nacell\n and \nangdeg\n\n\nThis will generate the primitive vectors in real space , with\n\n\n  [[acell]] a0 a0 a0    and      [[rprim]]  a 0 c    -a/2 a*sqrt(0.75) c    -a/2 -a*sqrt(0.75) c\n\n\n\n\n\nwith a^2+c^2=1, a^2=(1-cos(alpha))\n2/3, c^2=(1+2\ncos(alpha))\n1/3,\n(a/c)^2=2\n(1-cos(alpha))/(1+2*cos(alpha)) and also\ncos(alpha)=(1-(a/c)^2/2)/(1+(a/c)^2). Alternatively, these values of rprim\nmight directly be the input of ABINIT (then, the balance of the scaling factor\nmight be adjusted between \nacell\n and \nrprim\n).\n\n\nUnlike for the simple cubic, FCC, BCC, hexagonal (and some other) Bravais\nlattice, the topology of the Brillouin zone will depend on the alpha (or a/c)\nvalue. We give below information concerning the case when cos(alpha) is\npositive, that is, (a/c)^2 lower than 2.\n\n\nThe coordinates of several special points with respect to primitive vectors in\nreciprocal space will not depend on the a/c ratio, but some others will depend\non it. So, some care has to be exercised. Notations for the Brillouin Zone\nspecial points are the same as in Phys. Rev. B 41, 11827 (1990).\n\n\n  L (1/2 0 0) or (0 1/2 0) or (0 0 1/2) (or with negative signs)\n  T (1/2 1/2 1/2)\n  X (1/2 1/2 0) or (1/2 0 1/2) or (0 1/2 1/2) (or with separate negative signs)\n  W (5/6 - (a/c)^2/6 , 1/2 , 1/6 + (a/c)^2/6 ) = (1 0 -1)*(1-(a/c)^2/2)/3 + (1 1 1)/2\n  U ( (1+(a/c)^2)/6 , (8-(a/c)^2)/12 , (8-(a/c)^2)/12 ) = (-1 1/2 1/2)*(1-(a/c)^2/2)/3 + (1 1 1)/2\n  K (1 0 -1)*(1+(a/c)^2/4)/3\n\n\n\n\n\nSo, if you want to specify a typical circuit, the following might do the work\n(the representative points on lines of symmetry are indicated - there are\nsometimes more than one way to go from one point to another) : X-V-K-Sigma-\nGamma-Lambda-T-Q-W-Y-L-sigma-Gamma-sigma-X . The suggestion is to sample this\npath with the following coordinates for the special points X, Gamma, T, L,\nGamma, X :  \n\n\n  kptbounds  1/2 0 -1/2   0 0 0    1/2 1/2 1/2  1 1/2 0   1 0 0  1 1/2 1/2\n\n\n\n\n\nIn order to find the lengths of segments (this information is useful to draw\nthe band structure, with the correct relative scale between special points)\none needs to know the a and c lattice parameters. Also, in what follows, we\nomit the 2\npi factor sometimes present in the definition of the reciprocal\nspace vectors. The reciprocal vectors are (2/(3\na) 0 1/(3\nc)) , -(1/(3\na)\n1/(sqrt(3)\na) 1/(3\nc), -(1/(3\na) -1/(sqrt(3)\na) 1/(3\nc) ). The lengths of the\nabove-mentioned segments can be computed as :\nl(X-Gamma)=2/(sqrt(3)\na)=1.155\u2026/a , with\nl(K-Gamma)=(1+(a/c)^2/4)\n4/(3\nsqrt(3)\na); l(Gamma-T)=1/(2\nc) ;\nl(T-L)=2/(sqrt(3)\na)=1.155\u2026/a , with l(T-W)=(1-(a/c)^2/2)\n4/(3\nsqrt(3)\na);\nl(L-Gamma)=sqrt(4/(a^2)+1/(c^2))/3 l(Gamma-X)=sqrt(1/(a^2)+1/(c^2))*2/3\n\n\nkptrlatt\n\u00b6\n\n\nMnemonics: K - PoinTs grid : Real space LATTice\n\nVariable type: integer\n\nDimensions: (3,3)\n\nDefault value: *0\n\nThe use of this variable forbids the use of specified(\nngkpt\n)  \n\n\nThis input variable is used only when \nkptopt\n is positive. It partially\ndefines the k point grid. The other piece of information is contained in\n\nshiftk\n. \nkptrlatt\n cannot be used together with \nngkpt\n.\n\n\nThe values kptrlatt(1:3,1), kptrlatt(1:3,2), kptrlatt(1:3,3) are the\ncoordinates of three vectors in real space, expressed in the \nrprimd\n\ncoordinate system (reduced coordinates). They defines a super-lattice in real\nspace. The k point lattice is the reciprocal of this super-lattice, possibly\nshifted (see \nshiftk\n).\n\n\nIf neither \nngkpt\n nor \nkptrlatt\n are defined, ABINIT will automatically\ngenerate a set of k point grids, and select the best combination of\n\nkptrlatt\n and \nshiftk\n that allows to reach a sufficient value of\n\nkptrlen\n. See this latter variable for a complete description of this\nprocedure.\n\n\nkptrlen\n\u00b6\n\n\nMnemonics: K - PoinTs grid : Real space LENgth\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 30.0  \n\n\nThis input variable is used only when \nkptopt\n is positive and non-zero.\n\n\nPreliminary explanation :\n\nThe k point lattice defined by \nngkpt\n or \nkptrlatt\n is used to perform\nintegrations of periodic quantities in the Brillouin Zone, like the density or\nthe kinetic energy. One can relate the error made by replacing the continuous\nintegral by a sum over k point lattice to the Fourier transform of the\nperiodic quantity. Erroneous contributions will appear only for the vectors in\nreal space that belong to the reciprocal of the k point lattice, except the\norigin. Moreover, the expected size of these contributions usually decreases\nexponentially with the distance. So, the length of the smallest of these real\nspace vectors is a measure of the accuracy of the k point grid.\n\n\nWhen either \nngkpt\n or \nkptrlatt\n is defined, \nkptrlen\n is not used as\nan input variable, but the length of the smallest vector will be placed in\nthis variable, and echoed in the output file.\n\n\nOn the other hand, when neither \nngkpt\n nor \nkptrlatt\n are defined, ABINIT\nwill automatically generate a large set of possible k point grids, and select\namong this set, the grids that give a length of smallest vector LARGER than\n\nkptrlen\n, and among these grids, the one that, when used with \nkptopt\n=1,\nreduces to the smallest number of k points. Note that this procedure can be\ntime-consuming. It is worth doing it once for a given unit cell and set of\nsymmetries, but not use this procedure by default. The best is then to set\n\nprtkpt\n=1, in order to get a detailed analysis of the set of grids.\n\n\nIf some layer of vacuum is detected in the unit cell (see the input variable\n\nvacuum\n), the computation of \nkptrlen\n will ignore the dimension related\nto the direction perpendicular to the vacuum layer, and generate a bi-\ndimensional k point grid. If the system is confined in a tube, a one-\ndimensional k point grid will be generated. For a cluster, this procedure will\nonly generate the Gamma point.\n\n\nmagcon_lambda\n\u00b6\n\n\nMnemonics: MAGnetization CONstraint LAMBDA parameter\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 10.0  \n\n\nThis variable gives the amplitude of the constraint imposed on the\nmagnetization vectors on each atom (turned on with flag variable\n\nmagconon\n). Typical values for lambda are 10 to a few hundred. The energy\nwill vary strongly and convergence will be difficult if lambda is too large.\nThe constraint will be weak and the magnetization will not be close to\n\nspinat\n if lambda is too small. See variable \nmagconon\n for more details.\n\n\nmagconon\n\u00b6\n\n\nMnemonics: turn MAGnetization CONstraint ON\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nTurns on the imposition of a Lagrangian constraint on the magnetization. For\neach atom, the magnetization is calculated in a sphere (radius \nratsph\n) and\na constraint is applied to bring it closer to the input values of \nspinat\n.\nThe constraint can be either on the direction only (magconon 1) or on the full\nvector (magconon 2). The Lagrangian constraint has an amplitude\n\nmagcon_lambda\n which should be neither too big (bad or impossible\nconvergence) nor too small (no effect).\n\n\nmixalch\n\u00b6\n\n\nMnemonics: MIXing coefficients for ALCHemical potentials\n\nVariable type: real\n\nDimensions: (\nnpspalch\n,\nntypalch\n)\n\nDefault value: None  \n\n\nUsed for the generation of alchemical pseudoatoms, that is, when \nntypalch\n\nis non-zero.\n\n\nThis array gives, for each type of alchemical pseudatom (there are\n\nntypalch\n such pseudoatoms), the mixing coefficients of the basic\n\nnpspalch\n pseudopotentials for alchemical use. For each type of alchemical\npseudoatom, the sum of the mixing coefficients must equal 1.\n\n\nThe actual use of the mixing coefficients is defined by the input variable\n\nalgalch\n. Note that the masses of the atoms, \namu\n are also mixed\naccording to the value of \nmixalch\n, by default.\n\n\nExample 1. Suppose that we want to describe Ba(0.25) Sr(0.75) Ti O3.\n\nThe input variables related to the construction of the alchemical Ba(0.25)\nSr(0.75) potential will be :\n\n\n  npsp   4                 ! 4 pseudopotentials should be read.\n  znucl  8 40 56 38        ! The nuclear charges. Note that the two\n                           ! atoms whose pseudopotentials are to be mixed\n                           ! are mentioned at the end of the series.\n  ntypat  3                ! There will be three types of atoms.\n  ntypalch   1             ! One pseudoatom will be alchemical.\n                           ! Hence, there will be ntyppure=2 pure pseudoatoms,\n                           ! with znucl 8 (O) and 40 (Ti), corresponding to\n                           ! the two first pseudopotentials. Out of the\n                           ! four pseudopotentials, npspalch=2 are left\n                           ! for alchemical purposes, with znucl 56 (Ba)\n                           ! and 38 (Sr).\n  mixalch    0.25  0.75    ! For that unique pseudoatom to be\n                           ! generated, here are the mixing coeeficients,\n                           ! to be used to combine the Ba and Sr pseudopotentials.\n\n\n\n\n\nExample 2. More complicated, and illustrate some minor drawback of the design\nof input variables. Suppose that one wants to generate Al(0.25)Ga(0.75)\nAs(0.10)Sb(0.90).\n\nThe input variables will be :\n\n\n  npsp  4                  ! 4 pseudopotentials should be read\n  znucl  13 31 33 51       ! The atomic numbers. All pseudopotentials\n                           ! will be used for some alchemical purpose\n  ntypat  2                ! There will be two types of atoms.\n  ntypalch   2             ! None of the atoms will be \"pure\".\n                           ! Hence, there will be npspalch=4 pseudopotentials\n                           !  to be used for alchemical purposes.\n  mixalch    0.25  0.75 0.0  0.0   ! This array is a (4,2) array, arranged in the\n             0.0   0.0  0.1  0.9   ! usual Fortran order.\n\n\n\n\n\nMinor drawback : one should not forget to fill \nmixalch\n with the needed\nzero\u2019s, in this later case.\n\n\nIn most cases, the use of \nmixalch\n will be as a static (non-evolving)\nvariable. However, the possibility to have different values of \nmixalch\n for\ndifferent images has been coded. A population of cells with different atomic\ncharacteristics can thus be considered, and can be made to evolve, e.g. with a\ngenetic algorithm (not coded in v7.0.0 though). There is one restriction to\nthis possibility : the value of \nziontypat\n for the atoms that are mixed\nshould be identical.\n\n\nnatsph\n\u00b6\n\n\nMnemonics: Number of ATomic SPHeres for the atom-projected density-of-states\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \nnatom\n\nOnly relevant if \nprtdos\n == 3 or \npawfatbnd\n in [1,2]  \n\n\nnatsph\n gives the number of atoms around which the sphere for atom-\nprojected density-of-states will be built, in the \nprtdos\n=3 case. The\nindices of these atoms are given by \niatsph\n. The radius of these spheres is\ngiven by \nratsph\n.\n\nIf \npawfatbnd\n=1 or 2, it gives the number of atoms around which atom-\nprojected band structure will be built (the indices of these atoms are given\nby \niatsph\n).\n\n\nnatsph_extra\n\u00b6\n\n\nMnemonics: Number of ATomic SPHeres for the l-projected density-of-states in EXTRA set\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nprtdos\n == 3 or \npawfatbnd\n in [1,2]  \n\n\nnatsph_extra\n gives the number of extra spheres for which the angular-\nmomentum-projected density-of-states will be built, in the \nprtdos\n=3 case.\nThe radius of these spheres is given by \nratsph_extra\n. This simulates the\nSTS signal for an STM tip atom placed at the sphere position, according to the\nchemical nature of the tip (s- p- d- wave etc\u2026).\n\nIf \npawfatbnd\n=1 or 2, it gives the number of spheres in which l-projected\nband structure will be built.\n\nThe position of the spheres is given by the \nxredsph_extra\n variable.\n\n\nnbdbuf\n\u00b6\n\n\nMnemonics: Number of BanDs for the BUFfer\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2\nnspinor\n if \noptdriver\n==0 and \niscf\n<0,\n2\nnspinor\n if \noptdriver\n==1 and 3<=\noccopt\n and \noccopt\n<= 8,\n0 otherwise.\n\n\nnbdbuf\n gives the number of bands, the highest in energy, that, among the\n\nnband\n bands, are to be considered as part of a buffer. This concept is\nuseful in three situations: in non-self-consistent calculations, for the\ndetermination of the convergence tolerance ; for response functions of metals,\nto avoid instabilities, and also when finite electric fields or non-linear\nresponses (with electric field perturbations) are considered. For the two\nfirst, the need of a buffer is a natural requirement of the problem, so that\nthe default value is changed to 2 automatically, as explained in the\nfollowing. The third case is only for implementation convenience.\n\n\nIn non-self-consistent GS calculations (\niscf\n<0), the highest levels\nmight be difficult to converge, if they are degenerate with another level,\nthat does not belong to the set of bands treated. Then, it might take\nextremely long to reach \ntolwfr\n, although the other bands are already\nextremely well-converged, and the energy of the highest bands (whose residual\nare not yet good enough), is also rather well converged.\n\nIn response to this problem, for non-zero \nnbdbuf\n, the largest residual\n(residm), to be later compared with \ntolwfr\n, will be computed only in the\nset of non-buffer bands (this modification applies for non-self-consistent as\nwell as self-consistent calculation, for GS as well as RF calculations).\n\nFor a GS calculation, with \niscf\n<0, supposing \nnbdbuf\n is not\ninitialized in the input file, then ABINIT will overcome the default\n\nnbdbuf\n value, and automatically set \nnbdbuf\n to 2.\n\n\nIn metallic RF calculations, in the conjugate gradient optimisation of first-\norder wavefunctions, there is an instability situation when the q wavevector\nof the perturbation brings the eigenenergy of the highest treated band at some\nk point higher than the lowest untreated eigenenergy at some k+q point. If one\naccepts a buffer of frozen states, this instability can be made to disappear.\nFrozen states receive automatically a residual value of -0.1d0.\n\nFor a RF calculation, with 3<=\noccopt\n<=7, supposing \nnbdbuf\n is not\ninitialized in the input file, then ABINIT will overcome the default\n\nnbdbuf\n value, and automatically set \nnbdbuf\n to 2. This value might be\ntoo low in some cases.\n\n\nAlso, the number of active bands, in all cases, is imposed to be at least 1,\nirrespective of the value of \nnbdbuf\n.\n\n\nndivk\n\u00b6\n\n\nMnemonics: Number of DIVisions of K lines\n\nVariable type: integer\n\nDimensions: (abs(\nkptopt\n))\n\nDefault value: None\n\nComment: Will be generated automatically from \nndivsm\n if the latter is defined.\n\nOnly relevant if \nkptopt\n < 0\n\nThe use of this variable forbids the use of specified(\nndivsm\n)  \n\n\nGives the number of divisions of each of the segments of the band structure,\nwhose path is determined by \nkptopt\n and \nkptbounds\n. In this case, the\nabsolute value of \nkptopt\n is the number of such segments.\n\n\nFor example, suppose that the number of segment is just one (\nkptopt\n=-1), a\nvalue \nndivk\n=4 will lead to the computation of points with relative\ncoordinates 0.0, 0.25, 0.5, 0.75 and 1.0 , along the segment in consideration.\n\n\nNow, suppose that there are two segments (\nkptopt\n=-2), with \n[ndivk]\n=4\nand \n[ndivk]\n=2, the computation of the eigenvalues will be done at 7\npoints, 5 belonging to the first segment, with relative coordinates 0.0, 0.25,\n0.5, 0.75 and 1.0, the last one being also the starting point of the next\nsegment, for which two other points must be computed, with relative\ncoordinates 0.5 and 1.0 .\n\n\nIt is easy to compute disconnected circuits (non-chained segments), by\nseparating the circuits with the value \nndivk\n=1 for the intermediate\nsegment connecting the end of one circuit with the beginning of the next one\n(in which case no intermediate point is computed along this segment).\n\n\nAlternatively it is possible to generate automatically the array \nndivk\n by\njust specifying the number of divisions for the smallest segment. See the\nrelated input variable \nndivsm\n.\n\n\nndivsm\n\u00b6\n\n\nMnemonics: Number of DIVisions for the SMallest segment\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nThis variable defines the number of divisions used to sample the smallest\nsegment of the circuit employed in a band structure calculations (see related\ninput variables \nkptopt\n and \nkptbounds\n). If \nndivsm\n is given in the\ninput file, there is no need to specify the number of divisions to be used for\nthe other segments. Indeed \nndivk\n is automatically calculated inside the\ncode in order to generate a path where the number of divisions in each segment\nis proportional to the length of the segment itself. This option is activated\nonly when \nkptopt\n is negative. In this case, the absolute value of\n\nkptopt\n is the number of such segments.\n\n\nngfft\n\u00b6\n\n\nMnemonics: Number of Grid points for Fast Fourier Transform\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nComment: (automatic selection of optimal values)  \n\n\ngives the size of fast Fourier transform (fft) grid in three dimensions. Each\nnumber must be composed of the factors 2, 3, and 5 to be consistent with the\nradices available in our fft. If no \nngfft\n is provided or if \nngfft\n is\nset to 0 0 0, the code will automatically provide an optimal set of \nngfft\n\nvalues, based on \nacell\n, \nrprim\n and \necut\n (see also \nboxcutmin\n for\nspeed/accuracy concerns). This is the recommended procedure, of course.\n\nThe total number of FFT points is the product:\n\n\n[ngfft]\n[ngfft]\n[ngfft]\n=nfft  .\n\nWhen \nngfft\n is made smaller than recommended values (e.g. by setting\n\nboxcutmin\n to a value smaller than 2.0 or by setting \nngfft\n manually),\nthe code runs faster and the equations in effect are approximated by a low\npass Fourier filter. The code reports to standard output (unit 06) a parameter\n\u201cboxcut\u201d which is the smallest ratio of the fft box side to the G vector basis\nsphere diameter. When boxcut is less than 2 the Fourier filter approximation\nis being used. When boxcut gets less than about 1.5 the approximation may be\ntoo severe for realistic results and should be tested against larger values of\n\nngfft\n. When boxcut is larger than 2, \nngfft\n could be reduced without\nloss of accuracy. In this case, the small variations that are observed are\nsolely due to the xc quadrature, that may be handled with \nintxc\n=1 to even\nreduce this effect.\n\n\nInternally, \nngfft\n is an array of size 18. The present components are\nstored in \n[ngfft]\n, while\n\n\n\n\n[ngfft]\n contains slightly different (larger) values, modified for efficiency of the FFT \n\n\n[ngfft]\n is \nfftalg\n \n\n\n[ngfft]\n is \nfftcache\n \n\n\n[ngfft]\n is set to 0 if the parallelization of the FFT is not activated, while it is set to 1 if it is activated. \n\n\n[ngfft]\n is the number of processors of the FFT group \n\n\n[ngfft]\n is the index of the processor in the group of processors \n\n\n[ngfft]\n is n2proc, the number of x-z planes, in reciprocal space, treated by the processor \n\n\n[ngfft]\n is n3proc, the number of x-y planes, in real space, treated by the processor \n\n\n[ngfft]\n is mpi_comm_fft, the handle on the MPI communicator in charge of the FFT parallelisation \n\n\n[ngfft]\n are not yet used \n\n\n\n\nThe number of points stored by this processor in real space is n1\nn2\nn3proc,\nwhile in reciprocal space, it is n1\nn2proc\nn3.\n\n\nngqpt\n\u00b6\n\n\nMnemonics: Number of Grid pointsfor Q PoinTs generation\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \nnqpt\n==1 and \nkptopt\n>=0\n\nThe use of this variable forbids the use of specified(\nqptrlatt\n)  \n\n\nAt variance with \nngkpt\n, note that only one q point is selected per dataset\n(see \niqpt\n).\n\nIts three positive components give the number of q points of Monkhorst-Pack\ngrids (defined with respect to primitive axis in reciprocal space) in each of\nthe three dimensions. The use of \nnshiftq\n and \nshiftq\n, allows to\ngenerate shifted grids, or Monkhorst-Pack grids defined with respect to\nconventional unit cells.\n\n\nFor more information on Monkhorst-Pack grids, see \nngkpt\n.\n\n\nnline\n\u00b6\n\n\nMnemonics: Number of LINE minimisations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 4  \n\n\nGives maximum number of line minimizations allowed in preconditioned conjugate\ngradient minimization for each band. The Default, 4, is fine.\n\nSpecial cases, with degeneracies or near-degeneracies of levels at the Fermi\nenergy may require a larger value of \nnline\n (5 or 6 ?) Line minimizations\nwill be stopped anyway when improvement gets small. With the input variable\n\nnnsclo\n, governs the convergence of the wavefunctions for fixed potential.\n\nNote that \nnline\n=0 can be used to diagonalize the Hamiltonian matrix in the\nsubspace spanned by the input wavefunctions.\n\n\nnpsp\n\u00b6\n\n\nMnemonics: Number of PSeudoPotentials\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \nntypat\n  \n\n\nUsually, the number of pseudopotentials to be read is equal to the number of\ntype of atoms. However, in the case an alchemical mixing of pseudopotential is\nto be used, often the number of pseudopotentials to be read will not equal the\nnumber of types of atoms.\n\n\nAlchemical pseudopotentials will be present when \nntypalch\n is non-zero. See\n\nntypalch\n to understand how to use alchemical potentials in ABINIT. The\ninput variables (\nntypalch\n, \nalgalch\n,\nmixalch\n) are active, and\ngenerate alchemical potentials from the available pseudopotentials. Also, the\ninner variables (\nntyppure\n,\nnpspalch\n) become active. See these input\nvariables, especially \nmixalch\n, to understand how to use alchemical\npotentials in ABINIT.\n\n\nnpspalch\n\u00b6\n\n\nMnemonics: Number of PSeudoPotentials that are \u201cALCHemical\u201d\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \nnpsp\n-\nntyppure\n\nOnly relevant if \nntypalch\n/=0  \n\n\nGives the number of pseudopotentials that are used for alchemical mixing (when\n\nntypalch\n is non-zero) :\n\n\nnpspalch\n=\nnpsp\n-\nntyppure\n\n\nnqpt\n\u00b6\n\n\nMnemonics: Number of Q - POINTs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nDetermines whether one q point must be read (See the variable \nqptn\n).\n\nCan be either 0 or 1.\n\nIf 1 and used in ground-state calculation, a global shift of all the k-points\nis applied, to give calculation at k+q. In this case, the output wavefunction\nwill be appended by _WFQ instead of _WFK (see the \n section 4\n\n of the \nhelp_abinit\n) Also,\nif 1 and a RF calculation is done, defines the wavevector of the perturbation.\n\n\nnshiftq\n\u00b6\n\n\nMnemonics: Number of SHIFTs for Q point grids\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis parameter gives the number of shifted grids to be used concurrently to\ngenerate the full grid of q points. It can be used with primitive grids\ndefined either from \nngqpt\n or \nqptrlatt\n. The maximum allowed value of\n\nnshiftq\n is 8. The values of the shifts are given by \nshiftq\n.\n\n\nnspden\n\u00b6\n\n\nMnemonics: Number of SPin-DENsity components\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \nnsppol\n  \n\n\nIf \nnspden\n=1, no spin-magnetization : the density matrix is diagonal, with\nsame values spin-up and spin-down (compatible with \nnsppol\n=1 only, for both\n\nnspinor\n=1 or 2)\n\n\nIf \nnspden\n=2, scalar magnetization (the axis is arbitrarily fixed in the z\ndirection) : the density matrix is diagonal, with different values for spin-up\nand spin-down (compatible with \nnspinor\n=1, either with \nnsppol\n=2\n-general collinear magnetization- or \nnsppol\n=1 -antiferromagnetism)\n\n\nIf \nnspden\n=4, vector magnetization : the density matrix is full, with\nallowed x, y and z magnetization (useful only with \nnspinor\n=2 and\n\nnsppol\n=1, either because there is spin-orbit without time-reversal\nsymmetry - and thus spontaneous magnetization, or with spin-orbit, if one\nallows for spontaneous non-collinear magnetism). Not yet available for\nresponse functions. Also note that, with \nnspden\n=4, time-reversal symmetry\nis not taken into account (at present ; this has to be checked) and thus\n\nkptopt\n has to be different from 1 or 2.\n\n\nThe default (\nnspden\n=\nnsppol\n) does not suit the case of vector\nmagnetization.\n\n\nnspinor\n\u00b6\n\n\nMnemonics: Number of SPINORial components of the wavefunctions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2 if \npawspnorb\n==1,\n1 otherwise.\n\n\nIf \nnspinor\n=1, usual case : scalar wavefunction (compatible with\n(\nnsppol\n=1, \nnspden\n=1) as well as (\nnsppol\n=2, \nnspden\n=2) )\n\n\nIf \nnspinor\n=2, the wavefunction is a spinor (compatible with \nnsppol\n=1,\nwith \nnspden\n=1 or 4, but not with \nnsppol\n=2)\n\n\nWhen \nnspinor\n is 2, the values of \nistwfk\n are automatically set to 1.\nAlso, the number of bands, for each k-point, should be even.\n\n\nntypalch\n\u00b6\n\n\nMnemonics: Number of TYPe of atoms that are \u201cALCHemical\u201d\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed for the generation of alchemical pseudopotentials : when \nntypalch\n is\nnon-zero, alchemical mixing will be used.\n\n\nAmong the \nntypat\n types of atoms, the last \nntypalch\n will be\n\u201calchemical\u201d pseudoatoms, while only the first \n ntyppure \n will be uniquely\nassociated with a pseudopotential (the \n ntyppure \n first of these,\nactually). The \nntypalch\n types of alchemical pseudoatoms are to be made\nfrom the remaining \nnpspalch\n pseudopotentials.\n\n\nIn this case, the input variables \nalgalch\n,\nmixalch\n are active, and\ngenerate alchemical potentials from the available pseudopotentials. See these\ninput variables, especially \nmixalch\n, to understand how to use alchemical\npotentials in ABINIT.\n\n\nntyppure\n\u00b6\n\n\nMnemonics: Number of TYPe of atoms that are \u201cPURe\u201d\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \nntypat\n-\nntypalch\n  \n\n\nGives the number of type of atoms that are \u201cpure\u201d when alchemical mixing is\nused (\nntypalch\n /= 0) :\n\n\nntyppure\n=\nntypat\n-\nntypalch\n\n\nnucdipmom\n\u00b6\n\n\nMnemonics: NUClear DIPole MOMents\n\nVariable type: real\n\nDimensions: (3,\nnatom\n)\n\nDefault value: 0.0\n\nOnly relevant if \nusepaw\n = 1; \npawcpxocc\n = 2; \nkptopt\n > 2  \n\n\nPlaces an array of nuclear magnetic dipole moments on the atomic positions,\nuseful for computing the magnetization in the presence of nuclear dipoles and\nthus the chemical shielding by the converse method. The presence of these\ndipoles breaks time reversal symmetry and lowers the overall spatial symmetry.\n\n\nnwfshist\n\u00b6\n\n\nMnemonics: Number of WaveFunctionS HISTory\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIn the wavelet basis set, the ground state is found by direct minimisation.\nThe algorithm used can be either the steepest descent or the DIIS (Direct\nInversion of Iteration Space). When \nnwfshist\n = 0, the steepest descent is\nused ( _ i.e. _ there is no history storage of the previous iterations). If\n\nnwfshist\n is strictly positive, a DIIS is used. A typical value is 6. Using\na DIIS increases the memory required by the program since N previous\nwavefunctions are stored during the electronic minimisation.\n\n\nocc\n\u00b6\n\n\nMnemonics: OCCupation numbers\n\nVariable type: real\n\nDimensions: (\nnband\n)\n\nDefault value: *0  \n\n\nGives occupation numbers for all bands in the problem. Needed if \noccopt\n==0\nor \noccopt\n==2. Ignored otherwise. Also ignored when \niscf\n=-2.\n\nTypical band occupancy is either 2 or 0, but can be 1 for half-occupied band\nor other choices in special circumstances.\n\nIf \noccopt\n is not 2, then the occupancies must be the same for each k\npoint.\n\nIf \noccopt\n=2, then the band occupancies must be provided explicitly for\neach band, EACH k POINT, and EACH SPIN-POLARIZATION, in an array which runs\nover all bands, k points, and spin-polarizations.\n\nThe order of entries in the array would correspond to all bands at the first k\npoint (spin up), then all bands at the second k point (spin up), etc, then all\nk-points spin down.\n\nThe total number of array elements which must be provided is\n\n( \n[nband]\n+\n[nband]\n+\u2026+ \n[nband]\n ) * \nnsppol\n .\n\nThe occupation numbers evolve only for metallic occupations, that is,\n\noccopt\n \u2265 3 .\n\n\noptdriver\n\u00b6\n\n\nMnemonics: OPTions for the DRIVER\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nFor each dataset, choose the task to be done, at the level of the \u201cdriver\u201d\nroutine.\n\n\nThe choice is among :\n\n\noptdriver\n=0 : ground-state calculation (GS), routine \u201cgstate\u201d\n\n\noptdriver\n=1 : response-function calculation (RF), routine \u201crespfn\u201d\n\n\noptdriver\n=2 : susceptibility calculation (SUS), routine \u201csuscep\u201d\n\n\noptdriver\n=3 : susceptibility and dielectric matrix calculation (SCR),\nroutine \u201cscreening\u201d\n\n(see the input variables \necutwfn\n, \necuteps\n, \nppmfrq\n, \ngetwfk\n, as\nwell as \nnbandkss\n and \nnband\n)\n\n\noptdriver\n=4 : self-energy calculation (SIG), routine \u201csigma\u201d\n\n\noptdriver\n=5 : non-linear response functions (NONLINEAR), using the 2n+1\ntheorem, routine \u201cnonlinear\u201d\n\n\noptdriver\n =7: electron-phonon coupling (EPH)\n\n\noptdriver\n =66: GW using Lanczos-Sternheimer, see input variables whose\nname start with gwls_* .\n\n\noptdriver\n=99 : Bethe-Salpeter calculation (BSE), routine \u201cbethe_salpeter\u201d\n\n\nIf one of \nrfphon\n, \nrfddk\n, \nrfelfd\n, or \nrfstrs\n is non-zero, while\n\noptdriver\n is not defined in the input file, ABINIT will set \noptdriver\n\nto 1 automatically. These input variables (\nrfphon\n, \nrfddk\n, \nrfelfd\n,\nand \nrfstrs\n) must be zero if \noptdriver\n is not set to 1.\n\n\noptstress\n\u00b6\n\n\nMnemonics: OPTion for the computation of STRESS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nIf set to 1, the computation of stresses is done, in the SCF case (under the\nconditions \niscf\n > 0 , \nprtstm\n==0 , \npositron\n==0, and either\n\nnstep\n >0 , or \nusepaw\n==0 or \nirdwfk\n==1).\n\nOtherwise, to save CPU time, if no optimization of the cell is required, one\ncan skip the computation of stresses. The CPU time saving might be interesting\nfor some PAW calculations.\n\n\nposdoppler\n\u00b6\n\n\nMnemonics: POSitron computation of DOPPLER broadening\n\nVariable type: integer\n\nDefault value: 0  \n\n\nRelevant only when \npositron\n<>0.\n\nThis input parameter activates the calculation of the Doppler broadening of\nthe electron-positron annihilation radiation.\n\nAn output file containing the momentum distributions of annihilating electron-\npositron pairs is created.\n\nSuch a computation needs a core wave-function file (per atom type) to be\nprovided. This core WF file should be named \u2018<psp_file_name>.corewf\u2019\n(where <pspfile_name> is the name of the pseudo-potential (or PAW) file)\nor \u2018corewf.abinit<ityp>\u2018 (where <ityp> is the index of the atom\ntype). Core WF files can be obtained with the atompaw tool by the use of\n\u2018prtcorewf\u2019 keyword.\n\n\npositron\n\u00b6\n\n\nMnemonics: POSITRON calculation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis input parameter can be positive or negative.\n\nNegative values for \npositron\n are only relevant for PAW calculations.\n\nElectron-positron correlation functional is defined by \nixcpositron\n.\n\nOther relevant input parameter: \nposocc\n (occupation number for the\npositron).  \n\n\nPositive values for \npositron\n:\n\n\nFor \npositron\n=1 or 2\n, will perform the calculation of positron\nlifetime (and annihilation rate).\n  \n\n\n\n\npositron\n=1\n:\n\nStarting from a previous electronic GS density (with \npositron\n=0**), a\npositronic ground-state calculation is performed, considering that the\nelectrons are not perturbed by the presence of the positron.\n\nThis is almost correct for a positron in a perfect bulk material. But this\napproximation fails when defects exist in the material (for instance: the\npositron might be trapped by a vacancy).\n\nThe electronic density will be automatically read from a _DEN file (with or\nwithout \nirdden\n keyword).\n\nAt the end of the SCF cycle, the positron lifetime and annihilation rate are\nprinted out.  \n\n\n\n\n_Additional information for the use of pseudopotentials:  \n\n\n*\n \nPAW\n \ndatasets\n:\n \nnothing\n \nto\n \ndo\n;\n \nsimply\n \nuse\n \nusual\n \nelectronic\n \nPAW\n \ndatasets\n \n\n*\n \nNorm-conserving\n \npseudopotentials\n:\n \nOne\n \nhas\n \nto\n \nuse\n \nspecific\n \npseudopotentials\n \nfor\n \nthe\n \npositron\n \ncalculation\n.\n \nThey\n \nmust\n \nbe\n \nof\n \nthe\n \nFHI\n \ntype\n \n(\npspcod\n=\n6\n),\n \nand\n \nmust\n \ncontain\n \nat\n \ntheir\n \nend\n,\n \nthe\n \nall-electrons\n \ncore\n \ndensity\n \ngenerated\n \nwith\n \nFHI98PP\n.\n \nThey\n \nmust\n \nhave\n \nlmax\n=\nlloc\n=\n0\n \n(\ncheck\n \nthat\n \nthis\n \nworks\n \nfor\n \nthe\n \nelectronic\n \nGS\n \n!!\n \nNo\n \nghost\n,\n \netc\n \n...).\n \nOtherwise\n,\n \ntheir\n \nare\n \nsimilar\n \nto\n \nan\n \nusual\n \nFHI\n \npseudopotential\n.\n\n\n\n\n\n\n_  \n\n\n\n\npositron=2\n:\n\nStarting from a previous positronic GS density (with \npositron=1\n), an\nelectronic ground-state calculation is performed, keeping the positronic\ndensity constant.\n\nThe positronic density will be automatically read from a _DEN file (with or\nwithout \ngetden\n/\nirdden\n keyword).\n\nAt the end of the SCF cycle, the positron lifetime and annihilation rate are\nprinted out.  \n\n\n\n\n_Additional information for the use of pseudopotentials:  \n\n\n*\n \nPAW\n \ndatasets\n:\n \nnothing\n \nto\n \ndo\n;\n \nsimply\n \nuse\n \nusual\n \nelectronic\n \nPAW\n \ndatasets\n \n\n*\n \nNorm-conserving\n \npseudopotentials\n:\n \nOne\n \nhas\n \nto\n \nuse\n \nspecific\n \npseudopotentials\n \nfor\n \nthe\n \nelectron\n \ncalculation\n.\n \nThey\n \nmust\n \nbe\n \nof\n \nthe\n \nFHI\n \ntype\n \n(\npspcod\n=\n6\n),\n \nand\n \nmust\n \ncontain\n \nat\n \ntheir\n \nend\n,\n \nthe\n \nall-electrons\n \ncore\n \ndensity\n \ngenerated\n \nwith\n \nFHI98PP\n.\n\n\n\n\n\n\n_  \n\n\n\n\nTypical use\n:\n\nThe calculation is done in several steps:\n\nThe first one is a normal GS calculation for the electrons, with\n\npositron\n=0. The only specific thing to do is to set \nprtden\n=1 (this is\nthe defaut for ABINIT v6.x+). This will create the associated _DEN file which\nwill be used as input file for the positronic GS calculation.\n\nThe second step is the GS calculation of the positron and subsequently its\nlifetime, with \npositron\n=1. One has to define also \nixcpositron\n.\n\nThen, it is possible to perform an additional step, computing the GS\nelectronic density in presence of the positron, with \npositron\n=2.\n\nand so on\u2026\n\nThis procedure can be automated (for PAW only) by the use of a negative value\nfor \npositron\n.\n\nAt the end, a converged value of the positron lifetime (decomposed in several\ncontributions) is printed.\n\nSee also \nposdoppler\n keyword for the calculation of Doppler broadening.  \n\n\n\n\nNegative values for \npositron\n:\n\n\nFor \npositron<0\n, will perform an automatic calculation of electrons and\npositron densities in the two-component DFT context; then will compute\npositron lifetime (and annihilation rate).\n  \n\n\n\n\n\n\npositron=-1\n:\n\nStarting from scratch, will first perform an usual electronic ground-state\ncalculation until convergence (controlled by the use of one of the \ntolerance\n\nkeywords).\n\nThen will perform a positronic ground state calculation in presence of the\nelectrons and ions; then an electronic ground state calculation in presence of\nthe positron and the ions\u2026\n\nand so on\u2026 until the total energy is converged.\n\nThe convergence of the total energy of the ions+electrons+positron system is\ncontrolled by the use of the \npostoldfe\n, \npostoldff\n and \nposnstep\n\ninput keywords.\n\nWith \npositron=-1\n, at the beginning of each new electronic/positronic step,\nthe wave functions are unknown.\n\n\n\n\n\n\npositron=-10\n:\n\nSame as \npositron=-1\n except that the electronic/positronic wave functions\nare stored in memory.\n\nConsequently, the total number of iterations to reach the convergence\n(diff_Etotal<\npostoldfe\n or diff_Forces<\npostoldff\n) is smaller.\n\nBut, this can increase the total amount of memory needed by the code.\n\n\n\n\n\n\npositron=-2\n:\n\nSame as \npositron=-1\n except that the two-component DFT cycle is forced to\nstop at the end of an electronic step.\n\n\n\n\n\n\npositron=-20\n:\n\nSame as \npositron=-10\n except that the two-component DFT cycle is forced to\nstop at the end of an electronic step.\n\n\n\n\n\n\nAdvice for use:\n\nThere are two typical cases which have to be differently treated:\n\n\n\n\n\n\nA positron in a perfect \nbulk\n system\n:\n\nIn that case, the positron is delocalized in the whole crystal. Its density is\nalmost zero.\n\nThus, the \u201czero density positron limit\u201d has to be used. \nixcpositron\n has to\nbe choosen accordingly.\n\nIn order to have the zero density positron limit it is adviced to follow these\npoints:\n\n1- Put a small positronic charge (by setting a \nposocc\n to a small value)\n\nOR\n use a big supercell.\n\n2- Use only k=gamma wave vector for the positronic calculation.\n\n3- Use the manual procedure in 2 steps: first \npositron\n=0 and then\n\npositron\n=1; avoid the \npositron=2\n step and the automatic procedure\n(\npositron\n<0).\n\nIn principle, the positron lifetime should converge with the value of\n\nposocc\n or the size of the supercell.  \n\n\n\n\n\n\nA positron trapped in a \ndefault\n (vacancy\u2026)\n:\n\nIn that case, the positron is localized in the default. Its density can be\nlocalized in the simulation cell (provided that the cell is sufficiently\nlarge) and influences the electronic density.\n\nSo, it is advised to use the automatic procedure (\npositron\n<0) or the\nmanual procedure with several \npositron\n=0,1,2,1,\u2026 steps.\n\nK-points can be used as in usual electronic calculations.\n\nAlso note that it is possible to use forces and stresses to perform structural\nminimization.  \n\n\n\n\n\n\nReferences:  \n\n\n[1]\n J. Arponen and E. Pajanne, Ann. Phys. (N.Y.) 121, 343 (1979).\n\n\n[2]\n Boronski and R.M. Nieminen, Phys. Rev. B 34, 3820 (1986).\n\n\n[3]\n P.A. Sterne and J.H. Kaiser, Phys. Rev. B 43, 13892 (1991).\n\n\n[4]\n M.J. Puska, A.P. Seitsonen and R.M. Nieminen, Phys. Rev. B 52, 10947 (1994).\n\n\n[5]\n B. Barbiellini, M.J. Puska, T. Torsti and R.M.Nieminen, Phys. Rev. B 51, 7341 (1994)  \n\n\nposnstep\n\u00b6\n\n\nMnemonics: POSitron calculation: max. Number of STEPs for the two-component DFT\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 50  \n\n\nRelevant only when \npositron\n<0.\n\nSets the maximum number of electronic/positronic iterations that, when\nreached, will cause the two-component DFT SCF cycle to stop.\n\nThe code will first compute the electronic ground-state, then the positronic\nground state in the electronic density, then the electronic ground-state in\nthe positronic density, \u2026\n\n\u2026until diff_Etotal<\npostoldfe\n or diff_Forces<\npostoldff\n or the\nnumber of electronic/positronic steps is \nposnstep\n.  \n\n\nposocc\n\u00b6\n\n\nMnemonics: POSitron calculation: OCCupation number for the positron\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nRelevant only when \npositron\n/=0.\n\nSets the occupation number for the positron. Has to be <=1.\n\nChanging \nposocc\n is only useful for bulk calculation when one wants to\nperform lifetime computations using a small simulation cell (can avoid the use\nof a supercell). It simulates the dispersion of the positron in the whole\ncrystal.  \n\n\npostoldfe\n\u00b6\n\n\nMnemonics: POSitron calculation: TOLerance on the DiFference of total Energy\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1e-06 if \npostoldff\n=0,\n0.0 otherwise.\n\n\nRelevant only when \npositron\n<0.\n\nSets a tolerance for absolute difference of total energy (of _\nions+electrons+positron _ system) that, when reached, will cause the SCF cycle\nto stop before the number of steps is \nnstep\n or the number of\nelectronic/positronic steps is \nposnstep\n.  \n\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \n toldfe \n has\nthe \u2018\nENERGY\n\u2018 characteristics.\n\nOnly one and only one of \npostoldfe\n or \npostoldff\n can be set.\n\n\npostoldff\n\u00b6\n\n\nMnemonics: POSitron calculation: TOLerance on the DiFference of Forces\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nRelevant only when \npositron\n<0.\n\nSets a tolerance for absolute difference of maximum force acting on ions (due\nto _ ions+electrons+positron _ system) that, when reached, will cause the SCF\ncycle to stop before the number of SCF steps is \nnstep\n or the number of\nelectronic/positronic steps is \nposnstep\n.\n\nOnly one and only one of \npostoldfe\n or \npostoldff\n can be set.  \n\n\nprtdensph\n\u00b6\n\n\nMnemonics: PRinT integral of DENsity inside atomic SPHeres\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 otherwise.\n\n\nWhen this flag is activated, values of integral(s) of total density inside\nsphere(s) around each atom are printed in output file (for each spin\ncomponent). Spheres around atoms are defined by a radius given by \nratsph\n\nkeyword.\n\nNote: integral of density inside a sphere around an atom can be used to\ndetermine a rough approximation of the local magnetic moment; this is\nparticularly useful for antiferromagnetic systems.\n\nThe algorithm to compute this integral is particularly primitive : the points\non the FFT grids, belonging to the interior of the sphere are determined, and\nthe value of the functions on these points are summed, taking into account a\nfixed volume attributed to each point. In particular, the integral as a\nfunction of the radius will be a constant, except when a new point enters the\nsphere, in which case a sudden jump occurs. However, since the purpose of this\noutput is to get a rough idea of the repartition of the density, this is not a\nreal problem. If you are interested in a more accurate estimation of the\ndensity within a sphere, you should use the cut3d postprocessor.\n\n\nprtebands\n\u00b6\n\n\nMnemonics: PRinT Electron BANDS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0 if \nnimage\n > 1,\n1 otherwise.\n\n\nThis option activates the output of the electron eigenvalues. Possible values:\n\n\n\n\n0 Disable the output of the band energies.\n\n\n1 Write eigenvalues in xmgrace format. A file with extension \nEBANDS.agr\n is produced at the end of the run. Use \nxmgrace file_EBANDS.agr\n to visualize the band energies\n\n\n2 Write eigenvalues in gnuplot format. The code produces a \nEBANDS.dat\n file with the eigenvalues and a \nEBANDS.gnuplot\n script. Use \ngnuplot file_EBANDS.gnuplot\n to visualize the band energies.\n\n\n\n\nqpt\n\u00b6\n\n\nMnemonics: Q PoinT\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]  \n\n\nOnly used if \nnqpt\n=1.\n\n\nCombined with \nqptnrm\n, define the q vector \n[qptn]\n in the case\n\nqptopt\n=0.\n\n\nThis input variable is not internal (\n[qptn]\n is used instead), but is\nused to echo the value of \n[qptn]\n, with renormalisation factor one.\n\n\nqptnrm\n\u00b6\n\n\nMnemonics: Q PoinTs NoRMalization\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0  \n\n\nOnly used if \nnqpt\n=1 and \nqptopt\n=0\n\n\nProvides re-normalization of \nqpt\n. Must be positive, non-zero. The actual q\nvector (renormalized) is \n[qptn]\n= \n[qpt]\n/\nqptnrm\n.\n\n\nqptopt\n\u00b6\n\n\nMnemonics: QPoinTs OPTion\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nOnly used if \nnqpt\n=1.\n\n\nControls the set up to generate the Q point \n[qptn]\n to be used for the\nspecific dataset, either as a shift of k-point grid in ground-state\ncalculations, or as a stand-alone phonon wavevector.\n\n\nThere are two basic techniques to generate the Q point : either by specifying\nit directly, possibly with a renormalisation factor (\nqptopt\n=0), or\nextracting it from a grid a Q points (\nqptopt\n=1 to 4), using the index\n\niqpt\n. At variance with the similar generation of k points, only ONE q\npoint can be used per dataset.\n\n\nWith \nqptopt\n=1 to 4, rely on \nngqpt\n or \nqptrlatt\n, as well as on\n\nnshiftq\n and \nshiftq\n to set up a q point grid, from which the q point\nwith number \niqpt\n will be selected. The values \nqptopt\n=1 to 4 differ by\nthe treatment of symmetries. Note that the symmetries are recomputed starting\nfrom the values of \nrprimd\n \nxred\n and \nspinat\n. So, the explicit value\nof \nsymrel\n are not used. This is to allow doing calculations with\n\nnsym\n=1, sometimes needed for T-dependent electronic structure, still\ndecreasing the number of q points in the case \nqptopt\n=1 or \nqptopt\n=3.\n\n\n\n\n0=> read directly \nqpt\n, and its (eventual) renormalisation factor \nqptnrm\n. \n\n\n\n\n1=> Take fully into account the symmetry to generate the grid of q points in the Irreducible Brillouin Zone only. \n\n(This is the usual mode for RF calculations)\n\n\n\n\n\n\n2=> Take into account only the time-reversal symmetry : q points will be generated in half the Brillouin zone.   \n\n\n\n\n\n\n3=> Do not take into account any symmetry : q points will be generated in the full Brillouin zone.   \n\n\n\n\n\n\n4=> Take into account all the symmetries EXCEPT the time-reversal symmetry to generate the k points in the Irreducible Brillouin Zone.   \n\n\n\n\n\n\nIn the case of a grid of q points, the auxiliary variables \nkptrlen\n,\n\nngkpt\n and \nprtkpt\n might help you to select the optimal grid, similarly\nto the case of the K point grid.\n\n\nqptrlatt\n\u00b6\n\n\nMnemonics: Q - PoinTs grid : Real space LATTice\n\nVariable type: integer\n\nDimensions: (3,3)\n\nDefault value: *0\n\nThe use of this variable forbids the use of specified(\nngqpt\n)  \n\n\nThis input variable is used only when \nqptopt\n is positive. It partially\ndefines the q point grid. The other piece of information is contained in\n\nshiftq\n. \nqptrlatt\n cannot be used together with \nngqpt\n.\n\n\nThe values \n[qptrlatt]\n, \n[qptrlatt]\n, \n[qptrlatt]\n are\nthe coordinates of three vectors in real space, expressed in the \nrprimd\n\ncoordinate system (reduced coordinates). They defines a super-lattice in real\nspace. The k point lattice is the reciprocal of this super-lattice, possibly\nshifted (see \nshiftq\n).\n\n\nIf neither \nngqpt\n nor \nqptrlatt\n are defined, ABINIT will automatically\ngenerate a set of k point grids, and select the best combination of\n\nqptrlatt\n and \nshiftq\n that allows to reach a sufficient value of\n\nkptrlen\n. See this latter variable for a complete description of this\nprocedure.\n\n\nratsph\n\u00b6\n\n\nMnemonics: Radii of the ATomic SPHere(s)\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: [[\u2018AUTO_FROM_PSP\u2019]] if usepaw==1,\n2.0 otherwise.\n\n\nRelevant only when \nprtdos\n=3 or \nprtdensph\n=1.  \n\n\nWhen \nprtdos\n=3:\n\nProvides the radius of the spheres around the \nnatsph\n atoms of indices\n\niatsph\n, in which the local DOS and its angular-momentum projections will\nbe analysed. The choice of this radius is quite arbitrary. In a plane-wave\nbasis set, there is no natural definition of an atomic sphere. However, it\nmight be wise to use the following well-defined and physically motivated\nprocedure (in version 4.2, this procedure is NOT implemented, unfortunately) :\nfrom the Bader analysis, one can define the radius of the sphere that contains\nthe same charge as the Bader volume. This \u201cEquivalent Bader charge atomic\nradius\u201d might then be used to perform the present analysis. See the\n\nhelp_aim\n for more explanations. Another physically motivated choice would\nbe to rely on another charge partitioning, like the Hirshfeld one (see the\ncut3d utility). The advantage of using charge partitioning schemes comes from\nthe fact that the sum of atomic DOS, for all angular momenta and atoms,\nintegrated on the energy range of the occupied states, gives back the total\ncharge. If this is not an issue, one could rely on the half of the nearest-\nneighbour distances, or any scheme that allows to define an atomic radius.\nNote that the choice of this radius is however critical for the balance\nbetween the s, p and d components. Indeed, the integrated charge within a\ngiven radius, behave as a different power of the radius, for the different\nchannels s, p, d. At the limit of very small radii, the s component dominates\nthe charge contained in the sphere \u2026  \n\n\nWhen \nprtdensph\n=1:\n\nProvides the radius of the spheres around (all) atoms in which the total\ncharge density will be integrated.  \n\n\nIn case of PAW, \nratsph\n radius has to be greater or equal to PAW radius of\nconsidered atom type (which is read from the PAW dataset file; see rc_sph or\nr_paw).\n\n\nratsph_extra\n\u00b6\n\n\nMnemonics: Radii of the ATomic SPHere(s) in the EXTRA set\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 2.0 Bohr  \n\n\nRadius for extra spheres the DOS is projected into. See \nnatsph_extra\n and\n\nxredsph_extra\n for the number and positions of the spheres.\n\n\nscphon_supercell\n\u00b6\n\n\nMnemonics: Self Consistent PHONon SUPERCELL\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [1, 1, 1]  \n\n\nGive extent, in number of primitive unit cells, of the supercell being used\nfor a self-consistent phonon calculation. Presumes the phonon frequencies and\neigenvectors have been calculated in the original primitive unit cell, on a\ngrid of q-points which corresponds to the supercell in the present\ncalculation. TO BE IMPROVED : should contain a tutorial on how to do self-\nconsistent phonon calculations, David Waroquiers 090831\n\n\nscphon_temp\n\u00b6\n\n\nMnemonics: Self Consistent PHONon TEMPerature\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nTemperature which is imposed on phonon distribution, in the self-consistent\nscheme of Souvatzis et al. PRL \n 100 \n , 095901. Determines the extent of\nthe finite displacements used, and consequent anharmonic effects.\nExperimental.\n\n\nshiftq\n\u00b6\n\n\nMnemonics: SHIFT for Q points\n\nVariable type: real\n\nDimensions: (3,\nnshiftq\n)\n\nDefault value: None if \nnshiftq\n>1,\n[0.5, 0.5, 0.5] otherwise.\n\n\nIt is used only when \nqptopt\n>=0, and must be defined if \nnshiftq\n is\nlarger than 1.\n\n\n[shiftq]\n defines \nnshiftq\n shifts of the homogeneous\ngrid of q points based on \nngqpt\n or \nqptrlatt\n.\n\n\nSee \nshiftk\n for more information on the definition, use, and suitable\nvalues for these shifts.\n\n\nslabwsrad\n\u00b6\n\n\nMnemonics: jellium SLAB Wigner-Seitz RADius\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nFix the bulk-mean positive charge density nbulk of a jellium slab (if the\nlatter is employed, e.g. \njellslab\n \u2260 0). Often called \u201crs\u201d [see for example\nN. D. Lang and W. Kohn PRB 1, 4555 (1970)], \nslabwsrad\n is the radius of a\nsphere which has the same volume as the average volume per particle in a\nhomogeneous electron gas with density nbulk, so:\n\n\n  1/nbulk = 4/3 Pi * [[slabwsrad]]3\n\n\n\n\n\nFor example, the bulk aluminum fcc lattice constant is a=4.0495 Angstroms\n(webelements.com), each cubic centered cell includes 4 Al atoms and each atom\nhas 3 valence electrons, so the average volume per electron is a3/12=37.34\nBohr3 which has to be equal to 4/3 Pi*rs3. Consequently Al has approximately\nrs =2.07 Bohr, while for example magnesium has rs =2.65 Bohr, sodium 3.99\nBohr.\n\nBy default, given in Bohr atomic units (1 Bohr=0.5291772108 Angstroms).\n\n\nslabzbeg\n\u00b6\n\n\nMnemonics: jellium SLAB BEGinning edge along the Z direction\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: [0.0, 0.0]  \n\n\nDefine the edges of the jellium slab (if used, so if \njellslab\n \u2260 0) along\nz, namely the slab starts at a point along z which is expressed in Bohr by\n\nslabzbeg\n and it ends at a point expressed in Bohr by \nslabzend\n. The z\ndirection is parallel to the third crystal primitive lattice vector which has\nto be orthogonal to the other ones, so the length of the cell along z is\n\n[rprimd]\n. In addition \nslabzbeg\n and \nslabzend\n have to be such\nthat:\n\n\n  0 \u2264 **slabzbeg** < [[slabzend]] \u2264 [[rprimd]](3,3)\n\n\n\n\n\nTogether with \nslabwsrad\n they define the jellium positive charge density\ndistribution n+(x,y,z) in this way:\n\n\n  n+(x,y,z) = nbulk     if **slabzbeg** \u2264 z \u2264 [[slabzend]]\n            = 0        otherwise,\n\n\n\n\n\nso the positive charge density is invariant along the xy plane as well as the\nelectrostatic potential generated by it.\n\n\nslabzend\n\u00b6\n\n\nMnemonics: jellium SLAB ENDing edge along the Z direction\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: [0.0, 0.0]  \n\n\nDefine the edges of the jellium slab (if used, so if \njellslab\n \u2260 0) along\nz, namely the slab starts at a point along z which is expressed in Bohr by\n\nslabzbeg\n and it ends at a point expressed in Bohr by \nslabzend\n. The z\ndirection is parallel to the third crystal primitive lattice vector which has\nto be orthogonal to the other ones, so the length of the cell along z is\n\n[rprimd]\n. In addition \nslabzbeg\n and \nslabzend\n have to be such\nthat:\n\n\n  0 \u2264 [[slabzbeg]] < **slabzend** \u2264 [[rprimd]](3,3)\n\n\n\n\n\nTogether with \nslabwsrad\n they define the jellium positive charge density\ndistribution n+(x,y,z) in this way:\n\n\n  n+(x,y,z) = nbulk     if [[slabzbeg]] \u2264 z \u2264 **slabzend**\n            = 0        otherwise,\n\n\n\n\n\nso the positive charge density is invariant along the xy plane as well as the\nelectrostatic potential generated by it.\n\n\nso_psp\n\u00b6\n\n\nMnemonics: Spin-Orbit treatment for each PSeudoPotential\n\nVariable type: integer\n\nDimensions: (\nnpsp\n)\n\nDefault value: \nnpsp\n*1\n\nOnly relevant if \nnspinor\n==2 and \nusepaw\n==0  \n\n\nFor each type of atom (each pseudopotential), specify the treatment of spin-\norbit interaction (if \nnspinor\n==2 and Norm-conserving pseudopotentials\n\nusepaw\n==0)\n\nIf 0 : no spin-orbit interaction, even if \nnspinor\n=2\n\nIf 1 : treat spin-orbit as specified in the pseudopotential file.\n\nIf 2 : treat spin-orbit in the HGH form (usual form, although not allowed for\nall pseudopotentials)\n\nIf 3 : treat spin-orbit in the HFN form (Hemstreet-Fong-Nelson) (actually, not\nimplemented \u2026).\n\n\nFor typical usage, the default value is OK. If the spin-orbit needs to be\nturned off for one atom, 0 might be relevant. Note however, that the code will\nstop if \nnspinor\n=2 is used and one of the pseudopotential does not contain\nthe information about the spin-orbit interaction (this is the case for some\nold pseudopotentials). Indeed, for spinorial calculations, turning off the\nspin-orbit interaction is unphysical, and also does not save CPU time \u2026 It\nshould only be done for test purposes\n\n\nNote that if \nnspinor\n==1, the spin-orbit cannot be treated anyhow, so the\nvalue of \nso_psp\n is irrelevant. In case \nusepaw\n=1, please refer to\n\npawspnorb\n.\n\n\nPrior to v5.4, the input variable \n so_typat \n was used, in place of\n\nso_psp\n. Because the values 0 and 1 have been switched between \nso_psp\n\nand so_typat, it was dangerous to continue to allow the use of so_typat.\n\n\nspinat\n\u00b6\n\n\nMnemonics: SPIN for AToms\n\nVariable type: real\n\nDimensions: [3, \u2018\nnatrd\n\u2019] if \nnatrd\n<\nnatom\n,\n[3, \u2018\nnatom\n\u2019] otherwise.\n\n\nDefault value: 0.0  \n\n\nGives the initial electronic spin-magnetization for each atom, in unit of\nh-bar/2.\n\n\nNote that if \nnspden\n=2, the z-component must be given for each atom, in\ntriplets (0 0 z-component).\n\nFor example, the electron of an hydrogen atom can be spin up (0 0 1.0) or spin\ndown (0 0 -1.0).\n\n\nThis value is only used to create the first exchange and correlation\npotential, and is not used anymore afterwards.\n\nIt is not checked against the initial occupation numbers \nocc\n for each spin\nchannel.\n\nIt is meant to give an easy way to break the spin symmetry, and to allow to\nfind stable local spin fluctuations, for example : antiferromagnetism, or the\nspontaneous spatial spin separation of elongated H2 molecule.  \n\n\n\n\n\n\nIf the geometry builder is used, \nspinat\n will be related to the preprocessed set of atoms, generated by the geometry builder. The user must thus foresee the effect of this geometry builder (see \nobjarf\n). \n\n\n\n\n\n\nIf the geometry builder is not used, and the symmetries are not specified by the user (\nnsym\n=0), spinat will be used, if present, to determine the anti-ferromagnetic characteristics of the symmetry operations, see \nsymafm\n. \n\nIn case of collinear antiferromagnetism (\nnsppol\n=1, \nnspinor\n=1,\n\nnspden\n=2), these symmetries are used to symmetrize the density.\n\nIn case of non-collinear magnetism (\nnsppol\n=1, \nnspinor\n=1,\n\nnspden\n=4), they are also used to symmetrize the density. In the latter\ncase, this strongly constrains the magnetization (imposing its direction). If\nthe user want to let all degrees of freedom of the magnetization evolve, it is\nthen recommended to put \nnsym\n=1.  \n\n\n\n\n\n\nIf the symmetries are specified, and the irreducible set of atoms is specified, the anti-ferromagnetic characteristics of the symmetry operations \nsymafm\n will be used to generate \nspinat\n for all the non-irreducible atoms. \n\n\n\n\n\n\nIn the case of PAW+U calculations using the \ndmatpawu\n initial occupation matrix, and if \nnspden\n=4, \nspinat\n is also used to determine the direction of the integrated magnetization matrix. \n\n\n\n\n\n\nstmbias\n\u00b6\n\n\nMnemonics: Scanning Tunneling Microscopy BIAS voltage\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nGives, in Hartree, the bias of the STM tip, with respect to the sample, in\norder to generate the STM density map.\n\nUsed with positive \niscf\n, \noccopt\n=7 (metallic, gaussian), \nnstep\n=1 ,\nand positive \nprtstm\n, this value is used to generate a charge density map\nfrom electrons close to the Fermi energy, in a (positive or negative) energy\nrange. Positive \nstmbias\n will lead to the inclusion of occupied (valence)\nstates only, while negative \nstmbias\n will lead to the inclusion of\nunoccupied (conduction) states only.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \nstmbias\n has\nthe \u2018\nENERGY\n\u2018 characteristics (0.001 Ha = 27.2113845 meV = 315.773 Kelvin).\nWith \noccopt\n=7, one has also to specify an independent broadening\n\ntsmear\n.\n\n\nsymafm\n\u00b6\n\n\nMnemonics: SYMmetries, Anti-FerroMagnetic characteristics\n\nVariable type: integer\n\nDimensions: (\nnsym\n)\n\nDefault value: \nnsym\n*1  \n\n\nIn case the material is magnetic (well, this is only interesting in the case\nof antiferromagnetism, collinear or not), additional symmetries might appear,\nthat change the sign of the magnetization. They have been introduced by\nShubnikov (1951). They can be used by ABINIT to decrease the CPU time, by\nusing them to decrease the number of k-points.\n\n\nsymafm\n should be set to +1 for all the usual symmetry operations, that do\nnot change the sign of the magnetization, while it should be set to -1 for the\nmagnetization-changing symmetries.\n\nIf the symmetry operations are not specified by the user in the input file,\nthat is, if \nnsym\n=0, then ABINIT will use the values of \nspinat\n to\ndetermine the content of \nsymafm\n.\n\nThe symmetries found as \u201cantiferro magnetic\u201d (\nsymafm\n=-1) are used to\nsymmetrize density and magnetization in the following cases:\n\n- antiferromagnetism (\nnsppol\n=1, \nnspinor\n=1, \nnspden\n=2)\n\n- non-collinear magnetism (\nnsppol\n=1, \nnspinor\n=1, \nnspden\n=4)\n\nIn other cases they are not used.\n\n\ntimopt\n\u00b6\n\n\nMnemonics: TIMing OPTion\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \nSEQUENTIAL\n,\n0 otherwise.\n\n\nThis input variable allows to modulate the use of the timing routines.\n\n\nIf 0 => as soon as possible, suppresses all calls to timing routines\n\nIf 1 => usual timing behaviour, with short analysis, appropriate for\nsequential execution\n\nIf 2 => close to \ntimopt\n=1, except that the analysis routine does not\ntime the timer, appropriate for parallel execution.\n\nIf 3 => close to \ntimopt\n=1, except that the different parts of the\nlobpcg routine are timed in detail.\n\nIf 4 => close to \ntimopt\n=1, except that the different parts of the\nlobpcg routine are timed in detail. A different splitting of lobpcg than for\n\ntimopt\n=-3 is provided.\n\nIf -1 => a full analysis of timings is delivered\n\nIf -2 => a full analysis of timings is delivered, except timing the timer\n\nIf -3 => a full analysis of timings is delivered, including the detailed\ntiming of the different parts of the lobpcg routine. (this takes time, and is\ndiscouraged for too small runs - the timing would take more time than the run\n!). The timer is timed.\n\nIf -4 => a full analysis of timings is delivered, including the detailed\ntiming of the different parts of the lobpcg routine. A different splitting of\nlobpcg than for \ntimopt\n=-3 is provided (this takes time, and is discouraged\nfor too small runs - the timing would take more time than the run !). The\ntimer is timed. The sum of the independent parts is closer to 100% than for\n\ntimopt\n=-3.\n\n\ntl_nprccg\n\u00b6\n\n\nMnemonics: TaiL maximum Number of PReConditionner Conjugate Gradient iterations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 30  \n\n\nThis variable is similar to \nwvl_nprccg\n but for the preconditionner\niterations during the tail corrections (see \ntl_radius\n  ). TO BE IMPROVED :\nall tl_\n and wvl_\n variables should contain a link to a tutorial, David\nWaroquiers 090831.\n\n\ntl_radius\n\u00b6\n\n\nMnemonics: TaiL expansion RADIUS\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nIn the wavelet computation case, the linkage between the grid and the free\nboundary conditions can be smoothed using an exponential decay. This means a\ncorrection on the energy at the end on each wavefunction optimisation run. If\nthis parameter is set to zero, no tail computation is done. On the contrary,\nput it to a positive value makes the tail correction available. The value\ncorrespond to a length in atomic units being the spacial expansion with the\nexponential decay around the grid.\n\n\ntphysel\n\u00b6\n\n\nMnemonics: Temperature (PHYSical) of the ELectrons\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nGives, in Hartree, the physical temperature of the system, in case\n\noccopt\n=4, 5, 6, or 7.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \n ecut \n has\nthe \u2018\nENERGY\n\u2018 characteristics (0.001 Ha = 27.2113845 meV = 315.773 Kelvin).\nOne has to specify an independent broadening \ntsmear\n. The combination of\nthe two parameters \ntphysel\n and \ntsmear\n is described in a paper by M.\nVerstraete and X. Gonze, Phys. Rev. B 65, 035111 (2002). Note that the\nsignification of the entropy is modified with respect to the usual entropy.\nThe choice has been made to use \ntsmear\n as a prefactor of the entropy, to\ndefine the entropy contribution to the free energy.\n\n\ntsmear\n\u00b6\n\n\nMnemonics: Temperature of SMEARing\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.01  \n\n\nGives the broadening of occupation numbers \nocc\n, in the metallic cases\n(\noccopt\n=3, 4, 5, 6 and 7). Can be specified in Ha (the default), eV, Ry,\nor Kelvin, since \ntsmear\n has the \u2018\nENERGY\n\u2018 characteristics (0.001 Ha =\n27.2113845 meV = 315.773 Kelvin).\n\nDefault is 0.01 Ha. This should be OK using gaussian like smearings (occopt\n4,5,6,7) for a free-electron metal like Al. For d-band metals, you may need to\nuse less.\n\nAlways check the convergence of the calculation with respect to this\nparameter, and simultaneously, with respect to the sampling of k-points (see\n\nnkpt\n)\n\nIf \noccopt\n=3, \ntsmear\n is the physical temperature, as the broadening is\nbased on Fermi-Dirac statistics. However, if \noccopt\n=4, 5, 6, or 7, the\nbroadening is not based on Fermi-Dirac statistics, and \ntsmear\n is only a\nconvergence parameter. It is still possible to define a physical temperature,\nthanks to the input variable \ntphysel\n. See the paper by M. Verstraete and\nX. Gonze, Phys. Rev. B (2002).\n\n\nusekden\n\u00b6\n\n\nMnemonics: USE Kinetic energy DENsity\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf \nusekden\n=1 the kinetic energy density will be computed during the self-\nconsistency loop, in a way similar to the computation of the density. This is\nneeded if a meta-GGA is to be used as XC functional. Otherwise\n(\nusekden\n=0), the kinetic energy density is not computed during the self-\nconsistency loop.\n\n\nvacuum\n\u00b6\n\n\nMnemonics: VACUUM identification\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: None  \n\n\nEstablishes the presence (if 1) or absence (if 0) of a vacuum layer, along the\nthree possible directions normal to the primitive axes.\n\n\nThis information might be used to generate k-point grids, if \nkptopt\n=0 and\nneither \nngkpt\n nor \nkptrlatt\n are defined (see explanations with the\ninput variable \nprtkpt\n).\n\nIt will allow to select a zero-, one-, two- or three-dimensional grid of k\npoints. The coordinate of the k points along vacuum directions is\nautomatically set to zero.\n\n\nIf \nvacuum\n is not defined, the input variable \nvacwidth\n will be used to\ndetermine automatically whether the distance between atoms is sufficient to\nhave the presence or absence of vacuum.\n\n\nvacwidth\n\u00b6\n\n\nMnemonics: VACuum WIDTH\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 10.0  \n\n\nGive a minimum \u201cprojected\u201d distance between atoms to be found in order to\ndeclare that there is some \nvacuum\n present for each of the three\ndirections. By default, given in Bohr atomic units (1 Bohr=0.5291772108\nAngstroms), although Angstrom can be specified, if preferred, since\n\nvacwidth\n has the \u2018\nLENGTH\n\u2018 characteristics.\n\nThe precise requirement is that a slab of width \nvacwidth\n, delimited by two\nplanes of constant reduced coordinates in the investigated direction, must be\nempty of atoms.\n\n\nwtq\n\u00b6\n\n\nMnemonics: WeighTs for the current Q-points\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1\n\nComment: Except when \nqptopt\n/=0  \n\n\nGives the current q-point weight.\n\n\nwvl_bigdft_comp\n\u00b6\n\n\nMnemonics: WaVeLet BigDFT Comparison\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis variable is used for the wavelets capabilities of ABINIT (see \nusewvl\n\n). It is used to compare the results obtained with ABINIT with those obtained\nwith BigDFT stand-alone. When it is set to 1, ABINIT will follow the workflow\nas in BigDFT stand-alone. Therefore, the results must be exactly the same with\nthe two codes.\n\n\nwvl_crmult\n\u00b6\n\n\nMnemonics: WaVeLet Coarse grid Radius MULTiplier\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 6.0  \n\n\nThis factor is used to defined the expansion of the coarse resolution grid in\nthe case of wavelets (seea \nusewvl\n ). The grid is made of points inside\nspheres centered on atoms. The radius of these spheres are the product between\nthis factor and the covalent radius of element (read from the pseudo-potential\nfile).\n\nThis factor is responsible for the amount of used memory (see also\n\nwvl_hgrid\n).\n\n\nwvl_frmult\n\u00b6\n\n\nMnemonics: WaVeLet Fine grid Radius MULTiplier\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 10.0  \n\n\nThis factor is used to defined the expansion of the fine resolution grid in\nthe case of wavelets (see \nusewvl\n ). This fine resolution grid has the same\ngrid step than the coarse one (see \nwvl_crmult\n ), but on each point, 8\ncoefficients are stored instead of one, increasing the precision of the\ncalculation in this area. The grid is made of points inside spheres centered\non atoms. The radius of these spheres are the product between this factor and\na value read from the pseudo-potential file.\n\nThis factor is responsible for the amount of used memory (see also\n\nwvl_hgrid\n).\n\n\nwvl_ngauss\n\u00b6\n\n\nMnemonics: WaVeLet Number of GAUSSians\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: [1, 100]  \n\n\nIn the wavelet-PAW computation case, projectors may be fitted to a sum of\ncomplex Gaussians. The fit is done for wvl_ngauss(1), wvl_ngauss(1)+1 \u2026 up\nto wvl_ngauss(2) Gaussians.\n\n\nwvl_nprccg\n\u00b6\n\n\nMnemonics: WaVeLet maximum Number of PReConditionner Conjugate Gradient iterations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 5  \n\n\nIn the wavelet computation case, the wavefunctions are directly minimised\nusing a real-space preconditionner. This preconditionner has internally some\nconjugate gradient iterations. This value defines a boundary for the number of\nconjugate gradient iterations on each wavefunction convergence step.\n\n\nxredsph_extra\n\u00b6\n\n\nMnemonics: X(position) in REDuced coordinates of the SPHeres for dos projection in the EXTRA set\n\nVariable type: real\n\nDimensions: (3,\nnatsph_extra\n)\n\nDefault value: *0.0\n\nOnly relevant if \nnatsph_extra\n > 0  \n\n\nThe positions in reduced coordinates of extra spheres used in the DOS\nprojection, simulating an STS signal. See \nnatsph_extra\n for a more complete\ndescription.",
            "title": "Ground-State"
        },
        {
            "location": "/input_variables/vargs/#algalch",
            "text": "Mnemonics: ALGorithm for generating ALCHemical pseudopotentials \nVariable type: integer \nDimensions: ( ntypalch ) \nDefault value: *1    Used for the generation of alchemical pseudopotentials, that is, when ntypalch  is non-zero.  Give the algorithm to be used to generate the  ntypalch  alchemical\npotentials from the different  npspalch  pseudopotentials dedicated to this\nuse.  Presently,  algalch  can only have the value 1, that is :   the local potentials are mixed, thanks to the  mixalch  mixing coefficients   the form factors of the non-local projectors are all preserved, and all considered to generate the alchemical potential   the scalar coefficients of the non-local projectors are multiplied by the proportion of the corresponding type of atom that is present in  mixalch    the characteristic radius for the core charge is a linear combination of the characteristic radii of the core charges, build with the  mixalch  mixing coefficients   the core charge function f(r/rc) is a linear combination of the core charge functions, build with the  mixalch  mixing coefficients    Later, other algorithms for the mixing might be included.  Note that alchemical mixing cannot be used with PAW.",
            "title": "algalch"
        },
        {
            "location": "/input_variables/vargs/#boxcenter",
            "text": "Mnemonics: BOX CENTER \nVariable type: real \nDimensions: (3) \nDefault value: [0.5, 0.5, 0.5]    Defines the center of the box, in reduced coordinates. At present, this\ninformation is only used in the case of Time-Dependent DFT computation of the\noscillator strength. One must take boxcenter such as to be roughly the center\nof the cluster or molecule. The default is sensible when the vacuum\nsurrounding the cluster or molecule has xred 0 or 1. On the contrary, when the\ncluster or molecule is close to the origin, it is better to take boxcenter =(0 0 0).",
            "title": "boxcenter"
        },
        {
            "location": "/input_variables/vargs/#boxcutmin",
            "text": "Mnemonics: BOX CUT-off MINimum \nVariable type: real \nDimensions: scalar \nDefault value: 2.0    The box cut-off ratio is the ratio between the wavefunction plane wave sphere\nradius, and the radius of the sphere that can be inserted in the FFT box, in\nreciprocal space. In order for the density to be exact (in the case of plane\nwave, not PAW), this ratio should be at least two. If one uses a smaller\nratio, one will gain speed, at the expense of accuracy. In case of pure ground\nstate calculation (e.g. for the determination of geometries), this is\nsensible. However, the wavefunctions that are obtained CANNOT be used for\nstarting response function calculation.",
            "title": "boxcutmin"
        },
        {
            "location": "/input_variables/vargs/#charge",
            "text": "Mnemonics: CHARGE \nVariable type: real \nDimensions: scalar \nDefault value: 0    Used to establish charge balance between the number of electrons filling the\nbands and the nominal  charge  associated with the atomic cores. \nThe code adds up the number of valence electrons provided by the\npseudopotentials of each type (call this \u201czval\u201d), then add  charge , to get\nthe number of electrons per unit cell,  nelect . \nThen, if  iscf  is positive, the code adds up the band occupancies (given in\narray  occ ) for all bands at each k point, then multiplies by the k point\nweight  wtk  at each k point. Call this sum \u201cnelect_occ\u201d (for the number of\nelectrons from occupation numbers). It is then required that: \nnelect_occ = nelect \nTo treat a neutral system, which is desired in nearly all cases, one must use charge =0. To treat a system missing one electron per unit cell, set charge =+1.",
            "title": "charge"
        },
        {
            "location": "/input_variables/vargs/#chkexit",
            "text": "Mnemonics: CHecK whether the user want to EXIT \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If  chkexit  is 1 or 2, ABINIT will check whether the user wants to\ninterrupt the run (using the keyword \u201cexit\u201d on the top of the input file or\ncreating a file named \u201cabinit.exit\u201d: see the   end of section 3.2  of the help_abinit ).  If  chkexit =0, the check is not performed at all  If  chkexit =1, the check is not performed frequently (after each SCF step)  If  chkexit =2, the check is performed frequently (after a few bands, at\neach k point)  In all cases, the check is performed at most every 2 seconds of CPU time.",
            "title": "chkexit"
        },
        {
            "location": "/input_variables/vargs/#chkprim",
            "text": "Mnemonics: CHecK whether the cell is PRIMitive \nVariable type: integer \nDimensions: scalar \nDefault value: 1    If the symmetry finder is used (see  nsym ), a non-zero value of  chkprim \nwill make the code stop if a non-primitive cell is used. If  chkprim =0, a\nwarning is issued, but the run does not stop.  If you are generating the atomic and cell geometry using  spgroup , you\nmight generate a PRIMITIVE cell using  brvltt =-1 .",
            "title": "chkprim"
        },
        {
            "location": "/input_variables/vargs/#chksymbreak",
            "text": "Mnemonics: CHecK SYMmetry BREAKing \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This variable governs the behaviour of the code when there are potential\nsource of symmetry breaking, related e.g. to the k point grid or the presence\nof non-symmorphic translations which might not be coherent with the exchange-\ncorrelation grid.  When  chksymbreak =1, the code stops (or issue a warning) if :   (1) The k point grid is non-symmetric, in case  kptopt  =1, 2, or 4 ;   (2) The non-symmorphic translation part of the symmetry operations has components that are not zero, or simple fractions, with 2, 3, 4, 6, 8 or 12 as denominators.    When  chksymbreak  is zero, there is no such check. \nWhen  chksymbreak  is minus 1, the code stops if the condition (1) is met,\nbut in case the condition (2) is met, there will be a trial to shift the\natomic coordinates such as to obtain symmetry operations with the adequate\nnon-symmorphic part.  Explanation : \nIn the ground-state calculation, such breaking of the symmetry is usually\nharmless. However, if the user is doing a calculation of phonons using DFPT\n( rfphon =1), the convergence with respect to the number of k points will be\nmuch worse with a non-symmetric grid than with a symmetric one. Also, if the\nuser is doing a  GW  calculation, the presence of non-symmorphic\ntranslations that are not coherent with the FFT grid might cause problems. In\nthe  GW  part, indeed, one needs to reconstruct the wavefunctions in the\nfull Brillouin zone for calculating both the polarizability and the self-\nenergy. The wavefunctions in the full Brillouin zone are obtained from the\nirreducible wedge by applying the symmetry operations of the space group of\nthe crystal. In the present implementation, the symmetrization of the\nwavefunctions is done in real space on the FFT mesh that, therefore, has to be\ncoherent both with the rotational part as well as with the fractional\ntranslation of each symmetry operation. If the condition (2) is met, the GW  code will not be able to find a symmetry-preserving FFT mesh. \nSo, it was decided to warn the user about these possible problems already at\nthe level of the ground state calculations, although such warning might be\nirrelevant. \nIf you encounter a problem outlined above, you have two choices : change your\natomic positions (translate them) such that the origin appears as the most\nsymmetric point ; or ignore the problem, and set  chksymbreak =0 .",
            "title": "chksymbreak"
        },
        {
            "location": "/input_variables/vargs/#cpuh",
            "text": "Mnemonics: CPU time limit in Hours \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nThe use of this variable forbids the use of specified( cpum ) or specified( cpus )    Only one of the three real parameters  cpus ,  cpum  and  cpuh  can be\ndefined in the input file to set up a CPU time limit. When the job reaches\nthat limit, it will try to end smoothly. However, note that this might still\ntake some time. If the user want a firm CPU time limit, the present parameter\nmust be reduced sufficiently. Intuition about the actual margin to be taken\ninto account should come with experience \u2026 \nA zero value has no action of the job.",
            "title": "cpuh"
        },
        {
            "location": "/input_variables/vargs/#cpum",
            "text": "Mnemonics: CPU time limit in Minutes \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nThe use of this variable forbids the use of specified( cpum ) or specified( cpus )    Only one of the three real parameters  cpus ,  cpum  and  cpuh  can be\ndefined in the input file to set up a CPU time limit. When the job reaches\nthat limit, it will try to end smoothly. However, note that this might still\ntake some time. If the user want a firm CPU time limit, the present parameter\nmust be reduced sufficiently. Intuition about the actual margin to be taken\ninto account should come with experience \u2026 \nA zero value has no action of the job.",
            "title": "cpum"
        },
        {
            "location": "/input_variables/vargs/#cpus",
            "text": "Mnemonics: CPU time limit in seconds \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nThe use of this variable forbids the use of specified( cpum ) or specified( cpus )    Only one of the three real parameters  cpus ,  cpum  and  cpuh  can be\ndefined in the input file to set up a CPU time limit. When the job reaches\nthat limit, it will try to end smoothly. However, note that this might still\ntake some time. If the user want a firm CPU time limit, the present parameter\nmust be reduced sufficiently. Intuition about the actual margin to be taken\ninto account should come with experience \u2026 \nA zero value has no action of the job.",
            "title": "cpus"
        },
        {
            "location": "/input_variables/vargs/#diecut",
            "text": "Mnemonics: DIElectric matrix energy CUToff \nVariable type: real \nDimensions: scalar \nDefault value: 2.2    Kinetic energy cutoff that controls the number of planewaves used to represent\nthe dielectric matrix: \n(1/2)[(2 Pi)*(Gmax)]  2  = ecut  for Gmax. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since  diecut  has\nthe \u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV) \nAll planewaves inside this \u201cbasis sphere\u201d centered at G=0 are included in the\nbasis. This is useful only when  iprcel >=21, which means that a\npreconditioning scheme based on the dielectric matrix is used. \nNOTE : a negative  diecut  will define the same dielectric basis sphere as\nthe corresponding positive value, but the FFT grid will be identical to the\none used for the wavefunctions. The much smaller FFT grid, used when diecut  is positive, gives exactly the same results. \nNo meaning for RF calculations yet.",
            "title": "diecut"
        },
        {
            "location": "/input_variables/vargs/#diegap",
            "text": "Mnemonics: DIElectric matrix GAP \nVariable type: real \nDimensions: scalar \nDefault value: 0.1    Gives a rough estimation of the dielectric gap between the highest energy\nlevel computed in the run, and the set of bands not represented. Used to\nextrapolate dielectric matrix when  iprcel  >= 21. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since  diegap  has\nthe \u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV) \nNo meaning for RF calculations yet.",
            "title": "diegap"
        },
        {
            "location": "/input_variables/vargs/#dielam",
            "text": "Mnemonics: DIElectric matrix LAMbda \nVariable type: real \nDimensions: scalar \nDefault value: 0.5 \nOnly relevant if  iprcel  >= 21    Gives the amount of occupied states with mean energy given by the highest\nlevel computed in the run, included in the extrapolation of the dielectric\nmatrix. \nNo meaning for RF calculations yet.",
            "title": "dielam"
        },
        {
            "location": "/input_variables/vargs/#dielng",
            "text": "Mnemonics: model DIElectric screening LeNGth \nVariable type: real \nDimensions: scalar \nDefault value: 1.0774841d0    Used for screening length (in Bohr) of the model dielectric function, diagonal\nin reciprocal space. By default, given in Bohr atomic units (1\nBohr=0.5291772108 Angstrom), although Angstrom can be specified, if preferred,\nsince  dielng  has the \u2018 LENGTH \u2018 characteristics. \nThis model dielectric function is as follows (K being a wavevector) :           (     1        +     [[dielng]]2* K2   )\ndiel(K)= ------------------------------------\n         ( 1/[[diemac]] + [[dielng]]2 * K2 ) * [[diemix]]  The inverse of this model dielectric function will be applied to the residual,\nto give the preconditioned change of potential. Right at K=0, diel(K) is\nimposed to be 1.  If the preconditioning were perfect, the change of potential would lead to an\nexceedingly fast solution of the self-consistency problem (two or three\nsteps). The present model dielectric function is excellent for rather\nhomogeneous unit cells. \nWhen K->0 , it tends to the macroscopic dielectric constant, eventually\ndivided by the mixing factor  diemix  (or  diemixmag   for magnetization). \nFor metals, simply put  diemac  to a very large value (10^6 is OK) \nThe screening length  dielng  governs the length scale to go from the\nmacroscopic regime to the microscopic regime, where it is known that the\ndielectric function should tend to 1. It is on the order of 1 Bohr for metals\nwith medium density of states at the Fermi level, like Molybdenum, and for\nSilicon. For metals with a larger DOS at the Fermi level (like Iron), the\nscreening will be more effective, so that  dielng  has to be decreased by a\nfactor of 2-4. \nThis works for GS and RF calculations.",
            "title": "dielng"
        },
        {
            "location": "/input_variables/vargs/#diemac",
            "text": "Mnemonics: model DIElectric MACroscopic constant \nVariable type: real \nDimensions: scalar \nDefault value: 1000000.0    A rough knowledge of the macroscopic dielectric constant  diemac  of the\nsystem is a useful help to speed-up the SCF procedure: a model dielectric\nfunction, see the keyword  dielng , is used for that purpose. It is\nespecially useful for speeding up the treatment of rather homogeneous unit\ncells.  Some hint : \nThe value of  diemac  should usually be bigger than 1.0d0, on physical\ngrounds. \nFor metals, simply put  diemac  to a very large value (the default 10  6  is\nOK) \nFor silicon, use 12.0 . A similar value is likely to work well for other\nsemiconductors \nFor wider gap insulators, use 2.0 \u2026 4.0 \nFor molecules in an otherwise empty big box, try 1.5 \u2026 3.0 \nSystems that combine a highly polarisable part and some vacuum are rather\nbadly treated by the model dielectric function. One has to use the\n\u201cextrapolar\u201d technique, activated by the input variable  iprcel . \nIn sufficiently homogeneous systems, you might have to experiment a bit to\nfind the best  diemac . If you let  diemac  to its default value, you\nmight even never obtain the self-consistent convergence ! \nFor response function calculations, use the same values as for GS. The\nimprovement in speed can be considerable for small (but non-zero) values of\nthe wavevector.",
            "title": "diemac"
        },
        {
            "location": "/input_variables/vargs/#diemix",
            "text": "Mnemonics: model DIElectric MIXing factor \nVariable type: real \nDimensions: scalar \nDefault value: 1.0 if  usepaw ==0 or  iprcel  !=0,\n0.7 if  usepaw ==1 or  iprcel ==0,\nNone otherwise.  Only relevant if  diemix  >= 0.0 and  diemix  <=  1.0    Gives overall factor of the preconditioned residual density/potential to be\ntransferred in the SCF cycle. \nIt should be between 0.0 and 1.0 . \nIf the model dielectric function were perfect,  diemix  should be 1.0 . By\ncontrast, if the model dielectric function does nothing (when  diemac =1.0d0\nor  dielng  is larger than the size of the cell),  diemix  can be used to\ndamp the amplifying factor inherent to the SCF loop. \nFor molecules, a value on the order 0.5 or 0.33 is rather usual. \nWhen mod( iscf ,10)=3, 4 ,5 or 7,  diemix  is only important at the few\nfirst iterations when anharmonic effects are important, since these schemes\ncompute their own mixing factor for self-consistency. \nAlso note that a different value of diemix can be used for the magnetization\n(see  diemixmag ).",
            "title": "diemix"
        },
        {
            "location": "/input_variables/vargs/#diemixmag",
            "text": "Mnemonics: model DIElectric MIXing factor for the MAGgnetization \nVariable type: real \nDimensions: scalar \nDefault value:  diemix  if 70 <  iprcel  and  iprcel  < 80, diemix  if  iprcel ==0, diemix  if  iscf <10,\n- diemix  otherwise.  Gives overall factor of the preconditioned residual magnetization/magnetic\nfield to be transferred in the SCF cycle (see  diemix  for further\ninformation). \nFor the time being, apply only when the SCF mixing is done on the density\n( iscf >=10).    A negative value of diemixmag means that magnetization is only preconditionned\nby ABS(diemixmag), without the use of any preconditionner.    When SCF cycle has some difficulties to converge, changing the value of diemixmag  can have a positive effect. \nIn particular  diemixmag =-4 is a good choice (i.e. diemixmag=4, no other\npreconditionner on magnetization).",
            "title": "diemixmag"
        },
        {
            "location": "/input_variables/vargs/#dosdeltae",
            "text": "Mnemonics: DOS DELTA in Energy \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    Defines the linear grid resolution (energy increment) to be used for the\ncomputation of the Density-Of-States, when  prtdos  is non-zero. \nIf  dosdeltae  is set to zero (the default value), the actual increment is\n0.001 Ha if  prtdos =1, and the much smaller value 0.00005 Ha if prtdos =2. This different default value arises because the  prtdos =1\ncase, based on a smearing technique, gives a quite smooth DOS, while the DOS\nfrom the tetrahedron method,  prtdos =2, is rapidly varying.",
            "title": "dosdeltae"
        },
        {
            "location": "/input_variables/vargs/#enunit",
            "text": "Mnemonics: ENergy UNITs \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Governs the units to be used for output of eigenvalues (and eventual phonon\nfrequencies)   0=>print eigenvalues in hartree;   1=>print eigenvalues in eV;   2=>print eigenvalues in both hartree and eV.    If phonon frequencies are to be computed :   0=> phonon frequencies in Hartree and cm-1;   1=> phonon frequencies in eV and THz;   2=> phonon frequencies in hartree, eV, cm-1, Thz and Kelvin.",
            "title": "enunit"
        },
        {
            "location": "/input_variables/vargs/#fband",
            "text": "Mnemonics: Factor for the number of BANDs \nVariable type: real \nDimensions: scalar \nDefault value: 0.125 if  occopt ==1,\n0.5 if  occopt >2,\n0.0 if  usewvl ==1,\n0.0 otherwise.  Governs the number of bands to be used in the code in the case the parameter nband  is not defined in the input file (which means that  occopt  is not\nequal to 0 or 2).  In case  fband  is 0.0d0, the code computes from the pseudopotential files\nand the geometry data contained in the input file, the number of electrons\npresent in the system. Then, it computes the minimum number of bands that can\naccommodate them, and use that value for  nband . \nIn case  fband  differs from zero, other bands will be added, just larger\nthan  fband  times the number of atoms. This parameter is not echoed in the\ntop of the main output file, but only the parameter  nband  that it allowed\nto compute. It is also not present in the dtset array (no internal). \nThe default values are chosen such as to give naturally some conduction bands.\nThis improves the robustness of the code, since this allows to identify lack\nof convergence coming from (near-)degeneracies at the Fermi level. In the\nmetallic case, the number of bands generated might be too small if the\nsmearing factor is large. The occupation numbers of the higher bands should be\nsmall enough such as to neglect higher bands. It is difficult to automate\nthis, so a fixed default value has been chosen.",
            "title": "fband"
        },
        {
            "location": "/input_variables/vargs/#iatsph",
            "text": "Mnemonics: Index for the ATomic SPHeres of the atom-projected density-of-states \nVariable type: integer \nDimensions: ( natsph ) \nDefault value: [1 ..  natsph ] \nOnly relevant if  prtdos  == 3 or  pawfatbnd  in [1,2]    iatsph  gives the number of the  natsph  atoms around which the sphere\nfor atom-projected density-of-states will be build, in the  prtdos =3 case.\nThe radius of these spheres is given by  ratsph . \nIf  pawfatbnd =1 or 2, it gives the number of the  natsph  atoms around\nwhich atom-projected band structure will be built.",
            "title": "iatsph"
        },
        {
            "location": "/input_variables/vargs/#icoulomb",
            "text": "Mnemonics: Index for the Coulomb TReaTMenT \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Defines the type of computation used for Hartree potential, local part of\npseudo-potential and ion-ion interaction:   icoulomb =0 : usual reciprocal space computation, using 1 / g^2 for the Hartree potential and using Ewald correction.   icoulomb =1 : free boundary conditions are used when the Hartree potential is computed, real space expressions of pseudo-potentials are involved (restricted to GTH pseudo-potentials) and simple coulomb interaction gives the ion-ion energy.",
            "title": "icoulomb"
        },
        {
            "location": "/input_variables/vargs/#iprcel",
            "text": "Mnemonics: Integer for PReConditioning of ELectron response \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used when  iscf >0, to define the SCF preconditioning scheme. Potential-\nbased preconditioning schemes for the SCF loop (electronic part) are still a\nsubject of active research. The present parameter (electronic part) describes\nthe way the change of potential is derived from the residual. \nThe possible values of  iprcel  correspond to :   0 => model dielectric function described by  diemac ,  dielng  and  diemix .   larger or equal to 21 => will compute the dielectric matrix according to  diecut ,  dielam ,  diegap . This methodology is described in P.-M. Anglade, X. Gonze, Phys. Rev. B 78, 045126 (2008).   Between 21 and 29 => for the first few steps uses the same as option 0 then compute RPA dielectric function, and use it as such.   Between 31 and 39 => for the first few steps uses the same as option 0 then compute RPA dielectric function, and use it, with the mixing factor  diemix .   Between 41 and 49 => compute the RPA dielectric matrix at the first step, and recompute it at a later step, and take into account the mixing factor  diemix .   Between 51 and 59 => same as between 41 and 49, but compute the RPA dielectric matrix by another mean   Between 61 and 69 => same as between 41 and 49, but compute the electronic dielectric matrix instead of the RPA one.   Between 71 and 78 => STILL UNDER DEVELOPMENT \u2013 NOT USABLE ; Use the modified Kerker preconditioner with a real-space formulation (basic formulation is shown at  dielng ). The dielectric matrix is approximated thanks to  diemac  and  dielng . Note that  diemix  is also used.   79 => STILL UNDER DEVELOPMENT \u2013 NOT USABLE ; same as previous but with an alternate algorithm.   141 to 169 => same as Between 41 and 69 (but, the dielectric matrix is also recomputed every iprcel modulo 10 step).    The computation of the dielectric matrix (for 0 [100]<  iprcel  < 70\n[100]) is based on the   extrapolar   approximation. This approximation can\nbe tuned with  diecut ,  dielam , and  diegap . Yet its accuracy mainly\ndepends on the number of conduction bands included in the system. Having 2 to\n10 empty bands in the calculation is usually enough (use  nband ).    NOTES:   The step at which the dielectric matrix is computed or recomputed is determined by modulo( iprcel ,10). The recomputation happens just once in the calculation for  iprcel  < 100.   For non-homogeneous relatively large cells  iprcel =45 will likely give a large improvement over  iprcel =0.   In case of PAW and  iprcel >0, see  pawsushat  input variable. By default, an approximation (which can be suppressed) is done for the computation of susceptibility matrix.   For extremely large inhomogeneous cells where computation of the full dielectric matrix takes too many weeks, 70 <  iprcel  < 80 is advised.   For  nsppol =2 or  nspinor =2 with metallic  occopt , only   mod(iprcel,100)   <50 is allowed.   No meaning for RF calculations yet.   The exchange term in the full dielectric matrix diverges for vanishing densities. Therefore the values of  iprcel  beyond 60 must not be used for cells containing vacuum, unless ones computes this matrix for every step ( iprcel =161).",
            "title": "iprcel"
        },
        {
            "location": "/input_variables/vargs/#iqpt",
            "text": "Mnemonics: Index for QPoinT generation \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Only used if  nqpt =1, and  qptopt =1 to 4.  Defines the index of the Q point to be selected in the list of q points\ngenerated by  ngqpt ,  qptrlatt ,  nshiftq , and  shiftq .  If  iqpt =0, then the q point is Gamma (0 0 0).  The usual working mode is to define a series of values for  iqpt , starting\nwith  iqpt =0 or 1 (so through the definition of   iqpt:   ), and\nincreasing it by one for each dataset (thanks to   iqpt+   ).",
            "title": "iqpt"
        },
        {
            "location": "/input_variables/vargs/#ixcpositron",
            "text": "Mnemonics: Integer for the eXchange-Correlation applied to the electron-POSITRON interaction \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nComment: (Teter parameterization). However, if all the pseudopotentials have the same value of pspxc, the initial value of ixc will be that common value    Relevant only when  positron /=0. \nDefine the type of electron-positron correlation that is used in case of a\nelectron-positron two-component DFT calculation. \nDefine also the analytical formula of the enhancement factor used to compute\nthe electron-positron annhilation rate:    Electron-positron correlation functional:     ixcpositron=1   : LDA zero positron density limit parametrized by Arponen & Pajanne and provided by Boronski & Nieminen [1,2]    ixcpositron=11   : LDA zero positron density limit parametrized by Arponen & Pajanne and fitted by Sterne & Kaiser [1,3]    ixcpositron=2   : LDA electron-positron correlation provided by Puska, Seitsonen, and Nieminen [1,4]    ixcpositron=3   : GGA zero positron density limit parametrized by Arponen & Pajanne and provided by Boronski & Nieminen [1,2,5]    ixcpositron=31   : GGA zero positron density limit parametrized by Arponen & Pajanne and fitted by Sterne & Kaiser [1,3,5] \nAnnihilation rate enhancement factor:     ixcpositron=1   : Boronski and Nieminen full modelisation and RPA limit [1]    ixcpositron=11   : Sterne and Kaiser [2]    ixcpositron=2   : Puska, Seitsonen and Nieminen [3]    ixcpositron=3   : Boronski and Nieminen full modelisation and RPA limit [1], with GGA corrections    ixcpositron=31   : Sterne and Kaiser [2], with GGA corrections     References:    [1]   J. Arponen and E. Pajanne, Ann. Phys. (N.Y.) 121, 343\n(1979).   [2]   Boronski and R.M. Nieminen, Phys. Rev. B 34, 3820 (1986).    [3]   P.A. Sterne and J.H. Kaiser, Phys. Rev. B 43, 13892 (1991).    [4]   M.J. Puska, A.P. Seitsonen and R.M. Nieminen, Phys. Rev. B 52, 10947 (1994).    [5]   B. Barbiellini, M.J. Puska, T. Torsti and R.M.Nieminen, Phys. Rev. B 51, 7341 (1994)",
            "title": "ixcpositron"
        },
        {
            "location": "/input_variables/vargs/#jellslab",
            "text": "Mnemonics: include a JELLium SLAB in the cell \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1, a slab of uniform positive background charge density, that is, a\njellium slab, is included in the calculation cell. A portion of the unit cell\nis filled with such positive charge density distribution which is equal to a\nbulk-mean value n  bulk  between two edges and zero in the vacuum region if\npresent. \nFor the sake of convenience the unit cell is supposed to have the third\ncrystal primitive lattice vector orthogonal to the other ones so that the\nportion of the cell filled by the jellium slab can be defined through its\nedges along z. \nThe bulk-mean positive charge density is fixed by the input variable slabwsrad , while the position of the slab edges along z is defined through\nthe input variables  slabzbeg  and  slabzend .",
            "title": "jellslab"
        },
        {
            "location": "/input_variables/vargs/#kptbounds",
            "text": "Mnemonics: K PoinT BOUNDarieS \nVariable type: real \nDimensions: (3,abs( kptopt )+1)) \nDefault value: None    It is used to generate the circuit to be followed by the band structure, when kptopt  is negative (it is not read if  kptopt  is zero or positive).  There are abs( kptopt ) segments to be defined, each of which starting from\nthe end point of the preceeding one. Thus, the number of points to be input is\nabs( kptopt )+1. They form a circuit starting at [kptbounds] / kptnrm  and ending at [kptbounds] / kptnrm . The number of divisions of\neach segment can be defined either using the array  ndivk  or the variable ndivsm  that just defines the number of divisions for the smallest segment  As for  kpt ,  kptbounds  is specified using the primitive vectors in\nreciprocal space. If your Bravais lattice is simple, then it should be quite\neasy to find the coordinates of the end points. On the other hand, for\ncentered, body-centered, face-centered, hexagonal, and rhombohedral Bravais\nlattice, the conversion might be more difficult. See the description of kpt  for an explanation of how to convert data from the \u201cconventional\u201d\ncartesian coordinates to the primitive vectors in the reciprocal space. In\norder to help a bit, we list below a series of typical values, for the FCC,\nBCC, hexagonal and rhombohedral Bravais lattices. Note : all the data below\nare given in dimensionless units ; they have to be rescaled by the actual\nlengths defined by the  acell  values. However,  kptbounds  values can be\nused as such, if the values of  rprim  given below are adopted.  A.   FCC lattice   Suppose the primitive vectors in real space are given by      rprim   0 1 1    1 0 1    1 1 0  or    rprim   0 1/2 1/2    1/2 0 1/2    1/2 1/2 0  (these two possibilities only differ by a scaling factor, irrelevant for the\ndefinition of the k points in the primitive vectors in reciprocal space).\nThen, the reciprocal primitive vectors (in conventional cartesian coordinates)\nare    (-1/2 1/2 1/2), (1/2 -1/2 1/2), (1/2 1/2 -1/2)  or    (-1 1 1), (1 -1 1), (1 1 -1)  and, in both cases, the coordinates of several special points with respect to\nprimitive vectors in reciprocal space are    X (0   1/2 1/2)   (conventional cartesian coordinate 1/2 0 0)\n  X'(1/2 1/2 1  )   (conventional cartesian coordinate 1/2 1/2 0)  (an other instance of X, in another Brillouin zone)\n  L (1/2 1/2 1/2)   (conventional cartesian coordinate  1/4 1/4 1/4)\n  L'(1/2 0   0  )   (conventional cartesian coordinate -1/4 1/4 1/4) (an other instance of L, on another face of the BZ)\n  W (1/4 1/2 3/4)   (conventional cartesian coordinate 1/2 1/4 0)\n  U (1/4 5/8 5/8)   (conventional cartesian coordinate 1/2 1/8 1/8)\n  K (3/8 3/8 3/4)   (conventional cartesian coordinate 3/8 3/8 0)  Note that K is actually equivalent to U, by spatial and translational\nsymmetry. So, if you want to specify a typical circuit, the following might do\nthe work : L-Gamma-X-W-K,U-L-W-X-K,U-Gamma with      kptbounds  1/2 0 0  0 0 0  0 1/2 1/2  1/4 1/2 3/4  3/8 3/8 3/4  1/2 1/2 1/2  1/4 1/2 3/4  1/2 1/2 1  3/8 3/8 3/4  0 0 0  The lengths of segments (this information is useful to draw the band\nstructure, with the correct relative scale between special points) can be\nfound using the conventional cartesian coordinates :\nl(L-Gamma)=sqrt(3)/4=0.433\u2026 ; l(Gamma-X)=1/2=0.5 ; l(X-W)=1/4=0.25 ;\nl(W-K)=sqrt(2)/8=0.177\u2026 ; l(K-L)=sqrt(6)/8=0.306\u2026 ;\nl(L-W)=sqrt(2)/4=0.354\u2026 ; l(W-X)=1/4=0.25 ; l(X-K)=sqrt(2)/8=0.177\u2026 ;\nl(K-Gamma)=sqrt(2).3/8=0.530\u2026  B.   BCC lattice   Suppose the primitive vectors in real space are given by      rprim  -1 1 1    1 -1 1    1 1 -1  (as for the FCC lattice, there is a scale invariance). Then, the reciprocal\nprimitive vectors (in conventional cartesian coordinates) are (0 1/2 1/2),\n(1/2 0 1/2), and (1/2 1/2 0) and the coordinates of several special points\nwith respect to primitive vectors in reciprocal space are    H (-1/2 1/2 1/2)   (conventional cartesian coordinate 1/2 0 0)\n  N ( 0   0   1/2)   (conventional cartesian coordinate 1/4 1/4 0)\n  P ( 1/4 1/4 1/4)   (conventional cartesian coordinate 1/4 1/4 1/4)   So, if you want to specify a typical circuit, the following might do the work   Gamma-H-N-Gamma-P-N-P-H    kptbounds  0 0 0  -1/2 1/2 1/2  0 0 1/2  0 0 0   1/4 1/4 1/4  0 0 1/2  1/4 1/4 1/4  -1/2 1/2 1/2    The lengths of segments (this information is useful to draw the band\nstructure, with the correct relative scale between special points) can be\nfound using the conventional cartesian coordinates : l(Gamma-H)=1/2=0.5 ;\nl(H-N)=sqrt(2)/4=0.354\u2026 ; l(N-Gamma)=sqrt(2)/4=0.354\u2026 ;\nl(Gamma-P)=sqrt(3)/4=0.433\u2026 ; l(P-N)=1/4=0.25 ; l(N-P)=1/4=0.25 ;\nl(P-H)=sqrt(3)/4=0.433\u2026  C.   Hexagonal lattices   Suppose the primitive vectors in real space are given by      rprim  1 0 0    -1/2 sqrt(0.75) 0    0 0 1  The coordinates of several special points with respect to primitive vectors in\nreciprocal space are    M (1/2 0 0) or (0 1/2 0) or (-1/2 1/2 0)\n  L (1/2 0 1/2) or (0 1/2 1/2) or (-1/2 1/2 1/2)\n  K (1/3 1/3 0) or (2/3 -1/3 0) or (-1/3 2/3 0)\n  H (1/3 1/3 1/2) or (2/3 -1/3 1/2) or (-1/3 2/3 1/2)\n  A (0 0 1/2)   So, if you want to specify a typical circuit, the following might do the work   K-Gamma-M-K-H-A-L-H-L-M-Gamma-A    kptbounds  1/3 1/3 0  0 0 0  1/2 0 0  1/3 1/3 0  1/3 1/3 1/2  0 0 1/2  1/2 0 1/2  1/3 1/3 1/2  1/2 0 1/2  1/2 0 0  0 0 0  0 0 1/2    In order to find the lengths of segments (this information is useful to draw\nthe band structure, with the correct relative scale between special points)\none needs to know the a and c lattice parameters. Also, in what follows, we\nomit the 2 pi factor sometimes present in the definition of the reciprocal\nspace vectors. The reciprocal vectors are (1/a 1/(sqrt(3) a) 0) , (0\n2/(sqrt(3) a) 0), (0 0 1/c). The lengths of the above-mentioned segments can\nbe computed as : l(K-Gamma)=2/(3 a)=0.666\u2026/a ;\nl(Gamma-M)=1/(sqrt(3) a)=0.577\u2026/a ; l(M-K)=1/(3 a)=0.333\u2026/a ;\nl(K-H)=1/(2 c)=0.5\u2026/c ; l(H-A)=2/(3 a)=0.666\u2026/a ;\nl(A-L)=1/(sqrt(3) a)=0.577\u2026/a ; l(L-H)=1/(3 a)=0.333\u2026/a ;\nl(H-L)=1/(3 a)=0.333\u2026/a ; l(L-M)=1/(2 c)=0.5\u2026/c ;\nl(M-Gamma)=-1/(sqrt(3) a)=0.577\u2026/a ; l(Gamma-A)=1/(2 c)=0.5\u2026/c  D.   Rhombohedral lattices   Rhombohedral lattices are characterised by two parameters, the length of the\nprimitive vectors, that we will denote a0, and the angle they form, alpha.\nThese can be directly input of ABINIT, as  acell  and  angdeg  This will generate the primitive vectors in real space , with    [[acell]] a0 a0 a0    and      [[rprim]]  a 0 c    -a/2 a*sqrt(0.75) c    -a/2 -a*sqrt(0.75) c  with a^2+c^2=1, a^2=(1-cos(alpha)) 2/3, c^2=(1+2 cos(alpha)) 1/3,\n(a/c)^2=2 (1-cos(alpha))/(1+2*cos(alpha)) and also\ncos(alpha)=(1-(a/c)^2/2)/(1+(a/c)^2). Alternatively, these values of rprim\nmight directly be the input of ABINIT (then, the balance of the scaling factor\nmight be adjusted between  acell  and  rprim ).  Unlike for the simple cubic, FCC, BCC, hexagonal (and some other) Bravais\nlattice, the topology of the Brillouin zone will depend on the alpha (or a/c)\nvalue. We give below information concerning the case when cos(alpha) is\npositive, that is, (a/c)^2 lower than 2.  The coordinates of several special points with respect to primitive vectors in\nreciprocal space will not depend on the a/c ratio, but some others will depend\non it. So, some care has to be exercised. Notations for the Brillouin Zone\nspecial points are the same as in Phys. Rev. B 41, 11827 (1990).    L (1/2 0 0) or (0 1/2 0) or (0 0 1/2) (or with negative signs)\n  T (1/2 1/2 1/2)\n  X (1/2 1/2 0) or (1/2 0 1/2) or (0 1/2 1/2) (or with separate negative signs)\n  W (5/6 - (a/c)^2/6 , 1/2 , 1/6 + (a/c)^2/6 ) = (1 0 -1)*(1-(a/c)^2/2)/3 + (1 1 1)/2\n  U ( (1+(a/c)^2)/6 , (8-(a/c)^2)/12 , (8-(a/c)^2)/12 ) = (-1 1/2 1/2)*(1-(a/c)^2/2)/3 + (1 1 1)/2\n  K (1 0 -1)*(1+(a/c)^2/4)/3  So, if you want to specify a typical circuit, the following might do the work\n(the representative points on lines of symmetry are indicated - there are\nsometimes more than one way to go from one point to another) : X-V-K-Sigma-\nGamma-Lambda-T-Q-W-Y-L-sigma-Gamma-sigma-X . The suggestion is to sample this\npath with the following coordinates for the special points X, Gamma, T, L,\nGamma, X :      kptbounds  1/2 0 -1/2   0 0 0    1/2 1/2 1/2  1 1/2 0   1 0 0  1 1/2 1/2  In order to find the lengths of segments (this information is useful to draw\nthe band structure, with the correct relative scale between special points)\none needs to know the a and c lattice parameters. Also, in what follows, we\nomit the 2 pi factor sometimes present in the definition of the reciprocal\nspace vectors. The reciprocal vectors are (2/(3 a) 0 1/(3 c)) , -(1/(3 a)\n1/(sqrt(3) a) 1/(3 c), -(1/(3 a) -1/(sqrt(3) a) 1/(3 c) ). The lengths of the\nabove-mentioned segments can be computed as :\nl(X-Gamma)=2/(sqrt(3) a)=1.155\u2026/a , with\nl(K-Gamma)=(1+(a/c)^2/4) 4/(3 sqrt(3) a); l(Gamma-T)=1/(2 c) ;\nl(T-L)=2/(sqrt(3) a)=1.155\u2026/a , with l(T-W)=(1-(a/c)^2/2) 4/(3 sqrt(3) a);\nl(L-Gamma)=sqrt(4/(a^2)+1/(c^2))/3 l(Gamma-X)=sqrt(1/(a^2)+1/(c^2))*2/3",
            "title": "kptbounds"
        },
        {
            "location": "/input_variables/vargs/#kptrlatt",
            "text": "Mnemonics: K - PoinTs grid : Real space LATTice \nVariable type: integer \nDimensions: (3,3) \nDefault value: *0 \nThe use of this variable forbids the use of specified( ngkpt )    This input variable is used only when  kptopt  is positive. It partially\ndefines the k point grid. The other piece of information is contained in shiftk .  kptrlatt  cannot be used together with  ngkpt .  The values kptrlatt(1:3,1), kptrlatt(1:3,2), kptrlatt(1:3,3) are the\ncoordinates of three vectors in real space, expressed in the  rprimd \ncoordinate system (reduced coordinates). They defines a super-lattice in real\nspace. The k point lattice is the reciprocal of this super-lattice, possibly\nshifted (see  shiftk ).  If neither  ngkpt  nor  kptrlatt  are defined, ABINIT will automatically\ngenerate a set of k point grids, and select the best combination of kptrlatt  and  shiftk  that allows to reach a sufficient value of kptrlen . See this latter variable for a complete description of this\nprocedure.",
            "title": "kptrlatt"
        },
        {
            "location": "/input_variables/vargs/#kptrlen",
            "text": "Mnemonics: K - PoinTs grid : Real space LENgth \nVariable type: real \nDimensions: scalar \nDefault value: 30.0    This input variable is used only when  kptopt  is positive and non-zero.  Preliminary explanation : \nThe k point lattice defined by  ngkpt  or  kptrlatt  is used to perform\nintegrations of periodic quantities in the Brillouin Zone, like the density or\nthe kinetic energy. One can relate the error made by replacing the continuous\nintegral by a sum over k point lattice to the Fourier transform of the\nperiodic quantity. Erroneous contributions will appear only for the vectors in\nreal space that belong to the reciprocal of the k point lattice, except the\norigin. Moreover, the expected size of these contributions usually decreases\nexponentially with the distance. So, the length of the smallest of these real\nspace vectors is a measure of the accuracy of the k point grid.  When either  ngkpt  or  kptrlatt  is defined,  kptrlen  is not used as\nan input variable, but the length of the smallest vector will be placed in\nthis variable, and echoed in the output file.  On the other hand, when neither  ngkpt  nor  kptrlatt  are defined, ABINIT\nwill automatically generate a large set of possible k point grids, and select\namong this set, the grids that give a length of smallest vector LARGER than kptrlen , and among these grids, the one that, when used with  kptopt =1,\nreduces to the smallest number of k points. Note that this procedure can be\ntime-consuming. It is worth doing it once for a given unit cell and set of\nsymmetries, but not use this procedure by default. The best is then to set prtkpt =1, in order to get a detailed analysis of the set of grids.  If some layer of vacuum is detected in the unit cell (see the input variable vacuum ), the computation of  kptrlen  will ignore the dimension related\nto the direction perpendicular to the vacuum layer, and generate a bi-\ndimensional k point grid. If the system is confined in a tube, a one-\ndimensional k point grid will be generated. For a cluster, this procedure will\nonly generate the Gamma point.",
            "title": "kptrlen"
        },
        {
            "location": "/input_variables/vargs/#magcon_lambda",
            "text": "Mnemonics: MAGnetization CONstraint LAMBDA parameter \nVariable type: real \nDimensions: scalar \nDefault value: 10.0    This variable gives the amplitude of the constraint imposed on the\nmagnetization vectors on each atom (turned on with flag variable magconon ). Typical values for lambda are 10 to a few hundred. The energy\nwill vary strongly and convergence will be difficult if lambda is too large.\nThe constraint will be weak and the magnetization will not be close to spinat  if lambda is too small. See variable  magconon  for more details.",
            "title": "magcon_lambda"
        },
        {
            "location": "/input_variables/vargs/#magconon",
            "text": "Mnemonics: turn MAGnetization CONstraint ON \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Turns on the imposition of a Lagrangian constraint on the magnetization. For\neach atom, the magnetization is calculated in a sphere (radius  ratsph ) and\na constraint is applied to bring it closer to the input values of  spinat .\nThe constraint can be either on the direction only (magconon 1) or on the full\nvector (magconon 2). The Lagrangian constraint has an amplitude magcon_lambda  which should be neither too big (bad or impossible\nconvergence) nor too small (no effect).",
            "title": "magconon"
        },
        {
            "location": "/input_variables/vargs/#mixalch",
            "text": "Mnemonics: MIXing coefficients for ALCHemical potentials \nVariable type: real \nDimensions: ( npspalch , ntypalch ) \nDefault value: None    Used for the generation of alchemical pseudoatoms, that is, when  ntypalch \nis non-zero.  This array gives, for each type of alchemical pseudatom (there are ntypalch  such pseudoatoms), the mixing coefficients of the basic npspalch  pseudopotentials for alchemical use. For each type of alchemical\npseudoatom, the sum of the mixing coefficients must equal 1.  The actual use of the mixing coefficients is defined by the input variable algalch . Note that the masses of the atoms,  amu  are also mixed\naccording to the value of  mixalch , by default.  Example 1. Suppose that we want to describe Ba(0.25) Sr(0.75) Ti O3. \nThe input variables related to the construction of the alchemical Ba(0.25)\nSr(0.75) potential will be :    npsp   4                 ! 4 pseudopotentials should be read.\n  znucl  8 40 56 38        ! The nuclear charges. Note that the two\n                           ! atoms whose pseudopotentials are to be mixed\n                           ! are mentioned at the end of the series.\n  ntypat  3                ! There will be three types of atoms.\n  ntypalch   1             ! One pseudoatom will be alchemical.\n                           ! Hence, there will be ntyppure=2 pure pseudoatoms,\n                           ! with znucl 8 (O) and 40 (Ti), corresponding to\n                           ! the two first pseudopotentials. Out of the\n                           ! four pseudopotentials, npspalch=2 are left\n                           ! for alchemical purposes, with znucl 56 (Ba)\n                           ! and 38 (Sr).\n  mixalch    0.25  0.75    ! For that unique pseudoatom to be\n                           ! generated, here are the mixing coeeficients,\n                           ! to be used to combine the Ba and Sr pseudopotentials.  Example 2. More complicated, and illustrate some minor drawback of the design\nof input variables. Suppose that one wants to generate Al(0.25)Ga(0.75)\nAs(0.10)Sb(0.90). \nThe input variables will be :    npsp  4                  ! 4 pseudopotentials should be read\n  znucl  13 31 33 51       ! The atomic numbers. All pseudopotentials\n                           ! will be used for some alchemical purpose\n  ntypat  2                ! There will be two types of atoms.\n  ntypalch   2             ! None of the atoms will be \"pure\".\n                           ! Hence, there will be npspalch=4 pseudopotentials\n                           !  to be used for alchemical purposes.\n  mixalch    0.25  0.75 0.0  0.0   ! This array is a (4,2) array, arranged in the\n             0.0   0.0  0.1  0.9   ! usual Fortran order.  Minor drawback : one should not forget to fill  mixalch  with the needed\nzero\u2019s, in this later case.  In most cases, the use of  mixalch  will be as a static (non-evolving)\nvariable. However, the possibility to have different values of  mixalch  for\ndifferent images has been coded. A population of cells with different atomic\ncharacteristics can thus be considered, and can be made to evolve, e.g. with a\ngenetic algorithm (not coded in v7.0.0 though). There is one restriction to\nthis possibility : the value of  ziontypat  for the atoms that are mixed\nshould be identical.",
            "title": "mixalch"
        },
        {
            "location": "/input_variables/vargs/#natsph",
            "text": "Mnemonics: Number of ATomic SPHeres for the atom-projected density-of-states \nVariable type: integer \nDimensions: scalar \nDefault value:  natom \nOnly relevant if  prtdos  == 3 or  pawfatbnd  in [1,2]    natsph  gives the number of atoms around which the sphere for atom-\nprojected density-of-states will be built, in the  prtdos =3 case. The\nindices of these atoms are given by  iatsph . The radius of these spheres is\ngiven by  ratsph . \nIf  pawfatbnd =1 or 2, it gives the number of atoms around which atom-\nprojected band structure will be built (the indices of these atoms are given\nby  iatsph ).",
            "title": "natsph"
        },
        {
            "location": "/input_variables/vargs/#natsph_extra",
            "text": "Mnemonics: Number of ATomic SPHeres for the l-projected density-of-states in EXTRA set \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  prtdos  == 3 or  pawfatbnd  in [1,2]    natsph_extra  gives the number of extra spheres for which the angular-\nmomentum-projected density-of-states will be built, in the  prtdos =3 case.\nThe radius of these spheres is given by  ratsph_extra . This simulates the\nSTS signal for an STM tip atom placed at the sphere position, according to the\nchemical nature of the tip (s- p- d- wave etc\u2026). \nIf  pawfatbnd =1 or 2, it gives the number of spheres in which l-projected\nband structure will be built. \nThe position of the spheres is given by the  xredsph_extra  variable.",
            "title": "natsph_extra"
        },
        {
            "location": "/input_variables/vargs/#nbdbuf",
            "text": "Mnemonics: Number of BanDs for the BUFfer \nVariable type: integer \nDimensions: scalar \nDefault value: 2 nspinor  if  optdriver ==0 and  iscf <0,\n2 nspinor  if  optdriver ==1 and 3<= occopt  and  occopt <= 8,\n0 otherwise.  nbdbuf  gives the number of bands, the highest in energy, that, among the nband  bands, are to be considered as part of a buffer. This concept is\nuseful in three situations: in non-self-consistent calculations, for the\ndetermination of the convergence tolerance ; for response functions of metals,\nto avoid instabilities, and also when finite electric fields or non-linear\nresponses (with electric field perturbations) are considered. For the two\nfirst, the need of a buffer is a natural requirement of the problem, so that\nthe default value is changed to 2 automatically, as explained in the\nfollowing. The third case is only for implementation convenience.  In non-self-consistent GS calculations ( iscf <0), the highest levels\nmight be difficult to converge, if they are degenerate with another level,\nthat does not belong to the set of bands treated. Then, it might take\nextremely long to reach  tolwfr , although the other bands are already\nextremely well-converged, and the energy of the highest bands (whose residual\nare not yet good enough), is also rather well converged. \nIn response to this problem, for non-zero  nbdbuf , the largest residual\n(residm), to be later compared with  tolwfr , will be computed only in the\nset of non-buffer bands (this modification applies for non-self-consistent as\nwell as self-consistent calculation, for GS as well as RF calculations). \nFor a GS calculation, with  iscf <0, supposing  nbdbuf  is not\ninitialized in the input file, then ABINIT will overcome the default nbdbuf  value, and automatically set  nbdbuf  to 2.  In metallic RF calculations, in the conjugate gradient optimisation of first-\norder wavefunctions, there is an instability situation when the q wavevector\nof the perturbation brings the eigenenergy of the highest treated band at some\nk point higher than the lowest untreated eigenenergy at some k+q point. If one\naccepts a buffer of frozen states, this instability can be made to disappear.\nFrozen states receive automatically a residual value of -0.1d0. \nFor a RF calculation, with 3<= occopt <=7, supposing  nbdbuf  is not\ninitialized in the input file, then ABINIT will overcome the default nbdbuf  value, and automatically set  nbdbuf  to 2. This value might be\ntoo low in some cases.  Also, the number of active bands, in all cases, is imposed to be at least 1,\nirrespective of the value of  nbdbuf .",
            "title": "nbdbuf"
        },
        {
            "location": "/input_variables/vargs/#ndivk",
            "text": "Mnemonics: Number of DIVisions of K lines \nVariable type: integer \nDimensions: (abs( kptopt )) \nDefault value: None \nComment: Will be generated automatically from  ndivsm  if the latter is defined. \nOnly relevant if  kptopt  < 0 \nThe use of this variable forbids the use of specified( ndivsm )    Gives the number of divisions of each of the segments of the band structure,\nwhose path is determined by  kptopt  and  kptbounds . In this case, the\nabsolute value of  kptopt  is the number of such segments.  For example, suppose that the number of segment is just one ( kptopt =-1), a\nvalue  ndivk =4 will lead to the computation of points with relative\ncoordinates 0.0, 0.25, 0.5, 0.75 and 1.0 , along the segment in consideration.  Now, suppose that there are two segments ( kptopt =-2), with  [ndivk] =4\nand  [ndivk] =2, the computation of the eigenvalues will be done at 7\npoints, 5 belonging to the first segment, with relative coordinates 0.0, 0.25,\n0.5, 0.75 and 1.0, the last one being also the starting point of the next\nsegment, for which two other points must be computed, with relative\ncoordinates 0.5 and 1.0 .  It is easy to compute disconnected circuits (non-chained segments), by\nseparating the circuits with the value  ndivk =1 for the intermediate\nsegment connecting the end of one circuit with the beginning of the next one\n(in which case no intermediate point is computed along this segment).  Alternatively it is possible to generate automatically the array  ndivk  by\njust specifying the number of divisions for the smallest segment. See the\nrelated input variable  ndivsm .",
            "title": "ndivk"
        },
        {
            "location": "/input_variables/vargs/#ndivsm",
            "text": "Mnemonics: Number of DIVisions for the SMallest segment \nVariable type: integer \nDimensions: scalar \nDefault value: None    This variable defines the number of divisions used to sample the smallest\nsegment of the circuit employed in a band structure calculations (see related\ninput variables  kptopt  and  kptbounds ). If  ndivsm  is given in the\ninput file, there is no need to specify the number of divisions to be used for\nthe other segments. Indeed  ndivk  is automatically calculated inside the\ncode in order to generate a path where the number of divisions in each segment\nis proportional to the length of the segment itself. This option is activated\nonly when  kptopt  is negative. In this case, the absolute value of kptopt  is the number of such segments.",
            "title": "ndivsm"
        },
        {
            "location": "/input_variables/vargs/#ngfft",
            "text": "Mnemonics: Number of Grid points for Fast Fourier Transform \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nComment: (automatic selection of optimal values)    gives the size of fast Fourier transform (fft) grid in three dimensions. Each\nnumber must be composed of the factors 2, 3, and 5 to be consistent with the\nradices available in our fft. If no  ngfft  is provided or if  ngfft  is\nset to 0 0 0, the code will automatically provide an optimal set of  ngfft \nvalues, based on  acell ,  rprim  and  ecut  (see also  boxcutmin  for\nspeed/accuracy concerns). This is the recommended procedure, of course. \nThe total number of FFT points is the product:  [ngfft] [ngfft] [ngfft] =nfft  . \nWhen  ngfft  is made smaller than recommended values (e.g. by setting boxcutmin  to a value smaller than 2.0 or by setting  ngfft  manually),\nthe code runs faster and the equations in effect are approximated by a low\npass Fourier filter. The code reports to standard output (unit 06) a parameter\n\u201cboxcut\u201d which is the smallest ratio of the fft box side to the G vector basis\nsphere diameter. When boxcut is less than 2 the Fourier filter approximation\nis being used. When boxcut gets less than about 1.5 the approximation may be\ntoo severe for realistic results and should be tested against larger values of ngfft . When boxcut is larger than 2,  ngfft  could be reduced without\nloss of accuracy. In this case, the small variations that are observed are\nsolely due to the xc quadrature, that may be handled with  intxc =1 to even\nreduce this effect.  Internally,  ngfft  is an array of size 18. The present components are\nstored in  [ngfft] , while   [ngfft]  contains slightly different (larger) values, modified for efficiency of the FFT   [ngfft]  is  fftalg    [ngfft]  is  fftcache    [ngfft]  is set to 0 if the parallelization of the FFT is not activated, while it is set to 1 if it is activated.   [ngfft]  is the number of processors of the FFT group   [ngfft]  is the index of the processor in the group of processors   [ngfft]  is n2proc, the number of x-z planes, in reciprocal space, treated by the processor   [ngfft]  is n3proc, the number of x-y planes, in real space, treated by the processor   [ngfft]  is mpi_comm_fft, the handle on the MPI communicator in charge of the FFT parallelisation   [ngfft]  are not yet used    The number of points stored by this processor in real space is n1 n2 n3proc,\nwhile in reciprocal space, it is n1 n2proc n3.",
            "title": "ngfft"
        },
        {
            "location": "/input_variables/vargs/#ngqpt",
            "text": "Mnemonics: Number of Grid pointsfor Q PoinTs generation \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  nqpt ==1 and  kptopt >=0 \nThe use of this variable forbids the use of specified( qptrlatt )    At variance with  ngkpt , note that only one q point is selected per dataset\n(see  iqpt ). \nIts three positive components give the number of q points of Monkhorst-Pack\ngrids (defined with respect to primitive axis in reciprocal space) in each of\nthe three dimensions. The use of  nshiftq  and  shiftq , allows to\ngenerate shifted grids, or Monkhorst-Pack grids defined with respect to\nconventional unit cells.  For more information on Monkhorst-Pack grids, see  ngkpt .",
            "title": "ngqpt"
        },
        {
            "location": "/input_variables/vargs/#nline",
            "text": "Mnemonics: Number of LINE minimisations \nVariable type: integer \nDimensions: scalar \nDefault value: 4    Gives maximum number of line minimizations allowed in preconditioned conjugate\ngradient minimization for each band. The Default, 4, is fine. \nSpecial cases, with degeneracies or near-degeneracies of levels at the Fermi\nenergy may require a larger value of  nline  (5 or 6 ?) Line minimizations\nwill be stopped anyway when improvement gets small. With the input variable nnsclo , governs the convergence of the wavefunctions for fixed potential. \nNote that  nline =0 can be used to diagonalize the Hamiltonian matrix in the\nsubspace spanned by the input wavefunctions.",
            "title": "nline"
        },
        {
            "location": "/input_variables/vargs/#npsp",
            "text": "Mnemonics: Number of PSeudoPotentials \nVariable type: integer \nDimensions: scalar \nDefault value:  ntypat     Usually, the number of pseudopotentials to be read is equal to the number of\ntype of atoms. However, in the case an alchemical mixing of pseudopotential is\nto be used, often the number of pseudopotentials to be read will not equal the\nnumber of types of atoms.  Alchemical pseudopotentials will be present when  ntypalch  is non-zero. See ntypalch  to understand how to use alchemical potentials in ABINIT. The\ninput variables ( ntypalch ,  algalch , mixalch ) are active, and\ngenerate alchemical potentials from the available pseudopotentials. Also, the\ninner variables ( ntyppure , npspalch ) become active. See these input\nvariables, especially  mixalch , to understand how to use alchemical\npotentials in ABINIT.",
            "title": "npsp"
        },
        {
            "location": "/input_variables/vargs/#npspalch",
            "text": "Mnemonics: Number of PSeudoPotentials that are \u201cALCHemical\u201d \nVariable type: integer \nDimensions: scalar \nDefault value:  npsp - ntyppure \nOnly relevant if  ntypalch /=0    Gives the number of pseudopotentials that are used for alchemical mixing (when ntypalch  is non-zero) :  npspalch = npsp - ntyppure",
            "title": "npspalch"
        },
        {
            "location": "/input_variables/vargs/#nqpt",
            "text": "Mnemonics: Number of Q - POINTs \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Determines whether one q point must be read (See the variable  qptn ). \nCan be either 0 or 1. \nIf 1 and used in ground-state calculation, a global shift of all the k-points\nis applied, to give calculation at k+q. In this case, the output wavefunction\nwill be appended by _WFQ instead of _WFK (see the   section 4  of the  help_abinit ) Also,\nif 1 and a RF calculation is done, defines the wavevector of the perturbation.",
            "title": "nqpt"
        },
        {
            "location": "/input_variables/vargs/#nshiftq",
            "text": "Mnemonics: Number of SHIFTs for Q point grids \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This parameter gives the number of shifted grids to be used concurrently to\ngenerate the full grid of q points. It can be used with primitive grids\ndefined either from  ngqpt  or  qptrlatt . The maximum allowed value of nshiftq  is 8. The values of the shifts are given by  shiftq .",
            "title": "nshiftq"
        },
        {
            "location": "/input_variables/vargs/#nspden",
            "text": "Mnemonics: Number of SPin-DENsity components \nVariable type: integer \nDimensions: scalar \nDefault value:  nsppol     If  nspden =1, no spin-magnetization : the density matrix is diagonal, with\nsame values spin-up and spin-down (compatible with  nsppol =1 only, for both nspinor =1 or 2)  If  nspden =2, scalar magnetization (the axis is arbitrarily fixed in the z\ndirection) : the density matrix is diagonal, with different values for spin-up\nand spin-down (compatible with  nspinor =1, either with  nsppol =2\n-general collinear magnetization- or  nsppol =1 -antiferromagnetism)  If  nspden =4, vector magnetization : the density matrix is full, with\nallowed x, y and z magnetization (useful only with  nspinor =2 and nsppol =1, either because there is spin-orbit without time-reversal\nsymmetry - and thus spontaneous magnetization, or with spin-orbit, if one\nallows for spontaneous non-collinear magnetism). Not yet available for\nresponse functions. Also note that, with  nspden =4, time-reversal symmetry\nis not taken into account (at present ; this has to be checked) and thus kptopt  has to be different from 1 or 2.  The default ( nspden = nsppol ) does not suit the case of vector\nmagnetization.",
            "title": "nspden"
        },
        {
            "location": "/input_variables/vargs/#nspinor",
            "text": "Mnemonics: Number of SPINORial components of the wavefunctions \nVariable type: integer \nDimensions: scalar \nDefault value: 2 if  pawspnorb ==1,\n1 otherwise.  If  nspinor =1, usual case : scalar wavefunction (compatible with\n( nsppol =1,  nspden =1) as well as ( nsppol =2,  nspden =2) )  If  nspinor =2, the wavefunction is a spinor (compatible with  nsppol =1,\nwith  nspden =1 or 4, but not with  nsppol =2)  When  nspinor  is 2, the values of  istwfk  are automatically set to 1.\nAlso, the number of bands, for each k-point, should be even.",
            "title": "nspinor"
        },
        {
            "location": "/input_variables/vargs/#ntypalch",
            "text": "Mnemonics: Number of TYPe of atoms that are \u201cALCHemical\u201d \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used for the generation of alchemical pseudopotentials : when  ntypalch  is\nnon-zero, alchemical mixing will be used.  Among the  ntypat  types of atoms, the last  ntypalch  will be\n\u201calchemical\u201d pseudoatoms, while only the first   ntyppure   will be uniquely\nassociated with a pseudopotential (the   ntyppure   first of these,\nactually). The  ntypalch  types of alchemical pseudoatoms are to be made\nfrom the remaining  npspalch  pseudopotentials.  In this case, the input variables  algalch , mixalch  are active, and\ngenerate alchemical potentials from the available pseudopotentials. See these\ninput variables, especially  mixalch , to understand how to use alchemical\npotentials in ABINIT.",
            "title": "ntypalch"
        },
        {
            "location": "/input_variables/vargs/#ntyppure",
            "text": "Mnemonics: Number of TYPe of atoms that are \u201cPURe\u201d \nVariable type: integer \nDimensions: scalar \nDefault value:  ntypat - ntypalch     Gives the number of type of atoms that are \u201cpure\u201d when alchemical mixing is\nused ( ntypalch  /= 0) :  ntyppure = ntypat - ntypalch",
            "title": "ntyppure"
        },
        {
            "location": "/input_variables/vargs/#nucdipmom",
            "text": "Mnemonics: NUClear DIPole MOMents \nVariable type: real \nDimensions: (3, natom ) \nDefault value: 0.0 \nOnly relevant if  usepaw  = 1;  pawcpxocc  = 2;  kptopt  > 2    Places an array of nuclear magnetic dipole moments on the atomic positions,\nuseful for computing the magnetization in the presence of nuclear dipoles and\nthus the chemical shielding by the converse method. The presence of these\ndipoles breaks time reversal symmetry and lowers the overall spatial symmetry.",
            "title": "nucdipmom"
        },
        {
            "location": "/input_variables/vargs/#nwfshist",
            "text": "Mnemonics: Number of WaveFunctionS HISTory \nVariable type: integer \nDimensions: scalar \nDefault value: 0    In the wavelet basis set, the ground state is found by direct minimisation.\nThe algorithm used can be either the steepest descent or the DIIS (Direct\nInversion of Iteration Space). When  nwfshist  = 0, the steepest descent is\nused ( _ i.e. _ there is no history storage of the previous iterations). If nwfshist  is strictly positive, a DIIS is used. A typical value is 6. Using\na DIIS increases the memory required by the program since N previous\nwavefunctions are stored during the electronic minimisation.",
            "title": "nwfshist"
        },
        {
            "location": "/input_variables/vargs/#occ",
            "text": "Mnemonics: OCCupation numbers \nVariable type: real \nDimensions: ( nband ) \nDefault value: *0    Gives occupation numbers for all bands in the problem. Needed if  occopt ==0\nor  occopt ==2. Ignored otherwise. Also ignored when  iscf =-2. \nTypical band occupancy is either 2 or 0, but can be 1 for half-occupied band\nor other choices in special circumstances. \nIf  occopt  is not 2, then the occupancies must be the same for each k\npoint. \nIf  occopt =2, then the band occupancies must be provided explicitly for\neach band, EACH k POINT, and EACH SPIN-POLARIZATION, in an array which runs\nover all bands, k points, and spin-polarizations. \nThe order of entries in the array would correspond to all bands at the first k\npoint (spin up), then all bands at the second k point (spin up), etc, then all\nk-points spin down. \nThe total number of array elements which must be provided is \n(  [nband] + [nband] +\u2026+  [nband]  ) *  nsppol  . \nThe occupation numbers evolve only for metallic occupations, that is, occopt  \u2265 3 .",
            "title": "occ"
        },
        {
            "location": "/input_variables/vargs/#optdriver",
            "text": "Mnemonics: OPTions for the DRIVER \nVariable type: integer \nDimensions: scalar \nDefault value: 0    For each dataset, choose the task to be done, at the level of the \u201cdriver\u201d\nroutine.  The choice is among :  optdriver =0 : ground-state calculation (GS), routine \u201cgstate\u201d  optdriver =1 : response-function calculation (RF), routine \u201crespfn\u201d  optdriver =2 : susceptibility calculation (SUS), routine \u201csuscep\u201d  optdriver =3 : susceptibility and dielectric matrix calculation (SCR),\nroutine \u201cscreening\u201d \n(see the input variables  ecutwfn ,  ecuteps ,  ppmfrq ,  getwfk , as\nwell as  nbandkss  and  nband )  optdriver =4 : self-energy calculation (SIG), routine \u201csigma\u201d  optdriver =5 : non-linear response functions (NONLINEAR), using the 2n+1\ntheorem, routine \u201cnonlinear\u201d  optdriver  =7: electron-phonon coupling (EPH)  optdriver  =66: GW using Lanczos-Sternheimer, see input variables whose\nname start with gwls_* .  optdriver =99 : Bethe-Salpeter calculation (BSE), routine \u201cbethe_salpeter\u201d  If one of  rfphon ,  rfddk ,  rfelfd , or  rfstrs  is non-zero, while optdriver  is not defined in the input file, ABINIT will set  optdriver \nto 1 automatically. These input variables ( rfphon ,  rfddk ,  rfelfd ,\nand  rfstrs ) must be zero if  optdriver  is not set to 1.",
            "title": "optdriver"
        },
        {
            "location": "/input_variables/vargs/#optstress",
            "text": "Mnemonics: OPTion for the computation of STRESS \nVariable type: integer \nDimensions: scalar \nDefault value: 1    If set to 1, the computation of stresses is done, in the SCF case (under the\nconditions  iscf  > 0 ,  prtstm ==0 ,  positron ==0, and either nstep  >0 , or  usepaw ==0 or  irdwfk ==1). \nOtherwise, to save CPU time, if no optimization of the cell is required, one\ncan skip the computation of stresses. The CPU time saving might be interesting\nfor some PAW calculations.",
            "title": "optstress"
        },
        {
            "location": "/input_variables/vargs/#posdoppler",
            "text": "Mnemonics: POSitron computation of DOPPLER broadening \nVariable type: integer \nDefault value: 0    Relevant only when  positron <>0. \nThis input parameter activates the calculation of the Doppler broadening of\nthe electron-positron annihilation radiation. \nAn output file containing the momentum distributions of annihilating electron-\npositron pairs is created. \nSuch a computation needs a core wave-function file (per atom type) to be\nprovided. This core WF file should be named \u2018<psp_file_name>.corewf\u2019\n(where <pspfile_name> is the name of the pseudo-potential (or PAW) file)\nor \u2018corewf.abinit<ityp>\u2018 (where <ityp> is the index of the atom\ntype). Core WF files can be obtained with the atompaw tool by the use of\n\u2018prtcorewf\u2019 keyword.",
            "title": "posdoppler"
        },
        {
            "location": "/input_variables/vargs/#positron",
            "text": "Mnemonics: POSITRON calculation \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This input parameter can be positive or negative. \nNegative values for  positron  are only relevant for PAW calculations. \nElectron-positron correlation functional is defined by  ixcpositron . \nOther relevant input parameter:  posocc  (occupation number for the\npositron).    Positive values for  positron :  For  positron =1 or 2 , will perform the calculation of positron\nlifetime (and annihilation rate).      positron =1 : \nStarting from a previous electronic GS density (with  positron =0**), a\npositronic ground-state calculation is performed, considering that the\nelectrons are not perturbed by the presence of the positron. \nThis is almost correct for a positron in a perfect bulk material. But this\napproximation fails when defects exist in the material (for instance: the\npositron might be trapped by a vacancy). \nThe electronic density will be automatically read from a _DEN file (with or\nwithout  irdden  keyword). \nAt the end of the SCF cycle, the positron lifetime and annihilation rate are\nprinted out.     _Additional information for the use of pseudopotentials:    *   PAW   datasets :   nothing   to   do ;   simply   use   usual   electronic   PAW   datasets   *   Norm-conserving   pseudopotentials :   One   has   to   use   specific   pseudopotentials   for   the   positron   calculation .   They   must   be   of   the   FHI   type   ( pspcod = 6 ),   and   must   contain   at   their   end ,   the   all-electrons   core   density   generated   with   FHI98PP .   They   must   have   lmax = lloc = 0   ( check   that   this   works   for   the   electronic   GS   !!   No   ghost ,   etc   ...).   Otherwise ,   their   are   similar   to   an   usual   FHI   pseudopotential .   _     positron=2 : \nStarting from a previous positronic GS density (with  positron=1 ), an\nelectronic ground-state calculation is performed, keeping the positronic\ndensity constant. \nThe positronic density will be automatically read from a _DEN file (with or\nwithout  getden / irdden  keyword). \nAt the end of the SCF cycle, the positron lifetime and annihilation rate are\nprinted out.     _Additional information for the use of pseudopotentials:    *   PAW   datasets :   nothing   to   do ;   simply   use   usual   electronic   PAW   datasets   *   Norm-conserving   pseudopotentials :   One   has   to   use   specific   pseudopotentials   for   the   electron   calculation .   They   must   be   of   the   FHI   type   ( pspcod = 6 ),   and   must   contain   at   their   end ,   the   all-electrons   core   density   generated   with   FHI98PP .   _     Typical use : \nThe calculation is done in several steps: \nThe first one is a normal GS calculation for the electrons, with positron =0. The only specific thing to do is to set  prtden =1 (this is\nthe defaut for ABINIT v6.x+). This will create the associated _DEN file which\nwill be used as input file for the positronic GS calculation. \nThe second step is the GS calculation of the positron and subsequently its\nlifetime, with  positron =1. One has to define also  ixcpositron . \nThen, it is possible to perform an additional step, computing the GS\nelectronic density in presence of the positron, with  positron =2. \nand so on\u2026 \nThis procedure can be automated (for PAW only) by the use of a negative value\nfor  positron . \nAt the end, a converged value of the positron lifetime (decomposed in several\ncontributions) is printed. \nSee also  posdoppler  keyword for the calculation of Doppler broadening.     Negative values for  positron :  For  positron<0 , will perform an automatic calculation of electrons and\npositron densities in the two-component DFT context; then will compute\npositron lifetime (and annihilation rate).       positron=-1 : \nStarting from scratch, will first perform an usual electronic ground-state\ncalculation until convergence (controlled by the use of one of the  tolerance \nkeywords). \nThen will perform a positronic ground state calculation in presence of the\nelectrons and ions; then an electronic ground state calculation in presence of\nthe positron and the ions\u2026 \nand so on\u2026 until the total energy is converged. \nThe convergence of the total energy of the ions+electrons+positron system is\ncontrolled by the use of the  postoldfe ,  postoldff  and  posnstep \ninput keywords. \nWith  positron=-1 , at the beginning of each new electronic/positronic step,\nthe wave functions are unknown.    positron=-10 : \nSame as  positron=-1  except that the electronic/positronic wave functions\nare stored in memory. \nConsequently, the total number of iterations to reach the convergence\n(diff_Etotal< postoldfe  or diff_Forces< postoldff ) is smaller. \nBut, this can increase the total amount of memory needed by the code.    positron=-2 : \nSame as  positron=-1  except that the two-component DFT cycle is forced to\nstop at the end of an electronic step.    positron=-20 : \nSame as  positron=-10  except that the two-component DFT cycle is forced to\nstop at the end of an electronic step.    Advice for use: \nThere are two typical cases which have to be differently treated:    A positron in a perfect  bulk  system : \nIn that case, the positron is delocalized in the whole crystal. Its density is\nalmost zero. \nThus, the \u201czero density positron limit\u201d has to be used.  ixcpositron  has to\nbe choosen accordingly. \nIn order to have the zero density positron limit it is adviced to follow these\npoints: \n1- Put a small positronic charge (by setting a  posocc  to a small value) OR  use a big supercell. \n2- Use only k=gamma wave vector for the positronic calculation. \n3- Use the manual procedure in 2 steps: first  positron =0 and then positron =1; avoid the  positron=2  step and the automatic procedure\n( positron <0). \nIn principle, the positron lifetime should converge with the value of posocc  or the size of the supercell.      A positron trapped in a  default  (vacancy\u2026) : \nIn that case, the positron is localized in the default. Its density can be\nlocalized in the simulation cell (provided that the cell is sufficiently\nlarge) and influences the electronic density. \nSo, it is advised to use the automatic procedure ( positron <0) or the\nmanual procedure with several  positron =0,1,2,1,\u2026 steps. \nK-points can be used as in usual electronic calculations. \nAlso note that it is possible to use forces and stresses to perform structural\nminimization.      References:    [1]  J. Arponen and E. Pajanne, Ann. Phys. (N.Y.) 121, 343 (1979).  [2]  Boronski and R.M. Nieminen, Phys. Rev. B 34, 3820 (1986).  [3]  P.A. Sterne and J.H. Kaiser, Phys. Rev. B 43, 13892 (1991).  [4]  M.J. Puska, A.P. Seitsonen and R.M. Nieminen, Phys. Rev. B 52, 10947 (1994).  [5]  B. Barbiellini, M.J. Puska, T. Torsti and R.M.Nieminen, Phys. Rev. B 51, 7341 (1994)",
            "title": "positron"
        },
        {
            "location": "/input_variables/vargs/#posnstep",
            "text": "Mnemonics: POSitron calculation: max. Number of STEPs for the two-component DFT \nVariable type: integer \nDimensions: scalar \nDefault value: 50    Relevant only when  positron <0. \nSets the maximum number of electronic/positronic iterations that, when\nreached, will cause the two-component DFT SCF cycle to stop. \nThe code will first compute the electronic ground-state, then the positronic\nground state in the electronic density, then the electronic ground-state in\nthe positronic density, \u2026 \n\u2026until diff_Etotal< postoldfe  or diff_Forces< postoldff  or the\nnumber of electronic/positronic steps is  posnstep .",
            "title": "posnstep"
        },
        {
            "location": "/input_variables/vargs/#posocc",
            "text": "Mnemonics: POSitron calculation: OCCupation number for the positron \nVariable type: real \nDimensions: scalar \nDefault value: 1    Relevant only when  positron /=0. \nSets the occupation number for the positron. Has to be <=1. \nChanging  posocc  is only useful for bulk calculation when one wants to\nperform lifetime computations using a small simulation cell (can avoid the use\nof a supercell). It simulates the dispersion of the positron in the whole\ncrystal.",
            "title": "posocc"
        },
        {
            "location": "/input_variables/vargs/#postoldfe",
            "text": "Mnemonics: POSitron calculation: TOLerance on the DiFference of total Energy \nVariable type: real \nDimensions: scalar \nDefault value: 1e-06 if  postoldff =0,\n0.0 otherwise.  Relevant only when  positron <0. \nSets a tolerance for absolute difference of total energy (of _\nions+electrons+positron _ system) that, when reached, will cause the SCF cycle\nto stop before the number of steps is  nstep  or the number of\nelectronic/positronic steps is  posnstep .    Can be specified in Ha (the default), Ry, eV or Kelvin, since   toldfe   has\nthe \u2018 ENERGY \u2018 characteristics. \nOnly one and only one of  postoldfe  or  postoldff  can be set.",
            "title": "postoldfe"
        },
        {
            "location": "/input_variables/vargs/#postoldff",
            "text": "Mnemonics: POSitron calculation: TOLerance on the DiFference of Forces \nVariable type: real \nDimensions: scalar \nDefault value: 0    Relevant only when  positron <0. \nSets a tolerance for absolute difference of maximum force acting on ions (due\nto _ ions+electrons+positron _ system) that, when reached, will cause the SCF\ncycle to stop before the number of SCF steps is  nstep  or the number of\nelectronic/positronic steps is  posnstep . \nOnly one and only one of  postoldfe  or  postoldff  can be set.",
            "title": "postoldff"
        },
        {
            "location": "/input_variables/vargs/#prtdensph",
            "text": "Mnemonics: PRinT integral of DENsity inside atomic SPHeres \nVariable type: integer \nDimensions: scalar \nDefault value: 1 otherwise.  When this flag is activated, values of integral(s) of total density inside\nsphere(s) around each atom are printed in output file (for each spin\ncomponent). Spheres around atoms are defined by a radius given by  ratsph \nkeyword. \nNote: integral of density inside a sphere around an atom can be used to\ndetermine a rough approximation of the local magnetic moment; this is\nparticularly useful for antiferromagnetic systems. \nThe algorithm to compute this integral is particularly primitive : the points\non the FFT grids, belonging to the interior of the sphere are determined, and\nthe value of the functions on these points are summed, taking into account a\nfixed volume attributed to each point. In particular, the integral as a\nfunction of the radius will be a constant, except when a new point enters the\nsphere, in which case a sudden jump occurs. However, since the purpose of this\noutput is to get a rough idea of the repartition of the density, this is not a\nreal problem. If you are interested in a more accurate estimation of the\ndensity within a sphere, you should use the cut3d postprocessor.",
            "title": "prtdensph"
        },
        {
            "location": "/input_variables/vargs/#prtebands",
            "text": "Mnemonics: PRinT Electron BANDS \nVariable type: integer \nDimensions: scalar \nDefault value: 0 if  nimage  > 1,\n1 otherwise.  This option activates the output of the electron eigenvalues. Possible values:   0 Disable the output of the band energies.  1 Write eigenvalues in xmgrace format. A file with extension  EBANDS.agr  is produced at the end of the run. Use  xmgrace file_EBANDS.agr  to visualize the band energies  2 Write eigenvalues in gnuplot format. The code produces a  EBANDS.dat  file with the eigenvalues and a  EBANDS.gnuplot  script. Use  gnuplot file_EBANDS.gnuplot  to visualize the band energies.",
            "title": "prtebands"
        },
        {
            "location": "/input_variables/vargs/#qpt",
            "text": "Mnemonics: Q PoinT \nVariable type: real \nDimensions: (3) \nDefault value: [0, 0, 0]    Only used if  nqpt =1.  Combined with  qptnrm , define the q vector  [qptn]  in the case qptopt =0.  This input variable is not internal ( [qptn]  is used instead), but is\nused to echo the value of  [qptn] , with renormalisation factor one.",
            "title": "qpt"
        },
        {
            "location": "/input_variables/vargs/#qptnrm",
            "text": "Mnemonics: Q PoinTs NoRMalization \nVariable type: real \nDimensions: scalar \nDefault value: 1.0    Only used if  nqpt =1 and  qptopt =0  Provides re-normalization of  qpt . Must be positive, non-zero. The actual q\nvector (renormalized) is  [qptn] =  [qpt] / qptnrm .",
            "title": "qptnrm"
        },
        {
            "location": "/input_variables/vargs/#qptopt",
            "text": "Mnemonics: QPoinTs OPTion \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Only used if  nqpt =1.  Controls the set up to generate the Q point  [qptn]  to be used for the\nspecific dataset, either as a shift of k-point grid in ground-state\ncalculations, or as a stand-alone phonon wavevector.  There are two basic techniques to generate the Q point : either by specifying\nit directly, possibly with a renormalisation factor ( qptopt =0), or\nextracting it from a grid a Q points ( qptopt =1 to 4), using the index iqpt . At variance with the similar generation of k points, only ONE q\npoint can be used per dataset.  With  qptopt =1 to 4, rely on  ngqpt  or  qptrlatt , as well as on nshiftq  and  shiftq  to set up a q point grid, from which the q point\nwith number  iqpt  will be selected. The values  qptopt =1 to 4 differ by\nthe treatment of symmetries. Note that the symmetries are recomputed starting\nfrom the values of  rprimd   xred  and  spinat . So, the explicit value\nof  symrel  are not used. This is to allow doing calculations with nsym =1, sometimes needed for T-dependent electronic structure, still\ndecreasing the number of q points in the case  qptopt =1 or  qptopt =3.   0=> read directly  qpt , and its (eventual) renormalisation factor  qptnrm .    1=> Take fully into account the symmetry to generate the grid of q points in the Irreducible Brillouin Zone only.  \n(This is the usual mode for RF calculations)    2=> Take into account only the time-reversal symmetry : q points will be generated in half the Brillouin zone.       3=> Do not take into account any symmetry : q points will be generated in the full Brillouin zone.       4=> Take into account all the symmetries EXCEPT the time-reversal symmetry to generate the k points in the Irreducible Brillouin Zone.       In the case of a grid of q points, the auxiliary variables  kptrlen , ngkpt  and  prtkpt  might help you to select the optimal grid, similarly\nto the case of the K point grid.",
            "title": "qptopt"
        },
        {
            "location": "/input_variables/vargs/#qptrlatt",
            "text": "Mnemonics: Q - PoinTs grid : Real space LATTice \nVariable type: integer \nDimensions: (3,3) \nDefault value: *0 \nThe use of this variable forbids the use of specified( ngqpt )    This input variable is used only when  qptopt  is positive. It partially\ndefines the q point grid. The other piece of information is contained in shiftq .  qptrlatt  cannot be used together with  ngqpt .  The values  [qptrlatt] ,  [qptrlatt] ,  [qptrlatt]  are\nthe coordinates of three vectors in real space, expressed in the  rprimd \ncoordinate system (reduced coordinates). They defines a super-lattice in real\nspace. The k point lattice is the reciprocal of this super-lattice, possibly\nshifted (see  shiftq ).  If neither  ngqpt  nor  qptrlatt  are defined, ABINIT will automatically\ngenerate a set of k point grids, and select the best combination of qptrlatt  and  shiftq  that allows to reach a sufficient value of kptrlen . See this latter variable for a complete description of this\nprocedure.",
            "title": "qptrlatt"
        },
        {
            "location": "/input_variables/vargs/#ratsph",
            "text": "Mnemonics: Radii of the ATomic SPHere(s) \nVariable type: real \nDimensions: ( ntypat ) \nDefault value: [[\u2018AUTO_FROM_PSP\u2019]] if usepaw==1,\n2.0 otherwise.  Relevant only when  prtdos =3 or  prtdensph =1.    When  prtdos =3: \nProvides the radius of the spheres around the  natsph  atoms of indices iatsph , in which the local DOS and its angular-momentum projections will\nbe analysed. The choice of this radius is quite arbitrary. In a plane-wave\nbasis set, there is no natural definition of an atomic sphere. However, it\nmight be wise to use the following well-defined and physically motivated\nprocedure (in version 4.2, this procedure is NOT implemented, unfortunately) :\nfrom the Bader analysis, one can define the radius of the sphere that contains\nthe same charge as the Bader volume. This \u201cEquivalent Bader charge atomic\nradius\u201d might then be used to perform the present analysis. See the help_aim  for more explanations. Another physically motivated choice would\nbe to rely on another charge partitioning, like the Hirshfeld one (see the\ncut3d utility). The advantage of using charge partitioning schemes comes from\nthe fact that the sum of atomic DOS, for all angular momenta and atoms,\nintegrated on the energy range of the occupied states, gives back the total\ncharge. If this is not an issue, one could rely on the half of the nearest-\nneighbour distances, or any scheme that allows to define an atomic radius.\nNote that the choice of this radius is however critical for the balance\nbetween the s, p and d components. Indeed, the integrated charge within a\ngiven radius, behave as a different power of the radius, for the different\nchannels s, p, d. At the limit of very small radii, the s component dominates\nthe charge contained in the sphere \u2026    When  prtdensph =1: \nProvides the radius of the spheres around (all) atoms in which the total\ncharge density will be integrated.    In case of PAW,  ratsph  radius has to be greater or equal to PAW radius of\nconsidered atom type (which is read from the PAW dataset file; see rc_sph or\nr_paw).",
            "title": "ratsph"
        },
        {
            "location": "/input_variables/vargs/#ratsph_extra",
            "text": "Mnemonics: Radii of the ATomic SPHere(s) in the EXTRA set \nVariable type: real \nDimensions: scalar \nDefault value: 2.0 Bohr    Radius for extra spheres the DOS is projected into. See  natsph_extra  and xredsph_extra  for the number and positions of the spheres.",
            "title": "ratsph_extra"
        },
        {
            "location": "/input_variables/vargs/#scphon_supercell",
            "text": "Mnemonics: Self Consistent PHONon SUPERCELL \nVariable type: integer \nDimensions: (3) \nDefault value: [1, 1, 1]    Give extent, in number of primitive unit cells, of the supercell being used\nfor a self-consistent phonon calculation. Presumes the phonon frequencies and\neigenvectors have been calculated in the original primitive unit cell, on a\ngrid of q-points which corresponds to the supercell in the present\ncalculation. TO BE IMPROVED : should contain a tutorial on how to do self-\nconsistent phonon calculations, David Waroquiers 090831",
            "title": "scphon_supercell"
        },
        {
            "location": "/input_variables/vargs/#scphon_temp",
            "text": "Mnemonics: Self Consistent PHONon TEMPerature \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    Temperature which is imposed on phonon distribution, in the self-consistent\nscheme of Souvatzis et al. PRL   100   , 095901. Determines the extent of\nthe finite displacements used, and consequent anharmonic effects.\nExperimental.",
            "title": "scphon_temp"
        },
        {
            "location": "/input_variables/vargs/#shiftq",
            "text": "Mnemonics: SHIFT for Q points \nVariable type: real \nDimensions: (3, nshiftq ) \nDefault value: None if  nshiftq >1,\n[0.5, 0.5, 0.5] otherwise.  It is used only when  qptopt >=0, and must be defined if  nshiftq  is\nlarger than 1.  [shiftq]  defines  nshiftq  shifts of the homogeneous\ngrid of q points based on  ngqpt  or  qptrlatt .  See  shiftk  for more information on the definition, use, and suitable\nvalues for these shifts.",
            "title": "shiftq"
        },
        {
            "location": "/input_variables/vargs/#slabwsrad",
            "text": "Mnemonics: jellium SLAB Wigner-Seitz RADius \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    Fix the bulk-mean positive charge density nbulk of a jellium slab (if the\nlatter is employed, e.g.  jellslab  \u2260 0). Often called \u201crs\u201d [see for example\nN. D. Lang and W. Kohn PRB 1, 4555 (1970)],  slabwsrad  is the radius of a\nsphere which has the same volume as the average volume per particle in a\nhomogeneous electron gas with density nbulk, so:    1/nbulk = 4/3 Pi * [[slabwsrad]]3  For example, the bulk aluminum fcc lattice constant is a=4.0495 Angstroms\n(webelements.com), each cubic centered cell includes 4 Al atoms and each atom\nhas 3 valence electrons, so the average volume per electron is a3/12=37.34\nBohr3 which has to be equal to 4/3 Pi*rs3. Consequently Al has approximately\nrs =2.07 Bohr, while for example magnesium has rs =2.65 Bohr, sodium 3.99\nBohr. \nBy default, given in Bohr atomic units (1 Bohr=0.5291772108 Angstroms).",
            "title": "slabwsrad"
        },
        {
            "location": "/input_variables/vargs/#slabzbeg",
            "text": "Mnemonics: jellium SLAB BEGinning edge along the Z direction \nVariable type: real \nDimensions: scalar \nDefault value: [0.0, 0.0]    Define the edges of the jellium slab (if used, so if  jellslab  \u2260 0) along\nz, namely the slab starts at a point along z which is expressed in Bohr by slabzbeg  and it ends at a point expressed in Bohr by  slabzend . The z\ndirection is parallel to the third crystal primitive lattice vector which has\nto be orthogonal to the other ones, so the length of the cell along z is [rprimd] . In addition  slabzbeg  and  slabzend  have to be such\nthat:    0 \u2264 **slabzbeg** < [[slabzend]] \u2264 [[rprimd]](3,3)  Together with  slabwsrad  they define the jellium positive charge density\ndistribution n+(x,y,z) in this way:    n+(x,y,z) = nbulk     if **slabzbeg** \u2264 z \u2264 [[slabzend]]\n            = 0        otherwise,  so the positive charge density is invariant along the xy plane as well as the\nelectrostatic potential generated by it.",
            "title": "slabzbeg"
        },
        {
            "location": "/input_variables/vargs/#slabzend",
            "text": "Mnemonics: jellium SLAB ENDing edge along the Z direction \nVariable type: real \nDimensions: scalar \nDefault value: [0.0, 0.0]    Define the edges of the jellium slab (if used, so if  jellslab  \u2260 0) along\nz, namely the slab starts at a point along z which is expressed in Bohr by slabzbeg  and it ends at a point expressed in Bohr by  slabzend . The z\ndirection is parallel to the third crystal primitive lattice vector which has\nto be orthogonal to the other ones, so the length of the cell along z is [rprimd] . In addition  slabzbeg  and  slabzend  have to be such\nthat:    0 \u2264 [[slabzbeg]] < **slabzend** \u2264 [[rprimd]](3,3)  Together with  slabwsrad  they define the jellium positive charge density\ndistribution n+(x,y,z) in this way:    n+(x,y,z) = nbulk     if [[slabzbeg]] \u2264 z \u2264 **slabzend**\n            = 0        otherwise,  so the positive charge density is invariant along the xy plane as well as the\nelectrostatic potential generated by it.",
            "title": "slabzend"
        },
        {
            "location": "/input_variables/vargs/#so_psp",
            "text": "Mnemonics: Spin-Orbit treatment for each PSeudoPotential \nVariable type: integer \nDimensions: ( npsp ) \nDefault value:  npsp *1 \nOnly relevant if  nspinor ==2 and  usepaw ==0    For each type of atom (each pseudopotential), specify the treatment of spin-\norbit interaction (if  nspinor ==2 and Norm-conserving pseudopotentials usepaw ==0) \nIf 0 : no spin-orbit interaction, even if  nspinor =2 \nIf 1 : treat spin-orbit as specified in the pseudopotential file. \nIf 2 : treat spin-orbit in the HGH form (usual form, although not allowed for\nall pseudopotentials) \nIf 3 : treat spin-orbit in the HFN form (Hemstreet-Fong-Nelson) (actually, not\nimplemented \u2026).  For typical usage, the default value is OK. If the spin-orbit needs to be\nturned off for one atom, 0 might be relevant. Note however, that the code will\nstop if  nspinor =2 is used and one of the pseudopotential does not contain\nthe information about the spin-orbit interaction (this is the case for some\nold pseudopotentials). Indeed, for spinorial calculations, turning off the\nspin-orbit interaction is unphysical, and also does not save CPU time \u2026 It\nshould only be done for test purposes  Note that if  nspinor ==1, the spin-orbit cannot be treated anyhow, so the\nvalue of  so_psp  is irrelevant. In case  usepaw =1, please refer to pawspnorb .  Prior to v5.4, the input variable   so_typat   was used, in place of so_psp . Because the values 0 and 1 have been switched between  so_psp \nand so_typat, it was dangerous to continue to allow the use of so_typat.",
            "title": "so_psp"
        },
        {
            "location": "/input_variables/vargs/#spinat",
            "text": "Mnemonics: SPIN for AToms \nVariable type: real \nDimensions: [3, \u2018 natrd \u2019] if  natrd < natom ,\n[3, \u2018 natom \u2019] otherwise.  Default value: 0.0    Gives the initial electronic spin-magnetization for each atom, in unit of\nh-bar/2.  Note that if  nspden =2, the z-component must be given for each atom, in\ntriplets (0 0 z-component). \nFor example, the electron of an hydrogen atom can be spin up (0 0 1.0) or spin\ndown (0 0 -1.0).  This value is only used to create the first exchange and correlation\npotential, and is not used anymore afterwards. \nIt is not checked against the initial occupation numbers  occ  for each spin\nchannel. \nIt is meant to give an easy way to break the spin symmetry, and to allow to\nfind stable local spin fluctuations, for example : antiferromagnetism, or the\nspontaneous spatial spin separation of elongated H2 molecule.      If the geometry builder is used,  spinat  will be related to the preprocessed set of atoms, generated by the geometry builder. The user must thus foresee the effect of this geometry builder (see  objarf ).     If the geometry builder is not used, and the symmetries are not specified by the user ( nsym =0), spinat will be used, if present, to determine the anti-ferromagnetic characteristics of the symmetry operations, see  symafm .  \nIn case of collinear antiferromagnetism ( nsppol =1,  nspinor =1, nspden =2), these symmetries are used to symmetrize the density. \nIn case of non-collinear magnetism ( nsppol =1,  nspinor =1, nspden =4), they are also used to symmetrize the density. In the latter\ncase, this strongly constrains the magnetization (imposing its direction). If\nthe user want to let all degrees of freedom of the magnetization evolve, it is\nthen recommended to put  nsym =1.      If the symmetries are specified, and the irreducible set of atoms is specified, the anti-ferromagnetic characteristics of the symmetry operations  symafm  will be used to generate  spinat  for all the non-irreducible atoms.     In the case of PAW+U calculations using the  dmatpawu  initial occupation matrix, and if  nspden =4,  spinat  is also used to determine the direction of the integrated magnetization matrix.",
            "title": "spinat"
        },
        {
            "location": "/input_variables/vargs/#stmbias",
            "text": "Mnemonics: Scanning Tunneling Microscopy BIAS voltage \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    Gives, in Hartree, the bias of the STM tip, with respect to the sample, in\norder to generate the STM density map. \nUsed with positive  iscf ,  occopt =7 (metallic, gaussian),  nstep =1 ,\nand positive  prtstm , this value is used to generate a charge density map\nfrom electrons close to the Fermi energy, in a (positive or negative) energy\nrange. Positive  stmbias  will lead to the inclusion of occupied (valence)\nstates only, while negative  stmbias  will lead to the inclusion of\nunoccupied (conduction) states only. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since  stmbias  has\nthe \u2018 ENERGY \u2018 characteristics (0.001 Ha = 27.2113845 meV = 315.773 Kelvin).\nWith  occopt =7, one has also to specify an independent broadening tsmear .",
            "title": "stmbias"
        },
        {
            "location": "/input_variables/vargs/#symafm",
            "text": "Mnemonics: SYMmetries, Anti-FerroMagnetic characteristics \nVariable type: integer \nDimensions: ( nsym ) \nDefault value:  nsym *1    In case the material is magnetic (well, this is only interesting in the case\nof antiferromagnetism, collinear or not), additional symmetries might appear,\nthat change the sign of the magnetization. They have been introduced by\nShubnikov (1951). They can be used by ABINIT to decrease the CPU time, by\nusing them to decrease the number of k-points.  symafm  should be set to +1 for all the usual symmetry operations, that do\nnot change the sign of the magnetization, while it should be set to -1 for the\nmagnetization-changing symmetries. \nIf the symmetry operations are not specified by the user in the input file,\nthat is, if  nsym =0, then ABINIT will use the values of  spinat  to\ndetermine the content of  symafm . \nThe symmetries found as \u201cantiferro magnetic\u201d ( symafm =-1) are used to\nsymmetrize density and magnetization in the following cases: \n- antiferromagnetism ( nsppol =1,  nspinor =1,  nspden =2) \n- non-collinear magnetism ( nsppol =1,  nspinor =1,  nspden =4) \nIn other cases they are not used.",
            "title": "symafm"
        },
        {
            "location": "/input_variables/vargs/#timopt",
            "text": "Mnemonics: TIMing OPTion \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  SEQUENTIAL ,\n0 otherwise.  This input variable allows to modulate the use of the timing routines.  If 0 => as soon as possible, suppresses all calls to timing routines \nIf 1 => usual timing behaviour, with short analysis, appropriate for\nsequential execution \nIf 2 => close to  timopt =1, except that the analysis routine does not\ntime the timer, appropriate for parallel execution. \nIf 3 => close to  timopt =1, except that the different parts of the\nlobpcg routine are timed in detail. \nIf 4 => close to  timopt =1, except that the different parts of the\nlobpcg routine are timed in detail. A different splitting of lobpcg than for timopt =-3 is provided. \nIf -1 => a full analysis of timings is delivered \nIf -2 => a full analysis of timings is delivered, except timing the timer \nIf -3 => a full analysis of timings is delivered, including the detailed\ntiming of the different parts of the lobpcg routine. (this takes time, and is\ndiscouraged for too small runs - the timing would take more time than the run\n!). The timer is timed. \nIf -4 => a full analysis of timings is delivered, including the detailed\ntiming of the different parts of the lobpcg routine. A different splitting of\nlobpcg than for  timopt =-3 is provided (this takes time, and is discouraged\nfor too small runs - the timing would take more time than the run !). The\ntimer is timed. The sum of the independent parts is closer to 100% than for timopt =-3.",
            "title": "timopt"
        },
        {
            "location": "/input_variables/vargs/#tl_nprccg",
            "text": "Mnemonics: TaiL maximum Number of PReConditionner Conjugate Gradient iterations \nVariable type: integer \nDimensions: scalar \nDefault value: 30    This variable is similar to  wvl_nprccg  but for the preconditionner\niterations during the tail corrections (see  tl_radius   ). TO BE IMPROVED :\nall tl_  and wvl_  variables should contain a link to a tutorial, David\nWaroquiers 090831.",
            "title": "tl_nprccg"
        },
        {
            "location": "/input_variables/vargs/#tl_radius",
            "text": "Mnemonics: TaiL expansion RADIUS \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    In the wavelet computation case, the linkage between the grid and the free\nboundary conditions can be smoothed using an exponential decay. This means a\ncorrection on the energy at the end on each wavefunction optimisation run. If\nthis parameter is set to zero, no tail computation is done. On the contrary,\nput it to a positive value makes the tail correction available. The value\ncorrespond to a length in atomic units being the spacial expansion with the\nexponential decay around the grid.",
            "title": "tl_radius"
        },
        {
            "location": "/input_variables/vargs/#tphysel",
            "text": "Mnemonics: Temperature (PHYSical) of the ELectrons \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    Gives, in Hartree, the physical temperature of the system, in case occopt =4, 5, 6, or 7. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since   ecut   has\nthe \u2018 ENERGY \u2018 characteristics (0.001 Ha = 27.2113845 meV = 315.773 Kelvin).\nOne has to specify an independent broadening  tsmear . The combination of\nthe two parameters  tphysel  and  tsmear  is described in a paper by M.\nVerstraete and X. Gonze, Phys. Rev. B 65, 035111 (2002). Note that the\nsignification of the entropy is modified with respect to the usual entropy.\nThe choice has been made to use  tsmear  as a prefactor of the entropy, to\ndefine the entropy contribution to the free energy.",
            "title": "tphysel"
        },
        {
            "location": "/input_variables/vargs/#tsmear",
            "text": "Mnemonics: Temperature of SMEARing \nVariable type: real \nDimensions: scalar \nDefault value: 0.01    Gives the broadening of occupation numbers  occ , in the metallic cases\n( occopt =3, 4, 5, 6 and 7). Can be specified in Ha (the default), eV, Ry,\nor Kelvin, since  tsmear  has the \u2018 ENERGY \u2018 characteristics (0.001 Ha =\n27.2113845 meV = 315.773 Kelvin). \nDefault is 0.01 Ha. This should be OK using gaussian like smearings (occopt\n4,5,6,7) for a free-electron metal like Al. For d-band metals, you may need to\nuse less. \nAlways check the convergence of the calculation with respect to this\nparameter, and simultaneously, with respect to the sampling of k-points (see nkpt ) \nIf  occopt =3,  tsmear  is the physical temperature, as the broadening is\nbased on Fermi-Dirac statistics. However, if  occopt =4, 5, 6, or 7, the\nbroadening is not based on Fermi-Dirac statistics, and  tsmear  is only a\nconvergence parameter. It is still possible to define a physical temperature,\nthanks to the input variable  tphysel . See the paper by M. Verstraete and\nX. Gonze, Phys. Rev. B (2002).",
            "title": "tsmear"
        },
        {
            "location": "/input_variables/vargs/#usekden",
            "text": "Mnemonics: USE Kinetic energy DENsity \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If  usekden =1 the kinetic energy density will be computed during the self-\nconsistency loop, in a way similar to the computation of the density. This is\nneeded if a meta-GGA is to be used as XC functional. Otherwise\n( usekden =0), the kinetic energy density is not computed during the self-\nconsistency loop.",
            "title": "usekden"
        },
        {
            "location": "/input_variables/vargs/#vacuum",
            "text": "Mnemonics: VACUUM identification \nVariable type: integer \nDimensions: (3) \nDefault value: None    Establishes the presence (if 1) or absence (if 0) of a vacuum layer, along the\nthree possible directions normal to the primitive axes.  This information might be used to generate k-point grids, if  kptopt =0 and\nneither  ngkpt  nor  kptrlatt  are defined (see explanations with the\ninput variable  prtkpt ). \nIt will allow to select a zero-, one-, two- or three-dimensional grid of k\npoints. The coordinate of the k points along vacuum directions is\nautomatically set to zero.  If  vacuum  is not defined, the input variable  vacwidth  will be used to\ndetermine automatically whether the distance between atoms is sufficient to\nhave the presence or absence of vacuum.",
            "title": "vacuum"
        },
        {
            "location": "/input_variables/vargs/#vacwidth",
            "text": "Mnemonics: VACuum WIDTH \nVariable type: real \nDimensions: scalar \nDefault value: 10.0    Give a minimum \u201cprojected\u201d distance between atoms to be found in order to\ndeclare that there is some  vacuum  present for each of the three\ndirections. By default, given in Bohr atomic units (1 Bohr=0.5291772108\nAngstroms), although Angstrom can be specified, if preferred, since vacwidth  has the \u2018 LENGTH \u2018 characteristics. \nThe precise requirement is that a slab of width  vacwidth , delimited by two\nplanes of constant reduced coordinates in the investigated direction, must be\nempty of atoms.",
            "title": "vacwidth"
        },
        {
            "location": "/input_variables/vargs/#wtq",
            "text": "Mnemonics: WeighTs for the current Q-points \nVariable type: real \nDimensions: scalar \nDefault value: 1 \nComment: Except when  qptopt /=0    Gives the current q-point weight.",
            "title": "wtq"
        },
        {
            "location": "/input_variables/vargs/#wvl_bigdft_comp",
            "text": "Mnemonics: WaVeLet BigDFT Comparison \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This variable is used for the wavelets capabilities of ABINIT (see  usewvl \n). It is used to compare the results obtained with ABINIT with those obtained\nwith BigDFT stand-alone. When it is set to 1, ABINIT will follow the workflow\nas in BigDFT stand-alone. Therefore, the results must be exactly the same with\nthe two codes.",
            "title": "wvl_bigdft_comp"
        },
        {
            "location": "/input_variables/vargs/#wvl_crmult",
            "text": "Mnemonics: WaVeLet Coarse grid Radius MULTiplier \nVariable type: real \nDimensions: scalar \nDefault value: 6.0    This factor is used to defined the expansion of the coarse resolution grid in\nthe case of wavelets (seea  usewvl  ). The grid is made of points inside\nspheres centered on atoms. The radius of these spheres are the product between\nthis factor and the covalent radius of element (read from the pseudo-potential\nfile). \nThis factor is responsible for the amount of used memory (see also wvl_hgrid ).",
            "title": "wvl_crmult"
        },
        {
            "location": "/input_variables/vargs/#wvl_frmult",
            "text": "Mnemonics: WaVeLet Fine grid Radius MULTiplier \nVariable type: real \nDimensions: scalar \nDefault value: 10.0    This factor is used to defined the expansion of the fine resolution grid in\nthe case of wavelets (see  usewvl  ). This fine resolution grid has the same\ngrid step than the coarse one (see  wvl_crmult  ), but on each point, 8\ncoefficients are stored instead of one, increasing the precision of the\ncalculation in this area. The grid is made of points inside spheres centered\non atoms. The radius of these spheres are the product between this factor and\na value read from the pseudo-potential file. \nThis factor is responsible for the amount of used memory (see also wvl_hgrid ).",
            "title": "wvl_frmult"
        },
        {
            "location": "/input_variables/vargs/#wvl_ngauss",
            "text": "Mnemonics: WaVeLet Number of GAUSSians \nVariable type: integer \nDimensions: (2) \nDefault value: [1, 100]    In the wavelet-PAW computation case, projectors may be fitted to a sum of\ncomplex Gaussians. The fit is done for wvl_ngauss(1), wvl_ngauss(1)+1 \u2026 up\nto wvl_ngauss(2) Gaussians.",
            "title": "wvl_ngauss"
        },
        {
            "location": "/input_variables/vargs/#wvl_nprccg",
            "text": "Mnemonics: WaVeLet maximum Number of PReConditionner Conjugate Gradient iterations \nVariable type: integer \nDimensions: scalar \nDefault value: 5    In the wavelet computation case, the wavefunctions are directly minimised\nusing a real-space preconditionner. This preconditionner has internally some\nconjugate gradient iterations. This value defines a boundary for the number of\nconjugate gradient iterations on each wavefunction convergence step.",
            "title": "wvl_nprccg"
        },
        {
            "location": "/input_variables/vargs/#xredsph_extra",
            "text": "Mnemonics: X(position) in REDuced coordinates of the SPHeres for dos projection in the EXTRA set \nVariable type: real \nDimensions: (3, natsph_extra ) \nDefault value: *0.0 \nOnly relevant if  natsph_extra  > 0    The positions in reduced coordinates of extra spheres used in the DOS\nprojection, simulating an STS signal. See  natsph_extra  for a more complete\ndescription.",
            "title": "xredsph_extra"
        },
        {
            "location": "/input_variables/vargw/",
            "text": "awtr\n\u00b6\n\n\nMnemonics: evaluate the Adler-Wiser expression of \n\\chi^{0}_{KS}\n assuming Time-Reversal\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n==3  \n\n\nThis input variable defines whether the irreducible polarizability\n\n\\chi^{0}_{KS}\n is evaluated taking advantage of time-reversal symmetry or\nnot.\n\n\n\n\n0 => Use the \u201cstandard\u201d Adler-Wiser expression without assuming time-reversal symmetry. In this case, the irreducible polarizability is calculated summing over all possible electronic transitions (both resonant and antiresonant). \n\n\n1 => Take advantage of time-reversal symmetry to halve the number of transitions to be explicitly considered. This method leads to a decrease in the CPU time by a factor two with respect to the \nawtr\n=0 case. \n\n\n\n\nNote that the parallel algorithm \ngwpara\n=2 is not compatible with the\nchoice \nawtr\n=0.\n\n\nbdgw\n\u00b6\n\n\nMnemonics: BanDs for GW calculation\n\nVariable type: integer\n\nDimensions: (2,\nnkptgw\n,\nnsppol\n)\n\nDefault value: *0\n\nOnly relevant if \noptdriver\n==4  \n\n\nFor each k-point with number ikptgw in the range (1:\nnkptgw\n) and each spin\nindex isppol, \n bdgw(1,ikptgw,isppol) \n is the number of the lowest band for\nwhich the \nGW\n computation must be done, and \n bdgw(2,ikptgw,isppol) \n is\nthe number of the highest band for which the \nGW\n computation must be done.\n\n\nWhen \ngwcalctyp\n >= 20, the quasiparticle wavefunctions are computed and\nrepresented as linear combination of Kohn-Sham wavefunctions. In this case\n\nbdgw\n designates the range of KS wavefunctions used as basis set. For each\nk-point, indeed, the quasiparticle wavefunctions are expanded considering only\nthe KS states between \n bdgw(1,ikptgw,isppol) \n and \n bdgw(2,ikptgw,isppol)\n\n .\n\n\nNote that the initial values given in the input file might be changed inside\nthe code so that all the degenerate states at a given k-point and spin are\nincluded. This might happen when \nsymsigma\n=1 is used or in the case of\nself-consistent \nGW\n calculations.\n\n\nWhen \nsymsigma\n=1, the diagonal matrix elements of the self-energy are\nobtained by averaging the unsymmetrized results in the subspace spanned by the\ndegenerate states.\n\n\nFor self-consistent calculations, on the other hand, the basis set used to\nexpand the \nGW\n wavefunctions should include all the degenerate states\nbelonging to the same irreducible representation. Only in this case, indeed,\nthe initial symmetries and energy degenerations are preserved.\n\n\ncd_customnimfrqs\n\u00b6\n\n\nMnemonics: Contour Deformation CUSTOM IMaginary FReQuencieS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if (\noptdriver\n==3 or \noptdriver\n==4) and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ncd_customnimfrqs\n lets the user define the grid points along the imaginary\naxis by hand. Set this to the number of frequencies you want. The frequencies\nare specified with \ncd_imfrqs\n.\n\n\ncd_frqim_method\n\u00b6\n\n\nMnemonics: Contour Deformation FReQuency integration on IMaginary axis Method\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n==4  and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ncd_frqim_method\n defines the choice of integration method along the\nimaginary frequency axis for Contour Deformation calculations. The default\nmethod is very robust, fast and optimal for the vast majority of cases.\nHowever, for very accurate (\u201cparanoid level\u201d) convergence studies, ABINIT\noffers the possibility of a variety of methods and grids. Note that as one\nstarts to change the defaults, one needs to carefully consider the grid used.\nTherefore we recommend that in addition to reading the information below, the\nuser reads the description of the input variables \nfreqim_alpha\n,\n\nnfreqim\n, \nppmfrq\n, \ngw_frqim_inzgrid\n.\n\n\nThe integration to be performed for each matrix element of the self energy\nalong the imaginary axis is of the form:\n\n\n\n\nWhere  _ \u03c9 _ is the frequency point along the real axis,  _ \u03b5 s  _ is an\neigenvalue, and  _ i\u03c9\u2019 _ is the variable along the imaginary axis. Thus the\nfunction to be integrated is a Lorentzian weight function centred on the\norigin (whose FWHM is decided by |  _ \u03c9 - \u03b5 s  _ |), times a function. The\nfunction is related to the inverse dielectric matrix. It might have a peaked\nstructure near the origin and is very smooth otherwise. the function decays\nasymptotically as  1 / _ i\u03c9\u2019 _ , so the whole integral converges as this to\nthe third power.\n\n\n\n\n cd_frqim_method = 1 - Histogram: \n This is the \n default \n method where the function  _ f(i\u03c9\u2019) _ is approximated by a histogram, and the Lorentzian is integrated analytically in each sub-interval. See the section on grids below for a description of the default grid. This method combined with the default grid is the fastest and optimised for the use of few points along the imaginary axis. \n\n\n cd_frqim_method = 2 - Trapezoid: \n The next step up from the histogram approximation in the previous method. The integration region is transformed  _ [0,\u221e[ -> [0,1] _ with a proper weight depending on the width of the Lorentzian. In this space  _ f(i\u03c9\u2019) _ is approximated by a linear function between grid points (trapezoids), and the integrand is integrated analytically in each sub-interval. This method tends to slightly overestimate contributions while the default method tends to slightly underestimate them, so the results from methods 1 and 2 should bracket the converged values. The asymptotic behaviour is explicitly taken into account by a fit using the last two grid points. \n\n\n cd_frqim_method = 3, 4, 5 - Natural Spline: \n The function is transfomed  _ [0,\u221e[ -> [0,1] _ . In this space  _ f(i\u03c9\u2019) _ is approximated by a natural spline function whose starting and ending sections are linear. This transform is chosen so that the function should approach a linear function asymptotically as the integration interval approaches 1, so that the asymptotic behaviour is automatically taken into account. For each Lorentzian width (determined by |  _ \u03c9 - \u03b5 s  _ |) the integrand is appropriately scaled in the interval  _ [0,1] _ , and a nested Gauss-Kronrod (GK) numerical integration rule is performed. The integrand is evaluated at the GK nodes by means of a spline-fit. The order of the GK rule is controlled by the index of the method: \n\n\n 3 => Gauss 7 point, Kronrod 15 point rule \n\n\n 4 => Gauss 11 point, Kronrod 23 point rule \n\n\n 5 => Gauss 15 point, Kronrod 31 point rule \n\nThere is rarely any difference to machine precision between these rules, and\nthe code will issue a warning if a higher-order rule is recommended.\n\n\n\n\n\n\n\n\n Grids for the integral along the imaginary axis: \n\n\nAll the methods above should execute no matter what grid is used along the\nimaginary axis, so this is very much under the control of the user. The only\nrequirement is that the grid be strictly increasing. The point at zero\nfrequency is assumed to lie on the real axis, so the calculation of that point\nis controlled by \nnfreqre\n and corresponding variables. We highly recommend\nextracting various elements of the dielectric matrix from the _SCR file using\nthe \n Mrgscr \n utility and plotting them for visual inspection.\n\n\n\n\n Default \n - The default grid is an exponentially increasing grid given by the formula: \n\n\n\n\n\n\nHere  _ \u03c9 p  _ is the plasma frequency (by default determined by the average\ndensity of the system, but this can be overridden by setting \nppmfrq\n).  _ N\n_ is the total number of grid points (set by \nnfreqim\n).  _ \u03b1 _ is a\nparameter which determines how far out the final grid point will lie. The\nfinal point will be at  _ \u03b1*\u03c9 p  _ (the default is  _ \u03b1 = 5 _ , and was hard-\ncoded in older versions of ABINIT). This grid is designed so that\napproximately half the grid points are always distributed to values lower than\nthe plasma frequency, in order to resolve any peaked structure. If one seeks\nto increase the outermost reach by increasing \nppmfrq\n one must\nsimultaneously take care to increase \nnfreqim\n in order to have the\nappropriate resolution for the low-frequency region. In more recent versions\nof ABINIT one can also simply adjust the parameter  _ \u03b1 _ by using\n\nfreqim_alpha\n. This grid is optimised for speed and accurate results with\nfew grid points for \n cd_frqim_method = 1 \n .\n\n\n\n\n Inverse z transform \n - This grid is activated by the use of the variable \ngw_frqim_inzgrid\n. This is the standard  _ [0,\u221e[ -> [0,1] _ transform using the formula: \n\n\n\n\n\n\nHere  _ \u03c9 p  _ is the plasma frequency (default can be overridden by setting\n\nppmfrq\n). The grid points are then picked by an equidistant grid (number of\npoints set by \nnfreqim\n) in the interval  _ z \u2282 [0,1] _ . This grid can\neasily be uniquely converged by just increasing \nnfreqim\n. Again the points\nare distributed so that approximately half of them lie below the plasma\nfrequency.\n\n\n\n\n User defined \n - The user can also define their own grid using the variables \ncd_customnimfrqs\n and \ncd_imfrqs\n . _ With great power comes great responsibility! _\n\n\n\n\nThe \n Mrgscr \n utility is handy in optimising the numerical effort expended\nin convergence studies. By estimating the densest grid one can afford to\ncalculate in the SCR file, and successively removing frequencies from a single\nfile (using the utility), one only needs to perform the screening calculation\n\n once \n on the dense mesh for a given convergence study. One can also use\nthe utility to merge independent screening calculations over q-points and\nfrequency sections.\n\n\ncd_full_grid\n\u00b6\n\n\nMnemonics: Contour Deformation FULL GRID in complex plane\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==3 and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ncd_full_grid\n enables the calculation of the screening [both chi0 and\nepsilon^(-1)] on a grid in the first quadrant of the complex plane. The grid\nis determined by the (tensor) product of the grid in real frequency and the\ngrid in imaginary frequency. In the SUS and SCR files the grid points are\nstored as follows:\n\n\n  **\n   Index:\n  **\n  1   . . .   nfreqre   nfrqre+1 . . . nfreqre+nfreqim   nfreqre+nfreqim+1 . . . nfreqre*nfreqim\n  **\n   Entry:\n  **\n  | purely real freq.  |     purely imaginary freq.     |      gridpoints in complex plane        |\n\n\n\n\n\nThe grid in the complex plane is stored looping over the real dimension as the\ninner loop and the imaginary as the outer loop. The contents of the generated\nSUS and SCR files can be extracted for visualisation and further analysis with\nthe \n Mrgscr \n utility.\n\n\ncd_halfway_freq\n\u00b6\n\n\nMnemonics: Contour Deformation tangent grid HALFWAY FREQuency\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 100.0 eV\n\nOnly relevant if (\noptdriver\n==3 or \noptdriver\n==4) and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ncd_halfway_freq\n determines the frequency where half of the number of\npoints defined in \nnfreqre\n are used up. The tangent transformed grid is\napproximately linear up to this point. To be used in conjunction with\n\ngw_frqre_tangrid\n.\n\n\ncd_imfrqs\n\u00b6\n\n\nMnemonics: Contour Deformation IMaginary FReQuencieS\n\nVariable type: real\n\nDimensions: (\ncd_customnimfrqs\n)\n\nDefault value: None\n\nOnly relevant if \noptdriver\n==3 and \ngwcalctyp\n in [2,9,12,19,22,29] and \ncd_customnimfrqs\n != 0  \n\n\ncd_imfrqs\n specifies the grid points for the imaginary axis. The number of\nfrequencies is set by the value of \ncd_customnimfrqs\n. Example:\n\n\ncd_customnimfrqs   5\nnfreqim            5\ncd_imfrqs          0.1  0.2  0.5  1.0  5.0\n\n\n\n\n\nIf \nnfreqim\n is not equal to \ncd_customnimfrqs\n a warning will be issued.\n\n\n Use at own risk! \n The use of a custom grid makes it your responsibility that the SUS and SCR files are valid in self-energy (i.e. \noptdriver\n=4) calculations, so caution is advised. Note that frequencies have to be strictly increasing, and the point at zero frequency is \n not \n considered to be part of the imaginary grid, but rather the grid along the real axis. The calculation of that point should be controlled by \nnfreqre\n and related variables. \n\n\ncd_max_freq\n\u00b6\n\n\nMnemonics: Contour Deformation grid MAXimum FREQuency\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1000.0 eV\n\nOnly relevant if (\noptdriver\n==3 or \noptdriver\n==4) and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ncd_max_freq\n determines the frequency where all the points defined in\n\nnfreqre\n are used up. To be used in conjunction with \ngw_frqre_tangrid\n.\n\n\ncd_subset_freq\n\u00b6\n\n\nMnemonics: Contour Deformation grid calculate SUBSET of FREQuencies\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: [1, \u2018\nnfreqre\n\u2019]\n\nOnly relevant if \noptdriver\n==3 and \ngwcalctyp\n in [2,9,12,19,22,29] and  \ngw_frqre_tangrid\n==0  \n\n\ncd_subset_freq\n Specifies that only a subset of the frequencies defined by\n\nnfreqre\n are to be calculated. The first index is the start and the second\nthe end, with index number 1 always being the origin. For example a\ncalculation with \n \nnfreqre\n=100 \n could be separated into two datasets\nwith:\n\n\nsubset_freq1   1   50\nsubset_freq2   51  100\n\n\n\n\n\nAny resulting susceptibility (_SUS) and screening (_SCR) files can then be\nmerged with the \n mrgscr \n utility.\n\n\necuteps\n\u00b6\n\n\nMnemonics: Energy CUT-off for EPSilon (the dielectric matrix)\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n==3 or \noptdriver\n==4  \n\n\necuteps\n determines the cut-off energy of the planewave set used to\nrepresent the independent-particle susceptibility \n\\chi^{0}_{KS}\n, the\ndielectric matrix \n\\epsilon\n, and its inverse.\n\nIt is not worth to take \necuteps\n bigger than four times \necutwfn\n, this\nlatter limit corresponding to the highest Fourier components of a wavefunction\nconvoluted with itself. Usually, even twice the value of \necutwfn\n might\noverkill. A value of \necuteps\n between 5 and 10 Hartree often (but not\nalways) leads to converged results (at the level of 0.01 eV for the energy\ngap). In any case, a convergence study is worth.\n\n\necutsigx\n\u00b6\n\n\nMnemonics: Energy CUT-off for SIGma eXchange\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n==4  \n\n\necutsigx\n determines the cut-off energy of the planewave set used to\ngenerate the exchange part of the self-energy operator. For norm-conserving\ncalculations, it is pointless to have \necutsigx\n bigger than 4*\necut\n,\nwhile for PAW calculations, the maximal useful value is \npawecutdg\n. Thus,\nif you do not care about CPU time, please use these values. If you want to\nspare some CPU time, you might try to use a value between \necut\n and these\nupper limits.\n\n\necutwfn\n\u00b6\n\n\nMnemonics: Energy CUT-off for WaveFunctioNs\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: \necut\n if \noptdriver\n in [3, 4],\n0.0 otherwise.\n\n\nOnly relevant if  \noptdriver\n==3 or \noptdriver\n==4  \n\n\necutwfn\n determines the cut-off energy of the planewave set used to\nrepresent the wavefunctions in the formula that generates the independent-\nparticle susceptibility \n\\chi^{0}_{KS}\n (for \noptdriver\n=3), or the self-\nenergy (for \noptdriver\n=4).\n\nUsually, \necutwfn\n is smaller than \necut\n, so that the wavefunctions are\nfiltered, and some components are ignored. As a side effect, the wavefunctions\nare no more normalized, and also, no more orthogonal. Also, the set of plane\nwaves can be much smaller for \noptdriver\n=3, than for \noptdriver\n=4,\nalthough a convergence study is needed to choose correctly both values.\n\n\nThe size of this set of planewaves is \nnpwwfn\n.\n\n\nfftgw\n\u00b6\n\n\nMnemonics: FFT for GW calculation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 21\n\nOnly relevant if  \noptdriver\n==3 or \noptdriver\n==4  \n\n\nThe basic ingredients needed to perform both a screening and a sigma\ncalculation are the so-called oscillator matrix elements defined as  \n\n\n< \n k-q \n , b1 | e^{-i ( \n q+G \n ). \n r \n } | \n k \n b2 >  \n\n\nIn reciprocal space, this expression is evaluated by a convolution in which\nthe number of reciprocal lattice vectors employed to describe the\nwavefunctions is given by \necutwfn\n. In the case of screening calculations,\nthe number of \n G \n vectors in the above expression is defined by\n\necuteps\n, while \necutsigx\n defined the number of \n G \n used in sigma\ncalculations. To improve the efficiency of the code, the oscillator matrix\nelements are evaluated in real space through FFT techniques, and the \nfftgw\n\ninput variable is used to select the FFT mesh to be used.\n\n\nfftgw\n is the concatenation of two digits, labelled (A) and (B) whose value\nis internally used to define the value of \n[ngfft]\n (see the setmesh.F90\nroutine).\n\n\nThe first digit (A) defines the augmentation of the FFT grid. Possible values\nare 1, 2 and 3.\n\n\n\n\n0 => Use the FFT grid specified by the user through \n[ngfft]\n \n\n\n1 => Use a coarse FFT grid which encloses a sphere in reciprocal space whose radius depends on the largest value between \necutwfn\n and \necuteps\n \n\n\n2 => Use a slightly augmented FFT which is sufficient for the correct treatment of the convolution \n\n\n3 => Doubled FFT grid (same mesh as that used for GS calculations). \n\n\n\n\nThe second digit (B) can be chosen between 0 and 1. It defines whether a FFT\ngrid compatible with all the symmetries of the space group must be enforced or\nnot:\n\n\n\n\n0 => Use the smallest FFT mesh which is compatible with the FFT library (faster, save memory but is less accurate) \n\n\n1 => Enforce a FFT grid which is compatible with all the symmetry operations of the space group. This method leads to an increase both of CPU time and memory, but the matrix elements are more accurate since the symmetry properties of the system are preserved. \n\n\n\n\nThe behaviour of ABINIT before v5.5 corresponds to the default value 11.\n\n\nfreqim_alpha\n\u00b6\n\n\nMnemonics: FREQuencies along the IMaginary axis ALPHA parameter\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 5.0\n\nOnly relevant if \noptdriver\n==4  \n\n\nfreqim_alpha\n is used only for numerical integration of the \nGW\n self-\nenergy (\ngwcalctyp\n= 2, 12, 22, 9, 19, 29).\n\n\nfreqim_alpha\n determines the location of the maximum frequency point along\nthe imaginary axis if the default grid is used in Contour Deformation\n(numerical integration) calculations. It is set as  _ \u03b1*\u03c9 p  _ , where  _ \u03c9 p\n_ is the plasma frequency determined by the average density of the system\n(this can be set by hand by using the variable \nppmfrq\n). See the section on\ngrids in the descriptive text for \ncd_frqim_method\n for a detailed\ndescription of the formula.\n\n\nfreqremax\n\u00b6\n\n\nMnemonics: FREQuencies along the Real axis MAXimum\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n==3  \n\n\nfreqremax\n is used only for numerical integration of the \nGW\n self-energy\n(\ngwcalctyp\n= 2, 12, 22, 9, 19, 29).\n\n\nfreqremax\n sets the maximum real frequency used to calculate the dielectric\nmatrix in order to perform the numerical integration of the \nGW\n self-\nenergy. \nfreqremax\n, \nfreqremin\n and \nnfreqre\n define the spacing of the\nfrequency mesh along the real axis.\n\n\nfreqremin\n\u00b6\n\n\nMnemonics: FREQuencies along the Real axis MINimum\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n==3  \n\n\nfreqremin\n is used only for numerical integration of the \nGW\n self-energy\n(\ngwcalctyp\n= 2, 12, 22, 9, 19, 29).\n\n\nfreqremin\n sets the minimum real frequency used to calculate the dielectric\nmatrix in order to perform the numerical integration of the \nGW\n self-\nenergy. \nfreqremin\n can be used to split a wide frequency interval into\nsmaller subintervals that can be calculated independently. The different\nsubintervals can then be merged together with the \n Mrgscr \n utility thus\nobtaining a single screening file that can used for self-energy calculations.\nNote that \nfreqremax\n, \nfreqremin\n and \nnfreqre\n define the spacing of\nthe frequency mesh along the real axis.\n\n\nfreqspmax\n\u00b6\n\n\nMnemonics: FREQuencies for the SPectral function MAXimum\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n==4  \n\n\nfreqspmax\n sets the maximum real frequency used to calculate the spectral\nfunction from the \nGW\n Green\u2019s function. \nfreqspmin\n, \nfreqspmax\n and\n\nnfreqsp\n define the spacing of an equidistant frequency mesh along the real\naxis. Alternatively, the variables \ngw_customnfreqsp\n and \ngw_freqsp\n can\nbe used to make a user-defined grid.\n\n\nfreqspmin\n\u00b6\n\n\nMnemonics: FREQuencies for the SPectral function MINimum\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: -\nfreqspmax\n\nOnly relevant if \noptdriver\n==4  \n\n\nfreqspmin\n sets the minimum real frequency used to calculate the spectral\nfunction from the \nGW\n Green\u2019s function. \nfreqspmin\n is set to\n-\nfreqspmax\n if left undefined. \nfreqspmin\n, \nfreqspmax\n, and\n\nnfreqsp\n define the spacing of an equidistant frequency mesh along the real\naxis. Alternatively, the variables \ngw_customnfreqsp\n and \ngw_freqsp\n can\nbe used to make a user-defined grid.\n\n\ngw_customnfreqsp\n\u00b6\n\n\nMnemonics: GW CUSTOM FREQuencies for SPectral function\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==4 and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ngw_customnfreqsp\n lets the user define the grid points along the real\nfrequency axis by hand for the calculation of the self-energy along the real\naxis. Set this to the number of frequencies you want. The frequencies are\nspecified with \ngw_freqsp\n.\n\n\ngw_freqsp\n\u00b6\n\n\nMnemonics: GW SPectral FREQuencies\n\nVariable type: real\n\nDimensions: (\ngw_customnfreqsp\n)\n\nDefault value: [1 .. \ngw_customnfreqsp\n]\n\nOnly relevant if \noptdriver\n==4 and \ngw_customnfreqsp\n > 0   \n\n\ngw_freqsp\n specifies the grid points for the real frequency axis when the\nreal and imaginary (spectral funtion) parts of sigma are calculated explicitly\nfor post-processing or plotting. Only activated if \ngw_customnfreqsp\n is not\nequal to 0. The number of frequencies is set by the value of\n\ngw_customnfreqsp\n. Example:\n\n\ngw_customnfreqsp   5\nnfreqsp            5\ngw_freqsp         -0.5  -0.1  0.0  1.0  10.0 eV\n\n\n\n\n\nIf \nnfreqsp\n is not equal to \ngw_customnfreqsp\n a warning will be issued.\n\n\ngw_frqim_inzgrid\n\u00b6\n\n\nMnemonics: GW Contour Deformation FReQuencies on IMaginary axis Inverse Z Grid\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n in [3,4] and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ngw_frqim_inzgrid\n creates gridpoints along the \n imaginary \n frequency\naxis by using an equidistant grid in the variable  _ z \u2282 [0,1] _ where the\ntransform is:\n\n\n\n\nHere  _ \u03c9 p  _ is the plasma frequency (default can be overridden by setting\n\nppmfrq\n). The equidistant grid in z is determined uniquely by \nnfreqim\n)\nand the points are distributed so that half of them lie below the plasma\nfrequency.\n\n\ngw_frqre_inzgrid\n\u00b6\n\n\nMnemonics: GW Contour Deformation FReQuencies on REal axis Inverse Z Grid\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n in [3,4] and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ngw_frqre_inzgrid\n creates grid points along the \n real \n frequency axis\nby using an equidistant grid in the variable  _ z \u2282 [0,1] _ where the\ntransform is:\n\n\n\n\nHere  _ \u03c9 p  _ is the plasma frequency (default can be overridden by setting\n\nppmfrq\n). The equidistant grid in z is determined uniquely by \nnfreqre\n )\nand the points are distributed so that half of them lie below the plasma\nfrequency. This is useful in conjuction with \ngw_frqim_inzgrid\n if one needs\nto use a grid which maps  _ [0,\u221e[ -> [0,1] _ . Note that typically _ many _\nmore points are needed along the real axis in order to properly resolve peak\nstructures. In contrast, both the screening and self-energy are very smooth\nalong the imaginary axis. Also, please note that this is \n not \n an\nefficient grid for \n standard \n Contour Deformation calculations, where\ntypically only a smaller range of frequencies near the origin is required. The\nmaximum value needed along the real frequency axis is output in the logfile\nduring Contour Deformation sigma calculations.\n\n\ngw_frqre_tangrid\n\u00b6\n\n\nMnemonics: GW Contour Deformation FReQencies on REal axis - Use Tangent Grid\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n in [3,4] and \ngwcalctyp\n in [2,9,12,19,22,29]  \n\n\ngw_frqre_tangrid\n defines a nonuniform grid to be used in frequency, with\nstepsize increasing proportional to tan(x). This makes the grid approximately\nlinear to start with, with a rapid increase towards the end. Also, this is the\ngrid which gives equal importance to each point used in the integration of a\nfunction which decays as 1/x^2. To be used in conjunction with \nnfreqre\n,\n\ncd_max_freq\n and \ncd_halfway_freq\n which determine the parameters of the\ntransformed grid.\n\n\ngw_invalid_freq\n\u00b6\n\n\nMnemonics: GW treatment of INVALID FREQuency for Hybertsen-Louie PPM\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n in [3,4] and \nppmodel\n in [2]  \n\n\ngw_invalid_freq\n sets the procedure to follow when a PPM frequency is\ninvalid (negative or imaginary).\n\n\n\n\ngw_invalid_freq\n=0 : Drop them as proposed in Appendix B of PRB 34, 8, 5390, 1986. \n\n\ngw_invalid_freq\n=1 : Set them to 1 hartree, as done for the PPM of Godby-Needs. \n\n\ngw_invalid_freq\n=2 : Set them to infinity. \n\n\n\n\ngw_nqlwl\n\u00b6\n\n\nMnemonics: GW, Number of Q-points for the Long Wave-Length Limit\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n in [3,4,99]  \n\n\nOnly relevant if \noptdriver\n=3,4,99 that is, screening, sigma or\n\nBETHE_SALPETER\n calculations, although the actual meaning of the variable\ndepends on the particular run-level (see discussion below).\n\n\ngw_nqlwl\n defines the number of directions in reciprocal space used to\ndescribe the non-analytical behaviour of the heads (G = G\u2019=0) and the wings\n(G=0 or G\u2019=0) of the dielectric matrix in the optical limit (i.e. for q\ntending to zero). The number of directions is specified by the additional\nvariable \ngw_qlwl\n.\n\n\nWhen \noptdriver\n=3, \ngw_nqlwl\n and \n gw_qlwl \n define the set of \u201csmall\u201d\nq that will be calculated and stored in the final SCR file. Therefore, the two\nvariables can be used to analyze how the optical spectra depend on the\ndirection of the incident phonon (useful especially in anisotropic systems).\n\n\nWhen \noptdriver\n=4, \ngw_nqlwl\n and \n gw_qlwl \n can be used to specify\nthe heads and the wings to be used to perform the quadrature of the correlated\npart of the self-energy in the small region around the origin. (NB: not yet\navailable, at present the quadrature is performed using a single direction in\nq-space)\n\n\nWhen \noptdriver\n=99, \ngw_nqlwl\n and \n gw_qlwl \n define the set of\ndirections in q-space along which the macroscopic dielectric function is\nevaluated. By default the \nBETHE_SALPETER\n code calculates the macroscopic\ndielectric function using six different directions in q-space (the three basis\nvectors of the reciprocal lattice and the three Cartesian axis).\n\n\ngw_nstep\n\u00b6\n\n\nMnemonics: GW Number of self-consistent STEPs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 30\n\nOnly relevant if \noptdriver\n==8  \n\n\nGives the maximum number of self-consistent \nGW\n cycles (or \u201citerations\u201d).\nin which G and/or W will be updated until the quasi-particle energies are\nconverged within \ngw_toldfeig\n. \ngwcalctyp\n and \ngw_sctype\n are used to\ndefine the type of self-consistency.\n\n\ngw_qlwl\n\u00b6\n\n\nMnemonics: GW, Q-points for the Long Wave-Length limit\n\nVariable type: real\n\nDimensions: (3,\ngw_nqlwl\n)\n\nDefault value: [1e-05, 2e-05, 3e-05]\n\nOnly relevant if \noptdriver\n==3  \n\n\nWhen \noptdriver\n=3, \ngw_qlwl\n defines the set of q-points around Gamma\nthat are considered during the evaluation of the non-analytical behaviour of\nthe dielectric matrix. Optical spectra (with and without non-local field\neffects) are evaluated for each direction specified by \ngw_qlwl\n.\n\n\ngw_qprange\n\u00b6\n\n\nMnemonics: GW QuasiParticle RANGE policy\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==4  \n\n\ngw_qprange\n is active only when \nnkptgw\n is equal to zero (default\nvalue). This variable simplifies the specification of the list of kpoints and\nof the bands to be used for the computation of the quasi-particle corrections.\nThe possible values are:\n\n\n\n\n0 => Compute the QP corrections only for the fundamental and the optical gap \n\n\n+num => Compute the QP corrections for all the k-points in the irreducible zone. and include \nnum\n bands above and below the Fermi level. \n\n\n-num => Compute the QP corrections for all the k-points in the irreducible zone. Include all occupied states and \nnum\n empty states. \n\n\n\n\nThe default value is 0 and is very handy for one-shot calculations. It is\nimportant to stress, however, that the position of the optical/fundamental\ngaps is deduced from the energies computed on the k-mesh used for the WFK\nfile. Therefore the computed gaps might differ from the correct ones that can\nonly be obtained with an appropriate sampling of the irreducible zone.\nPositive values are useful if we do not know the position of the \nGW\n HOMO,\nLOMO and we want to investigate the effect of the \nGW\n corrections on the\nstates close to the gap Negative values are usually used for self-consistent\ncalculations Note that, in the case of self-consistency or symsigma=1, the\ncode might change the bands range so that all the degenerate states are\nincluded. Note also that \nkptgw\n, and \nbdgw\n are ignored when this options\nis used. If you want to select manually the list of k-points and bands, you\nhave to provide the three variables \nnkptgw\n, \nkptgw\n, and \nbdgw\n.\n\n\ngw_sctype\n\u00b6\n\n\nMnemonics: GW, Self-Consistency TYPE\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n in [3,4]  \n\n\nThis variable is used to partially define the kind of self-consistency for\n\nGW\n calculations. The other piece of information is given by \ngwcalctyp\n\nthat defines the particular approximation for the self-energy operator as well\nas whether the wavefunctions have to replaced by quasi-particle amplitudes.\n\n\nIf \ngw_sctype\n is specified in the input file, the code will perform an\niterative update of the quantities entering the \nGW\n equations until the\nquasi-particle energies are converged within \ngw_toldfeig\n. The maximum\nnumber of iterations is specified by \ngw_nstep\n. Possible values are:\n\n\n\n\n1 => standard one-shot method (one screening calculation followed by a single sigma run) \n\n\n2 => self-consistency only on W (iterative update of W followed by a sigma run in which G is approximated with the Kohn-Sham independent-particle Green\u2019s function G0) \n\n\n3 => self-consistency only of G (a single screening calculation to obtain the Kohn-Sham polarizability followed by an iterative update of the Green\u2019s functions in the self-energy) \n\n\n4 => fully self-consistent algorithm (iterative update of both G and W) \n\n\n\n\nIt is possible to initialize the self-consistent procedure by reading a\npreviously calculated SCR or SUSC file via the variables \ngetscr\n or\n\ngetsuscep\n, respectively. \ngetqps\n can be used to read a previous QPS\nfile thus initializing the Green functions to be used in the first self-\nconsistent iteration.\n\n\ngw_sigxcore\n\u00b6\n\n\nMnemonics: GW, SIGma (self-energy) for the CORE contribution\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==4 and \nusepaw\n==1  \n\n\nOnly available for PAW and relevant if \noptdriver\n=4 that is, sigma\ncalculations.\n\n\nTheoretical introduction: \nGW\n calculations performed on top of electronic\ncalculations relying when the frozen-core approximation is used to separate\ninner-core electrons from valence electrons, only the contribution to the\nself-energy arising from valence electrons is explicitly accounted for. In the\nstandard approach based on pseudopotentials the contribution to the self-\nenergy due to core electrons is approximated by means of the KS exchange-\ncorrelation potential generated by the core density. In the case of \nGW\n\ncalculations employing the PAW method, the core contribution to the self-\nenergy can be more accurately estimated in terms of the Fock operator\ngenerated by the core wavefunctions. In the simplest approach, the only\ningredients required for this more refined treatment are the wave functions of\nthe core electrons in the reference atomic configuration that are calculated\nduring the generation of the PAW setup. This is a good approximation provided\nthat the core wave functions are strictly localized inside the PAW spheres.\n\n\ngw_sigxcore\n defines the approximation used to evaluate the core\ncontribution to sigma.\n\n\n\n\ngw_sigxcore\n = 0, standard approach, the core contribution is approximated with vxc. \n\n\ngw_sigxcore\n = 1, the core term is approximated with the Fock operator inside the PAW spheres. \n\n\n\n\ngw_toldfeig\n\u00b6\n\n\nMnemonics: GW TOLerance on the DiFference of the EIGenvalues\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.1 eV\n\nOnly relevant if \noptdriver\n==8  \n\n\nSets a tolerance for absolute differences of QP energies that will cause one\nself-consistent \nGW\n cycle to stop.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \n toldfe \n has\nthe \u2018\nENERGY\n\u2018 characteristics (1 Ha=27.2113845 eV)  \n\n\ngwcalctyp\n\u00b6\n\n\nMnemonics: GW CALCulation TYPe\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n in [3,4]  \n\n\ngwcalctyp\n governs the choice between the different capabilities of the\n\nGW\n code.\n\n\n\n\n0 <= \ngwcalctyp\n <= 9 : standard \u201c1 shot\u201d quasiparticle method \n\n\n10 <= \ngwcalctyp\n <= 19 : self-consistent quasiparticle method on energies only \n\n\n\n\n20 <= \ngwcalctyp\n <= 29 : self-consistent quasiparticle method on energies and wavefunctions \n\n\n\n\n\n\ngwcalctyp\n = 0, 10, or 20 : standard Plasmon-Pole model \nGW\n calculation \n\n\n\n\ngwcalctyp\n = 1 : \nGW\n calculation where the self-energy along the real axis is obtained by performing the analytic continuation from the imaginary axis to the full complex plane via the Pade approximant. Only available for standard \u201c1 shot\u201d quasiparticle method. \n\n\ngwcalctyp\n = 2, 12, or 22 : \nGW\n calculation using numerical integration (contour deformation method, see e.g. S. Lebegue _ et al. _ PRB \n 67 \n , 155208 (2003).) \n\n\ngwcalctyp\n = 5, 15, or 25 : Hartree-Fock calculation \n\n\ngwcalctyp\n = 6, 16, or 26 : Screened Exchange calculation \n\n\ngwcalctyp\n = 7, 17, or 27 : COHSEX calculation \n\n\ngwcalctyp\n = 8, 18, or 28 : model \nGW\n calculation following S. Faleev _ et al. _ PRL \n 93 \n , 126406 (2004) using a Plasmon-Pole model \n\n\ngwcalctyp\n = 9, 19, or 29 : model \nGW\n calculation following S. Faleev _ et al. _ PRL \n 93 \n , 126406 (2004) using numerical integration (contour deformation method) \n\n\n\n\nAlso\n\n\n\n\ngwcalctyp\n = 105,125 : HSE06 calculations (1-shot and self-consistent) \n\n\ngwcalctyp\n = 205,225 : PBE0 calculations (1-shot and self-consistent) \n\n\ngwcalctyp\n = 305,325 : B3LYP calculations (1-shot and self-consistent) \n\n\n\n\ngwcomp\n\u00b6\n\n\nMnemonics: GW COMPleteness\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n in [3,4]  \n\n\ngwcomp\n governs the use of an extrapolar approximation. If \ngwcomp\n==1,\none improves the completeness in a truncated sum over states. In practice,\nthis permits one to reduce quite much the number of bands required in the\ncalculation of the screening or of the self-energy. The energy parameter\nneeded in the extrapolar approximation is set by \ngwencomp\n. See F.\nBruneval, X. Gonze, Phys. Rev. B 78, 085125 (2008) for a description of the\nmethodology.\n\n\ngwencomp\n\u00b6\n\n\nMnemonics: GW ENergy for COMPleteness\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 2.0\n\nOnly relevant if \noptdriver\n in [3,4] and \ngwcomp\n==1  \n\n\ngwencomp\n sets the energy parameter used in the extrapolar approximation\nused to improve completeness and make the convergence against the number of\nbands much faster.\n\n\nSee F. Bruneval, X. Gonze, Phys. Rev. B 78, 085125 (2008) for a description of\nthe methodology.\n\n\ngwfockmix\n\u00b6\n\n\nMnemonics: GW FOCK exchange MIXing parameter\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.25\n\nOnly relevant if \noptdriver\n=4, \ngwcalctyp\n = 1x5 (HSE) or 2x5 (PBE0).  \n\n\nMixing parameter of Fock exchange for PBE0 and HSE hybrid-functional\ncalculations via the GW self-energy subroutine. \ngwfockmix\n ranges from 0\n(essentially PBE) to 1.\n\n\ngwgamma\n\u00b6\n\n\nMnemonics: GW GAMMA\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n=3 or 4 (Sigma calculations)  \n\n\nIf \ngwgamma\n is 1, the vertex correction will be included leading to what is\nknown as \u201c\nGW\nGamma\u201d approximation. see R. Del Sole, L. Reining, and R. W.\nGodby, Phys. Rev. B 49, 8024 (1994). Note that, in order to include the vertex\ncorrection in W, one has to start the sigma calculation from the\nsusceptibility file_SUSC instead of the _SCR file (see \ngetsuscep\n   and\n\nirdsuscep\n  ) Not available for PAW calculations.\n\n\ngwgamma\n=-4 activates the bootstrap kernel of Sharma et al. [Phys. Rev.\nLett. 107, 186401 (2011)] in the test-charge-test-charge dielectric function\n[cf. Chen and Pasquarello, Phys. Rev. B 92, 041115(R) (2015)]. A cheaper one-\nshot variant can be achieved with \ngwgamma\n=-6 using only the head of the\nkernel.\n\n\ngwgamma\n=-8 uses the RPA bootstrap-like kernel (one-shot) [Phys. Rev. Lett.\n115, 137402 (2015), ibid. 114, 146402 (2015)].\n\n\ngwls_band_index\n\u00b6\n\n\nMnemonics: GWLS BAND INDEX\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n==66  \n\n\nGoverns the DFT eigenstate |e> in which the self-energy will be evaluated, as\nshown in eq. (7) of Phys. Rev. B 91, 125120 (2015). That is, it is the state\nto be corrected in the G0W0 scheme.\n\n\ngwls_correlation\n\u00b6\n\n\nMnemonics: GWLS CORRELATION\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 3\n\nOnly relevant if \noptdriver\n==66  \n\n\nGoverns the use of a dielectric model (as explained in section V of Phys. Rev.\nB 91, 125120 (2015). and the use of the Lanczos scheme to solve eqs. (30) and\n(35) of the same reference at all external \ngw_freqsp\n and integration (as\ngenerated from \ngwls_npt_gauss_quad\n) frequencies. The different choices\nare:\n\n\n\n\ngwls_correlation\n == 1 : GWLS calculation WITH the dielectric model and WITHOUT the shift Lanczos technique, \n\n\ngwls_correlation\n == 2 : GWLS calculation WITHOUT the dielectric model and WITHOUT the shift Lanczos technique, \n\n\ngwls_correlation\n == 3 : GWLS calculation WITH the dielectric model and WITH the shift Lanczos technique, \n\n\ngwls_correlation\n == 4 : GWLS calculation WITHOUT the dielectric model and WITH the shift Lanczos technique, \n\n\ngwls_correlation\n == 5 : Not a GWLS calculation; just calculate and print the eigenvalues of the (static) dielectric matrix (for debugging purposes). \n\n\n\n\nThe default, (\ngwls_correlation\n == 3), is the most performant option and\nshould be kept by the user. Option 1, 2 and 5 are deprecated and will be\nremoved.\n\n\ngwls_dielectric_model\n\u00b6\n\n\nMnemonics: GWLS dielectric model\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2\n\nOnly relevant if \noptdriver\n==66  \n\n\nNot used yet.\n\n\ngwls_exchange\n\u00b6\n\n\nMnemonics: GWLS exact EXCHANGE\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n==66  \n\n\nGoverns whether the exact exchange for the state to be corrected\n(\ngwls_band_index\n) is calculated (\ngwls_exchange\n==1) or not\n(\ngwls_exchange\n==0).\n\n\ngwls_first_seed\n\u00b6\n\n\nMnemonics: GWLS FIRST SEED vector\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \ngwls_band_index\n\nOnly relevant if \noptdriver\n==66  \n\n\nThis variable sets the band index to be used to generate the first seed vector\nto be used in the construction of the Lanczos basis for the (static)\ndielectric matrix in a GWLS calculation. See section IV of Phys. Rev. B 91,\n125120 (2015). Together with \ngwls_nseeds\n, defines the seeds for the\nLanczos procedure. That is, the states associated to band index\n\ngwls_first_seed\n to \ngwls_first_seed\n+\ngwls_nseeds\n-1 are used to\ngenerate the seed vectors.\n\n\nThe default \ngwls_first_seed\n==\ngwls_band_index\n and \ngwls_nseeds\n==1\nhas been touroughly tested and seems to be the most performant. Users should\ntherefore keep the default value.\n\n\ngwls_kmax_analytic\n\u00b6\n\n\nMnemonics: GWLS KMAX for the ANALYTIC term\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 8\n\nOnly relevant if \noptdriver\n==66  \n\n\nGoverns the number of iterations to be done in the shift Lanczos solution of\neq. (35) of Phys. Rev. B 91, 125120 (2015) to solve it at all external\nfrequencies requested by the user (\ngw_freqsp\n). The default value is\nconverged to a few 10s of meV for all molecules studied so far.\n\n\ngwls_kmax_complement\n\u00b6\n\n\nMnemonics: GWLS KMAX for the COMPLEMENT space.\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n==66  \n\n\nThe G0W0 formalism involves the calculation of a summation conceptually linked\nto the trace of the dielectric matrix (see eq. (38) of Phys. Rev. B 91, 125120\n(2015). Since the eigenvalues spectrum of the dielectric matrix of formed by a\nfew large discrete eigenvalues and an integrable divergence in the density of\neigenvalues around 0, it is expensive to sample accurately this divergence\nusing the exact dielectric operator. It this becomes interesting to calculate\nthe \u2018trace\u2019 of the \u2018exact - model\u2019 dielectric matrix in a small basis and add\nit to the \u2018trace\u2019 of the \u2018model\u2019 dielectric matrix obtained in a large bais.\nIn the context where the model dielectric matrix is used in the calculations,\n\ngwls_sternheimer_kmax\n determines the size of the \u2018small\u2019 basis and\n\ngwls_kmax_complement\n determines the size of the \u2018large\u2019 basis.\n\n\nFor more information on the exact role of these bases and on the model\ndielectric operator used, see section V of Phys. Rev. B 91, 125120 (2015).\n\n\ngwls_kmax_numeric\n\u00b6\n\n\nMnemonics: GWLS KMAX for the NUMERIC term\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 16\n\nOnly relevant if \noptdriver\n==66  \n\n\nGoverns the number of iterations to be done in the shift Lanczos solution of\neq. (30) of Phys. Rev. B 91, 125120 (2015) to solve it simultaneously at all\nintegration frequencies (generated automatically by the number of points\n\ngwls_npt_gauss_quad\n to use in the gaussian quadrature) and all external\nfrequencies requested by the user (\ngw_freqsp\n). The default value is\nconverged to a few 10s of meV for all molecules studied so far.\n\n\ngwls_kmax_poles\n\u00b6\n\n\nMnemonics: GWLS KMAX for the calculation of the POLES residue\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 4\n\nOnly relevant if \noptdriver\n==66  \n\n\nThe contour deformation technique, in the G0W0 context, will involve the\ncalculation of pole residues associated to states lying between the one\ncorrected (\ngwls_band_index\n) and the fermi level. These residues take the\nform of a matrix element of the inverse dielectric matrix at a real frequency\n(see eq. (11) of Phys. Rev. B 91, 125120 (2015)). Therefore, the dielectric\nmatrix must be constructed in some basis at these frequencies and inverted to\ncalculate the matrix element. The present input variable sets the size of the\nLanczos basis to be constructed for this purpose. The default value has proven\nto be very robust for many molecular systems and should therefore be left to\nthe default value by the user.\n\n\nFor more information on the Lanczos basis constructed for the calculation of\nthe residues, see section IV of Phys. Rev. B 91, 125120 (2015).\n\n\ngwls_list_proj_freq\n\u00b6\n\n\nMnemonics: GWLS LIST of the PROJection FREQuencies\n\nVariable type: real\n\nDimensions: (\ngwls_n_proj_freq\n)\n\nDefault value: *0.0\n\nOnly relevant if \noptdriver\n==66  \n\n\nThis variable sets the frequencies to be used to construct the basis in which\nthe Hamiltonian is projected to accelerate the solution of the Sternheimer\nequations involved by the construction of the dielectric matrix at finite\nfrequencies. See section VI of Phys. Rev. B 91, 125120 (2015). For most cases,\nsince the frequencies \\Infty and (if \ngwls_recycle\n>0) 0.0 are used at no\ncomputational cost, \ngwls_n_proj_freq\n==0 (which means no ADDITIONAL\nfrequency is to be used) is fine and no frequencies need to be picked up.\n\n\ngwls_model_parameter\n\u00b6\n\n\nMnemonics: GWLS MODEL PARAMETER\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0\n\nOnly relevant if \noptdriver\n==66  \n\n\nThis is the width of the lorentzian, in Ha, used to model the frequency\ndependence of the dielectric matrix in the GWLS calculation (see eqs. (12),\n(13), (14), (15), (16) and (34) of Phys. Rev. B 91, 125120 (2015)). More\nprecisely, this parameter is the value of \\alpha used in eq. (34). This model\nis then used to separate the integration over frequencies into a \u2018model\u2019 part\n(second term of eq. (12)) and a \u2018exact - model\u2019 part (first term of eq. (12)).\nSince the \u2018model\u2019 part can be integrated analytically (see eqs. (15), (16) and\n(34)), only the the \u2018exact - model\u2019 part needs to be integrated numerically.\n\n\nThe only effect of this model is therefore to alleviate the numerical cost of\nthe integration over frequencies in the G0W0 calculation. The value of the\nassociated parameter has thus an impact on the convergence rate of the GWLS\ncalculation with respect to the number of frequencies of integration\n(\ngwls_npt_gauss_quad\n), but no impact on the converged result of the GWLS\ncalculation. Typically, the default (\ngwls_model_parameter\n==1.0) is\noptimal.\n\n\ngwls_n_proj_freq\n\u00b6\n\n\nMnemonics: GWLS Number of PROJection FREQuencies\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==66  \n\n\nThis variable sets the number of frequencies, on top of \\Infty and (if\n\ngwls_recycle\n>0) 0.0, to be used for the construction of the basis in which\nthe hamiltonian is projected to accelerate the solution of the Sternheimer\nequations involved in the construction of the dielectric matrix at finite\nfrequencies. See section VI of Phys. Rev. B 91, 125120 (2015). For most cases,\nthe default (\ngwls_n_proj_freq\n==0) is fine.\n\n\ngwls_npt_gauss_quad\n\u00b6\n\n\nMnemonics: GWLS Number of PoinTs to use for the GAUSSian QUADrature \n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 10\n\nOnly relevant if \noptdriver\n==66  \n\n\nThis variable defines the number of points used for the numerical integration\nof the self-energy over frequencies in GWLS computations (see eq. (12) of\nPhys. Rev. B 91, 125120 (2015)). The default is fine for most cases.\n\n\ngwls_nseeds\n\u00b6\n\n\nMnemonics: GWLS Number of SEED vectorS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n==66  \n\n\nThis variable sets the number of seed vectors to be used in the construction\nof the Lanczos basis for the (static) dielectric matrix in a GWLS calculation.\nSee section IV of Phys. Rev. B 91, 125120 (2015). Only \ngwls_nseeds\n==1 has\nbeen tested for now and users should keep this value.\n\n\ngwls_print_debug\n\u00b6\n\n\nMnemonics: GWLS PRINT level for DEBUGging\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==66  \n\n\nInfluences the level of verbosity for debugging purposes in a GWLS\ncalculation. Users should keep its value at the default.\n\n\ngwls_recycle\n\u00b6\n\n\nMnemonics: GWLS RECYCLE\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2\n\nOnly relevant if \noptdriver\n==66  \n\n\nThis variable let the user choose if and how he wants to recycle the solutions\nof the Sternheimer equations involved in the construction of the static\ndielectric matrix.\n\n\n\n\ngwls_recycle\n==0 : No recycling of the solutions \n\n\ngwls_recycle\n==1 : Recycle the solutions. To do so, store them in RAM. \n\n\ngwls_recycle\n==2 : Recycle the solutions. To do so, store them on disk. \n\n\n\n\nIf the user choose to recycle the solutions, they are used to construct the\nbasis in which the hamiltonian is projected for the solution of the\nSternheimer equations involved by the calculation of the dielectric matrix at\nfinite frequencies. The other solutions used will be those at \\omega \\to\n\\Infty (alwyas used) and those at \\omega=\ngwls_list_proj_freq\n. For more\ninformation of the basis constructed, see section IV of Phys. Rev. B 91,\n125120 (2015).\n\n\nIt is important to note that the solutions rapidly take much space to store.\nTherefore, it is often not possible to store them in RAM in production\ncalculations, yet still desirable to retain them. This is when it becomes\ninteresting to store them on disk. It is particularly efficient to choose the\npath of the file to be on disk space local to the processor in large MPI\ncalculations, since each processor need only his own solutions in the\nconstruction of the basis.\n\n\ngwls_second_model_parameter\n\u00b6\n\n\nMnemonics: GWLS SECOND MODEL PARAMETER\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n==66  \n\n\nNot used yet.\n\n\ngwls_sternheimer_kmax\n\u00b6\n\n\nMnemonics: GWLS Kmax\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n==66  \n\n\nThis variable sets the dimension of the dielectric matrix used in a GWLS\ncalculation (see section IV of Phys. Rev. B 91, 125120 (2015)). Typically\nconverged at a value of a few hundreds to a few thousands for a convergence\ncriterion of 50meV on the eigenenergies.\n\n\ngwmem\n\u00b6\n\n\nMnemonics: GW MEMory\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 11\n\nOnly relevant if \noptdriver\n in [3,4]  \n\n\ngwmem\n governs the memory strategy during a screening and/or a sigma run.\n\n\n\n\ngwmem\n = 1x , the screening matrix are read for all q-vectors and stored in the memory. \n\n\n\n\ngwmem\n = 0x , the screening matrix are read just a q-vector after another.   \n\n\n\n\n\n\ngwmem\n = x1 , the real-space wavefunctions are stored in the memory. \n\n\n\n\ngwmem\n = x0 , the real-space wavefunctions are not stored, but rather recalculated on-fly each abinit needs them using FFTs. \n\n\n\n\nThe default is \ngwmem\n = 11, which is the fastest, but also the most memory\nconsuming. When experiencing memory shortage, one should try \ngwmem\n = 0.\nThe first digit is only meaningful when performing sigma calculations.\n\n\ngwrpacorr\n\u00b6\n\n\nMnemonics: GW RPA CORRelation energy\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==3 and \ngwcalctyp\n in [1,11,21]  \n\n\ngwrpacorr\n governs the calculation of the RPA correlation energy.\n\n\n\n\ngwrpacorr\n = 0, no RPA correlation energy is calculated \n\n\ngwrpacorr\n = 1, the RPA correlation energy is calculated using an exact integration over the coupling constant: it requires one diagonalization of the polarizability matrix \n\n\ngwrpacorr\n = _ n _ > 1, the RPA correlation energy is calculated using _ n _ values for the coupling constant: it requires _ n _ inversions of the polarizability matrix \n\n\n\n\nicutcoul\n\u00b6\n\n\nMnemonics: Integer that governs the CUT-off for COULomb interaction\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 6\n\nOnly relevant if \noptdriver\n in [3,4]  \n\n\nMany-body calculations for isolated systems present a slow convergence with\nrespect to the size of the supercell due to the long ranged Coulomb\ninteraction and the high degree of non-locality of the operators involved. A\nsimilar issue also occurs in fully periodic systems due to the presence of the\nintegrable Coulomb singularity at G=0 that hinders the convergence with\nrespect to the number of q-points used to sample the Brillouin zone. The\nconvergence can be accelerated by replacing the true bare Coulomb interaction\nwith other expressions.\n\n\nicutcoul\n defines the particular expression to be used for the Coulomb term\nin reciprocal space. The choice of \nicutcoul\n depends on the dimensionality\nof the system. Possible values of \nicutcoul\n are from 0 to 6. The\ncorresponding influential variables are \nvcutgeo\n and \nrcut\n.\n\n\n\n\n0 => sphere (molecules but also 3D-crystals) \n\n\n1 => cylinder (nanowires, nanotubes) \n\n\n2 => surface \n\n\n3 => 3D crystal (no cut-off, integration in a spherical mini-Brillouin Zone, legacy value) \n\n\n4 => ERF, long-range only Coulomb interaction \n\n\n5 => ERFC, short-range only Coulomb interaction (e.g. as used in the HSE functional) \n\n\n6 => auxiliary function integration for 3D systems from P. Carrier _ et al. _ , PRB \n 75 \n ,205126 (2007). \n\n\n7 => auxiliary function for 3D systems of Gygi and Baldereschi [cf. Phys. Rev. B \n34\n, 4405 (1986) and Massidda et al., ibid. \n48\n, 5058 (1993)]. \n\n\n\n\nNote that Spencer and Alavi PRB \n77\n, 193110 (2008) showed that the\nspherical cutoff can efficiently be used also for 3D systems. In the latter\ncase, use a negative value for the cutoff radius of the sphere\n(\nrcut\n<0), which is automatically calculated so that the volume enclosed\nin the sphere is equal to the volume of the solid.\n\n\ninclvkb\n\u00b6\n\n\nMnemonics: INCLude VKB\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2\n\nOnly relevant if \noptdriver\n in [3,99]  \n\n\nPossible values of \ninclvkb\n are 0,1,2. If \ninclvkb\n is 1 or 2, the\ncommutator of the non-local part of the pseudopotential with the position\noperator is correctly included in the q => 0 contribution. This is\nunfortunately time-consuming and in particular when the old algorithm\nimplemented by inclvkb==1 is used (inclvkb=2 is the recommended option). When\n\ninclvkb\n is 0, this contribution is incorrectly omitted, but the\ncomputation is much faster.\n\n\nThe importance of this contribution depends on the number of k points. Turning\noff \ninclvkb\n is let to the choice of the user.\n\n\nIn general, the use of \ninclvkb\n=0 is fine for \nGW\n calculations in\ncrystalline systems provided that the k-point sampling is sufficiently\nconverged.\n\n\nThe use of \ninclvkb\n=2 is strongly recommended for the calculation of\noptical properties.\n\n\nkptgw\n\u00b6\n\n\nMnemonics: K-PoinTs for GW calculations\n\nVariable type: real\n\nDimensions: (3,\nnkptgw\n)\n\nDefault value: *0.0\n\nOnly relevant if \noptdriver\n==4  \n\n\nFor each k-point with number igwpt in the range (1:\nnkptgw\n),\n\n[kptgw]\n is the reduced coordinate of the k-point where \nGW\n\ncorrections are required. while \nbdgw\n (1:2,igwpt) specifies the range of\nbands to be considered.\n\n\nAt present, not all k-points are possible. Only those corresponding to the\nk-point grid defined with the same repetition parameters ( \nkptrlatt\n, or\n\nngkpt\n ) than the GS one, but WITHOUT any shift, are allowed.\n\n\nmbpt_sciss\n\u00b6\n\n\nMnemonics: Many Body Perturbation Theory SCISSor operator\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n in [3,4,99]  \n\n\nThe Scissors operator energy added to the conductions states. In some cases,\nit mimics a second iteration self-consistent \nGW\n calculation.\n\n\nmdf_epsinf\n\u00b6\n\n\nMnemonics: Model Dielectric Function, EPSilon INFinity\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n==99 and \nbs_coulomb_term\n in [20,21] (Bethe-Salpeter calculas with a model dielectric function  \n\n\nmdf_epsinf\n specifies the value of the macroscopic dielectric function used\nto model the screening function (see Solid State Commun. \n84\n, 765 (1992)).\nThe proper spatial symmetry of the screening W(r,r_prime) is enforced using\nEq. (7) of Phys. Rev. B \n37\n, (1988)  \n\n\nnbandkss\n\u00b6\n\n\nMnemonics: Number of BANDs in the KSS file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis input variable is used for the preparation of a \nGW\n calculation : it\nis used in a GS run (where \noptdriver\n=0) to generate a _KSS file. In this\nrun, \nnbandkss\n should be non-zero. The generated _KSS file can be\nsubsequently used to calculate the irreducible polarizabilty \n\\chi^{(0)}_{KS}\n\nusing \noptdriver\n=3 or to calculate \nGW\n corrections setting\n\noptdriver\n=4.\n\n\n\n\nIf \nnbandkss\n=0, no _KSS file is created \n\n\nIf \nnbandkss\n=-1, all the available eigenstates (energies and eigenfunctions) are stored in the abo_KSS file at the end of the ground state calculation. The number of states is forced to be the same for all k-points : it will be the minimum of the number of plane waves over all k-points. \n\n\nIf \nnbandkss\n is greater than 0, abinit stores (about) \nnbandkss\n eigenstates in the abo_KSS file. This number of states is forced to be the same for all k-points. \n\n\n\n\nSee \nnpwkss\n for the selection of the number of the planewave components of\nthe eigenstates to be stored.\n\nThe input variable \niomode\n can be used to read and write KSS files\naccording to different fileformat (presently only \niomode\n=0 and 3 are\navailable in the \nGW\n part).\n\nThe precision of the KSS file can be tuned through the input variable\n\nkssform\n.\n\nFor more details about the format of the abo_KSS file, see the routine\noutkss.F90.\n\n\nVery important : for the time being, \nistwfk\n must be 1 for all the k-points\nin order to generate a _KSS file.\n\n\nnfreqim\n\u00b6\n\n\nMnemonics: Number of FREQuencies along the IMaginary axis\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==3 and \ngwcalctyp\n in [2,12,22,9,19,29]  \n\n\nnfreqim\n sets the number of pure imaginary frequencies used to calculate\nthe dielectric matrix in order to perform the numerical integration of the\n\nGW\n self-energy.\n\n\nnfreqmidm\n\u00b6\n\n\nMnemonics: Nth FREQuency Moment of the Imaginary part of the Dielectric Matrix\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None\n\nOnly relevant if \noptdriver\n==4  \n\n\ndepending on the value of \nnfreqmidm\n will calculate the frequency moment of\nthe Dielectric matrix or its inverse,\n\n\n\n\nif \nnfreqmidm\n is positive : calculate (nth=\nnfreqmidm\n) frequency moment of the Dielectric matrix\n\n\nif \nnfreqmidm\n is negative : calculate (nth=\nnfreqmidm\n) frequency moment of the inverse Dielectric matrix\n\n\nif \nnfreqmidm\n = 0 : calculate first frequency moment of the full polarizability\n\n\n\n\nsee M. Taut, J. Phys. C: Solid State Phys. 18 (1985) 2677-2690.\n\n\nnfreqre\n\u00b6\n\n\nMnemonics: Number of FREQuencies along the REal axis\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==3 and \ngwcalctyp\n in [2,12,22,9,19,29]  \n\n\nnfreqre\n sets the number of real frequencies used to calculate the\ndielectric matrix in order to perform the numerical integration of the \nGW\n\nself-energy.\n\n\nIt can be used also in case of \nGW\n calculations with plasmon-pole models, _\ni.e _ \ngwcalctyp\n<10, to reduce the number of frequencies used to\nevaluate the dielectric matrix from the (default) two to one frequency\n(omega=0) by setting \nnfreqre\n=1. This might be a good idea in case one is\nplanning to use ppmodel>1. This will force the calculation of the\nscreening on a single frequency (omega=0) and hence reduce memory and disk\nspace requirement. The only draw back is that the user will not be able to\nperform self energy calculation using \nppmodel\n=1, since in the last case\nthe dielectric matrix calculated on two frequencies is required. If the user\nis not sure which ppmodel to use, then s/he is not advised to use this input\nvariable. Using the default values, one must be able to get a screening file\nthat can be used with any ppmodel.\n\n\nnfreqsp\n\u00b6\n\n\nMnemonics: Number of FREQuencies for the SPectral function\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==4  \n\n\nnfreqsp\n defines the number of real frequencies used to calculate the\nspectral function of the \nGW\n Green\u2019s function.\n\n\nnkptgw\n\u00b6\n\n\nMnemonics: Number of K-PoinTs for GW corrections\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==4  \n\n\nnkptgw\n gives the number of k-points for which the \nGW\n calculation must\nbe done. It is used to dimension \nkptgw\n\n\nnomegasf\n\u00b6\n\n\nMnemonics: Number of OMEGA to evaluate the Spectral Function\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==3 and \nspmeth\n!=0  \n\n\nnomegasf\n defines the number of real frequencies used to describe the\nspectral function associated to the irreducible polarizability\n\n\\chi^{(0)}_{KS}\n. The frequency mesh will cover the interval between 0 and\nthe maximum (positive) transition energy between occupied and empty states.\nThe delta function entering the expression defining the spectral function is\napproximated using two different methods according to the value of the\n\nspmeth\n input variable.\n\n\nIt is important to notice that an accurate description of the imaginary part\nof \n\\chi^{(0)}_{KS}\n requires an extremely dense frequency mesh. It should be\nkept in mind, however, that the memory required grows fast with the value of\n\nnomegasf\n.\n\n\nnomegasi\n\u00b6\n\n\nMnemonics: Number of OMEGA(S) along the Imaginary axis\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 12\n\nOnly relevant if \noptdriver\n==4 and \ngwcalctyp\n==1  \n\n\nnomegasi\n defines the number of frequency points used to sample the self-\nenergy along the imaginary axis. The frequency mesh is linear and covers the\ninterval between OMEGASIMIN=0.01 Hartree and \nomegasimax\n.\n\n\nnomegasrd\n\u00b6\n\n\nMnemonics: Number of OMEGA to evaluate the Sigma Real axis Derivative\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 9\n\nOnly relevant if \noptdriver\n==4  \n\n\nThe number of real frequencies around the KS energy where the self-energy\nSigma is evaluated. From these values, the derivative of Sigma at the KS\nenergy is numerically estimated through linear interpolation.\n\n\nnpvel\n\u00b6\n\n\nMnemonics: Number of Particle VELocities\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==3  \n\n\nIn the context of the electronic stopping power of impinging ion in matter,\n\nnpvel\n sets the number of the ion velocities to be calculated via linear\nresponse.\n\nWhen \nnpvel\n=0, no stopping power calculation is performed.\n\nThe direction and the velocity maximum are set with the input variable\n\npvelmax\n. Note that the results are output for a Z=1 impinging ion, i.e. a\nproton.\n\n\nnpwkss\n\u00b6\n\n\nMnemonics: Number of PlaneWaves in the KSS file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis input variable is used for the preparation of a \nGW\n calculation: the\nGS run (where \noptdriver\n=1 and \n nbandkss \n /=0) should be followed with\na run where \noptdriver\n=3. Also, if \nnbandkss\n=0, no use of \nnpwkss\n.\n\n\nnpwkss\n defines the number of planewave components of the Kohn-Sham states\nto build the Hamiltonian, in the routine outkss.F90, and so, the size of the\nmatrix, the size of eigenvectors, and the number of available states, to be\nstored in the abo_KSS file. If it is set to 0, then, the planewave basis set\ndefined by the usual Ground State input variable \necut\n is used to generate\nthe superset of all planewaves used for all k-points. Note that this (large)\nplanewave basis is the same for all k-points.\n\n\nVery important : for the time being, \nistwfk\n must be 1 for all the\nk-points.\n\n\nnqptdm\n\u00b6\n\n\nMnemonics: Number of Q-PoinTs for the Dielectric Matrix\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==3  \n\n\nIf \nnqptdm\n is equal to 0, the set of q-points for computing the dielectric\nmatrix is determined automatically considering all the possible differences\nbetween the k-points contained in the _KSS file. When \nnqptdm\n is non-zero,\nthe list of q points is read from \nqptdm\n. This allows one to split the big\ncalculation of all the dielectric matrices into smaller calculations that can\nbe performed independently. The _SCR files generated in different runs can be\nmerged thanks to the \n Mrgscr \n utility. If \nnqptdm\n is equal to -1, the\ncode reports the list of q-points in the log file (YAML format) and then\nstops.\n\n\nomegasimax\n\u00b6\n\n\nMnemonics: OMEGA to evaluate Sigma along the Imaginary axis D: MAXimal value\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 50 eV\n\nOnly relevant if \noptdriver\n==4 and \ngwcalctyp\n==1  \n\n\nomegasimax\n defines the maximum frequency along the imaginary the axis. In\nconjunction with \nnomegasi\n, \nomegasimax\n uniquely defines the linear mesh\nemployed to sample the self-energy along the imaginary axis.\n\n\nomegasrdmax\n\u00b6\n\n\nMnemonics: OMEGA to evaluate the Sigma Real axis Derivative : MAXimal value\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0 eV\n\nOnly relevant if \noptdriver\n==4  \n\n\nThe maximum distance from the KS energy where to evaluate Sigma. Sigma is\nevaluated at [KS_energy - \nomegasrdmax\n, KS_energy + \nomegasrdmax\n]\nsampled \nnomegasrd\n times.\n\n\nppmfrq\n\u00b6\n\n\nMnemonics: Plasmon Pole Model FReQuency\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0 Ha\n\nOnly relevant if \noptdriver\n in [3,4]  \n\n\n In plasmon-pole calculations \n\n\nUsually only effective if \nGW\n corrections are evaluated using the plasmon-\npole model of Godby-Needs (\nppmodel\n==1).  \n\n\nIn the present status of the \nGW\n code, the convolution in frequency space\ndefining the self-energy operator can be evaluated using two different\napproaches: numerical integration and plasmon-pole models.\n\nMethods based on the numerical integration (contour deformation, analytic\ncontinuation) require the knowledge of the screened interaction for several\nfrequencies. These approaches give the most accurate results but at the price\nof an increase in the CPU time required.\n\nAlternatively, it is possible to approximate the dynamical behaviour of the\nscreened interaction through simple analytical expressions, the so-called\nplasmon-pole models. In the plasmon-pole model proposed by Godby-Needs\n(\nppmodel\n=1), the screening must be available at zero frequency, as well as\nat another imaginary frequency, of the order of the plasmon frequency (the\npeak in the EELS spectrum). This information is used to model the behaviour of\nthe dielectric matrix for all frequencies. During the calculation of the\nscreening, \nppmfrq\n defines the imaginary frequency where the dielectric\nmatrix is evaluated, in addition to the zero frequency. During the self-energy\nrun, \nppmfrq\n can be used to define the second frequency to be used to\ncalculate the plasmon-pole parameters. This is particularly useful when the\nSCR file contains several frequencies along the imaginary axis. In this case\nthe frequency whose value is the closest one to \nppmfrq\n will be selected.\nNote that, if the plasmon-pole approximation is good, then, the choice of\n\nppmfrq\n should have no influence on the final result. One should check\nwhether this is the case. In general, the plasmon frequencies of bulk solids\nare of the order of 0.5 Hartree.  \n\n\n In Contour Deformation calculations \n\n\nppmfrq\n is here used to \n override \n the default value calculated from\nthe average electronic density per unit cell. This can affect the distribution\nof gridpoints along the imaginary and real frequency axes. See\n\ncd_frqim_method\n, \ngw_frqim_inzgrid\n and \ngw_frqre_inzgrid\n for more\ndetails.\n\n\nppmodel\n\u00b6\n\n\nMnemonics: Plasmon Pole MODEL\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n in [3,4]  \n\n\n\n\nppmodel\n=1 : PP model of Godby and Needs, See Phys Rev Lett 62, 1169 (1989) \n\n\nppmodel\n=2 : PP model of Hybertsen and Louie, See Phys Rev B 34, 5390 (1986) \n\n\nppmodel\n=3 : PP model of W. von der Linden and P. Horsh see Phys Rev B 37, 8351 (1988) \n\n\nppmodel\n=4 : PP model of Farid and Engel. See Phys Rev B47,15931 (1993) \n\n\nppmodel\n=0 : no PP model, numerical integration (contour deformation method, see e.g. S. Lebegue et al. PRB 67, 155208 (2003).) \n\n\n\n\nPlease note the difference between \nppmodel\n 1 and \nppmodel\n 2,3,4. In the\nfirst case (\nppmodel\n=1), the plasmon-pole parameters are determined in\norder to reproduce the behaviour of the dielectric matrix at two calculated\nfrequencies: the static limit (omega=0) and the imaginary frequency defined by\n\nppmfrq\n. In the last three cases, instead, the plasmon-pole parameters are\nfound by using the dielectric matrix calculated only at omega=0 and enforcing\nthe so-called f-sum rule. See also \nnfreqre\n.\n\n\nPlease note also that in the case of \nppmodel\n 4, the plasmon energies are\nnot simple mathematical parameters, but rather have a physical meaning (at\nleast the lowest ones). Thus the calculated plasmon band structure (plasmon\nenergy vs q vector) is reported in the output file for the lowest 10 bands.\n\n\npvelmax\n\u00b6\n\n\nMnemonics: Particle VELocity MAXimum\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*1.0\n\nOnly relevant if \noptdriver\n==3  \n\n\nWhen \nnpvel\n is larger than 0, it performs electronic stopping power\ncalculations on a velocity grid along the direction determined by \npvelmax\n.\n\nThe vector \npvelmax\n defines both the direction and the maximum velocity.\n\npvelmax\n is input in Cartesian coordinates.\n\n\nqptdm\n\u00b6\n\n\nMnemonics: Q-PoinTs for the Dielectric Matrix\n\nVariable type: real\n\nDimensions: (3,\nnqptdm\n)\n\nDefault value: *0.0\n\nOnly relevant if \noptdriver\n==3 and \nnqptdm\n!=0  \n\n\nqptdm\n contains the set of q-points used in the screening part of ABINIT,\ninstead of the automatic generation of the q points when \nnqptdm\n=0. These q\npoints are given in terms of reciprocal space primitive translations (NOT in\ncartesian coordinates!). For further explanation, see the input variable\n\nnqptdm\n.\n\n\nrcut\n\u00b6\n\n\nMnemonics: Radius of the CUT-off for coulomb interaction\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nTruncation of the Coulomb interaction in real space. The meaning of \nrcut\n\nis governed by the cutoff shape option \nicutcoul\n.\n\n\nIf \nrcut\n is negative, the cutoff is automatically calculated so to enclose\nthe same volume inside the cutoff as the volume of the primitive cell.\n\n\nrhoqpmix\n\u00b6\n\n\nMnemonics: RHO QuasiParticle MIXing\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0  \n\n\nFor self-consistent \nGW\n runs, \nrhoqpmix\n sets the mixing coefficient\nbetween the new and the previous electronic densities. This mixing damps the\nspurious oscillations in the Hartree potential when achieving self-\nconsistency. \nrhoqpmix\n is meaningful only when doing self-consistency on\nthe wavefunctions with \ngwcalctyp\n >= 20.\n\n\nspbroad\n\u00b6\n\n\nMnemonics: SPectral BROADening\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \noptdriver\n==3 and \nspmeth\n==2  \n\n\nWhen a screening calculation (\noptdriver\n==3) uses a spectral representation\nof the irreducible polarizability in which the delta function is replaced by\nthe gaussian approximant (\nspmeth\n==2), the standard deviation of the\ngaussian is given by \nspbroad\n.\n\n\nspmeth\n\u00b6\n\n\nMnemonics: SPectral METHod\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==4  \n\n\nThe \nspmeth\n input variable defines the method used to calculate the\nirreducible polarizability \n\\chi^{(0)}_{KS}\n.\n\n\nBy default \n\\chi^{(0)}_{KS}\n is calculated employing the Adler-Wiser\nexpression (\nspmeth\n=0) with a CPU effort that scales linearly with the\nnumber of frequencies. This approach is convenient when few frequencies are\nrequired, and is usually used in conjunction with plasmon-pole models in which\nonly one or two frequencies are calculated, according to the value of\n\nppmodel\n.\n\nUnfortunately a calculation based on the Adler-Wiser expression might be quite\nCPU demanding if the matrix elements of the self-energy operator are evaluated\nby performing numerically the convolution defining the self-energy. The\nintegrand function, indeed, has poles above and below the real axis, and the\nscreened interaction has to be evaluated on a dense frequency mesh in order to\nobtain accurate results.\n\n\nIn the spectral method (\nspmeth\n=1 or 2) the irreducible polarizability is\nexpressed as the Hilbert transform of the imaginary part. The advantage in\nusing this approach consists in the fact that, once the spectral function is\nknown, the irreducible polarizability for an arbitrary frequency can be easily\nobtained through inexpensive integrations. On the other hand an accurate\nevaluation of the imaginary part requires a dense frequency mesh due to the\npresence of delta functions. Two different approaches can be used to\napproximate these delta functions thus allowing the use of affordable\nfrequency grids.\n\n\nSummarizing:\n\n\n\n\n0 => use Adler-Wiser expression to calculate \n\\chi^{(0)}_{KS}\n\n\n\n\n1 => use the spectral method approximating the delta function with a triangular approximant as proposed in \n REF TO BE ADDED \n\n\n2 => use spectral method but approximating the delta function with a Taylor expansion of the exponential as proposed in \n REF TO BE ADDED \n\n\n\n\nsymchi\n\u00b6\n\n\nMnemonics: SYMmetryze \\chi_o\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \noptdriver\n==3  \n\n\nThe evaluation of the irreducible polarizability for a given q-point requires\nan integration over the Brillouin zone (BZ) which is approximated by a\ndiscrete sum over k-points. In principle the integrand function should be\nevaluated for each k-point in the BZ, however it is possible to reduce the\nnumber of points to be explicitly considered by taking advantage of symmetry\nproperties. The development input variable \nsymchi\n is used to choose\nbetween these two equivalent methods:\n\n\n\n\n0=> the summation over k-points is performed considering ALL the points in the BZ (useful for testing and debugging). \n\n\n1=> the summation is restricted to the k-points belonging to the irreducible wedge defined by the little group associated to the external vector q. \n\n\n\n\nsymsigma\n\u00b6\n\n\nMnemonics: SYMmetrization of SIGMA matrix elements\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==4  \n\n\nThis option is used to switch on the symmetrization of the self-energy matrix\nelements (\nsymsigma\n=1). In this case the BZ integration defining the self-\nenergy matrix elements is reduced to an appropriate irreducible wedge defined\nby the point group of the wave-vector k specified in the \nkptgw\n list.\n\n\nThe symmetrized expression leads to a considerable speedup of the run but,\nunfortunately, this option is not yet compatible with self-consistent \nGW\n\ncalculations (see \ngwcalctyp\n).\n\n\nThe algorithm implemented in \nsymsigma\n=1 constructs a symmetric invariant\nfor the diagonal matrix elements of the self-energy by simply averaging the\n\nGW\n results within the degenerate subspace. Therefore particular care has\nto be taken in the presence of accidental degeneracies. since \nGW\n\ncalculations performed with \nsymsigma\n=1 will not be able to remove the\ninitial accidental degeneracy.\n\n\nucrpa\n\u00b6\n\n\nMnemonics: calculation of the screened interaction U with the Constrained RPA method\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nnspinor\n == 1  \n\n\nWhen equal to one or two, this variable allows for the calculation of U with\nthe cRPA method. An explicit test is shown in automatic tests v7/t23-t24-t25\nand in v7/t68-t69. The present implementation is parallelized (as for usual\n\nGW\n calculations), use symetry over k-points only for calculations\ninvolving one correlated atom, and can be use when correlated bands are\nentangled or not. The constrained calculation of the polarisability can be\ndone by eliminating transition betweens correlated bands (and not orbitals)\nwith the variable \nucrpa_bands\n.\n\n\nFor \nucrpa\n = 1, two solutions are possible. The first one is to specify\n(with the variable \nucrpa_bands\n) the bands to exclude from the\npolarisability calculation. The second solution is to provide an energy window\n(with the variable \nucrpa_window\n). The electronic transitions inside this\nwindow will not be taken into account in the polarisability calculation.\n\n\nFor \nucrpa\n = 2, the ucrpa_bands should be equal to the \ndmftbandi\n and\n\ndmftbandf\n values, and the polarisability of the correlated subspace is\nconstructed with a band and k-point dependent weight.\n\n\nThe implementation is restricted to the case of \nnspinor\n = 1 (collinear\ncase).\n\n\nA short presentation of the method and some aspect of the implementation can\nbe found in Section II and Appendix A of \n B. Amadon, T. Applencourt and F.\nBruneval Phys. Rev. B 89, 125110 (2014)\n\n .\n\n\nucrpa_bands\n\u00b6\n\n\nMnemonics: For the calculation of U with the Constrained RPA method, gives correlated BANDS\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: [-1, -1]\n\nComment: That is, the default includes no band.  \n\n\nGives the first and last correlated bands for the cRPA calculation of the\npolarisability.\n\n\nucrpa_window\n\u00b6\n\n\nMnemonics: For the calculation of U with the Constrained RPA method, gives energy WINDOW\n\nVariable type: real\n\nDimensions: (2)\n\nDefault value: [-1, -1]\n\nComment: That is, the energy window is empty by default.  \n\n\nSpecify a window of energy for the cRPA calculation of the polarisability. The\ntransition inside this window will not be taken into account in the\nconstrained polarisabilty calculations.\n\n\nThe lower bound and the upper bound energies must be specified (two real\nnumbers) with respect to the position of the Fermi level.\n\n\nvcutgeo\n\u00b6\n\n\nMnemonics: V (potential) CUT-off GEOmetry\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0.0\n\nOnly relevant if \nicutcoul\n in [1,2]  \n\n\nvcutgeo\n is used in conjunction with \nicutcoul\n to specify the geometry\nused to truncate the Coulomb interaction, as well as the particular approach\nto be used. It has a meaning only for the cylindrical symmetry\n(\nicutcoul\n=1) or in the case of surfaces (\nicutcoul\n=2). For each\ngeometry, two different definitions of the cutoff region are available (see\nPhys. Rev. B 73, 233103 and Phys. Rev. B 73, 205119 for a complete description\nof the methods)\n\n\nIn Beigi method (Phys. Rev. B 73, 233103), the cutoff region is given by the\nWigner-Seitz cell centered on the axis of the cylinder. The cutoff region is\nthus automatically defined by the unit cell and there is no need to specify\nWhen \nrcut\n.\n\n\nTo define a cylinder along the z-axis use the following lines. icutcoul 1\nvcutgeo 0 0 1\n\n\nPlease note that Beigi method is implemented only in the case if an\northorhombic Bravais lattic. For hexagonal lattices, one has to use the method\nof Rozzi (Phys. Rev. B 73, 205119) In this case, the interaction is truncated\nin a finite cylinder. Contrarily to the first approach, here one has to\nspecify both the radius of the cylinder with \nrcut\n as well as the length of\nthe cylinder along the periodic dimension that should always be smaller than\nthe extension of the Born von Karman box. The length of the cylinder is given\nin terms of the fraction of the primitive vector along the periodic direction.\n\n\nFor example, in order to define a finite cylinder along z of radius 2.5 Bohr\nand length 3*R3 icutcoul 1 vcutgeo 0 0 -3.0 # note the minus sign rcut 2.5\n\n\nFor surface calculations (\nicutcoul\n=2), \nvcutgeo\n is used to define the\ntwo periodic directions defining the surface. Also in this case two different\ntechniques are available. In the method of Beigi, the (positive) non-zero\ncomponents of vcutgeo define the periodic directions of the infinite surface.\nThe interaction is truncated within a slab of width L where L is the length of\nthe primitive vector of the lattice along the non-periodic dimension. For\nexample: icutcoul 2 vcutgeo 1 1 0 It is also possible to define a finite\nsurface by employing negative values For example: icutcoul 2 vcutgeo -3 -2 0\ndefines ....\n\n\nzcut\n\u00b6\n\n\nMnemonics: Z-CUT\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0036749326\n\nComment: 0.0036749326 Ha = 0.1 eV\n\nOnly relevant if \noptdriver\n in [3,4,99]  \n\n\nIt is meant to avoid some divergencies that might occur during the evaluation\nof the Adler-Wiser expression of the irreducible polarizability\n(\noptdriver\n=3) or during the numerical treatment of the integrals defining\nthe contribution to the self-energy matrix elements (\noptdriver\n=4). If the\ndenominator becomes smaller than \nzcut\n, a small imaginary part (depending\non \nzcut\n) is added, in order to avoid the divergence.\n\n\nWhen \noptdriver\n=99, \nzcut\n defines the small complex shift used to avoid\ndivergences in the expression for the macroscopic dieletric function. It\nsimulates the experimental uncertainty and the finite lifetime of the\nquasiparticles (although the true lifetime should be k- and band-dependent).\nThe value of \nzcut\n affects the number of iteration needed to achieve\nconvergence in the Haydock iterative method. In this case, \nzcut\n should be\nlarger than the typical distance between the eigenvalues of the exciton\nHamiltonian.\n\nIdeally, one should make a convergence study decreasing the value of \nzcut\n\nfor increasing number of k-points.",
            "title": "GW"
        },
        {
            "location": "/input_variables/vargw/#awtr",
            "text": "Mnemonics: evaluate the Adler-Wiser expression of  \\chi^{0}_{KS}  assuming Time-Reversal \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver ==3    This input variable defines whether the irreducible polarizability \\chi^{0}_{KS}  is evaluated taking advantage of time-reversal symmetry or\nnot.   0 => Use the \u201cstandard\u201d Adler-Wiser expression without assuming time-reversal symmetry. In this case, the irreducible polarizability is calculated summing over all possible electronic transitions (both resonant and antiresonant).   1 => Take advantage of time-reversal symmetry to halve the number of transitions to be explicitly considered. This method leads to a decrease in the CPU time by a factor two with respect to the  awtr =0 case.    Note that the parallel algorithm  gwpara =2 is not compatible with the\nchoice  awtr =0.",
            "title": "awtr"
        },
        {
            "location": "/input_variables/vargw/#bdgw",
            "text": "Mnemonics: BanDs for GW calculation \nVariable type: integer \nDimensions: (2, nkptgw , nsppol ) \nDefault value: *0 \nOnly relevant if  optdriver ==4    For each k-point with number ikptgw in the range (1: nkptgw ) and each spin\nindex isppol,   bdgw(1,ikptgw,isppol)   is the number of the lowest band for\nwhich the  GW  computation must be done, and   bdgw(2,ikptgw,isppol)   is\nthe number of the highest band for which the  GW  computation must be done.  When  gwcalctyp  >= 20, the quasiparticle wavefunctions are computed and\nrepresented as linear combination of Kohn-Sham wavefunctions. In this case bdgw  designates the range of KS wavefunctions used as basis set. For each\nk-point, indeed, the quasiparticle wavefunctions are expanded considering only\nthe KS states between   bdgw(1,ikptgw,isppol)   and   bdgw(2,ikptgw,isppol)  .  Note that the initial values given in the input file might be changed inside\nthe code so that all the degenerate states at a given k-point and spin are\nincluded. This might happen when  symsigma =1 is used or in the case of\nself-consistent  GW  calculations.  When  symsigma =1, the diagonal matrix elements of the self-energy are\nobtained by averaging the unsymmetrized results in the subspace spanned by the\ndegenerate states.  For self-consistent calculations, on the other hand, the basis set used to\nexpand the  GW  wavefunctions should include all the degenerate states\nbelonging to the same irreducible representation. Only in this case, indeed,\nthe initial symmetries and energy degenerations are preserved.",
            "title": "bdgw"
        },
        {
            "location": "/input_variables/vargw/#cd_customnimfrqs",
            "text": "Mnemonics: Contour Deformation CUSTOM IMaginary FReQuencieS \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if ( optdriver ==3 or  optdriver ==4) and  gwcalctyp  in [2,9,12,19,22,29]    cd_customnimfrqs  lets the user define the grid points along the imaginary\naxis by hand. Set this to the number of frequencies you want. The frequencies\nare specified with  cd_imfrqs .",
            "title": "cd_customnimfrqs"
        },
        {
            "location": "/input_variables/vargw/#cd_frqim_method",
            "text": "Mnemonics: Contour Deformation FReQuency integration on IMaginary axis Method \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver ==4  and  gwcalctyp  in [2,9,12,19,22,29]    cd_frqim_method  defines the choice of integration method along the\nimaginary frequency axis for Contour Deformation calculations. The default\nmethod is very robust, fast and optimal for the vast majority of cases.\nHowever, for very accurate (\u201cparanoid level\u201d) convergence studies, ABINIT\noffers the possibility of a variety of methods and grids. Note that as one\nstarts to change the defaults, one needs to carefully consider the grid used.\nTherefore we recommend that in addition to reading the information below, the\nuser reads the description of the input variables  freqim_alpha , nfreqim ,  ppmfrq ,  gw_frqim_inzgrid .  The integration to be performed for each matrix element of the self energy\nalong the imaginary axis is of the form:   Where  _ \u03c9 _ is the frequency point along the real axis,  _ \u03b5 s  _ is an\neigenvalue, and  _ i\u03c9\u2019 _ is the variable along the imaginary axis. Thus the\nfunction to be integrated is a Lorentzian weight function centred on the\norigin (whose FWHM is decided by |  _ \u03c9 - \u03b5 s  _ |), times a function. The\nfunction is related to the inverse dielectric matrix. It might have a peaked\nstructure near the origin and is very smooth otherwise. the function decays\nasymptotically as  1 / _ i\u03c9\u2019 _ , so the whole integral converges as this to\nthe third power.    cd_frqim_method = 1 - Histogram:   This is the   default   method where the function  _ f(i\u03c9\u2019) _ is approximated by a histogram, and the Lorentzian is integrated analytically in each sub-interval. See the section on grids below for a description of the default grid. This method combined with the default grid is the fastest and optimised for the use of few points along the imaginary axis.    cd_frqim_method = 2 - Trapezoid:   The next step up from the histogram approximation in the previous method. The integration region is transformed  _ [0,\u221e[ -> [0,1] _ with a proper weight depending on the width of the Lorentzian. In this space  _ f(i\u03c9\u2019) _ is approximated by a linear function between grid points (trapezoids), and the integrand is integrated analytically in each sub-interval. This method tends to slightly overestimate contributions while the default method tends to slightly underestimate them, so the results from methods 1 and 2 should bracket the converged values. The asymptotic behaviour is explicitly taken into account by a fit using the last two grid points.    cd_frqim_method = 3, 4, 5 - Natural Spline:   The function is transfomed  _ [0,\u221e[ -> [0,1] _ . In this space  _ f(i\u03c9\u2019) _ is approximated by a natural spline function whose starting and ending sections are linear. This transform is chosen so that the function should approach a linear function asymptotically as the integration interval approaches 1, so that the asymptotic behaviour is automatically taken into account. For each Lorentzian width (determined by |  _ \u03c9 - \u03b5 s  _ |) the integrand is appropriately scaled in the interval  _ [0,1] _ , and a nested Gauss-Kronrod (GK) numerical integration rule is performed. The integrand is evaluated at the GK nodes by means of a spline-fit. The order of the GK rule is controlled by the index of the method:    3 => Gauss 7 point, Kronrod 15 point rule    4 => Gauss 11 point, Kronrod 23 point rule    5 => Gauss 15 point, Kronrod 31 point rule  \nThere is rarely any difference to machine precision between these rules, and\nthe code will issue a warning if a higher-order rule is recommended.      Grids for the integral along the imaginary axis:   All the methods above should execute no matter what grid is used along the\nimaginary axis, so this is very much under the control of the user. The only\nrequirement is that the grid be strictly increasing. The point at zero\nfrequency is assumed to lie on the real axis, so the calculation of that point\nis controlled by  nfreqre  and corresponding variables. We highly recommend\nextracting various elements of the dielectric matrix from the _SCR file using\nthe   Mrgscr   utility and plotting them for visual inspection.    Default   - The default grid is an exponentially increasing grid given by the formula:     Here  _ \u03c9 p  _ is the plasma frequency (by default determined by the average\ndensity of the system, but this can be overridden by setting  ppmfrq ).  _ N\n_ is the total number of grid points (set by  nfreqim ).  _ \u03b1 _ is a\nparameter which determines how far out the final grid point will lie. The\nfinal point will be at  _ \u03b1*\u03c9 p  _ (the default is  _ \u03b1 = 5 _ , and was hard-\ncoded in older versions of ABINIT). This grid is designed so that\napproximately half the grid points are always distributed to values lower than\nthe plasma frequency, in order to resolve any peaked structure. If one seeks\nto increase the outermost reach by increasing  ppmfrq  one must\nsimultaneously take care to increase  nfreqim  in order to have the\nappropriate resolution for the low-frequency region. In more recent versions\nof ABINIT one can also simply adjust the parameter  _ \u03b1 _ by using freqim_alpha . This grid is optimised for speed and accurate results with\nfew grid points for   cd_frqim_method = 1   .    Inverse z transform   - This grid is activated by the use of the variable  gw_frqim_inzgrid . This is the standard  _ [0,\u221e[ -> [0,1] _ transform using the formula:     Here  _ \u03c9 p  _ is the plasma frequency (default can be overridden by setting ppmfrq ). The grid points are then picked by an equidistant grid (number of\npoints set by  nfreqim ) in the interval  _ z \u2282 [0,1] _ . This grid can\neasily be uniquely converged by just increasing  nfreqim . Again the points\nare distributed so that approximately half of them lie below the plasma\nfrequency.    User defined   - The user can also define their own grid using the variables  cd_customnimfrqs  and  cd_imfrqs  . _ With great power comes great responsibility! _   The   Mrgscr   utility is handy in optimising the numerical effort expended\nin convergence studies. By estimating the densest grid one can afford to\ncalculate in the SCR file, and successively removing frequencies from a single\nfile (using the utility), one only needs to perform the screening calculation  once   on the dense mesh for a given convergence study. One can also use\nthe utility to merge independent screening calculations over q-points and\nfrequency sections.",
            "title": "cd_frqim_method"
        },
        {
            "location": "/input_variables/vargw/#cd_full_grid",
            "text": "Mnemonics: Contour Deformation FULL GRID in complex plane \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==3 and  gwcalctyp  in [2,9,12,19,22,29]    cd_full_grid  enables the calculation of the screening [both chi0 and\nepsilon^(-1)] on a grid in the first quadrant of the complex plane. The grid\nis determined by the (tensor) product of the grid in real frequency and the\ngrid in imaginary frequency. In the SUS and SCR files the grid points are\nstored as follows:    **\n   Index:\n  **\n  1   . . .   nfreqre   nfrqre+1 . . . nfreqre+nfreqim   nfreqre+nfreqim+1 . . . nfreqre*nfreqim\n  **\n   Entry:\n  **\n  | purely real freq.  |     purely imaginary freq.     |      gridpoints in complex plane        |  The grid in the complex plane is stored looping over the real dimension as the\ninner loop and the imaginary as the outer loop. The contents of the generated\nSUS and SCR files can be extracted for visualisation and further analysis with\nthe   Mrgscr   utility.",
            "title": "cd_full_grid"
        },
        {
            "location": "/input_variables/vargw/#cd_halfway_freq",
            "text": "Mnemonics: Contour Deformation tangent grid HALFWAY FREQuency \nVariable type: real \nDimensions: scalar \nDefault value: 100.0 eV \nOnly relevant if ( optdriver ==3 or  optdriver ==4) and  gwcalctyp  in [2,9,12,19,22,29]    cd_halfway_freq  determines the frequency where half of the number of\npoints defined in  nfreqre  are used up. The tangent transformed grid is\napproximately linear up to this point. To be used in conjunction with gw_frqre_tangrid .",
            "title": "cd_halfway_freq"
        },
        {
            "location": "/input_variables/vargw/#cd_imfrqs",
            "text": "Mnemonics: Contour Deformation IMaginary FReQuencieS \nVariable type: real \nDimensions: ( cd_customnimfrqs ) \nDefault value: None \nOnly relevant if  optdriver ==3 and  gwcalctyp  in [2,9,12,19,22,29] and  cd_customnimfrqs  != 0    cd_imfrqs  specifies the grid points for the imaginary axis. The number of\nfrequencies is set by the value of  cd_customnimfrqs . Example:  cd_customnimfrqs   5\nnfreqim            5\ncd_imfrqs          0.1  0.2  0.5  1.0  5.0  If  nfreqim  is not equal to  cd_customnimfrqs  a warning will be issued.   Use at own risk!   The use of a custom grid makes it your responsibility that the SUS and SCR files are valid in self-energy (i.e.  optdriver =4) calculations, so caution is advised. Note that frequencies have to be strictly increasing, and the point at zero frequency is   not   considered to be part of the imaginary grid, but rather the grid along the real axis. The calculation of that point should be controlled by  nfreqre  and related variables.",
            "title": "cd_imfrqs"
        },
        {
            "location": "/input_variables/vargw/#cd_max_freq",
            "text": "Mnemonics: Contour Deformation grid MAXimum FREQuency \nVariable type: real \nDimensions: scalar \nDefault value: 1000.0 eV \nOnly relevant if ( optdriver ==3 or  optdriver ==4) and  gwcalctyp  in [2,9,12,19,22,29]    cd_max_freq  determines the frequency where all the points defined in nfreqre  are used up. To be used in conjunction with  gw_frqre_tangrid .",
            "title": "cd_max_freq"
        },
        {
            "location": "/input_variables/vargw/#cd_subset_freq",
            "text": "Mnemonics: Contour Deformation grid calculate SUBSET of FREQuencies \nVariable type: integer \nDimensions: (2) \nDefault value: [1, \u2018 nfreqre \u2019] \nOnly relevant if  optdriver ==3 and  gwcalctyp  in [2,9,12,19,22,29] and   gw_frqre_tangrid ==0    cd_subset_freq  Specifies that only a subset of the frequencies defined by nfreqre  are to be calculated. The first index is the start and the second\nthe end, with index number 1 always being the origin. For example a\ncalculation with    nfreqre =100   could be separated into two datasets\nwith:  subset_freq1   1   50\nsubset_freq2   51  100  Any resulting susceptibility (_SUS) and screening (_SCR) files can then be\nmerged with the   mrgscr   utility.",
            "title": "cd_subset_freq"
        },
        {
            "location": "/input_variables/vargw/#ecuteps",
            "text": "Mnemonics: Energy CUT-off for EPSilon (the dielectric matrix) \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver ==3 or  optdriver ==4    ecuteps  determines the cut-off energy of the planewave set used to\nrepresent the independent-particle susceptibility  \\chi^{0}_{KS} , the\ndielectric matrix  \\epsilon , and its inverse. \nIt is not worth to take  ecuteps  bigger than four times  ecutwfn , this\nlatter limit corresponding to the highest Fourier components of a wavefunction\nconvoluted with itself. Usually, even twice the value of  ecutwfn  might\noverkill. A value of  ecuteps  between 5 and 10 Hartree often (but not\nalways) leads to converged results (at the level of 0.01 eV for the energy\ngap). In any case, a convergence study is worth.",
            "title": "ecuteps"
        },
        {
            "location": "/input_variables/vargw/#ecutsigx",
            "text": "Mnemonics: Energy CUT-off for SIGma eXchange \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver ==4    ecutsigx  determines the cut-off energy of the planewave set used to\ngenerate the exchange part of the self-energy operator. For norm-conserving\ncalculations, it is pointless to have  ecutsigx  bigger than 4* ecut ,\nwhile for PAW calculations, the maximal useful value is  pawecutdg . Thus,\nif you do not care about CPU time, please use these values. If you want to\nspare some CPU time, you might try to use a value between  ecut  and these\nupper limits.",
            "title": "ecutsigx"
        },
        {
            "location": "/input_variables/vargw/#ecutwfn",
            "text": "Mnemonics: Energy CUT-off for WaveFunctioNs \nVariable type: real \nDimensions: scalar \nDefault value:  ecut  if  optdriver  in [3, 4],\n0.0 otherwise.  Only relevant if   optdriver ==3 or  optdriver ==4    ecutwfn  determines the cut-off energy of the planewave set used to\nrepresent the wavefunctions in the formula that generates the independent-\nparticle susceptibility  \\chi^{0}_{KS}  (for  optdriver =3), or the self-\nenergy (for  optdriver =4). \nUsually,  ecutwfn  is smaller than  ecut , so that the wavefunctions are\nfiltered, and some components are ignored. As a side effect, the wavefunctions\nare no more normalized, and also, no more orthogonal. Also, the set of plane\nwaves can be much smaller for  optdriver =3, than for  optdriver =4,\nalthough a convergence study is needed to choose correctly both values.  The size of this set of planewaves is  npwwfn .",
            "title": "ecutwfn"
        },
        {
            "location": "/input_variables/vargw/#fftgw",
            "text": "Mnemonics: FFT for GW calculation \nVariable type: integer \nDimensions: scalar \nDefault value: 21 \nOnly relevant if   optdriver ==3 or  optdriver ==4    The basic ingredients needed to perform both a screening and a sigma\ncalculation are the so-called oscillator matrix elements defined as    <   k-q   , b1 | e^{-i (   q+G   ).   r   } |   k   b2 >    In reciprocal space, this expression is evaluated by a convolution in which\nthe number of reciprocal lattice vectors employed to describe the\nwavefunctions is given by  ecutwfn . In the case of screening calculations,\nthe number of   G   vectors in the above expression is defined by ecuteps , while  ecutsigx  defined the number of   G   used in sigma\ncalculations. To improve the efficiency of the code, the oscillator matrix\nelements are evaluated in real space through FFT techniques, and the  fftgw \ninput variable is used to select the FFT mesh to be used.  fftgw  is the concatenation of two digits, labelled (A) and (B) whose value\nis internally used to define the value of  [ngfft]  (see the setmesh.F90\nroutine).  The first digit (A) defines the augmentation of the FFT grid. Possible values\nare 1, 2 and 3.   0 => Use the FFT grid specified by the user through  [ngfft]    1 => Use a coarse FFT grid which encloses a sphere in reciprocal space whose radius depends on the largest value between  ecutwfn  and  ecuteps    2 => Use a slightly augmented FFT which is sufficient for the correct treatment of the convolution   3 => Doubled FFT grid (same mesh as that used for GS calculations).    The second digit (B) can be chosen between 0 and 1. It defines whether a FFT\ngrid compatible with all the symmetries of the space group must be enforced or\nnot:   0 => Use the smallest FFT mesh which is compatible with the FFT library (faster, save memory but is less accurate)   1 => Enforce a FFT grid which is compatible with all the symmetry operations of the space group. This method leads to an increase both of CPU time and memory, but the matrix elements are more accurate since the symmetry properties of the system are preserved.    The behaviour of ABINIT before v5.5 corresponds to the default value 11.",
            "title": "fftgw"
        },
        {
            "location": "/input_variables/vargw/#freqim_alpha",
            "text": "Mnemonics: FREQuencies along the IMaginary axis ALPHA parameter \nVariable type: real \nDimensions: scalar \nDefault value: 5.0 \nOnly relevant if  optdriver ==4    freqim_alpha  is used only for numerical integration of the  GW  self-\nenergy ( gwcalctyp = 2, 12, 22, 9, 19, 29).  freqim_alpha  determines the location of the maximum frequency point along\nthe imaginary axis if the default grid is used in Contour Deformation\n(numerical integration) calculations. It is set as  _ \u03b1*\u03c9 p  _ , where  _ \u03c9 p\n_ is the plasma frequency determined by the average density of the system\n(this can be set by hand by using the variable  ppmfrq ). See the section on\ngrids in the descriptive text for  cd_frqim_method  for a detailed\ndescription of the formula.",
            "title": "freqim_alpha"
        },
        {
            "location": "/input_variables/vargw/#freqremax",
            "text": "Mnemonics: FREQuencies along the Real axis MAXimum \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver ==3    freqremax  is used only for numerical integration of the  GW  self-energy\n( gwcalctyp = 2, 12, 22, 9, 19, 29).  freqremax  sets the maximum real frequency used to calculate the dielectric\nmatrix in order to perform the numerical integration of the  GW  self-\nenergy.  freqremax ,  freqremin  and  nfreqre  define the spacing of the\nfrequency mesh along the real axis.",
            "title": "freqremax"
        },
        {
            "location": "/input_variables/vargw/#freqremin",
            "text": "Mnemonics: FREQuencies along the Real axis MINimum \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver ==3    freqremin  is used only for numerical integration of the  GW  self-energy\n( gwcalctyp = 2, 12, 22, 9, 19, 29).  freqremin  sets the minimum real frequency used to calculate the dielectric\nmatrix in order to perform the numerical integration of the  GW  self-\nenergy.  freqremin  can be used to split a wide frequency interval into\nsmaller subintervals that can be calculated independently. The different\nsubintervals can then be merged together with the   Mrgscr   utility thus\nobtaining a single screening file that can used for self-energy calculations.\nNote that  freqremax ,  freqremin  and  nfreqre  define the spacing of\nthe frequency mesh along the real axis.",
            "title": "freqremin"
        },
        {
            "location": "/input_variables/vargw/#freqspmax",
            "text": "Mnemonics: FREQuencies for the SPectral function MAXimum \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver ==4    freqspmax  sets the maximum real frequency used to calculate the spectral\nfunction from the  GW  Green\u2019s function.  freqspmin ,  freqspmax  and nfreqsp  define the spacing of an equidistant frequency mesh along the real\naxis. Alternatively, the variables  gw_customnfreqsp  and  gw_freqsp  can\nbe used to make a user-defined grid.",
            "title": "freqspmax"
        },
        {
            "location": "/input_variables/vargw/#freqspmin",
            "text": "Mnemonics: FREQuencies for the SPectral function MINimum \nVariable type: real \nDimensions: scalar \nDefault value: - freqspmax \nOnly relevant if  optdriver ==4    freqspmin  sets the minimum real frequency used to calculate the spectral\nfunction from the  GW  Green\u2019s function.  freqspmin  is set to\n- freqspmax  if left undefined.  freqspmin ,  freqspmax , and nfreqsp  define the spacing of an equidistant frequency mesh along the real\naxis. Alternatively, the variables  gw_customnfreqsp  and  gw_freqsp  can\nbe used to make a user-defined grid.",
            "title": "freqspmin"
        },
        {
            "location": "/input_variables/vargw/#gw_customnfreqsp",
            "text": "Mnemonics: GW CUSTOM FREQuencies for SPectral function \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==4 and  gwcalctyp  in [2,9,12,19,22,29]    gw_customnfreqsp  lets the user define the grid points along the real\nfrequency axis by hand for the calculation of the self-energy along the real\naxis. Set this to the number of frequencies you want. The frequencies are\nspecified with  gw_freqsp .",
            "title": "gw_customnfreqsp"
        },
        {
            "location": "/input_variables/vargw/#gw_freqsp",
            "text": "Mnemonics: GW SPectral FREQuencies \nVariable type: real \nDimensions: ( gw_customnfreqsp ) \nDefault value: [1 ..  gw_customnfreqsp ] \nOnly relevant if  optdriver ==4 and  gw_customnfreqsp  > 0     gw_freqsp  specifies the grid points for the real frequency axis when the\nreal and imaginary (spectral funtion) parts of sigma are calculated explicitly\nfor post-processing or plotting. Only activated if  gw_customnfreqsp  is not\nequal to 0. The number of frequencies is set by the value of gw_customnfreqsp . Example:  gw_customnfreqsp   5\nnfreqsp            5\ngw_freqsp         -0.5  -0.1  0.0  1.0  10.0 eV  If  nfreqsp  is not equal to  gw_customnfreqsp  a warning will be issued.",
            "title": "gw_freqsp"
        },
        {
            "location": "/input_variables/vargw/#gw_frqim_inzgrid",
            "text": "Mnemonics: GW Contour Deformation FReQuencies on IMaginary axis Inverse Z Grid \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver  in [3,4] and  gwcalctyp  in [2,9,12,19,22,29]    gw_frqim_inzgrid  creates gridpoints along the   imaginary   frequency\naxis by using an equidistant grid in the variable  _ z \u2282 [0,1] _ where the\ntransform is:   Here  _ \u03c9 p  _ is the plasma frequency (default can be overridden by setting ppmfrq ). The equidistant grid in z is determined uniquely by  nfreqim )\nand the points are distributed so that half of them lie below the plasma\nfrequency.",
            "title": "gw_frqim_inzgrid"
        },
        {
            "location": "/input_variables/vargw/#gw_frqre_inzgrid",
            "text": "Mnemonics: GW Contour Deformation FReQuencies on REal axis Inverse Z Grid \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver  in [3,4] and  gwcalctyp  in [2,9,12,19,22,29]    gw_frqre_inzgrid  creates grid points along the   real   frequency axis\nby using an equidistant grid in the variable  _ z \u2282 [0,1] _ where the\ntransform is:   Here  _ \u03c9 p  _ is the plasma frequency (default can be overridden by setting ppmfrq ). The equidistant grid in z is determined uniquely by  nfreqre  )\nand the points are distributed so that half of them lie below the plasma\nfrequency. This is useful in conjuction with  gw_frqim_inzgrid  if one needs\nto use a grid which maps  _ [0,\u221e[ -> [0,1] _ . Note that typically _ many _\nmore points are needed along the real axis in order to properly resolve peak\nstructures. In contrast, both the screening and self-energy are very smooth\nalong the imaginary axis. Also, please note that this is   not   an\nefficient grid for   standard   Contour Deformation calculations, where\ntypically only a smaller range of frequencies near the origin is required. The\nmaximum value needed along the real frequency axis is output in the logfile\nduring Contour Deformation sigma calculations.",
            "title": "gw_frqre_inzgrid"
        },
        {
            "location": "/input_variables/vargw/#gw_frqre_tangrid",
            "text": "Mnemonics: GW Contour Deformation FReQencies on REal axis - Use Tangent Grid \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver  in [3,4] and  gwcalctyp  in [2,9,12,19,22,29]    gw_frqre_tangrid  defines a nonuniform grid to be used in frequency, with\nstepsize increasing proportional to tan(x). This makes the grid approximately\nlinear to start with, with a rapid increase towards the end. Also, this is the\ngrid which gives equal importance to each point used in the integration of a\nfunction which decays as 1/x^2. To be used in conjunction with  nfreqre , cd_max_freq  and  cd_halfway_freq  which determine the parameters of the\ntransformed grid.",
            "title": "gw_frqre_tangrid"
        },
        {
            "location": "/input_variables/vargw/#gw_invalid_freq",
            "text": "Mnemonics: GW treatment of INVALID FREQuency for Hybertsen-Louie PPM \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver  in [3,4] and  ppmodel  in [2]    gw_invalid_freq  sets the procedure to follow when a PPM frequency is\ninvalid (negative or imaginary).   gw_invalid_freq =0 : Drop them as proposed in Appendix B of PRB 34, 8, 5390, 1986.   gw_invalid_freq =1 : Set them to 1 hartree, as done for the PPM of Godby-Needs.   gw_invalid_freq =2 : Set them to infinity.",
            "title": "gw_invalid_freq"
        },
        {
            "location": "/input_variables/vargw/#gw_nqlwl",
            "text": "Mnemonics: GW, Number of Q-points for the Long Wave-Length Limit \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver  in [3,4,99]    Only relevant if  optdriver =3,4,99 that is, screening, sigma or BETHE_SALPETER  calculations, although the actual meaning of the variable\ndepends on the particular run-level (see discussion below).  gw_nqlwl  defines the number of directions in reciprocal space used to\ndescribe the non-analytical behaviour of the heads (G = G\u2019=0) and the wings\n(G=0 or G\u2019=0) of the dielectric matrix in the optical limit (i.e. for q\ntending to zero). The number of directions is specified by the additional\nvariable  gw_qlwl .  When  optdriver =3,  gw_nqlwl  and   gw_qlwl   define the set of \u201csmall\u201d\nq that will be calculated and stored in the final SCR file. Therefore, the two\nvariables can be used to analyze how the optical spectra depend on the\ndirection of the incident phonon (useful especially in anisotropic systems).  When  optdriver =4,  gw_nqlwl  and   gw_qlwl   can be used to specify\nthe heads and the wings to be used to perform the quadrature of the correlated\npart of the self-energy in the small region around the origin. (NB: not yet\navailable, at present the quadrature is performed using a single direction in\nq-space)  When  optdriver =99,  gw_nqlwl  and   gw_qlwl   define the set of\ndirections in q-space along which the macroscopic dielectric function is\nevaluated. By default the  BETHE_SALPETER  code calculates the macroscopic\ndielectric function using six different directions in q-space (the three basis\nvectors of the reciprocal lattice and the three Cartesian axis).",
            "title": "gw_nqlwl"
        },
        {
            "location": "/input_variables/vargw/#gw_nstep",
            "text": "Mnemonics: GW Number of self-consistent STEPs \nVariable type: integer \nDimensions: scalar \nDefault value: 30 \nOnly relevant if  optdriver ==8    Gives the maximum number of self-consistent  GW  cycles (or \u201citerations\u201d).\nin which G and/or W will be updated until the quasi-particle energies are\nconverged within  gw_toldfeig .  gwcalctyp  and  gw_sctype  are used to\ndefine the type of self-consistency.",
            "title": "gw_nstep"
        },
        {
            "location": "/input_variables/vargw/#gw_qlwl",
            "text": "Mnemonics: GW, Q-points for the Long Wave-Length limit \nVariable type: real \nDimensions: (3, gw_nqlwl ) \nDefault value: [1e-05, 2e-05, 3e-05] \nOnly relevant if  optdriver ==3    When  optdriver =3,  gw_qlwl  defines the set of q-points around Gamma\nthat are considered during the evaluation of the non-analytical behaviour of\nthe dielectric matrix. Optical spectra (with and without non-local field\neffects) are evaluated for each direction specified by  gw_qlwl .",
            "title": "gw_qlwl"
        },
        {
            "location": "/input_variables/vargw/#gw_qprange",
            "text": "Mnemonics: GW QuasiParticle RANGE policy \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==4    gw_qprange  is active only when  nkptgw  is equal to zero (default\nvalue). This variable simplifies the specification of the list of kpoints and\nof the bands to be used for the computation of the quasi-particle corrections.\nThe possible values are:   0 => Compute the QP corrections only for the fundamental and the optical gap   +num => Compute the QP corrections for all the k-points in the irreducible zone. and include  num  bands above and below the Fermi level.   -num => Compute the QP corrections for all the k-points in the irreducible zone. Include all occupied states and  num  empty states.    The default value is 0 and is very handy for one-shot calculations. It is\nimportant to stress, however, that the position of the optical/fundamental\ngaps is deduced from the energies computed on the k-mesh used for the WFK\nfile. Therefore the computed gaps might differ from the correct ones that can\nonly be obtained with an appropriate sampling of the irreducible zone.\nPositive values are useful if we do not know the position of the  GW  HOMO,\nLOMO and we want to investigate the effect of the  GW  corrections on the\nstates close to the gap Negative values are usually used for self-consistent\ncalculations Note that, in the case of self-consistency or symsigma=1, the\ncode might change the bands range so that all the degenerate states are\nincluded. Note also that  kptgw , and  bdgw  are ignored when this options\nis used. If you want to select manually the list of k-points and bands, you\nhave to provide the three variables  nkptgw ,  kptgw , and  bdgw .",
            "title": "gw_qprange"
        },
        {
            "location": "/input_variables/vargw/#gw_sctype",
            "text": "Mnemonics: GW, Self-Consistency TYPE \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver  in [3,4]    This variable is used to partially define the kind of self-consistency for GW  calculations. The other piece of information is given by  gwcalctyp \nthat defines the particular approximation for the self-energy operator as well\nas whether the wavefunctions have to replaced by quasi-particle amplitudes.  If  gw_sctype  is specified in the input file, the code will perform an\niterative update of the quantities entering the  GW  equations until the\nquasi-particle energies are converged within  gw_toldfeig . The maximum\nnumber of iterations is specified by  gw_nstep . Possible values are:   1 => standard one-shot method (one screening calculation followed by a single sigma run)   2 => self-consistency only on W (iterative update of W followed by a sigma run in which G is approximated with the Kohn-Sham independent-particle Green\u2019s function G0)   3 => self-consistency only of G (a single screening calculation to obtain the Kohn-Sham polarizability followed by an iterative update of the Green\u2019s functions in the self-energy)   4 => fully self-consistent algorithm (iterative update of both G and W)    It is possible to initialize the self-consistent procedure by reading a\npreviously calculated SCR or SUSC file via the variables  getscr  or getsuscep , respectively.  getqps  can be used to read a previous QPS\nfile thus initializing the Green functions to be used in the first self-\nconsistent iteration.",
            "title": "gw_sctype"
        },
        {
            "location": "/input_variables/vargw/#gw_sigxcore",
            "text": "Mnemonics: GW, SIGma (self-energy) for the CORE contribution \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==4 and  usepaw ==1    Only available for PAW and relevant if  optdriver =4 that is, sigma\ncalculations.  Theoretical introduction:  GW  calculations performed on top of electronic\ncalculations relying when the frozen-core approximation is used to separate\ninner-core electrons from valence electrons, only the contribution to the\nself-energy arising from valence electrons is explicitly accounted for. In the\nstandard approach based on pseudopotentials the contribution to the self-\nenergy due to core electrons is approximated by means of the KS exchange-\ncorrelation potential generated by the core density. In the case of  GW \ncalculations employing the PAW method, the core contribution to the self-\nenergy can be more accurately estimated in terms of the Fock operator\ngenerated by the core wavefunctions. In the simplest approach, the only\ningredients required for this more refined treatment are the wave functions of\nthe core electrons in the reference atomic configuration that are calculated\nduring the generation of the PAW setup. This is a good approximation provided\nthat the core wave functions are strictly localized inside the PAW spheres.  gw_sigxcore  defines the approximation used to evaluate the core\ncontribution to sigma.   gw_sigxcore  = 0, standard approach, the core contribution is approximated with vxc.   gw_sigxcore  = 1, the core term is approximated with the Fock operator inside the PAW spheres.",
            "title": "gw_sigxcore"
        },
        {
            "location": "/input_variables/vargw/#gw_toldfeig",
            "text": "Mnemonics: GW TOLerance on the DiFference of the EIGenvalues \nVariable type: real \nDimensions: scalar \nDefault value: 0.1 eV \nOnly relevant if  optdriver ==8    Sets a tolerance for absolute differences of QP energies that will cause one\nself-consistent  GW  cycle to stop. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since   toldfe   has\nthe \u2018 ENERGY \u2018 characteristics (1 Ha=27.2113845 eV)",
            "title": "gw_toldfeig"
        },
        {
            "location": "/input_variables/vargw/#gwcalctyp",
            "text": "Mnemonics: GW CALCulation TYPe \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver  in [3,4]    gwcalctyp  governs the choice between the different capabilities of the GW  code.   0 <=  gwcalctyp  <= 9 : standard \u201c1 shot\u201d quasiparticle method   10 <=  gwcalctyp  <= 19 : self-consistent quasiparticle method on energies only    20 <=  gwcalctyp  <= 29 : self-consistent quasiparticle method on energies and wavefunctions     gwcalctyp  = 0, 10, or 20 : standard Plasmon-Pole model  GW  calculation    gwcalctyp  = 1 :  GW  calculation where the self-energy along the real axis is obtained by performing the analytic continuation from the imaginary axis to the full complex plane via the Pade approximant. Only available for standard \u201c1 shot\u201d quasiparticle method.   gwcalctyp  = 2, 12, or 22 :  GW  calculation using numerical integration (contour deformation method, see e.g. S. Lebegue _ et al. _ PRB   67   , 155208 (2003).)   gwcalctyp  = 5, 15, or 25 : Hartree-Fock calculation   gwcalctyp  = 6, 16, or 26 : Screened Exchange calculation   gwcalctyp  = 7, 17, or 27 : COHSEX calculation   gwcalctyp  = 8, 18, or 28 : model  GW  calculation following S. Faleev _ et al. _ PRL   93   , 126406 (2004) using a Plasmon-Pole model   gwcalctyp  = 9, 19, or 29 : model  GW  calculation following S. Faleev _ et al. _ PRL   93   , 126406 (2004) using numerical integration (contour deformation method)    Also   gwcalctyp  = 105,125 : HSE06 calculations (1-shot and self-consistent)   gwcalctyp  = 205,225 : PBE0 calculations (1-shot and self-consistent)   gwcalctyp  = 305,325 : B3LYP calculations (1-shot and self-consistent)",
            "title": "gwcalctyp"
        },
        {
            "location": "/input_variables/vargw/#gwcomp",
            "text": "Mnemonics: GW COMPleteness \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver  in [3,4]    gwcomp  governs the use of an extrapolar approximation. If  gwcomp ==1,\none improves the completeness in a truncated sum over states. In practice,\nthis permits one to reduce quite much the number of bands required in the\ncalculation of the screening or of the self-energy. The energy parameter\nneeded in the extrapolar approximation is set by  gwencomp . See F.\nBruneval, X. Gonze, Phys. Rev. B 78, 085125 (2008) for a description of the\nmethodology.",
            "title": "gwcomp"
        },
        {
            "location": "/input_variables/vargw/#gwencomp",
            "text": "Mnemonics: GW ENergy for COMPleteness \nVariable type: real \nDimensions: scalar \nDefault value: 2.0 \nOnly relevant if  optdriver  in [3,4] and  gwcomp ==1    gwencomp  sets the energy parameter used in the extrapolar approximation\nused to improve completeness and make the convergence against the number of\nbands much faster.  See F. Bruneval, X. Gonze, Phys. Rev. B 78, 085125 (2008) for a description of\nthe methodology.",
            "title": "gwencomp"
        },
        {
            "location": "/input_variables/vargw/#gwfockmix",
            "text": "Mnemonics: GW FOCK exchange MIXing parameter \nVariable type: real \nDimensions: scalar \nDefault value: 0.25 \nOnly relevant if  optdriver =4,  gwcalctyp  = 1x5 (HSE) or 2x5 (PBE0).    Mixing parameter of Fock exchange for PBE0 and HSE hybrid-functional\ncalculations via the GW self-energy subroutine.  gwfockmix  ranges from 0\n(essentially PBE) to 1.",
            "title": "gwfockmix"
        },
        {
            "location": "/input_variables/vargw/#gwgamma",
            "text": "Mnemonics: GW GAMMA \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver =3 or 4 (Sigma calculations)    If  gwgamma  is 1, the vertex correction will be included leading to what is\nknown as \u201c GW Gamma\u201d approximation. see R. Del Sole, L. Reining, and R. W.\nGodby, Phys. Rev. B 49, 8024 (1994). Note that, in order to include the vertex\ncorrection in W, one has to start the sigma calculation from the\nsusceptibility file_SUSC instead of the _SCR file (see  getsuscep    and irdsuscep   ) Not available for PAW calculations.  gwgamma =-4 activates the bootstrap kernel of Sharma et al. [Phys. Rev.\nLett. 107, 186401 (2011)] in the test-charge-test-charge dielectric function\n[cf. Chen and Pasquarello, Phys. Rev. B 92, 041115(R) (2015)]. A cheaper one-\nshot variant can be achieved with  gwgamma =-6 using only the head of the\nkernel.  gwgamma =-8 uses the RPA bootstrap-like kernel (one-shot) [Phys. Rev. Lett.\n115, 137402 (2015), ibid. 114, 146402 (2015)].",
            "title": "gwgamma"
        },
        {
            "location": "/input_variables/vargw/#gwls_band_index",
            "text": "Mnemonics: GWLS BAND INDEX \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver ==66    Governs the DFT eigenstate |e> in which the self-energy will be evaluated, as\nshown in eq. (7) of Phys. Rev. B 91, 125120 (2015). That is, it is the state\nto be corrected in the G0W0 scheme.",
            "title": "gwls_band_index"
        },
        {
            "location": "/input_variables/vargw/#gwls_correlation",
            "text": "Mnemonics: GWLS CORRELATION \nVariable type: integer \nDimensions: scalar \nDefault value: 3 \nOnly relevant if  optdriver ==66    Governs the use of a dielectric model (as explained in section V of Phys. Rev.\nB 91, 125120 (2015). and the use of the Lanczos scheme to solve eqs. (30) and\n(35) of the same reference at all external  gw_freqsp  and integration (as\ngenerated from  gwls_npt_gauss_quad ) frequencies. The different choices\nare:   gwls_correlation  == 1 : GWLS calculation WITH the dielectric model and WITHOUT the shift Lanczos technique,   gwls_correlation  == 2 : GWLS calculation WITHOUT the dielectric model and WITHOUT the shift Lanczos technique,   gwls_correlation  == 3 : GWLS calculation WITH the dielectric model and WITH the shift Lanczos technique,   gwls_correlation  == 4 : GWLS calculation WITHOUT the dielectric model and WITH the shift Lanczos technique,   gwls_correlation  == 5 : Not a GWLS calculation; just calculate and print the eigenvalues of the (static) dielectric matrix (for debugging purposes).    The default, ( gwls_correlation  == 3), is the most performant option and\nshould be kept by the user. Option 1, 2 and 5 are deprecated and will be\nremoved.",
            "title": "gwls_correlation"
        },
        {
            "location": "/input_variables/vargw/#gwls_dielectric_model",
            "text": "Mnemonics: GWLS dielectric model \nVariable type: integer \nDimensions: scalar \nDefault value: 2 \nOnly relevant if  optdriver ==66    Not used yet.",
            "title": "gwls_dielectric_model"
        },
        {
            "location": "/input_variables/vargw/#gwls_exchange",
            "text": "Mnemonics: GWLS exact EXCHANGE \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver ==66    Governs whether the exact exchange for the state to be corrected\n( gwls_band_index ) is calculated ( gwls_exchange ==1) or not\n( gwls_exchange ==0).",
            "title": "gwls_exchange"
        },
        {
            "location": "/input_variables/vargw/#gwls_first_seed",
            "text": "Mnemonics: GWLS FIRST SEED vector \nVariable type: integer \nDimensions: scalar \nDefault value:  gwls_band_index \nOnly relevant if  optdriver ==66    This variable sets the band index to be used to generate the first seed vector\nto be used in the construction of the Lanczos basis for the (static)\ndielectric matrix in a GWLS calculation. See section IV of Phys. Rev. B 91,\n125120 (2015). Together with  gwls_nseeds , defines the seeds for the\nLanczos procedure. That is, the states associated to band index gwls_first_seed  to  gwls_first_seed + gwls_nseeds -1 are used to\ngenerate the seed vectors.  The default  gwls_first_seed == gwls_band_index  and  gwls_nseeds ==1\nhas been touroughly tested and seems to be the most performant. Users should\ntherefore keep the default value.",
            "title": "gwls_first_seed"
        },
        {
            "location": "/input_variables/vargw/#gwls_kmax_analytic",
            "text": "Mnemonics: GWLS KMAX for the ANALYTIC term \nVariable type: integer \nDimensions: scalar \nDefault value: 8 \nOnly relevant if  optdriver ==66    Governs the number of iterations to be done in the shift Lanczos solution of\neq. (35) of Phys. Rev. B 91, 125120 (2015) to solve it at all external\nfrequencies requested by the user ( gw_freqsp ). The default value is\nconverged to a few 10s of meV for all molecules studied so far.",
            "title": "gwls_kmax_analytic"
        },
        {
            "location": "/input_variables/vargw/#gwls_kmax_complement",
            "text": "Mnemonics: GWLS KMAX for the COMPLEMENT space. \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver ==66    The G0W0 formalism involves the calculation of a summation conceptually linked\nto the trace of the dielectric matrix (see eq. (38) of Phys. Rev. B 91, 125120\n(2015). Since the eigenvalues spectrum of the dielectric matrix of formed by a\nfew large discrete eigenvalues and an integrable divergence in the density of\neigenvalues around 0, it is expensive to sample accurately this divergence\nusing the exact dielectric operator. It this becomes interesting to calculate\nthe \u2018trace\u2019 of the \u2018exact - model\u2019 dielectric matrix in a small basis and add\nit to the \u2018trace\u2019 of the \u2018model\u2019 dielectric matrix obtained in a large bais.\nIn the context where the model dielectric matrix is used in the calculations, gwls_sternheimer_kmax  determines the size of the \u2018small\u2019 basis and gwls_kmax_complement  determines the size of the \u2018large\u2019 basis.  For more information on the exact role of these bases and on the model\ndielectric operator used, see section V of Phys. Rev. B 91, 125120 (2015).",
            "title": "gwls_kmax_complement"
        },
        {
            "location": "/input_variables/vargw/#gwls_kmax_numeric",
            "text": "Mnemonics: GWLS KMAX for the NUMERIC term \nVariable type: integer \nDimensions: scalar \nDefault value: 16 \nOnly relevant if  optdriver ==66    Governs the number of iterations to be done in the shift Lanczos solution of\neq. (30) of Phys. Rev. B 91, 125120 (2015) to solve it simultaneously at all\nintegration frequencies (generated automatically by the number of points gwls_npt_gauss_quad  to use in the gaussian quadrature) and all external\nfrequencies requested by the user ( gw_freqsp ). The default value is\nconverged to a few 10s of meV for all molecules studied so far.",
            "title": "gwls_kmax_numeric"
        },
        {
            "location": "/input_variables/vargw/#gwls_kmax_poles",
            "text": "Mnemonics: GWLS KMAX for the calculation of the POLES residue \nVariable type: integer \nDimensions: scalar \nDefault value: 4 \nOnly relevant if  optdriver ==66    The contour deformation technique, in the G0W0 context, will involve the\ncalculation of pole residues associated to states lying between the one\ncorrected ( gwls_band_index ) and the fermi level. These residues take the\nform of a matrix element of the inverse dielectric matrix at a real frequency\n(see eq. (11) of Phys. Rev. B 91, 125120 (2015)). Therefore, the dielectric\nmatrix must be constructed in some basis at these frequencies and inverted to\ncalculate the matrix element. The present input variable sets the size of the\nLanczos basis to be constructed for this purpose. The default value has proven\nto be very robust for many molecular systems and should therefore be left to\nthe default value by the user.  For more information on the Lanczos basis constructed for the calculation of\nthe residues, see section IV of Phys. Rev. B 91, 125120 (2015).",
            "title": "gwls_kmax_poles"
        },
        {
            "location": "/input_variables/vargw/#gwls_list_proj_freq",
            "text": "Mnemonics: GWLS LIST of the PROJection FREQuencies \nVariable type: real \nDimensions: ( gwls_n_proj_freq ) \nDefault value: *0.0 \nOnly relevant if  optdriver ==66    This variable sets the frequencies to be used to construct the basis in which\nthe Hamiltonian is projected to accelerate the solution of the Sternheimer\nequations involved by the construction of the dielectric matrix at finite\nfrequencies. See section VI of Phys. Rev. B 91, 125120 (2015). For most cases,\nsince the frequencies \\Infty and (if  gwls_recycle >0) 0.0 are used at no\ncomputational cost,  gwls_n_proj_freq ==0 (which means no ADDITIONAL\nfrequency is to be used) is fine and no frequencies need to be picked up.",
            "title": "gwls_list_proj_freq"
        },
        {
            "location": "/input_variables/vargw/#gwls_model_parameter",
            "text": "Mnemonics: GWLS MODEL PARAMETER \nVariable type: real \nDimensions: scalar \nDefault value: 1.0 \nOnly relevant if  optdriver ==66    This is the width of the lorentzian, in Ha, used to model the frequency\ndependence of the dielectric matrix in the GWLS calculation (see eqs. (12),\n(13), (14), (15), (16) and (34) of Phys. Rev. B 91, 125120 (2015)). More\nprecisely, this parameter is the value of \\alpha used in eq. (34). This model\nis then used to separate the integration over frequencies into a \u2018model\u2019 part\n(second term of eq. (12)) and a \u2018exact - model\u2019 part (first term of eq. (12)).\nSince the \u2018model\u2019 part can be integrated analytically (see eqs. (15), (16) and\n(34)), only the the \u2018exact - model\u2019 part needs to be integrated numerically.  The only effect of this model is therefore to alleviate the numerical cost of\nthe integration over frequencies in the G0W0 calculation. The value of the\nassociated parameter has thus an impact on the convergence rate of the GWLS\ncalculation with respect to the number of frequencies of integration\n( gwls_npt_gauss_quad ), but no impact on the converged result of the GWLS\ncalculation. Typically, the default ( gwls_model_parameter ==1.0) is\noptimal.",
            "title": "gwls_model_parameter"
        },
        {
            "location": "/input_variables/vargw/#gwls_n_proj_freq",
            "text": "Mnemonics: GWLS Number of PROJection FREQuencies \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==66    This variable sets the number of frequencies, on top of \\Infty and (if gwls_recycle >0) 0.0, to be used for the construction of the basis in which\nthe hamiltonian is projected to accelerate the solution of the Sternheimer\nequations involved in the construction of the dielectric matrix at finite\nfrequencies. See section VI of Phys. Rev. B 91, 125120 (2015). For most cases,\nthe default ( gwls_n_proj_freq ==0) is fine.",
            "title": "gwls_n_proj_freq"
        },
        {
            "location": "/input_variables/vargw/#gwls_npt_gauss_quad",
            "text": "Mnemonics: GWLS Number of PoinTs to use for the GAUSSian QUADrature  \nVariable type: integer \nDimensions: scalar \nDefault value: 10 \nOnly relevant if  optdriver ==66    This variable defines the number of points used for the numerical integration\nof the self-energy over frequencies in GWLS computations (see eq. (12) of\nPhys. Rev. B 91, 125120 (2015)). The default is fine for most cases.",
            "title": "gwls_npt_gauss_quad"
        },
        {
            "location": "/input_variables/vargw/#gwls_nseeds",
            "text": "Mnemonics: GWLS Number of SEED vectorS \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver ==66    This variable sets the number of seed vectors to be used in the construction\nof the Lanczos basis for the (static) dielectric matrix in a GWLS calculation.\nSee section IV of Phys. Rev. B 91, 125120 (2015). Only  gwls_nseeds ==1 has\nbeen tested for now and users should keep this value.",
            "title": "gwls_nseeds"
        },
        {
            "location": "/input_variables/vargw/#gwls_print_debug",
            "text": "Mnemonics: GWLS PRINT level for DEBUGging \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==66    Influences the level of verbosity for debugging purposes in a GWLS\ncalculation. Users should keep its value at the default.",
            "title": "gwls_print_debug"
        },
        {
            "location": "/input_variables/vargw/#gwls_recycle",
            "text": "Mnemonics: GWLS RECYCLE \nVariable type: integer \nDimensions: scalar \nDefault value: 2 \nOnly relevant if  optdriver ==66    This variable let the user choose if and how he wants to recycle the solutions\nof the Sternheimer equations involved in the construction of the static\ndielectric matrix.   gwls_recycle ==0 : No recycling of the solutions   gwls_recycle ==1 : Recycle the solutions. To do so, store them in RAM.   gwls_recycle ==2 : Recycle the solutions. To do so, store them on disk.    If the user choose to recycle the solutions, they are used to construct the\nbasis in which the hamiltonian is projected for the solution of the\nSternheimer equations involved by the calculation of the dielectric matrix at\nfinite frequencies. The other solutions used will be those at \\omega \\to\n\\Infty (alwyas used) and those at \\omega= gwls_list_proj_freq . For more\ninformation of the basis constructed, see section IV of Phys. Rev. B 91,\n125120 (2015).  It is important to note that the solutions rapidly take much space to store.\nTherefore, it is often not possible to store them in RAM in production\ncalculations, yet still desirable to retain them. This is when it becomes\ninteresting to store them on disk. It is particularly efficient to choose the\npath of the file to be on disk space local to the processor in large MPI\ncalculations, since each processor need only his own solutions in the\nconstruction of the basis.",
            "title": "gwls_recycle"
        },
        {
            "location": "/input_variables/vargw/#gwls_second_model_parameter",
            "text": "Mnemonics: GWLS SECOND MODEL PARAMETER \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver ==66    Not used yet.",
            "title": "gwls_second_model_parameter"
        },
        {
            "location": "/input_variables/vargw/#gwls_sternheimer_kmax",
            "text": "Mnemonics: GWLS Kmax \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver ==66    This variable sets the dimension of the dielectric matrix used in a GWLS\ncalculation (see section IV of Phys. Rev. B 91, 125120 (2015)). Typically\nconverged at a value of a few hundreds to a few thousands for a convergence\ncriterion of 50meV on the eigenenergies.",
            "title": "gwls_sternheimer_kmax"
        },
        {
            "location": "/input_variables/vargw/#gwmem",
            "text": "Mnemonics: GW MEMory \nVariable type: integer \nDimensions: scalar \nDefault value: 11 \nOnly relevant if  optdriver  in [3,4]    gwmem  governs the memory strategy during a screening and/or a sigma run.   gwmem  = 1x , the screening matrix are read for all q-vectors and stored in the memory.    gwmem  = 0x , the screening matrix are read just a q-vector after another.       gwmem  = x1 , the real-space wavefunctions are stored in the memory.    gwmem  = x0 , the real-space wavefunctions are not stored, but rather recalculated on-fly each abinit needs them using FFTs.    The default is  gwmem  = 11, which is the fastest, but also the most memory\nconsuming. When experiencing memory shortage, one should try  gwmem  = 0.\nThe first digit is only meaningful when performing sigma calculations.",
            "title": "gwmem"
        },
        {
            "location": "/input_variables/vargw/#gwrpacorr",
            "text": "Mnemonics: GW RPA CORRelation energy \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==3 and  gwcalctyp  in [1,11,21]    gwrpacorr  governs the calculation of the RPA correlation energy.   gwrpacorr  = 0, no RPA correlation energy is calculated   gwrpacorr  = 1, the RPA correlation energy is calculated using an exact integration over the coupling constant: it requires one diagonalization of the polarizability matrix   gwrpacorr  = _ n _ > 1, the RPA correlation energy is calculated using _ n _ values for the coupling constant: it requires _ n _ inversions of the polarizability matrix",
            "title": "gwrpacorr"
        },
        {
            "location": "/input_variables/vargw/#icutcoul",
            "text": "Mnemonics: Integer that governs the CUT-off for COULomb interaction \nVariable type: integer \nDimensions: scalar \nDefault value: 6 \nOnly relevant if  optdriver  in [3,4]    Many-body calculations for isolated systems present a slow convergence with\nrespect to the size of the supercell due to the long ranged Coulomb\ninteraction and the high degree of non-locality of the operators involved. A\nsimilar issue also occurs in fully periodic systems due to the presence of the\nintegrable Coulomb singularity at G=0 that hinders the convergence with\nrespect to the number of q-points used to sample the Brillouin zone. The\nconvergence can be accelerated by replacing the true bare Coulomb interaction\nwith other expressions.  icutcoul  defines the particular expression to be used for the Coulomb term\nin reciprocal space. The choice of  icutcoul  depends on the dimensionality\nof the system. Possible values of  icutcoul  are from 0 to 6. The\ncorresponding influential variables are  vcutgeo  and  rcut .   0 => sphere (molecules but also 3D-crystals)   1 => cylinder (nanowires, nanotubes)   2 => surface   3 => 3D crystal (no cut-off, integration in a spherical mini-Brillouin Zone, legacy value)   4 => ERF, long-range only Coulomb interaction   5 => ERFC, short-range only Coulomb interaction (e.g. as used in the HSE functional)   6 => auxiliary function integration for 3D systems from P. Carrier _ et al. _ , PRB   75   ,205126 (2007).   7 => auxiliary function for 3D systems of Gygi and Baldereschi [cf. Phys. Rev. B  34 , 4405 (1986) and Massidda et al., ibid.  48 , 5058 (1993)].    Note that Spencer and Alavi PRB  77 , 193110 (2008) showed that the\nspherical cutoff can efficiently be used also for 3D systems. In the latter\ncase, use a negative value for the cutoff radius of the sphere\n( rcut <0), which is automatically calculated so that the volume enclosed\nin the sphere is equal to the volume of the solid.",
            "title": "icutcoul"
        },
        {
            "location": "/input_variables/vargw/#inclvkb",
            "text": "Mnemonics: INCLude VKB \nVariable type: integer \nDimensions: scalar \nDefault value: 2 \nOnly relevant if  optdriver  in [3,99]    Possible values of  inclvkb  are 0,1,2. If  inclvkb  is 1 or 2, the\ncommutator of the non-local part of the pseudopotential with the position\noperator is correctly included in the q => 0 contribution. This is\nunfortunately time-consuming and in particular when the old algorithm\nimplemented by inclvkb==1 is used (inclvkb=2 is the recommended option). When inclvkb  is 0, this contribution is incorrectly omitted, but the\ncomputation is much faster.  The importance of this contribution depends on the number of k points. Turning\noff  inclvkb  is let to the choice of the user.  In general, the use of  inclvkb =0 is fine for  GW  calculations in\ncrystalline systems provided that the k-point sampling is sufficiently\nconverged.  The use of  inclvkb =2 is strongly recommended for the calculation of\noptical properties.",
            "title": "inclvkb"
        },
        {
            "location": "/input_variables/vargw/#kptgw",
            "text": "Mnemonics: K-PoinTs for GW calculations \nVariable type: real \nDimensions: (3, nkptgw ) \nDefault value: *0.0 \nOnly relevant if  optdriver ==4    For each k-point with number igwpt in the range (1: nkptgw ), [kptgw]  is the reduced coordinate of the k-point where  GW \ncorrections are required. while  bdgw  (1:2,igwpt) specifies the range of\nbands to be considered.  At present, not all k-points are possible. Only those corresponding to the\nk-point grid defined with the same repetition parameters (  kptrlatt , or ngkpt  ) than the GS one, but WITHOUT any shift, are allowed.",
            "title": "kptgw"
        },
        {
            "location": "/input_variables/vargw/#mbpt_sciss",
            "text": "Mnemonics: Many Body Perturbation Theory SCISSor operator \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver  in [3,4,99]    The Scissors operator energy added to the conductions states. In some cases,\nit mimics a second iteration self-consistent  GW  calculation.",
            "title": "mbpt_sciss"
        },
        {
            "location": "/input_variables/vargw/#mdf_epsinf",
            "text": "Mnemonics: Model Dielectric Function, EPSilon INFinity \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver ==99 and  bs_coulomb_term  in [20,21] (Bethe-Salpeter calculas with a model dielectric function    mdf_epsinf  specifies the value of the macroscopic dielectric function used\nto model the screening function (see Solid State Commun.  84 , 765 (1992)).\nThe proper spatial symmetry of the screening W(r,r_prime) is enforced using\nEq. (7) of Phys. Rev. B  37 , (1988)",
            "title": "mdf_epsinf"
        },
        {
            "location": "/input_variables/vargw/#nbandkss",
            "text": "Mnemonics: Number of BANDs in the KSS file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This input variable is used for the preparation of a  GW  calculation : it\nis used in a GS run (where  optdriver =0) to generate a _KSS file. In this\nrun,  nbandkss  should be non-zero. The generated _KSS file can be\nsubsequently used to calculate the irreducible polarizabilty  \\chi^{(0)}_{KS} \nusing  optdriver =3 or to calculate  GW  corrections setting optdriver =4.   If  nbandkss =0, no _KSS file is created   If  nbandkss =-1, all the available eigenstates (energies and eigenfunctions) are stored in the abo_KSS file at the end of the ground state calculation. The number of states is forced to be the same for all k-points : it will be the minimum of the number of plane waves over all k-points.   If  nbandkss  is greater than 0, abinit stores (about)  nbandkss  eigenstates in the abo_KSS file. This number of states is forced to be the same for all k-points.    See  npwkss  for the selection of the number of the planewave components of\nthe eigenstates to be stored. \nThe input variable  iomode  can be used to read and write KSS files\naccording to different fileformat (presently only  iomode =0 and 3 are\navailable in the  GW  part). \nThe precision of the KSS file can be tuned through the input variable kssform . \nFor more details about the format of the abo_KSS file, see the routine\noutkss.F90.  Very important : for the time being,  istwfk  must be 1 for all the k-points\nin order to generate a _KSS file.",
            "title": "nbandkss"
        },
        {
            "location": "/input_variables/vargw/#nfreqim",
            "text": "Mnemonics: Number of FREQuencies along the IMaginary axis \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==3 and  gwcalctyp  in [2,12,22,9,19,29]    nfreqim  sets the number of pure imaginary frequencies used to calculate\nthe dielectric matrix in order to perform the numerical integration of the GW  self-energy.",
            "title": "nfreqim"
        },
        {
            "location": "/input_variables/vargw/#nfreqmidm",
            "text": "Mnemonics: Nth FREQuency Moment of the Imaginary part of the Dielectric Matrix \nVariable type: integer \nDimensions: scalar \nDefault value: None \nOnly relevant if  optdriver ==4    depending on the value of  nfreqmidm  will calculate the frequency moment of\nthe Dielectric matrix or its inverse,   if  nfreqmidm  is positive : calculate (nth= nfreqmidm ) frequency moment of the Dielectric matrix  if  nfreqmidm  is negative : calculate (nth= nfreqmidm ) frequency moment of the inverse Dielectric matrix  if  nfreqmidm  = 0 : calculate first frequency moment of the full polarizability   see M. Taut, J. Phys. C: Solid State Phys. 18 (1985) 2677-2690.",
            "title": "nfreqmidm"
        },
        {
            "location": "/input_variables/vargw/#nfreqre",
            "text": "Mnemonics: Number of FREQuencies along the REal axis \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==3 and  gwcalctyp  in [2,12,22,9,19,29]    nfreqre  sets the number of real frequencies used to calculate the\ndielectric matrix in order to perform the numerical integration of the  GW \nself-energy.  It can be used also in case of  GW  calculations with plasmon-pole models, _\ni.e _  gwcalctyp <10, to reduce the number of frequencies used to\nevaluate the dielectric matrix from the (default) two to one frequency\n(omega=0) by setting  nfreqre =1. This might be a good idea in case one is\nplanning to use ppmodel>1. This will force the calculation of the\nscreening on a single frequency (omega=0) and hence reduce memory and disk\nspace requirement. The only draw back is that the user will not be able to\nperform self energy calculation using  ppmodel =1, since in the last case\nthe dielectric matrix calculated on two frequencies is required. If the user\nis not sure which ppmodel to use, then s/he is not advised to use this input\nvariable. Using the default values, one must be able to get a screening file\nthat can be used with any ppmodel.",
            "title": "nfreqre"
        },
        {
            "location": "/input_variables/vargw/#nfreqsp",
            "text": "Mnemonics: Number of FREQuencies for the SPectral function \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==4    nfreqsp  defines the number of real frequencies used to calculate the\nspectral function of the  GW  Green\u2019s function.",
            "title": "nfreqsp"
        },
        {
            "location": "/input_variables/vargw/#nkptgw",
            "text": "Mnemonics: Number of K-PoinTs for GW corrections \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==4    nkptgw  gives the number of k-points for which the  GW  calculation must\nbe done. It is used to dimension  kptgw",
            "title": "nkptgw"
        },
        {
            "location": "/input_variables/vargw/#nomegasf",
            "text": "Mnemonics: Number of OMEGA to evaluate the Spectral Function \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==3 and  spmeth !=0    nomegasf  defines the number of real frequencies used to describe the\nspectral function associated to the irreducible polarizability \\chi^{(0)}_{KS} . The frequency mesh will cover the interval between 0 and\nthe maximum (positive) transition energy between occupied and empty states.\nThe delta function entering the expression defining the spectral function is\napproximated using two different methods according to the value of the spmeth  input variable.  It is important to notice that an accurate description of the imaginary part\nof  \\chi^{(0)}_{KS}  requires an extremely dense frequency mesh. It should be\nkept in mind, however, that the memory required grows fast with the value of nomegasf .",
            "title": "nomegasf"
        },
        {
            "location": "/input_variables/vargw/#nomegasi",
            "text": "Mnemonics: Number of OMEGA(S) along the Imaginary axis \nVariable type: integer \nDimensions: scalar \nDefault value: 12 \nOnly relevant if  optdriver ==4 and  gwcalctyp ==1    nomegasi  defines the number of frequency points used to sample the self-\nenergy along the imaginary axis. The frequency mesh is linear and covers the\ninterval between OMEGASIMIN=0.01 Hartree and  omegasimax .",
            "title": "nomegasi"
        },
        {
            "location": "/input_variables/vargw/#nomegasrd",
            "text": "Mnemonics: Number of OMEGA to evaluate the Sigma Real axis Derivative \nVariable type: integer \nDimensions: scalar \nDefault value: 9 \nOnly relevant if  optdriver ==4    The number of real frequencies around the KS energy where the self-energy\nSigma is evaluated. From these values, the derivative of Sigma at the KS\nenergy is numerically estimated through linear interpolation.",
            "title": "nomegasrd"
        },
        {
            "location": "/input_variables/vargw/#npvel",
            "text": "Mnemonics: Number of Particle VELocities \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==3    In the context of the electronic stopping power of impinging ion in matter, npvel  sets the number of the ion velocities to be calculated via linear\nresponse. \nWhen  npvel =0, no stopping power calculation is performed. \nThe direction and the velocity maximum are set with the input variable pvelmax . Note that the results are output for a Z=1 impinging ion, i.e. a\nproton.",
            "title": "npvel"
        },
        {
            "location": "/input_variables/vargw/#npwkss",
            "text": "Mnemonics: Number of PlaneWaves in the KSS file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This input variable is used for the preparation of a  GW  calculation: the\nGS run (where  optdriver =1 and   nbandkss   /=0) should be followed with\na run where  optdriver =3. Also, if  nbandkss =0, no use of  npwkss .  npwkss  defines the number of planewave components of the Kohn-Sham states\nto build the Hamiltonian, in the routine outkss.F90, and so, the size of the\nmatrix, the size of eigenvectors, and the number of available states, to be\nstored in the abo_KSS file. If it is set to 0, then, the planewave basis set\ndefined by the usual Ground State input variable  ecut  is used to generate\nthe superset of all planewaves used for all k-points. Note that this (large)\nplanewave basis is the same for all k-points.  Very important : for the time being,  istwfk  must be 1 for all the\nk-points.",
            "title": "npwkss"
        },
        {
            "location": "/input_variables/vargw/#nqptdm",
            "text": "Mnemonics: Number of Q-PoinTs for the Dielectric Matrix \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==3    If  nqptdm  is equal to 0, the set of q-points for computing the dielectric\nmatrix is determined automatically considering all the possible differences\nbetween the k-points contained in the _KSS file. When  nqptdm  is non-zero,\nthe list of q points is read from  qptdm . This allows one to split the big\ncalculation of all the dielectric matrices into smaller calculations that can\nbe performed independently. The _SCR files generated in different runs can be\nmerged thanks to the   Mrgscr   utility. If  nqptdm  is equal to -1, the\ncode reports the list of q-points in the log file (YAML format) and then\nstops.",
            "title": "nqptdm"
        },
        {
            "location": "/input_variables/vargw/#omegasimax",
            "text": "Mnemonics: OMEGA to evaluate Sigma along the Imaginary axis D: MAXimal value \nVariable type: real \nDimensions: scalar \nDefault value: 50 eV \nOnly relevant if  optdriver ==4 and  gwcalctyp ==1    omegasimax  defines the maximum frequency along the imaginary the axis. In\nconjunction with  nomegasi ,  omegasimax  uniquely defines the linear mesh\nemployed to sample the self-energy along the imaginary axis.",
            "title": "omegasimax"
        },
        {
            "location": "/input_variables/vargw/#omegasrdmax",
            "text": "Mnemonics: OMEGA to evaluate the Sigma Real axis Derivative : MAXimal value \nVariable type: real \nDimensions: scalar \nDefault value: 1.0 eV \nOnly relevant if  optdriver ==4    The maximum distance from the KS energy where to evaluate Sigma. Sigma is\nevaluated at [KS_energy -  omegasrdmax , KS_energy +  omegasrdmax ]\nsampled  nomegasrd  times.",
            "title": "omegasrdmax"
        },
        {
            "location": "/input_variables/vargw/#ppmfrq",
            "text": "Mnemonics: Plasmon Pole Model FReQuency \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 Ha \nOnly relevant if  optdriver  in [3,4]     In plasmon-pole calculations   Usually only effective if  GW  corrections are evaluated using the plasmon-\npole model of Godby-Needs ( ppmodel ==1).    In the present status of the  GW  code, the convolution in frequency space\ndefining the self-energy operator can be evaluated using two different\napproaches: numerical integration and plasmon-pole models. \nMethods based on the numerical integration (contour deformation, analytic\ncontinuation) require the knowledge of the screened interaction for several\nfrequencies. These approaches give the most accurate results but at the price\nof an increase in the CPU time required. \nAlternatively, it is possible to approximate the dynamical behaviour of the\nscreened interaction through simple analytical expressions, the so-called\nplasmon-pole models. In the plasmon-pole model proposed by Godby-Needs\n( ppmodel =1), the screening must be available at zero frequency, as well as\nat another imaginary frequency, of the order of the plasmon frequency (the\npeak in the EELS spectrum). This information is used to model the behaviour of\nthe dielectric matrix for all frequencies. During the calculation of the\nscreening,  ppmfrq  defines the imaginary frequency where the dielectric\nmatrix is evaluated, in addition to the zero frequency. During the self-energy\nrun,  ppmfrq  can be used to define the second frequency to be used to\ncalculate the plasmon-pole parameters. This is particularly useful when the\nSCR file contains several frequencies along the imaginary axis. In this case\nthe frequency whose value is the closest one to  ppmfrq  will be selected.\nNote that, if the plasmon-pole approximation is good, then, the choice of ppmfrq  should have no influence on the final result. One should check\nwhether this is the case. In general, the plasmon frequencies of bulk solids\nare of the order of 0.5 Hartree.     In Contour Deformation calculations   ppmfrq  is here used to   override   the default value calculated from\nthe average electronic density per unit cell. This can affect the distribution\nof gridpoints along the imaginary and real frequency axes. See cd_frqim_method ,  gw_frqim_inzgrid  and  gw_frqre_inzgrid  for more\ndetails.",
            "title": "ppmfrq"
        },
        {
            "location": "/input_variables/vargw/#ppmodel",
            "text": "Mnemonics: Plasmon Pole MODEL \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver  in [3,4]     ppmodel =1 : PP model of Godby and Needs, See Phys Rev Lett 62, 1169 (1989)   ppmodel =2 : PP model of Hybertsen and Louie, See Phys Rev B 34, 5390 (1986)   ppmodel =3 : PP model of W. von der Linden and P. Horsh see Phys Rev B 37, 8351 (1988)   ppmodel =4 : PP model of Farid and Engel. See Phys Rev B47,15931 (1993)   ppmodel =0 : no PP model, numerical integration (contour deformation method, see e.g. S. Lebegue et al. PRB 67, 155208 (2003).)    Please note the difference between  ppmodel  1 and  ppmodel  2,3,4. In the\nfirst case ( ppmodel =1), the plasmon-pole parameters are determined in\norder to reproduce the behaviour of the dielectric matrix at two calculated\nfrequencies: the static limit (omega=0) and the imaginary frequency defined by ppmfrq . In the last three cases, instead, the plasmon-pole parameters are\nfound by using the dielectric matrix calculated only at omega=0 and enforcing\nthe so-called f-sum rule. See also  nfreqre .  Please note also that in the case of  ppmodel  4, the plasmon energies are\nnot simple mathematical parameters, but rather have a physical meaning (at\nleast the lowest ones). Thus the calculated plasmon band structure (plasmon\nenergy vs q vector) is reported in the output file for the lowest 10 bands.",
            "title": "ppmodel"
        },
        {
            "location": "/input_variables/vargw/#pvelmax",
            "text": "Mnemonics: Particle VELocity MAXimum \nVariable type: real \nDimensions: (3) \nDefault value: 3*1.0 \nOnly relevant if  optdriver ==3    When  npvel  is larger than 0, it performs electronic stopping power\ncalculations on a velocity grid along the direction determined by  pvelmax . \nThe vector  pvelmax  defines both the direction and the maximum velocity. pvelmax  is input in Cartesian coordinates.",
            "title": "pvelmax"
        },
        {
            "location": "/input_variables/vargw/#qptdm",
            "text": "Mnemonics: Q-PoinTs for the Dielectric Matrix \nVariable type: real \nDimensions: (3, nqptdm ) \nDefault value: *0.0 \nOnly relevant if  optdriver ==3 and  nqptdm !=0    qptdm  contains the set of q-points used in the screening part of ABINIT,\ninstead of the automatic generation of the q points when  nqptdm =0. These q\npoints are given in terms of reciprocal space primitive translations (NOT in\ncartesian coordinates!). For further explanation, see the input variable nqptdm .",
            "title": "qptdm"
        },
        {
            "location": "/input_variables/vargw/#rcut",
            "text": "Mnemonics: Radius of the CUT-off for coulomb interaction \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    Truncation of the Coulomb interaction in real space. The meaning of  rcut \nis governed by the cutoff shape option  icutcoul .  If  rcut  is negative, the cutoff is automatically calculated so to enclose\nthe same volume inside the cutoff as the volume of the primitive cell.",
            "title": "rcut"
        },
        {
            "location": "/input_variables/vargw/#rhoqpmix",
            "text": "Mnemonics: RHO QuasiParticle MIXing \nVariable type: real \nDimensions: scalar \nDefault value: 1.0    For self-consistent  GW  runs,  rhoqpmix  sets the mixing coefficient\nbetween the new and the previous electronic densities. This mixing damps the\nspurious oscillations in the Hartree potential when achieving self-\nconsistency.  rhoqpmix  is meaningful only when doing self-consistency on\nthe wavefunctions with  gwcalctyp  >= 20.",
            "title": "rhoqpmix"
        },
        {
            "location": "/input_variables/vargw/#spbroad",
            "text": "Mnemonics: SPectral BROADening \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  optdriver ==3 and  spmeth ==2    When a screening calculation ( optdriver ==3) uses a spectral representation\nof the irreducible polarizability in which the delta function is replaced by\nthe gaussian approximant ( spmeth ==2), the standard deviation of the\ngaussian is given by  spbroad .",
            "title": "spbroad"
        },
        {
            "location": "/input_variables/vargw/#spmeth",
            "text": "Mnemonics: SPectral METHod \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==4    The  spmeth  input variable defines the method used to calculate the\nirreducible polarizability  \\chi^{(0)}_{KS} .  By default  \\chi^{(0)}_{KS}  is calculated employing the Adler-Wiser\nexpression ( spmeth =0) with a CPU effort that scales linearly with the\nnumber of frequencies. This approach is convenient when few frequencies are\nrequired, and is usually used in conjunction with plasmon-pole models in which\nonly one or two frequencies are calculated, according to the value of ppmodel . \nUnfortunately a calculation based on the Adler-Wiser expression might be quite\nCPU demanding if the matrix elements of the self-energy operator are evaluated\nby performing numerically the convolution defining the self-energy. The\nintegrand function, indeed, has poles above and below the real axis, and the\nscreened interaction has to be evaluated on a dense frequency mesh in order to\nobtain accurate results.  In the spectral method ( spmeth =1 or 2) the irreducible polarizability is\nexpressed as the Hilbert transform of the imaginary part. The advantage in\nusing this approach consists in the fact that, once the spectral function is\nknown, the irreducible polarizability for an arbitrary frequency can be easily\nobtained through inexpensive integrations. On the other hand an accurate\nevaluation of the imaginary part requires a dense frequency mesh due to the\npresence of delta functions. Two different approaches can be used to\napproximate these delta functions thus allowing the use of affordable\nfrequency grids.  Summarizing:   0 => use Adler-Wiser expression to calculate  \\chi^{(0)}_{KS}   1 => use the spectral method approximating the delta function with a triangular approximant as proposed in   REF TO BE ADDED   2 => use spectral method but approximating the delta function with a Taylor expansion of the exponential as proposed in   REF TO BE ADDED",
            "title": "spmeth"
        },
        {
            "location": "/input_variables/vargw/#symchi",
            "text": "Mnemonics: SYMmetryze \\chi_o \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  optdriver ==3    The evaluation of the irreducible polarizability for a given q-point requires\nan integration over the Brillouin zone (BZ) which is approximated by a\ndiscrete sum over k-points. In principle the integrand function should be\nevaluated for each k-point in the BZ, however it is possible to reduce the\nnumber of points to be explicitly considered by taking advantage of symmetry\nproperties. The development input variable  symchi  is used to choose\nbetween these two equivalent methods:   0=> the summation over k-points is performed considering ALL the points in the BZ (useful for testing and debugging).   1=> the summation is restricted to the k-points belonging to the irreducible wedge defined by the little group associated to the external vector q.",
            "title": "symchi"
        },
        {
            "location": "/input_variables/vargw/#symsigma",
            "text": "Mnemonics: SYMmetrization of SIGMA matrix elements \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==4    This option is used to switch on the symmetrization of the self-energy matrix\nelements ( symsigma =1). In this case the BZ integration defining the self-\nenergy matrix elements is reduced to an appropriate irreducible wedge defined\nby the point group of the wave-vector k specified in the  kptgw  list.  The symmetrized expression leads to a considerable speedup of the run but,\nunfortunately, this option is not yet compatible with self-consistent  GW \ncalculations (see  gwcalctyp ).  The algorithm implemented in  symsigma =1 constructs a symmetric invariant\nfor the diagonal matrix elements of the self-energy by simply averaging the GW  results within the degenerate subspace. Therefore particular care has\nto be taken in the presence of accidental degeneracies. since  GW \ncalculations performed with  symsigma =1 will not be able to remove the\ninitial accidental degeneracy.",
            "title": "symsigma"
        },
        {
            "location": "/input_variables/vargw/#ucrpa",
            "text": "Mnemonics: calculation of the screened interaction U with the Constrained RPA method \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  nspinor  == 1    When equal to one or two, this variable allows for the calculation of U with\nthe cRPA method. An explicit test is shown in automatic tests v7/t23-t24-t25\nand in v7/t68-t69. The present implementation is parallelized (as for usual GW  calculations), use symetry over k-points only for calculations\ninvolving one correlated atom, and can be use when correlated bands are\nentangled or not. The constrained calculation of the polarisability can be\ndone by eliminating transition betweens correlated bands (and not orbitals)\nwith the variable  ucrpa_bands .  For  ucrpa  = 1, two solutions are possible. The first one is to specify\n(with the variable  ucrpa_bands ) the bands to exclude from the\npolarisability calculation. The second solution is to provide an energy window\n(with the variable  ucrpa_window ). The electronic transitions inside this\nwindow will not be taken into account in the polarisability calculation.  For  ucrpa  = 2, the ucrpa_bands should be equal to the  dmftbandi  and dmftbandf  values, and the polarisability of the correlated subspace is\nconstructed with a band and k-point dependent weight.  The implementation is restricted to the case of  nspinor  = 1 (collinear\ncase).  A short presentation of the method and some aspect of the implementation can\nbe found in Section II and Appendix A of   B. Amadon, T. Applencourt and F.\nBruneval Phys. Rev. B 89, 125110 (2014)  .",
            "title": "ucrpa"
        },
        {
            "location": "/input_variables/vargw/#ucrpa_bands",
            "text": "Mnemonics: For the calculation of U with the Constrained RPA method, gives correlated BANDS \nVariable type: integer \nDimensions: (2) \nDefault value: [-1, -1] \nComment: That is, the default includes no band.    Gives the first and last correlated bands for the cRPA calculation of the\npolarisability.",
            "title": "ucrpa_bands"
        },
        {
            "location": "/input_variables/vargw/#ucrpa_window",
            "text": "Mnemonics: For the calculation of U with the Constrained RPA method, gives energy WINDOW \nVariable type: real \nDimensions: (2) \nDefault value: [-1, -1] \nComment: That is, the energy window is empty by default.    Specify a window of energy for the cRPA calculation of the polarisability. The\ntransition inside this window will not be taken into account in the\nconstrained polarisabilty calculations.  The lower bound and the upper bound energies must be specified (two real\nnumbers) with respect to the position of the Fermi level.",
            "title": "ucrpa_window"
        },
        {
            "location": "/input_variables/vargw/#vcutgeo",
            "text": "Mnemonics: V (potential) CUT-off GEOmetry \nVariable type: real \nDimensions: (3) \nDefault value: 3*0.0 \nOnly relevant if  icutcoul  in [1,2]    vcutgeo  is used in conjunction with  icutcoul  to specify the geometry\nused to truncate the Coulomb interaction, as well as the particular approach\nto be used. It has a meaning only for the cylindrical symmetry\n( icutcoul =1) or in the case of surfaces ( icutcoul =2). For each\ngeometry, two different definitions of the cutoff region are available (see\nPhys. Rev. B 73, 233103 and Phys. Rev. B 73, 205119 for a complete description\nof the methods)  In Beigi method (Phys. Rev. B 73, 233103), the cutoff region is given by the\nWigner-Seitz cell centered on the axis of the cylinder. The cutoff region is\nthus automatically defined by the unit cell and there is no need to specify\nWhen  rcut .  To define a cylinder along the z-axis use the following lines. icutcoul 1\nvcutgeo 0 0 1  Please note that Beigi method is implemented only in the case if an\northorhombic Bravais lattic. For hexagonal lattices, one has to use the method\nof Rozzi (Phys. Rev. B 73, 205119) In this case, the interaction is truncated\nin a finite cylinder. Contrarily to the first approach, here one has to\nspecify both the radius of the cylinder with  rcut  as well as the length of\nthe cylinder along the periodic dimension that should always be smaller than\nthe extension of the Born von Karman box. The length of the cylinder is given\nin terms of the fraction of the primitive vector along the periodic direction.  For example, in order to define a finite cylinder along z of radius 2.5 Bohr\nand length 3*R3 icutcoul 1 vcutgeo 0 0 -3.0 # note the minus sign rcut 2.5  For surface calculations ( icutcoul =2),  vcutgeo  is used to define the\ntwo periodic directions defining the surface. Also in this case two different\ntechniques are available. In the method of Beigi, the (positive) non-zero\ncomponents of vcutgeo define the periodic directions of the infinite surface.\nThe interaction is truncated within a slab of width L where L is the length of\nthe primitive vector of the lattice along the non-periodic dimension. For\nexample: icutcoul 2 vcutgeo 1 1 0 It is also possible to define a finite\nsurface by employing negative values For example: icutcoul 2 vcutgeo -3 -2 0\ndefines ....",
            "title": "vcutgeo"
        },
        {
            "location": "/input_variables/vargw/#zcut",
            "text": "Mnemonics: Z-CUT \nVariable type: real \nDimensions: scalar \nDefault value: 0.0036749326 \nComment: 0.0036749326 Ha = 0.1 eV \nOnly relevant if  optdriver  in [3,4,99]    It is meant to avoid some divergencies that might occur during the evaluation\nof the Adler-Wiser expression of the irreducible polarizability\n( optdriver =3) or during the numerical treatment of the integrals defining\nthe contribution to the self-energy matrix elements ( optdriver =4). If the\ndenominator becomes smaller than  zcut , a small imaginary part (depending\non  zcut ) is added, in order to avoid the divergence.  When  optdriver =99,  zcut  defines the small complex shift used to avoid\ndivergences in the expression for the macroscopic dieletric function. It\nsimulates the experimental uncertainty and the finite lifetime of the\nquasiparticles (although the true lifetime should be k- and band-dependent).\nThe value of  zcut  affects the number of iteration needed to achieve\nconvergence in the Haydock iterative method. In this case,  zcut  should be\nlarger than the typical distance between the eigenvalues of the exciton\nHamiltonian. \nIdeally, one should make a convergence study decreasing the value of  zcut \nfor increasing number of k-points.",
            "title": "zcut"
        },
        {
            "location": "/input_variables/varint/",
            "text": "kptns\n\u00b6\n\n\nMnemonics: K-PoinTs re-Normalized and Shifted\n\nVariable type: real\n\nDimensions: (3,\nnkpt\n)\n\nDefault value: None  \n\n\nIf \nnqpt\n=0, or if one is doing a reponse calculation, this internal\nvariable is derived from \nkpt\n and \nkptnrm\n: \n[kptns]\n=\n\n[kpt]\n/ \nkptnrm\n, so that it is \nkpt\n renormalized by \nkptnrm\n.\n\nIf \nnqpt\n=1 and one is not doing a ground-state calculation, this internal\nvariable is derived from \nkpt\n,\nkptnrm\n and \nqptn\n \n[kptns]\n=\n\n[kpt]\n/ \nkptnrm\n+ \n[qptn]\n, so that it is \nkpt\n renormalized\nby \nkptnrm\n, then shifted by \n[qptn]\n.\n\n\nmband\n\u00b6\n\n\nMnemonics: Maximum number of BANDs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nThis internal variable derives the maximum number of bands over all k-points\nand spin-polarisation from \n[nband]\n.\n\n\nmgfft\n\u00b6\n\n\nMnemonics: Maximum of nGFFT\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nThis internal variable contains the maximum of \n[ngfft]\n.\n\n\nmgfftdg\n\u00b6\n\n\nMnemonics: Maximum of nGFFT for the Double Grid\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nThis internal variable contains the maximum of \n[ngfftdg]\n.\n\n\nmpw\n\u00b6\n\n\nMnemonics: Maximum number of Plane Waves\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nThis internal variable gives the maximum of the number of plane waves over all\nk-points. It is computed from \necut\n and the description of the cell,\nprovided by \nacell\n, \nrprim\n, and/or \nangdeg\n.\n\n\nnatpawu\n\u00b6\n\n\nMnemonics: Number of AToms on which PAW+U is applied\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None\n\nOnly relevant if \nusepawu\n==1  \n\n\nThis internal variable gives the number of atoms on which the LDA/GGA+U method\nis applied. This value is determined from \nlpawu\n.\n\n\nndynimage\n\u00b6\n\n\nMnemonics: Number of DYNamical IMAGEs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nThis internal variable gives the number of dynamical images, immediately\ndeduced from the number of non-zero values present in \ndynimage\n. It is used\nto dimension many memory-consuming arrays (one copy for each image), e.g. the\nwavefunction array (cg), the density array (rho), etc .\n\n\nnelect\n\u00b6\n\n\nMnemonics: Number of ELECTrons\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: \nAUTO_FROM_PSP\n  \n\n\nThis internal variable gives the number of electrons per unit cell, as\ncomputed from the sum of the valence electrons related to each atom (given in\nthe pseudopotential, where it is called \u201czion\u201d), and the input variable\n\ncharge\n:\n\n\nnelect\n=zion-\ncharge\n.\n\n\nnfft\n\u00b6\n\n\nMnemonics: Number of FFT points\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nIf space parallelisation is not used (that is, if \nparal_kgb\n==0), this\ninternal variable gives the number of Fast Fourier Transform points in the\ngrid generated by \n[ngfft]\n. It is simply the product of the three\ncomponents of \nngfft\n.\n\nIf space parallelisation is used (that is, if \nparal_kgb\n==1), then it\nbecomes the number of Fast Fourier Transform points attributed to the\nparticular processor. It is no longer the above-mentioned simple product, but\na number usually close to this product divided by the number of processors on\nwhich the space is shared.\n\n\nnfftdg\n\u00b6\n\n\nMnemonics: Number of FFT points for the Double Grid\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nIf space parallelisation is not used (that is, if \nparal_kgb\n==0), this\ninternal variable gives the number of Fast Fourier Transform points in the\n(double) grid generated by \n[ngfftdg]\n. It is simply the product of the\nthree components of \nngfftdg\n.\n\nIf space parallelisation is used (that is, if \nparal_kgb\n==1), then it\nbecomes the number of Fast Fourier Transform points attributed to the\nparticular processor. It is no longer the above-mentioned simple product, but\na number usually close to this product divided by the number of processors on\nwhich the space is shared.\n\n\nnpweps\n\u00b6\n\n\nMnemonics: Number of PlaneWaves for EPSilon (the dielectric matrix)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nnpweps\n determines the size of the planewave set used to represent the\nindependent-particle susceptibility \n\\chi^{(0)}_{KS}\n, the dielectric matrix\n\n\\epsilon\n and its inverse.\n\nIt is an internal variable, determined from \necuteps\n.\n\n\nnpwsigx\n\u00b6\n\n\nMnemonics: Number of PlaneWaves for SIGma eXchange\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nnpwsigx\n determines the cut-off energy of the planewave set used to\ngenerate the exchange part of the self-energy operator.\n\nIt is an internal variable, determed from \necutsigx\n.\n\n\nnpwwfn\n\u00b6\n\n\nMnemonics: Number of PlaneWaves for WaveFunctioNs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nnpwwfn\n is the size of the planewave set used to represent the\nwavefunctions in the formula that generates the independent-particle\nsusceptibility \n\\chi^{(0)}_{KS}\n. It is an internal variable, determined from\n\necutwfn\n.\n\n\nqptn\n\u00b6\n\n\nMnemonics: Q-PoinT re-Normalized\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 3*0\n\nOnly relevant if \nnqpt\n==1  \n\n\nOnly used if \nnqpt\n=1.\n\nIn ground-state calculation, the vector \n[qptn]\n is added to each\nrenormalized k point (whatever the value of \nkptopt\n that was used) to\ngenerate the normalized, shifted, set of k-points \n[kptns]\n.\n\nIn response-function calculations, \n[qptn]\n is the wavevector of the\nphonon-type calculation.\n\n\n[qptn]\n can be produced on the basis of the different methods described\nin \nqptopt\n, like using \n[qpt]\n with renormalisation provided by\n\nqptnrm\n, or using the other possibilities defined by \niqpt\n, \nngqpt\n,\n\nnshiftq\n, \nqptrlatt\n, \nshiftq\n,\n\nFor insulators, there is no restriction on the q-points to be used for the\nperturbations. By contrast, for metals, for the time being, it is advised to\ntake q points for which the k and k+q grids are the same (when the periodicity\nin reciprocal space is taken into account). Tests remain to be done to see\nwhether other q points might be allowed (perhaps with some modification of the\ncode).\n\n\nusefock\n\u00b6\n\n\nMnemonics: USE FOCK exact exchange\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis internal variable is automatically set to 1 when the value of \nixc\n\nrefers to an Hartree-Fock calculation or hybrid functionals.\n\n\n\n\n0 => No use of exact exchange. \n\n\n1 => exact exchange is required for the calculation. \n\n\n\n\nusepaw\n\u00b6\n\n\nMnemonics: USE Projector Augmented Waves method\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: \nAUTO_FROM_PSP\n  \n\n\nThis variable is determined by the pseudopotentials files. PAW calculations\n(see \n PAW variables \n ) can only be performed with PAW atomic\ndata input files, while pseudopotential calculations are performed in ABINIT\nwith norm-conserving pseudopotential input files. Most functionalities in\nABINIT are available with either type of calculation.\n\n\nuserec\n\u00b6\n\n\nMnemonics: USE RECursion\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis internal variable is set to 1 when the recursion method is activated (see\n\ntfkinfunc\n).\n\n\nxclevel\n\u00b6\n\n\nMnemonics: eXchange Correlation functional LEVEL\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nAutomatically determined from the value of \nixc\n.\n\n\n\n\n0 => No XC contribution. \n\n\n1 => LDA functional. \n\n\n2 => GGA functional or hybrid functional based on GGA. \n\n\n3 => Functional for \nTDDFT\n. \n\n\n\n\nziontypat\n\u00b6\n\n\nMnemonics: Z (charge) of the IONs for the different TYPes of AToms\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: \nAUTO_FROM_PSP\n  \n\n\nCharge of the pseudo-ion (=number of valence electrons that are needed to\nscreen exactly the pseudopotential).",
            "title": "Internal"
        },
        {
            "location": "/input_variables/varint/#kptns",
            "text": "Mnemonics: K-PoinTs re-Normalized and Shifted \nVariable type: real \nDimensions: (3, nkpt ) \nDefault value: None    If  nqpt =0, or if one is doing a reponse calculation, this internal\nvariable is derived from  kpt  and  kptnrm :  [kptns] = [kpt] /  kptnrm , so that it is  kpt  renormalized by  kptnrm . \nIf  nqpt =1 and one is not doing a ground-state calculation, this internal\nvariable is derived from  kpt , kptnrm  and  qptn   [kptns] = [kpt] /  kptnrm +  [qptn] , so that it is  kpt  renormalized\nby  kptnrm , then shifted by  [qptn] .",
            "title": "kptns"
        },
        {
            "location": "/input_variables/varint/#mband",
            "text": "Mnemonics: Maximum number of BANDs \nVariable type: integer \nDimensions: scalar \nDefault value: None    This internal variable derives the maximum number of bands over all k-points\nand spin-polarisation from  [nband] .",
            "title": "mband"
        },
        {
            "location": "/input_variables/varint/#mgfft",
            "text": "Mnemonics: Maximum of nGFFT \nVariable type: integer \nDimensions: scalar \nDefault value: None    This internal variable contains the maximum of  [ngfft] .",
            "title": "mgfft"
        },
        {
            "location": "/input_variables/varint/#mgfftdg",
            "text": "Mnemonics: Maximum of nGFFT for the Double Grid \nVariable type: integer \nDimensions: scalar \nDefault value: None    This internal variable contains the maximum of  [ngfftdg] .",
            "title": "mgfftdg"
        },
        {
            "location": "/input_variables/varint/#mpw",
            "text": "Mnemonics: Maximum number of Plane Waves \nVariable type: integer \nDimensions: scalar \nDefault value: None    This internal variable gives the maximum of the number of plane waves over all\nk-points. It is computed from  ecut  and the description of the cell,\nprovided by  acell ,  rprim , and/or  angdeg .",
            "title": "mpw"
        },
        {
            "location": "/input_variables/varint/#natpawu",
            "text": "Mnemonics: Number of AToms on which PAW+U is applied \nVariable type: integer \nDimensions: scalar \nDefault value: None \nOnly relevant if  usepawu ==1    This internal variable gives the number of atoms on which the LDA/GGA+U method\nis applied. This value is determined from  lpawu .",
            "title": "natpawu"
        },
        {
            "location": "/input_variables/varint/#ndynimage",
            "text": "Mnemonics: Number of DYNamical IMAGEs \nVariable type: integer \nDimensions: scalar \nDefault value: None    This internal variable gives the number of dynamical images, immediately\ndeduced from the number of non-zero values present in  dynimage . It is used\nto dimension many memory-consuming arrays (one copy for each image), e.g. the\nwavefunction array (cg), the density array (rho), etc .",
            "title": "ndynimage"
        },
        {
            "location": "/input_variables/varint/#nelect",
            "text": "Mnemonics: Number of ELECTrons \nVariable type: real \nDimensions: scalar \nDefault value:  AUTO_FROM_PSP     This internal variable gives the number of electrons per unit cell, as\ncomputed from the sum of the valence electrons related to each atom (given in\nthe pseudopotential, where it is called \u201czion\u201d), and the input variable charge :  nelect =zion- charge .",
            "title": "nelect"
        },
        {
            "location": "/input_variables/varint/#nfft",
            "text": "Mnemonics: Number of FFT points \nVariable type: integer \nDimensions: scalar \nDefault value: None    If space parallelisation is not used (that is, if  paral_kgb ==0), this\ninternal variable gives the number of Fast Fourier Transform points in the\ngrid generated by  [ngfft] . It is simply the product of the three\ncomponents of  ngfft . \nIf space parallelisation is used (that is, if  paral_kgb ==1), then it\nbecomes the number of Fast Fourier Transform points attributed to the\nparticular processor. It is no longer the above-mentioned simple product, but\na number usually close to this product divided by the number of processors on\nwhich the space is shared.",
            "title": "nfft"
        },
        {
            "location": "/input_variables/varint/#nfftdg",
            "text": "Mnemonics: Number of FFT points for the Double Grid \nVariable type: integer \nDimensions: scalar \nDefault value: None    If space parallelisation is not used (that is, if  paral_kgb ==0), this\ninternal variable gives the number of Fast Fourier Transform points in the\n(double) grid generated by  [ngfftdg] . It is simply the product of the\nthree components of  ngfftdg . \nIf space parallelisation is used (that is, if  paral_kgb ==1), then it\nbecomes the number of Fast Fourier Transform points attributed to the\nparticular processor. It is no longer the above-mentioned simple product, but\na number usually close to this product divided by the number of processors on\nwhich the space is shared.",
            "title": "nfftdg"
        },
        {
            "location": "/input_variables/varint/#npweps",
            "text": "Mnemonics: Number of PlaneWaves for EPSilon (the dielectric matrix) \nVariable type: integer \nDimensions: scalar \nDefault value: None    npweps  determines the size of the planewave set used to represent the\nindependent-particle susceptibility  \\chi^{(0)}_{KS} , the dielectric matrix \\epsilon  and its inverse. \nIt is an internal variable, determined from  ecuteps .",
            "title": "npweps"
        },
        {
            "location": "/input_variables/varint/#npwsigx",
            "text": "Mnemonics: Number of PlaneWaves for SIGma eXchange \nVariable type: integer \nDimensions: scalar \nDefault value: None    npwsigx  determines the cut-off energy of the planewave set used to\ngenerate the exchange part of the self-energy operator. \nIt is an internal variable, determed from  ecutsigx .",
            "title": "npwsigx"
        },
        {
            "location": "/input_variables/varint/#npwwfn",
            "text": "Mnemonics: Number of PlaneWaves for WaveFunctioNs \nVariable type: integer \nDimensions: scalar \nDefault value: None    npwwfn  is the size of the planewave set used to represent the\nwavefunctions in the formula that generates the independent-particle\nsusceptibility  \\chi^{(0)}_{KS} . It is an internal variable, determined from ecutwfn .",
            "title": "npwwfn"
        },
        {
            "location": "/input_variables/varint/#qptn",
            "text": "Mnemonics: Q-PoinT re-Normalized \nVariable type: real \nDimensions: (3) \nDefault value: 3*0 \nOnly relevant if  nqpt ==1    Only used if  nqpt =1. \nIn ground-state calculation, the vector  [qptn]  is added to each\nrenormalized k point (whatever the value of  kptopt  that was used) to\ngenerate the normalized, shifted, set of k-points  [kptns] . \nIn response-function calculations,  [qptn]  is the wavevector of the\nphonon-type calculation.  [qptn]  can be produced on the basis of the different methods described\nin  qptopt , like using  [qpt]  with renormalisation provided by qptnrm , or using the other possibilities defined by  iqpt ,  ngqpt , nshiftq ,  qptrlatt ,  shiftq , \nFor insulators, there is no restriction on the q-points to be used for the\nperturbations. By contrast, for metals, for the time being, it is advised to\ntake q points for which the k and k+q grids are the same (when the periodicity\nin reciprocal space is taken into account). Tests remain to be done to see\nwhether other q points might be allowed (perhaps with some modification of the\ncode).",
            "title": "qptn"
        },
        {
            "location": "/input_variables/varint/#usefock",
            "text": "Mnemonics: USE FOCK exact exchange \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This internal variable is automatically set to 1 when the value of  ixc \nrefers to an Hartree-Fock calculation or hybrid functionals.   0 => No use of exact exchange.   1 => exact exchange is required for the calculation.",
            "title": "usefock"
        },
        {
            "location": "/input_variables/varint/#usepaw",
            "text": "Mnemonics: USE Projector Augmented Waves method \nVariable type: integer \nDimensions: scalar \nDefault value:  AUTO_FROM_PSP     This variable is determined by the pseudopotentials files. PAW calculations\n(see   PAW variables   ) can only be performed with PAW atomic\ndata input files, while pseudopotential calculations are performed in ABINIT\nwith norm-conserving pseudopotential input files. Most functionalities in\nABINIT are available with either type of calculation.",
            "title": "usepaw"
        },
        {
            "location": "/input_variables/varint/#userec",
            "text": "Mnemonics: USE RECursion \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This internal variable is set to 1 when the recursion method is activated (see tfkinfunc ).",
            "title": "userec"
        },
        {
            "location": "/input_variables/varint/#xclevel",
            "text": "Mnemonics: eXchange Correlation functional LEVEL \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Automatically determined from the value of  ixc .   0 => No XC contribution.   1 => LDA functional.   2 => GGA functional or hybrid functional based on GGA.   3 => Functional for  TDDFT .",
            "title": "xclevel"
        },
        {
            "location": "/input_variables/varint/#ziontypat",
            "text": "Mnemonics: Z (charge) of the IONs for the different TYPes of AToms \nVariable type: real \nDimensions: ( ntypat ) \nDefault value:  AUTO_FROM_PSP     Charge of the pseudo-ion (=number of valence electrons that are needed to\nscreen exactly the pseudopotential).",
            "title": "ziontypat"
        },
        {
            "location": "/input_variables/varpar/",
            "text": "autoparal\n\u00b6\n\n\nMnemonics: AUTOmatisation of the PARALlelism\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis input variable is used only when running ABINIT in parallel and for\nGround-State calculations.\n\nIt controls the automatic determination of parameters related to parallel work\ndistribution (if not imposed in input file). Given a total number of\nprocessors, ABINIT can find a suitable distribution that fill (when possible)\nall the different levels of parallelization. ABINIT can also determine optimal\nparameters for the use of parallel Linear Algebra routines (using Scalapack or\nCuda, at present).\n\nThe different values for \nautoparal\n are:\n\n\n\n\n 0: \n The \nautoparal\n feature is deactivated. For ground-state and response function calculations, ABINIT can only activate automatically the parallelism over spins and k-points. \n\n\n\n\n 1: \n The number of processors per parallelization level is determined by mean of a simple (but relatively efficient) heuristic. A scaling factor is attributed to each level and an simple speedup factor is computed. The selected parameters are those giving the best speedup factor. \n\nPossibly concerned parameters: \nnpimage\n, \nnpkpt\n, \nnpspinor\n,\n\nnpfft\n, \nnpband\n, \nbandpp\n.\n\n\n\n\n\n\n 2: \n The number of processors per parallelization level is first determined by mean of a simple (but relatively efficient) heuristic (see 1 above). Then the code performs a series of small benchmarks using the scheme applied for the LOBPCG algorithm (see: \nwfoptalg\n=4 or 14). The parallel distribution is then changed according to the benchmarks. \n\nPossibly concerned parameters: \nnpimage\n, \nnpkpt\n, \nnpspinor\n,\n\nnpfft\n, \nnpband\n, \nbandpp\n.\n\n\n\n\n\n\n 3: \n Same as \nautoparal\n=1, plus automatic determination of Linear Algebra routines parameters. \n\nIn addition, the code performs a series of small benchmarks using the Linear\nAlgebra routines (ScaLapack or Cuda-GPU). The parameters used to optimize\nLinear Algebra work distribution are then changed according to the benchmarks.\n\nPossibly concerned parameters (in addition to those modified for\n\nautoparal\n=1): \nuse_slk\n, \nnp_slk\n, \ngpu_linalg_limit\n\n\n\n\n\n\n 4: \n combination of \nautoparal\n=2 and \nautoparal\n=3. \n\n\n\n\n\n\nNote that \nautoparal\n=1 can be used on every set of processors;\n\nautoparal\n > 1 should be used on a sufficiently large number of MPI\nprocess.\n\nAlso note that \nautoparal\n can be used simultaneously with \nmax_ncpus\n; in\nthis case, ABINIT performs an optimization of process distribution for each\ntotal number of processors from 2 to \nmax_ncpus\n. A weight is associated to\neach distribution and the higher this weight is the better the distribution\nis. After having printed out the weights, the code stops.\n\n\nbandpp\n\u00b6\n\n\nMnemonics: BAND Per Processor\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nparal_kgb\n==1  \n\n\nControl the size of the block in the LOBPCG algorithm. This keyword works only\nwith \nparal_kgb\n=1 and has to be either 1 or a multiple of 2.  \n\n\n-- With \nnpband\n=1:\n\n\n\n\n1 => band-per-band algorithm \n\n\nn => The minimization is performed using \nnband\n/n blocks of n bands. \n\n\n\n\nNote: \nnband\n/n has to be an integer.  \n\n\n-- With \nnpband\n/=1:\n\n\n\n\n1 => The minimization is performed using \nnband\n/\nnpband\n blocks of \nnpband\n bands. \n\n\nn => The minimization is performed using \nnband\n/(\nnpband\nn) blocks of \nnpband\nn bands. \n\n\n\n\nNote: \nnband\n/(\nnpband\n*n) has to be an integer.  \n\n\nBy minimizing a larger number of bands together in LOBPCG, we increase the\nconvergency of the residual. The better minimization procedure (as concerns\nthe convergency, but not as concerns the speed) is generally performed by\nusing \nbandpp\n*\nnpband\n=\nnband\n. Put \nbandpp\n=2 when \nistwfk\n=2 (the\ntime spent in FFTs is divided by two).\n\n\ngpu_devices\n\u00b6\n\n\nMnemonics: GPU: choice of DEVICES on one node\n\nVariable type: integer\n\nDimensions: (5)\n\nDefault value: [-1, -1, -1, -1, -1]\n\nOnly relevant if \nuse_gpu_cuda\n==1 (CUDA functionality)  \n\n\nTo be used when several GPU devices are present on each node, assuming the\nsame number of devices on all nodes.\n\nAllows to choose in which order the GPU devices are chosen and distributed\namong MPI processes (see examples below). When the default value (-1) is set,\nthe GPU devices are chosen by order of performance (FLOPS, memory).  \n\n\nExamples:\n\n\n\n\n\n\n2 GPU devices per node, 4 MPI processes per node, \ngpu_device\n=[-1,-1,-1,-1,-1] (default):\n\nMPI processes 0 and 2 use the best GPU card, MPI processes 1 and 3 use the\nslowest GPU card.\n\n\n\n\n\n\n3 GPU devices per node, 5 MPI processes per node, \ngpu_device\n=[1,0,2,-1,-1]:\n\nMPI processes 0 and 3 use GPU card 1, MPI processes 1 and 4 use GPU card 0,\nMPI process 2 uses GPU card 2.\n\n\n\n\n\n\n3 GPU devices per node, 5 MPI processes per node, \ngpu_device\n=[0,1,-1,-1,-1]:\n\nMPI processes 0, 2 and 4 use GPU card 0, MPI processes 1 and 3 use GPU card 1;\nthe 3rd GPU card is not used.\n\n\n\n\n\n\nGPU card are numbered starting from 0; to get the GPU devices list, type\n\u201cnvidia-smi\u201d or \u201clspci | grep -i nvidia\u201d.\n\n\ngpu_linalg_limit\n\u00b6\n\n\nMnemonics: GPU (Cuda): LINear ALGebra LIMIT\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2000000\n\nOnly relevant if \nuse_gpu_cuda\n==1 (CUDA functionality)  \n\n\nUse of linear algebra and matrix algebra on GPU is only efficient if the size\nof the involved matrices is large enough. The \ngpu_linalg_limit\n parameter\ndefines the threshold above which linear (and matrix) algebra operations are\ndone on the Graphics Processing Unit.\n\nThe considered matrix size is equal to:  \n\n\n\n\nSIZE=(\nmpw\nnspinor\n/ \nnpspinor\n)\n (\nnpband\nbandpp\n)\n*2 \n\n\n\n\nWhen SIZE>=\ngpu_linalg_limit\n, \nwfoptalg\n parameter is automatically\nset to 14 which corresponds to the use of LOBPCG algorithm for the calculation\nof the eigenstates.\n\n\ngwpara\n\u00b6\n\n\nMnemonics: GW PARAllelization level\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2\n\nComment: The default value has been changed in v8. From 1 to 2 \n\nOnly relevant if \noptdriver\n in [3,4]  \n\n\ngwpara\n is used to choose between the two different parallelization levels\navailable in the \nGW\n code. The available options are:\n\n\n\n\n=1 => parallelisation on k points \n\n\n=2 => parallelisation on bands \n\n\n\n\nAdditional notes:\n\nIn the present status of the code, only the parallelization over bands\n(\ngwpara\n=2) allows to reduce the memory allocated by each processor.\n\nUsing \ngwpara\n=1, indeed, requires the same amount of memory as a sequential\nrun, irrespectively of the number of CPUs used.\n\n\nlocalrdwf\n\u00b6\n\n\nMnemonics: LOCAL ReaD WaveFunctions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis input variable is used only when running abinit in parallel. If\n\nlocalrdwf\n=1, the input wavefunction disk file or the KSS/SCR file in case\nof \nGW\n calculations, is read locally by each processor, while if\n\nlocalrdwf\n=0, only one processor reads it, and broadcast the data to the\nother processors.\n\n\nThe option \nlocalrdwf\n=0 is NOT allowed when parallel I/O are activated\n(MPI-IO access), i.e. when \niomode\n==1.\n\n\nIn the case of a parallel computer with a unique file system, both options are\nas convenient for the user. However, if the I/O are slow compared to\ncommunications between processors, , \nlocalrdwf\n=0 should be much more\nefficient; if you really need temporary disk storage, switch to localrdwf=1 ).\n\n\nIn the case of a cluster of nodes, with a different file system for each\nmachine, the input wavefunction file must be available on all nodes if\n\nlocalrdwf\n=1, while it is needed only for the master node if\n\nlocalrdwf\n=0.\n\n\nmax_ncpus\n\u00b6\n\n\nMnemonics: MAXimum Number of CPUS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf \nautoparal\n > 1 and \nmax_ncpus\n is greater than 0, ABINIT analyzes\nthe efficiency of the process distribution for each possible number of\nprocessors from 2 to \nmax_ncpus\n. After having printed out the efficiency,\nthe code stops.\n\n\nnp_slk\n\u00b6\n\n\nMnemonics: Number of mpi Processors used for ScaLapacK calls\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1000000\n\nOnly relevant if \noptdriver\n==1 and \nparal_kgb\n==1 (Ground-state calculations with LOBPCG algorithm)  \n\n\nWhen using Scalapack (or any similar Matrix Algebra library), the efficiency\nof the eigenproblem resolution saturates as the number of CPU cores increases.\nIt is better to use a smaller number of CPU cores for the LINALG calls.\n\nThis maximum number of cores can be set with \nnp_slk\n.\n\nA large number for \nnp_slk\n (i.e. 1000000) means that all cores are used for\nthe Linear Algebra calls.\n\nnp_slk must divide the number of processors involved in diagonalizations\n(\nnpband\nnpfft\nnpspinor\n).\n\nNote: an optimal value for this parameter can be automatically found by using\nthe \nautoparal\n input keyword.\n\n\nnpband\n\u00b6\n\n\nMnemonics: Number of Processors at the BAND level\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nparal_kgb\n==1  \n\n\nRelevant only for the band/FFT parallelisation (see the \nparal_kgb\n input\nvariable).\n\n\nnpband\n gives the number of processors among which the work load over the\nband level is shared. \nnpband\n, \nnpfft\n, \nnpkpt\n and \nnpspinor\n are\ncombined to give the total number of processors (nproc) working on the\nband/FFT/k-point parallelisation.\n\nSee \nnpfft\n, \nnpkpt\n, \nnpspinor\n and \nparal_kgb\n for the additional\ninformation on the use of band/FFT/k-point parallelisation. \nnpband\n has to\nbe a divisor or equal to \nnband\n\nNote: an optimal value for this parameter can be automatically found by using\nthe \nautoparal\n input keyword.\n\n\nnpfft\n\u00b6\n\n\nMnemonics: Number of Processors at the FFT level\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nparal_kgb\n==1  \n\n\nRelevant only for the band/FFT/k-point parallelisation (see the \nparal_kgb\n\ninput variable).\n\n\nnpfft\n gives the number of processors among which the work load over the\nFFT level is shared. \nnpfft\n, \nnpkpt\n, \nnpband\n and \nnpspinor\n are\ncombined to give the total number of processors (nproc) working on the\nband/FFT/k-point parallelisation.\n\nSee \nnpband\n, \nnpkpt\n, \nnpspinor\n, and \nparal_kgb\n for the additional\ninformation on the use of band/FFT/k-point parallelisation.\n\n\nNote : \nngfft\n is automatically adjusted to \nnpfft\n. If the number of\nprocessor is changed from a calculation to another one, \nnpfft\n may change,\nand then \nngfft\n also.\n\nNote: an optimal value for this parameter can be automatically found by using\nthe \nautoparal\n input keyword.\n\n\nnphf\n\u00b6\n\n\nMnemonics: Number of Processors for (Hartree)-Fock exact exchange\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nRelevant only for the k-point/fock parallelisation (option \nparal_kgb\n input\nvariable).\n\n\nnphf\n gives the number of processors among which the work load over the\noccupied states level is shared. \nnphf\n and \nnpkpt\n are combined to give\nthe total number of processors (nproc) working on the parallelisation.  \n\n\nNote : \nnphf\n should be a divisor or equal to the number of k-point times\nthe number of bands for exact exchange (\nnkpthf\n*\nnbandhf\n) in order to\nhave the better load-balancing and efficiency.  \n\n\nnpimage\n\u00b6\n\n\nMnemonics: Number of Processors at the IMAGE level\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nRelevant only when sets of images are activated (see \nimgmov\n and \nnimage\n\n).\n\n\nnpimage\n gives the number of processors among which the work load over the\nimage level is shared. It is compatible with all other parallelization levels\navailable for ground-state calculations.\n\nNote: an optimal value for this parameter can be automatically found by using\nthe \nautoparal\n input keyword.  \n\n\n_See \nparal_kgb\n, \nnpkpt\n, \nnpband\n, \nnpfft\n and \nnpspinor\n for the\nadditional information on the use of k-point/band/FFT parallelisation. _\n\n\nnpkpt\n\u00b6\n\n\nMnemonics: Number of Processors at the K-Point Level\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nparal_kgb\n==1  \n\n\nRelevant only for the band/FFT/k-point parallelisation (see the \nparal_kgb\n\ninput variable).\n\n\nnpkpt\n gives the number of processors among which the work load over the\nk-point/spin-component level is shared. \nnpkpt\n, \nnpfft\n, \nnpband\n and\n\nnpspinor\n are combined to give the total number of processors (nproc)\nworking on the band/FFT/k-point parallelisation.\n\nSee \nnpband\n, \nnpfft\n, \nnpspinor\n and \nparal_kgb\n for the additional\ninformation on the use of band/FFT/k-point parallelisation.\n\n\nnpkpt\n should be a divisor or equal to with the number of k-point/spin-\ncomponents (\nnkpt\n*\nnsppol\n) in order to have the better load-balancing\nand efficiency.\n\nNote: an optimal value for this parameter can be automatically found by using\nthe \nautoparal\n input keyword.\n\n\nnppert\n\u00b6\n\n\nMnemonics: Number of Processors at the PERTurbation level\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nparal_rf\n==1  \n\n\nThis parameter is used in connection to the parallelization over\nperturbations(see \nparal_rf\n ), for a linear response calculation.\n\nnppert\n gives the number of processors among which the work load over the\nperturbation level is shared. It can even be specified separately for each\ndataset.\n\n\nnpspinor\n\u00b6\n\n\nMnemonics: Number of Processors at the SPINOR level\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nparal_kgb\n==1  \n\n\nCan be 1 or 2 (if \nnspinor\n=2).\n\nRelevant only for the band/FFT/k-point parallelisation (see the \nparal_kgb\n\ninput variable).\n\n\nnpspinor\n gives the number of processors among which the work load over the\nspinorial components of wave-functions is shared. \nnpspinor\n, \nnpfft\n,\n\nnpband\n and \nnpkpt\n are combined to give the total number of processors\n(nproc) working on the band/FFT/k-point parallelisation.\n\nNote: an optimal value for this parameter can be automatically found by using\nthe \nautoparal\n input keyword.  \n\n\nSee \nnpkpt\n, \nnpband\n, \nnpfft\n, and \nparal_kgb\n for the additional\ninformation on the use of band/FFT/k-point parallelisation.\n  \n\n\nparal_atom\n\u00b6\n\n\nMnemonics: activate PARALelization over (paw) ATOMic sites\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nRelevant only for PAW calculations.\n\nThis keyword controls the parallel distribution of memory over atomic sites.\nCalculations are also distributed using the \u201ckpt-band\u201d communicator.\nCompatible with ground-state calculations and response function calculations  \n\n\nparal_kgb\n\u00b6\n\n\nMnemonics: activate PARALelization over K-point, G-vectors and Bands\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\n If paral_kgb is not explicitely put in the input file \n , ABINIT automatically detects if the job has been sent in sequential or in parallel. In this last case, it detects the number of processors on which the job has been sent and calculates values of \nnpkpt\n, \nnpfft\n, \nnpband\n, \nbandpp\n , \nnpimage\n and \nnpspinor\n that are compatible with the number of processors. It then set paral_kgb to 0 or 1 (see hereunder) and launches the job. \n\n\n If paral_kgb=0 \n , the parallelization over k-points only is activated. In this case, \nnpkpt\n, \nnpspinor\n, \nnpfft\n and \nnpband\n are ignored. Require compilation option \u2013enable-mpi=\u201dyes\u201d. \n\n\n If paral_kgb=1 \n , the parallelization over bands, FFTs, and k-point/spin-components is activated (see \nnpkpt\n, \nnpfft\n \nnpband\n and eventually \nnpspinor\n). With this parallelization, the work load is split over four levels of parallelization (three level of parallelisation (kpt-band-fft )+ spin) The different communications almost occur along one dimension only. Require compilation option \u2013enable-mpi=\u201dyes\u201d. \n\n\nHOWTO fix the number of processors along one level of parallelisation:\n\nAt first, try to parallelise over the k point and spin (see\n\nnpkpt\n,\nnpspinor\n). Otherwise, for unpolarized calculation at the gamma\npoint, parallelise over the two other levels: the band and FFT ones. For\nnproc<=50, the best speed-up is achieved for \nnpband\n=nproc and\n\nnpfft\n=1 (which is not yet the default). For nproc>=50, the best speed-\nup is achieved for \nnpband\n >=4*\nnpfft\n.\n\n\nFor additional information, download F. Bottin presentation at the \n ABINIT\nworkshop 2007 \n\n\nSuggested acknowledgments :\n\nF. Bottin, S. Leroux, A. Knyazev and G. Zerah, _ Large scale ab initio\ncalculations based on three levels of parallelization _ , Comput. Mat. Science\n\n 42 \n , 329 (2008), also available on arXiv, http://arxiv.org/abs/0707.3405\n.\n\n\nIf the total number of processors used is compatible with the four levels of\nparallelization, the values for \nnpkpt\n, \nnpspinor\n, \nnpfft\n, \nnpband\n\nand \nbandpp\n will be filled automatically, although the repartition may not\nbe optimal. To optimize the repartition use:\n\n\n If paral_kgb=1 \n and \n max_ncpus = n /= 0 \n ABINIT will test automatically if all the processor numbers between 2 and n are convenient for a parallel calculation and print the possible values in the log file. A weight is attributed to each possible processors repartition. It is adviced to select a processor repartition for which the weight is high (as closed to the number of processors as possible). The code will then stop after the printing. This test can be done as well with a sequential as with a parallel version of the code. The user can then choose the adequate number of processor on which he can run his job. He must put again paral_kgb=1 in the input file and put the corresponding values for \nnpkpt\n, \nnpfft\n, \nnpband\n,\nbandpp\n and eventually \nnpspinor\n in the input file. \n\n\nparal_rf\n\u00b6\n\n\nMnemonics: activate PARALlelization over Response Function perturbations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis parameter activates the parallelization over perturbations which can be\nused during RF-Calculation. It is possible to use this type of parallelization\nin combination to the parallelization over k-points.\n\n\nCurrently total energies calculated by groups, where the master process is not\nin, are saved in .status_LOGxxxx files.\n\n\nIf \nparal_rf\n is set to -1, the code reports the list of irreducible\nperturbations for the specified q-point in the log file (YAML format) and then\nstops.\n\n\nparal_rf\n can be specified separately for each dataset.\n\n\npw_unbal_thresh\n\u00b6\n\n\nMnemonics: Plane Wave UNBALancing: THRESHold for balancing procedure\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 40%\n\nOnly relevant if \nparal_kgb\n==1  \n\n\nThis parameter (in %) activates a load balancing procedure when the\ndistribution of plane wave components over MPI processes is not optimal. The\nbalancing procedure is activated when the ratio between the number of plane\nwaves treated by a processor and the ideal one is higher than\n\npw_unbal_thresh\n %.\n\n\nuse_gpu_cuda\n\u00b6\n\n\nMnemonics: activate USE of GPU accelerators with CUDA (nvidia)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \noptdriver\n==0 and \nCUDA\n,\n0 otherwise.\n\n\nOnly available if ABINIT executable has been compiled with cuda nvcc compiler.\n\nThis parameter activates the use of NVidia graphic accelerators (GPU) if\npresent.\n\nIf \nuse_gpu_cuda\n = 1, some parts of the computation are transmitted to the\nGPUs.\n\nIf \nuse_gpu_cuda\n = 0, no computation is done on GPUs, even if present.  \n\n\nNote that, while running ABINIT on GPUs, it is recommended to use MAGMA\nexternal library (i.e. Lapack on GPUs). The latter is activated during\ncompilation stage (see \u201cconfigure\u201d step of ABINIT compilation process). If\nMAGMA is not used, ABINIT performances on GPUs can be poor.\n\n\nuse_slk\n\u00b6\n\n\nMnemonics: USE ScaLapacK\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf set to 1, enable the use of ScaLapack within LOBPCG.",
            "title": "Parallelism"
        },
        {
            "location": "/input_variables/varpar/#autoparal",
            "text": "Mnemonics: AUTOmatisation of the PARALlelism \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This input variable is used only when running ABINIT in parallel and for\nGround-State calculations. \nIt controls the automatic determination of parameters related to parallel work\ndistribution (if not imposed in input file). Given a total number of\nprocessors, ABINIT can find a suitable distribution that fill (when possible)\nall the different levels of parallelization. ABINIT can also determine optimal\nparameters for the use of parallel Linear Algebra routines (using Scalapack or\nCuda, at present). \nThe different values for  autoparal  are:    0:   The  autoparal  feature is deactivated. For ground-state and response function calculations, ABINIT can only activate automatically the parallelism over spins and k-points.     1:   The number of processors per parallelization level is determined by mean of a simple (but relatively efficient) heuristic. A scaling factor is attributed to each level and an simple speedup factor is computed. The selected parameters are those giving the best speedup factor.  \nPossibly concerned parameters:  npimage ,  npkpt ,  npspinor , npfft ,  npband ,  bandpp .     2:   The number of processors per parallelization level is first determined by mean of a simple (but relatively efficient) heuristic (see 1 above). Then the code performs a series of small benchmarks using the scheme applied for the LOBPCG algorithm (see:  wfoptalg =4 or 14). The parallel distribution is then changed according to the benchmarks.  \nPossibly concerned parameters:  npimage ,  npkpt ,  npspinor , npfft ,  npband ,  bandpp .     3:   Same as  autoparal =1, plus automatic determination of Linear Algebra routines parameters.  \nIn addition, the code performs a series of small benchmarks using the Linear\nAlgebra routines (ScaLapack or Cuda-GPU). The parameters used to optimize\nLinear Algebra work distribution are then changed according to the benchmarks. \nPossibly concerned parameters (in addition to those modified for autoparal =1):  use_slk ,  np_slk ,  gpu_linalg_limit     4:   combination of  autoparal =2 and  autoparal =3.     Note that  autoparal =1 can be used on every set of processors; autoparal  > 1 should be used on a sufficiently large number of MPI\nprocess. \nAlso note that  autoparal  can be used simultaneously with  max_ncpus ; in\nthis case, ABINIT performs an optimization of process distribution for each\ntotal number of processors from 2 to  max_ncpus . A weight is associated to\neach distribution and the higher this weight is the better the distribution\nis. After having printed out the weights, the code stops.",
            "title": "autoparal"
        },
        {
            "location": "/input_variables/varpar/#bandpp",
            "text": "Mnemonics: BAND Per Processor \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  paral_kgb ==1    Control the size of the block in the LOBPCG algorithm. This keyword works only\nwith  paral_kgb =1 and has to be either 1 or a multiple of 2.    -- With  npband =1:   1 => band-per-band algorithm   n => The minimization is performed using  nband /n blocks of n bands.    Note:  nband /n has to be an integer.    -- With  npband /=1:   1 => The minimization is performed using  nband / npband  blocks of  npband  bands.   n => The minimization is performed using  nband /( npband n) blocks of  npband n bands.    Note:  nband /( npband *n) has to be an integer.    By minimizing a larger number of bands together in LOBPCG, we increase the\nconvergency of the residual. The better minimization procedure (as concerns\nthe convergency, but not as concerns the speed) is generally performed by\nusing  bandpp * npband = nband . Put  bandpp =2 when  istwfk =2 (the\ntime spent in FFTs is divided by two).",
            "title": "bandpp"
        },
        {
            "location": "/input_variables/varpar/#gpu_devices",
            "text": "Mnemonics: GPU: choice of DEVICES on one node \nVariable type: integer \nDimensions: (5) \nDefault value: [-1, -1, -1, -1, -1] \nOnly relevant if  use_gpu_cuda ==1 (CUDA functionality)    To be used when several GPU devices are present on each node, assuming the\nsame number of devices on all nodes. \nAllows to choose in which order the GPU devices are chosen and distributed\namong MPI processes (see examples below). When the default value (-1) is set,\nthe GPU devices are chosen by order of performance (FLOPS, memory).    Examples:    2 GPU devices per node, 4 MPI processes per node,  gpu_device =[-1,-1,-1,-1,-1] (default): \nMPI processes 0 and 2 use the best GPU card, MPI processes 1 and 3 use the\nslowest GPU card.    3 GPU devices per node, 5 MPI processes per node,  gpu_device =[1,0,2,-1,-1]: \nMPI processes 0 and 3 use GPU card 1, MPI processes 1 and 4 use GPU card 0,\nMPI process 2 uses GPU card 2.    3 GPU devices per node, 5 MPI processes per node,  gpu_device =[0,1,-1,-1,-1]: \nMPI processes 0, 2 and 4 use GPU card 0, MPI processes 1 and 3 use GPU card 1;\nthe 3rd GPU card is not used.    GPU card are numbered starting from 0; to get the GPU devices list, type\n\u201cnvidia-smi\u201d or \u201clspci | grep -i nvidia\u201d.",
            "title": "gpu_devices"
        },
        {
            "location": "/input_variables/varpar/#gpu_linalg_limit",
            "text": "Mnemonics: GPU (Cuda): LINear ALGebra LIMIT \nVariable type: integer \nDimensions: scalar \nDefault value: 2000000 \nOnly relevant if  use_gpu_cuda ==1 (CUDA functionality)    Use of linear algebra and matrix algebra on GPU is only efficient if the size\nof the involved matrices is large enough. The  gpu_linalg_limit  parameter\ndefines the threshold above which linear (and matrix) algebra operations are\ndone on the Graphics Processing Unit. \nThe considered matrix size is equal to:     SIZE=( mpw nspinor /  npspinor )  ( npband bandpp ) *2    When SIZE>= gpu_linalg_limit ,  wfoptalg  parameter is automatically\nset to 14 which corresponds to the use of LOBPCG algorithm for the calculation\nof the eigenstates.",
            "title": "gpu_linalg_limit"
        },
        {
            "location": "/input_variables/varpar/#gwpara",
            "text": "Mnemonics: GW PARAllelization level \nVariable type: integer \nDimensions: scalar \nDefault value: 2 \nComment: The default value has been changed in v8. From 1 to 2  \nOnly relevant if  optdriver  in [3,4]    gwpara  is used to choose between the two different parallelization levels\navailable in the  GW  code. The available options are:   =1 => parallelisation on k points   =2 => parallelisation on bands    Additional notes: \nIn the present status of the code, only the parallelization over bands\n( gwpara =2) allows to reduce the memory allocated by each processor. \nUsing  gwpara =1, indeed, requires the same amount of memory as a sequential\nrun, irrespectively of the number of CPUs used.",
            "title": "gwpara"
        },
        {
            "location": "/input_variables/varpar/#localrdwf",
            "text": "Mnemonics: LOCAL ReaD WaveFunctions \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This input variable is used only when running abinit in parallel. If localrdwf =1, the input wavefunction disk file or the KSS/SCR file in case\nof  GW  calculations, is read locally by each processor, while if localrdwf =0, only one processor reads it, and broadcast the data to the\nother processors.  The option  localrdwf =0 is NOT allowed when parallel I/O are activated\n(MPI-IO access), i.e. when  iomode ==1.  In the case of a parallel computer with a unique file system, both options are\nas convenient for the user. However, if the I/O are slow compared to\ncommunications between processors, ,  localrdwf =0 should be much more\nefficient; if you really need temporary disk storage, switch to localrdwf=1 ).  In the case of a cluster of nodes, with a different file system for each\nmachine, the input wavefunction file must be available on all nodes if localrdwf =1, while it is needed only for the master node if localrdwf =0.",
            "title": "localrdwf"
        },
        {
            "location": "/input_variables/varpar/#max_ncpus",
            "text": "Mnemonics: MAXimum Number of CPUS \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If  autoparal  > 1 and  max_ncpus  is greater than 0, ABINIT analyzes\nthe efficiency of the process distribution for each possible number of\nprocessors from 2 to  max_ncpus . After having printed out the efficiency,\nthe code stops.",
            "title": "max_ncpus"
        },
        {
            "location": "/input_variables/varpar/#np_slk",
            "text": "Mnemonics: Number of mpi Processors used for ScaLapacK calls \nVariable type: integer \nDimensions: scalar \nDefault value: 1000000 \nOnly relevant if  optdriver ==1 and  paral_kgb ==1 (Ground-state calculations with LOBPCG algorithm)    When using Scalapack (or any similar Matrix Algebra library), the efficiency\nof the eigenproblem resolution saturates as the number of CPU cores increases.\nIt is better to use a smaller number of CPU cores for the LINALG calls. \nThis maximum number of cores can be set with  np_slk . \nA large number for  np_slk  (i.e. 1000000) means that all cores are used for\nthe Linear Algebra calls. \nnp_slk must divide the number of processors involved in diagonalizations\n( npband npfft npspinor ). \nNote: an optimal value for this parameter can be automatically found by using\nthe  autoparal  input keyword.",
            "title": "np_slk"
        },
        {
            "location": "/input_variables/varpar/#npband",
            "text": "Mnemonics: Number of Processors at the BAND level \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  paral_kgb ==1    Relevant only for the band/FFT parallelisation (see the  paral_kgb  input\nvariable).  npband  gives the number of processors among which the work load over the\nband level is shared.  npband ,  npfft ,  npkpt  and  npspinor  are\ncombined to give the total number of processors (nproc) working on the\nband/FFT/k-point parallelisation. \nSee  npfft ,  npkpt ,  npspinor  and  paral_kgb  for the additional\ninformation on the use of band/FFT/k-point parallelisation.  npband  has to\nbe a divisor or equal to  nband \nNote: an optimal value for this parameter can be automatically found by using\nthe  autoparal  input keyword.",
            "title": "npband"
        },
        {
            "location": "/input_variables/varpar/#npfft",
            "text": "Mnemonics: Number of Processors at the FFT level \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  paral_kgb ==1    Relevant only for the band/FFT/k-point parallelisation (see the  paral_kgb \ninput variable).  npfft  gives the number of processors among which the work load over the\nFFT level is shared.  npfft ,  npkpt ,  npband  and  npspinor  are\ncombined to give the total number of processors (nproc) working on the\nband/FFT/k-point parallelisation. \nSee  npband ,  npkpt ,  npspinor , and  paral_kgb  for the additional\ninformation on the use of band/FFT/k-point parallelisation.  Note :  ngfft  is automatically adjusted to  npfft . If the number of\nprocessor is changed from a calculation to another one,  npfft  may change,\nand then  ngfft  also. \nNote: an optimal value for this parameter can be automatically found by using\nthe  autoparal  input keyword.",
            "title": "npfft"
        },
        {
            "location": "/input_variables/varpar/#nphf",
            "text": "Mnemonics: Number of Processors for (Hartree)-Fock exact exchange \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Relevant only for the k-point/fock parallelisation (option  paral_kgb  input\nvariable).  nphf  gives the number of processors among which the work load over the\noccupied states level is shared.  nphf  and  npkpt  are combined to give\nthe total number of processors (nproc) working on the parallelisation.    Note :  nphf  should be a divisor or equal to the number of k-point times\nthe number of bands for exact exchange ( nkpthf * nbandhf ) in order to\nhave the better load-balancing and efficiency.",
            "title": "nphf"
        },
        {
            "location": "/input_variables/varpar/#npimage",
            "text": "Mnemonics: Number of Processors at the IMAGE level \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Relevant only when sets of images are activated (see  imgmov  and  nimage \n).  npimage  gives the number of processors among which the work load over the\nimage level is shared. It is compatible with all other parallelization levels\navailable for ground-state calculations. \nNote: an optimal value for this parameter can be automatically found by using\nthe  autoparal  input keyword.    _See  paral_kgb ,  npkpt ,  npband ,  npfft  and  npspinor  for the\nadditional information on the use of k-point/band/FFT parallelisation. _",
            "title": "npimage"
        },
        {
            "location": "/input_variables/varpar/#npkpt",
            "text": "Mnemonics: Number of Processors at the K-Point Level \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  paral_kgb ==1    Relevant only for the band/FFT/k-point parallelisation (see the  paral_kgb \ninput variable).  npkpt  gives the number of processors among which the work load over the\nk-point/spin-component level is shared.  npkpt ,  npfft ,  npband  and npspinor  are combined to give the total number of processors (nproc)\nworking on the band/FFT/k-point parallelisation. \nSee  npband ,  npfft ,  npspinor  and  paral_kgb  for the additional\ninformation on the use of band/FFT/k-point parallelisation.  npkpt  should be a divisor or equal to with the number of k-point/spin-\ncomponents ( nkpt * nsppol ) in order to have the better load-balancing\nand efficiency. \nNote: an optimal value for this parameter can be automatically found by using\nthe  autoparal  input keyword.",
            "title": "npkpt"
        },
        {
            "location": "/input_variables/varpar/#nppert",
            "text": "Mnemonics: Number of Processors at the PERTurbation level \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  paral_rf ==1    This parameter is used in connection to the parallelization over\nperturbations(see  paral_rf  ), for a linear response calculation. nppert  gives the number of processors among which the work load over the\nperturbation level is shared. It can even be specified separately for each\ndataset.",
            "title": "nppert"
        },
        {
            "location": "/input_variables/varpar/#npspinor",
            "text": "Mnemonics: Number of Processors at the SPINOR level \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  paral_kgb ==1    Can be 1 or 2 (if  nspinor =2). \nRelevant only for the band/FFT/k-point parallelisation (see the  paral_kgb \ninput variable).  npspinor  gives the number of processors among which the work load over the\nspinorial components of wave-functions is shared.  npspinor ,  npfft , npband  and  npkpt  are combined to give the total number of processors\n(nproc) working on the band/FFT/k-point parallelisation. \nNote: an optimal value for this parameter can be automatically found by using\nthe  autoparal  input keyword.    See  npkpt ,  npband ,  npfft , and  paral_kgb  for the additional\ninformation on the use of band/FFT/k-point parallelisation.",
            "title": "npspinor"
        },
        {
            "location": "/input_variables/varpar/#paral_atom",
            "text": "Mnemonics: activate PARALelization over (paw) ATOMic sites \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Relevant only for PAW calculations. \nThis keyword controls the parallel distribution of memory over atomic sites.\nCalculations are also distributed using the \u201ckpt-band\u201d communicator.\nCompatible with ground-state calculations and response function calculations",
            "title": "paral_atom"
        },
        {
            "location": "/input_variables/varpar/#paral_kgb",
            "text": "Mnemonics: activate PARALelization over K-point, G-vectors and Bands \nVariable type: integer \nDimensions: scalar \nDefault value: 0     If paral_kgb is not explicitely put in the input file   , ABINIT automatically detects if the job has been sent in sequential or in parallel. In this last case, it detects the number of processors on which the job has been sent and calculates values of  npkpt ,  npfft ,  npband ,  bandpp  ,  npimage  and  npspinor  that are compatible with the number of processors. It then set paral_kgb to 0 or 1 (see hereunder) and launches the job.    If paral_kgb=0   , the parallelization over k-points only is activated. In this case,  npkpt ,  npspinor ,  npfft  and  npband  are ignored. Require compilation option \u2013enable-mpi=\u201dyes\u201d.    If paral_kgb=1   , the parallelization over bands, FFTs, and k-point/spin-components is activated (see  npkpt ,  npfft   npband  and eventually  npspinor ). With this parallelization, the work load is split over four levels of parallelization (three level of parallelisation (kpt-band-fft )+ spin) The different communications almost occur along one dimension only. Require compilation option \u2013enable-mpi=\u201dyes\u201d.   HOWTO fix the number of processors along one level of parallelisation: \nAt first, try to parallelise over the k point and spin (see npkpt , npspinor ). Otherwise, for unpolarized calculation at the gamma\npoint, parallelise over the two other levels: the band and FFT ones. For\nnproc<=50, the best speed-up is achieved for  npband =nproc and npfft =1 (which is not yet the default). For nproc>=50, the best speed-\nup is achieved for  npband  >=4* npfft .  For additional information, download F. Bottin presentation at the   ABINIT\nworkshop 2007   Suggested acknowledgments : \nF. Bottin, S. Leroux, A. Knyazev and G. Zerah, _ Large scale ab initio\ncalculations based on three levels of parallelization _ , Comput. Mat. Science  42   , 329 (2008), also available on arXiv, http://arxiv.org/abs/0707.3405\n.  If the total number of processors used is compatible with the four levels of\nparallelization, the values for  npkpt ,  npspinor ,  npfft ,  npband \nand  bandpp  will be filled automatically, although the repartition may not\nbe optimal. To optimize the repartition use:   If paral_kgb=1   and   max_ncpus = n /= 0   ABINIT will test automatically if all the processor numbers between 2 and n are convenient for a parallel calculation and print the possible values in the log file. A weight is attributed to each possible processors repartition. It is adviced to select a processor repartition for which the weight is high (as closed to the number of processors as possible). The code will then stop after the printing. This test can be done as well with a sequential as with a parallel version of the code. The user can then choose the adequate number of processor on which he can run his job. He must put again paral_kgb=1 in the input file and put the corresponding values for  npkpt ,  npfft ,  npband , bandpp  and eventually  npspinor  in the input file.",
            "title": "paral_kgb"
        },
        {
            "location": "/input_variables/varpar/#paral_rf",
            "text": "Mnemonics: activate PARALlelization over Response Function perturbations \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This parameter activates the parallelization over perturbations which can be\nused during RF-Calculation. It is possible to use this type of parallelization\nin combination to the parallelization over k-points.  Currently total energies calculated by groups, where the master process is not\nin, are saved in .status_LOGxxxx files.  If  paral_rf  is set to -1, the code reports the list of irreducible\nperturbations for the specified q-point in the log file (YAML format) and then\nstops.  paral_rf  can be specified separately for each dataset.",
            "title": "paral_rf"
        },
        {
            "location": "/input_variables/varpar/#pw_unbal_thresh",
            "text": "Mnemonics: Plane Wave UNBALancing: THRESHold for balancing procedure \nVariable type: real \nDimensions: scalar \nDefault value: 40% \nOnly relevant if  paral_kgb ==1    This parameter (in %) activates a load balancing procedure when the\ndistribution of plane wave components over MPI processes is not optimal. The\nbalancing procedure is activated when the ratio between the number of plane\nwaves treated by a processor and the ideal one is higher than pw_unbal_thresh  %.",
            "title": "pw_unbal_thresh"
        },
        {
            "location": "/input_variables/varpar/#use_gpu_cuda",
            "text": "Mnemonics: activate USE of GPU accelerators with CUDA (nvidia) \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  optdriver ==0 and  CUDA ,\n0 otherwise.  Only available if ABINIT executable has been compiled with cuda nvcc compiler. \nThis parameter activates the use of NVidia graphic accelerators (GPU) if\npresent. \nIf  use_gpu_cuda  = 1, some parts of the computation are transmitted to the\nGPUs. \nIf  use_gpu_cuda  = 0, no computation is done on GPUs, even if present.    Note that, while running ABINIT on GPUs, it is recommended to use MAGMA\nexternal library (i.e. Lapack on GPUs). The latter is activated during\ncompilation stage (see \u201cconfigure\u201d step of ABINIT compilation process). If\nMAGMA is not used, ABINIT performances on GPUs can be poor.",
            "title": "use_gpu_cuda"
        },
        {
            "location": "/input_variables/varpar/#use_slk",
            "text": "Mnemonics: USE ScaLapacK \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If set to 1, enable the use of ScaLapack within LOBPCG.",
            "title": "use_slk"
        },
        {
            "location": "/input_variables/varpaw/",
            "text": "bxctmindg\n\u00b6\n\n\nMnemonics: BoX CuT-off MINimum for the Double Grid (PAW)\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 2.0\n\nOnly relevant if \nusepaw\n==1  \n\n\nThe box cut-off ratio is the ratio between the wavefunction plane wave sphere\nradius, and the radius of the sphere that can be inserted in the FFT box, in\nreciprocal space.\n\nIf the density was generated only from wavefunctions, this ratio should be at\nleast two in order for the density to be exact. If one uses a smaller ratio,\none will gain speed, at the expense of accuracy. In case of pure ground state\ncalculation (e.g. for the determination of geometries), this is sensible.\nHowever, the wavefunctions that are obtained CANNOT be used for starting\nresponse function calculation.\n\nHowever, some augmentation charge is always added in PAW, and even with the\nbox cut-off ratio larger than two, the density is never exact. Sometimes, this\nratio must be much larger than two for the computation to be converged at the\nrequired level of accuracy.\n\n\ndmatpawu\n\u00b6\n\n\nMnemonics: initial Density MATrix for PAW+U\n\nVariable type: real\n\nDimensions: (2\nmax(\nlpawu\n)+1,2\nmax(\nlpawu\n)+1,max(\nnsppol\n, \nnspinor\n),\nnatpawu\n)\n\nDefault value: *-10.0\n\nOnly relevant if \nusepaw\n==1 and \nusepawu\n==1 and \nusedmatpu\n!=0  \n\n\nFor Ground state calculations only.\n\nGives the value of an initial density matrix used in LDA+U and kept fixed\nduring the first abs(\nusedmatpu\n) SCF iterations.\n\nOnly components corresponding to \nlpawu\n angular momentum are requested.\n\nRestriction: In order to use dmatpawu, \nlpawu\n must be identical for all\natom types (or -1).\n\nThe occupation matrix is in the basis of real spherical harmonics Slm (note\nthat this differs from the choice made when \nprtdosm\n=1 , that is in the\nbasis of complex spherical harmonics). Their are ordered by increasing m, and\nare defined e.g. in the article \u201cEvaluation of the rotation matrices in the\nbasis of real spherical harmonics\u201d, by Miguel A. Blancoa, M. Floreza, M.\nBermejo, Journal of Molecular Structure (Theochem) 419, 19 (1997), that can be\ndownloaded from \n the author Web site\n\n . For the case l=2 (d states), the five columns corresponds\nrespectively to (the normalisation factor has been dropped)  \n\n\n\n\nm=-2, xy \n\n\nm=-1, yz \n\n\nm=0, 3z^2-r^2 \n\n\nm=1, xz \n\n\nm=2, x^2-y^2 \n\n\n\n\ndmatpawu\n must always be given as a \u201cspin-up\u201d occupation matrix (and\neventually a \u201cspin-down\u201d matrix). Be aware that its physical meaning depends\non the magnetic properties imposed to the system (with \nnsppol\n,\n\nnspinor\n, \nnspden\n):  \n\n\n\n\n\n\n Non-magnetic system \n (\nnsppol\n=1, \nnspinor\n=1, \nnspden\n=1): \n\nOne (2lpawu+1)x(2lpawu+1) \ndmatpawu\n matrix is given for each atom on which\n+U is applied.\n\nIt contains the \u201cspin-up\u201d occupations.\n\n\n\n\n\n\n Ferromagnetic spin-polarized (collinear) system \n (\nnsppol\n=2, \nnspinor\n=1, \nnspden\n=2): \n\nTwo (2lpawu+1)x(2lpawu+1) \ndmatpawu\n matrices are given for each atom on\nwhich +U is applied.\n\nThey contain the \u201cspin-up\u201d and \u201cspin-down\u201d occupations.\n\n\n\n\n\n\n Anti-ferromagnetic spin-polarized (collinear) system \n (\nnsppol\n=1, \nnspinor\n=1, \nnspden\n=2): \n\nOne (2lpawu+1)x(2lpawu+1) \ndmatpawu\n matrix is given for each atom on which\n+U is applied.\n\nIt contains the \u201cspin-up\u201d occupations.\n\n\n\n\n\n\n Non-collinear magnetic system \n (\nnsppol\n=1, \nnspinor\n=2, \nnspden\n=4): \n\nTwo (2lpawu+1)x(2lpawu+1) \ndmatpawu\n matrices are given for each atom on\nwhich +U is applied.\n\nThey contains the \u201cspin-up\u201d and \u201cspin-down\u201d occupations (defined as\nn_up=(n+|m|)/2 and n_dn=(n-|m|)/2), where m is the integrated magnetization\nvector).\n\nThe direction of the magnetization (which is also the direction of n_up and\nn_dn) is given by \nspinat\n.\n\n_ Warning: unlike collinear case, atoms having the same magnetization\nmagnitude with different directions must be given the same occupation matrix;\n\nthe magnetization will be oriented by the value of \nspinat\n (this is the\ncase for antiferro-magnetism). _\n\n\n\n\n\n\n Non-collinear magnetic system with zero magnetization \n (\nnsppol\n=1, \nnspinor\n=2, \nnspden\n=1): \n\nTwo (2lpawu+1)x(2lpawu+1) \ndmatpawu\n matrices are given for each atom on\nwhich +U is applied.\n\nThey contain the \u201cspin-up\u201d and \u201cspin-down\u201d occupations;\n\nBut, as \u201cspin-up\u201d and \u201cspin-down\u201d are constrained identical, the \u201cspin-down\u201d\none is ignored by the code.\n\n\n\n\n\n\ndmatpuopt\n\u00b6\n\n\nMnemonics: Density MATrix for PAW+U OPTion\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2\n\nOnly relevant if \nusepaw\n==1 and \nusepawu\n==1  \n\n\nThis option governs the way occupations of localized atomic levels are\ncomputed:  \n\n\n\n\n\n\ndmatpuopt\n=1: atomic occupations are projections on atomic orbitals (Eq. (6) of PRB 77, 155104 (2008)).   \n\n\n\n\n\n\ndmatpuopt\n=2: atomic occupations are integrated values in PAW spheres of angular-momentum-decomposed charge densities (Eq. (7) of PRB 77, 155104 (2008)).   \n\n\n\n\n\n\ndmatpuopt\n=3: only for tests   \n\n\n\n\n\n\ndmatpuopt\n=4: Extrapolations of occupancies outside the PAW-sphere. This Definition gives normalized operator for occupation.   \n\n\n\n\n\n\nIn the general case \ndmatpuopt\n=2 is suitable. The use of \ndmatpuopt\n=1 is\nrestricted to PAW datasets in which the first atomic wavefunction of the\ncorrelated subspace is a normalized atomic eigenfunction.\n\n\ndmatudiag\n\u00b6\n\n\nMnemonics: Density MATrix for paw+U, DIAGonalization\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1 and \nusepawu\n==1 and \nnspden\n != 4  \n\n\nRelevant only for Ground-State calculations.\n\nThis option can be used to diagonalize the occupation matrix Nocc_{m,m_prime}.\n\nRelevant values are:  \n\n\n\n\n0: desactivated. \n\n\n1: occupation matrix is diagonalized and printed in log file at each SCF cycle (eigenvectors are also given in the log file). \n\n\n2: for testing purpose. \n\n\n\n\nf4of2_sla\n\u00b6\n\n\nMnemonics: F4 Over F2 ratio of Slater integrals\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: [\u20180.625 for d electron\u2019, \u20180.6681 for f electron\u2019]\n\nOnly relevant if \nusepaw\n==1 and (\nusepawu\n==1 or \nusedmft\n==1)  \n\n\nThis gives the ratio of Slater Integrals F4 and F2. It is used in DFT+U or\nDFT+DMFT for the calculation of the orbital dependent screened coulomb\ninteraction.\n\n\nf6of2_sla\n\u00b6\n\n\nMnemonics: F6 Over F2 ratio of Slater integrals\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.4943\n\nOnly relevant if (\nusepawu\n==1 or \nusedmft\n==1) and \nlpawu\n=3  \n\n\nGives the ratio of Slater Integrals F6 and F2. It is used with\n\nf4of2_sla\n==3 in DFT+U or DFT+DMFT for the calculation of the orbital\ndependent screened coulomb interaction.\n\n\niboxcut\n\u00b6\n\n\nMnemonics: Integer governing the internal use of BOXCUT - not a very good choice of variable name\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nConcern all summations in the reciprocal space and is allowed in PAW and norm-\nconserving.\n\n\n\n\nif set to 0 all reciprocal space summations are done in a sphere contained in the FFT box. \n\n\nif set to 1 all reciprocal space summations are done in the whole FFT box (useful for tests). \n\n\n\n\njpawu\n\u00b6\n\n\nMnemonics: value of J for PAW+U\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: *0\n\nOnly relevant if \nusepaw\n==1 and \nusepawu\n==1  \n\n\nGives the value of the screened exchange interaction between correlated\nelectrons corresponding to \nlpawu\n for each species.\n\nIn the case where \nlpawu\n =-1, the value is not used.\n\n\nlexexch\n\u00b6\n\n\nMnemonics: value of angular momentum L for EXact EXCHange\n\nVariable type: integer\n\nDimensions: (\nntypat\n)\n\nDefault value: -1\n\nOnly relevant if \nuseexexch\n==1  \n\n\nGive for each species the value of the angular momentum (only values 2 or 3\nare allowed) on which to apply the exact exchange correction.\n\n\nlpawu\n\u00b6\n\n\nMnemonics: value of angular momentum L for PAW+U\n\nVariable type: integer\n\nDimensions: (\nntypat\n)\n\nDefault value: *-1\n\nOnly relevant if \nusepawu\n==1 or \nusepawu\n== 2  \n\n\nGive for each species the value of the angular momentum (only values 2 or 3\nare allowed)  on which to apply the LDA+U correction.  \n\n\n\n\nIf equal to 2 (d-orbitals)  or 3 (f-orbitals), values of \nupawu\n and  \njpawu\n are used in the calculation. \n\n\nIf equal to -1: do not apply LDA+U correction on the species. \n\n\n\n\nmqgriddg\n\u00b6\n\n\nMnemonics: Maximum number of Q-wavevectors for the 1-dimensional GRID  for the Double Grid in PAW\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 3001  \n\n\nMaximum number of wavevectors used to sample the local part of the potential,\nin PAW. Actually referred to as mqgrid_vl internally. Should change name to\nthe latter \u2026 See also \nmqgrid\n\n\nngfftdg\n\u00b6\n\n\nMnemonics: Number of Grid points for Fast Fourier Transform : Double Grid\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \nusepaw\n==1  \n\n\nThis variable has the same meaning as ngfft (gives the size of fast Fourier\ntransform (fft) grid in three dimensions) but concerns the \u201cdouble grid\u201d only\nused for PAW calculations.\n\n\npawcpxocc\n\u00b6\n\n\nMnemonics: PAW - use ComPleX rhoij OCCupancies\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2 if \noptdriver\n==0 and \nionmov\n<6 and \npawspnorb\n==1 and \niscf\n>=10 and (\nkptopt\n !=1 or \nkptopt\n!=2) and \nusepaw\n==1,\n1 otherwise.\n\n\nOnly relevant if \nusepaw\n==1  \n\n\nThe only possible values for \npawcpxocc\n are 1 or 2.\n\nWhen \n \npawcpxocc\n==1 \n , \u201cdirect\u201d decomposition of total energy cannot be\nprinted out.\n\nWhen \n \npawcpxocc\n==2 \n , PAW augmentation occupancies are treated as\nCOMPLEX; else they are considered as REAL.\n\nThis is needed when time-reversal symmetry is broken (typically when spin-\norbit coupling is activated).  \n\n\nNote for ground-state calculations (\noptdriver\n=0):\n\nThe imaginary part of PAW augmentation occupancies is only used for the\ncomputation of the total energy by \u201cdirect scheme\u201d; this is only necessary\nwhen SCF mixing on potential is chosen (\niscf\n<10).\n\nWhen SCF mixing on density is chosen (\niscf\n>=10), the \u201cdirect\u201d\ndecomposition of energy is only printed out without being used. It is thus\npossible to use \npawcpxocc\n=1 in the latter case.\n\nIn order to save CPU time, when molecular dynamics is selected\n(\nionmov\n>=6) and SCF mixing done on density (\niscf\n>=10),\n\npawcpxocc\n=2 is (by default) set to \n 1 \n\n\npawcross\n\u00b6\n\n\nMnemonics: PAW - add CROSS term in oscillator strengths\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if (\noptdriver\n==3 or \noptdriver\n==4) and \nusepaw\n==1  \n\n\nWhen \n pawcross=1 \n , the overlap between the plane-wave part of one band\nand the on-site part of an other is taken into account in the computation of\nthe oscillator strengths. Hence, the completeness of the on-site basis is no\nlonger assumed.\n\n\npawecutdg\n\u00b6\n\n\nMnemonics: PAW - Energy CUToff for the Double Grid\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: -1\n\nComment: pawecutdg MUST be specified for PAW calculations.\n\nOnly relevant if \nusepaw\n==1  \n\n\nDefine the energy cut-off for the fine FFT grid (the \u201cdouble grid\u201d, that\nallows to transfer data from the normal, coarse, FFT grid to the spherical\ngrid around each atom).\n\n\npawecutdg\n must be larger or equal to \necut\n. If it is equal to it, then\nno fine grid is used. The results are not very accurate, but the computations\nproceed quite fast.\n\nFor typical PAW computations, where \necut\n is on the order of 15 Ha,\n\npawecutdg\n must be tested according to what you want to do. For\ncalculations that do not require a high accuracy (molecular dynamics for\ninstance) a value of 20 Ha is enough. For calculations that require a high\naccuracy (response fonctions for instance) it should be on the order of 30 Ha.\nChoosing a larger value should not increase the accuracy, but does not slow\ndown the computation either, only the memory. The choice made for this\nvariable DOES have a bearing on the numerical accuracy of the results, and, as\nsuch, should be the object of a convergence study. The convergence test might\nbe made on the total energy or derived quantities, like forces, but also on\nthe two values of the \u201cCompensation charge inside spheres\u201d, a quantity written\nin the log file.\n\n\npawfatbnd\n\u00b6\n\n\nMnemonics: PAW: print band structure in the FAT-BaND representation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1   \n\n\nFor Ground-State calculations and non self-consistent calculations only.\n\nThis option can be used to plot band structure. For each atom (specified by\n\nnatsph\n and \niatsph\n), each angular momentum, and each spin polarisation,\nthe band structure is written in files (such as e.g.\nFATBANDS_at0001_Ni_is2_l2_m-1). Each file contains the eigenvalue, and the\ncontribution of angular momentum L, and projection of angular momentum M, (for\nthe corresponding wavefunction) to the PAW density inside the PAW sphere as a\nfunction of the index of the k-point. The output can be readily plotted with\nthe software \n xmgrace \n (e.g\nxmgrace FATBANDS_at0001_Ni_is2_l2_m-1). Relevant values are:  \n\n\n\n\n0: desactivated. \n\n\n1: The fatbands are only resolved in L. \n\n\n2: The fatbands are resolved in L and M. \n\n\n\n\npawlcutd\n\u00b6\n\n\nMnemonics: PAW - L angular momentum used to CUT the development in moments of the Densitites\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 10\n\nOnly relevant if \nusepaw\n==1  \n\n\nThe expansion of the densities in angular momenta is performed up to\nl=\npawlcutd\n.\n\nNote that, for a given system, the maximum value of \npawlcutd\n is \n 2*l_max\n\n , where l_max is the maximum l of the PAW partial waves basis.  \n\n\nThe choice made for this variable DOES have a bearing on the numerical\naccuracy of the results, and, as such, should be the object of a convergence\nstudy. The convergence test might be made on the total energy or derived\nquantities, like forces, but also on the two values of the \u201cCompensation\ncharge inside spheres\u201d, a quantity written in the log file.\n\n\npawlmix\n\u00b6\n\n\nMnemonics: PAW - maximum L used in the spherical part MIXing\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 10\n\nOnly relevant if \nusepaw\n==1  \n\n\nThe choice made for this variable determine how the spherical part of the\ndensity is mixed during electronic iterations.  \n\n\nOnly parts of rhoij quantities associated with l angular momenta up to\nl=pawlmix are mixed. Other parts of augmentation occupancies are not included\nin the mixing process.\n\nThis option is useful to save CPU time but DOES have a bearing on the\nnumerical accuracy of the results.\n\n\npawmixdg\n\u00b6\n\n\nMnemonics: PAW - MIXing is done (or not) on the (fine) Double Grid\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0 if \nnpfft\n==1,\n1 otherwise.\n\n\nOnly relevant if \nusepaw\n==1  \n\n\nThe choice made for this variable determines the grid on which the density (or\npotential) is mixed during the SCF cycle.  \n\n\n- If \n pawmixdg=1 \n the density/potential is mixed in REAL space using the\nfine FFT grid (defined by \npawecutdg\n or \nngfftdg\n).\n\n- If \n pawmixdg=0 \n the density/potential is mixed in RECIPROCAL space\nusing the coarse FFT grid (defined by \necut\n or \nngfft\n). Only components\nof the coarse grid are mixed using the scheme defined by \niscf\n; other\ncomponents are only precondionned by \ndiemix\n and simply mixed.\n\nThis option is useful to save memory and does not affect numerical accuracy of\nconverged results. If \n pawmixdg=1 \n , density and corresponding residual\nare stored for previous iterations and are REAL arrays of size \nnfftdg\n. If\n\n pawmixdg=0 \n , density and corresponding residual are stored for previous\niterations and are COMPLEX arrays of size \nnfft\n. The memory saving is\nparticularly efficient when using the Pulay mixing (\niscf\n=7 or 17).  \n\n\nIn \n wavelet \n calculations \nusewvl\n=1:\n\n- pawmixdg is set to 1 by default.\n\n- A value of 0 is not allowed.\n\n- Density/potential is mixed in REAL space (Here only one grid is used).\n\n\npawnhatxc\n\u00b6\n\n\nMnemonics: PAW - Flag for exact computation of gradients of NHAT density in eXchange-Correlation.\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nusepaw\n==1  \n\n\nRelevant only when a GGA exchange-correlation functional is used.\n\nWhen this flag is activated, the gradients of compensation charge density\n(n_hat) are exactly computed (i.e. analytically); when it is deactivated, they\nare computed with a numerical scheme in reciprocal space (which can produce\ninaccurate results if the compensation charge density is highly localized).\n\nAs analytical treatment of compensation charge density gradients is CPU time\ndemanding, it is possible to bypass it with \npawnhatxc\n=0; but the numerical\naccuracy can be affected by this choice. It is recommended to test the\nvalidity of this approximation before use.\n\n\npawnphi\n\u00b6\n\n\nMnemonics: PAW - Number of PHI angles used to discretize the sphere around each atom.\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 13\n\nOnly relevant if \nusepaw\n==1  \n\n\nNumber of phi angles (longitude) used to discretize the data on the atomic\nspheres. This discretization is completely defined by \npawnphi\n and\n\npawntheta\n.\n\n\npawntheta\n\u00b6\n\n\nMnemonics: PAW - Number of THETA angles used to discretize the sphere around each atom.\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 12\n\nOnly relevant if \nusepaw\n==1  \n\n\nNumber of theta angles (latitude) used to discretize the data on the atomic\nspheres. This discretization is completely defined by \npawntheta\n and\n\npawnphi\n.\n\n\npawnzlm\n\u00b6\n\n\nMnemonics: PAW - only compute Non-Zero LM-moments of the contributions to the density from the spheres\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nusepaw\n==1  \n\n\nConcerns the computation of the contributions to the density from the spheres\n(named rho_1 - rho_tild_1).\n\nIf set to 0, all lm-moments of the sphere contributions to the density are\ncomputed at each electronic iteration.\n\nIf set to 1, only non-zero lm-moments of the sphere contributions to the\ndensity are computed at each electronic iteration (they are all computed at\nthe first iteration then only those found to be non-zero will be computed ;\nthus the first iteration is more cpu intensive)\n\n\npawoptmix\n\u00b6\n\n\nMnemonics: PAW - OPTion for the MIXing of the spherical part\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1  \n\n\nIn the case of PAW computations, during the self-consistent cycle, ABINIT\nmixes the density \u03c1(r)= \u223c\u03c1(r) +\u2227\u03c1(r) and the occupancy matrix \u03c1ij. (\u223c\u03c1(r) is\nthe pseudo density, \u2227\u03c1(r) is the compensation charge density). It can be\nredundant as \u03c1ij is contained in \u2227\u03c1(r).  \n\n\n\n\n\n\nIf \npawoptmix\n=0:\n\nABINIT mixes \u03c1(r) and \u03c1ij but the residual used to control the mixing\nalgorithm is only based on \u03c1(r).\n\n\n\n\n\n\nIf \npawoptmix\n=1:\n\nABINIT mixes \u03c1(r) and \u03c1ij and the residual used to control the mixing\nalgorithm is based on \u03c1(r) and \u03c1ij.\n\n\n\n\n\n\nThis has only an influence on the efficiency of the mixing algorithm.\n\nIn cas of mixing problems, the first suggestion is to increase the size of the\nhistory (see \nnpulayit\n). Then it is also possible to play with the\nparameters of the Kerker mixing: \ndiemix\n, \ndiemac\n, etc\u2026\n\n\npawoptosc\n\u00b6\n\n\nMnemonics: PAW - OPTion for the computation of the OSCillator matrix elements\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nOnly relevant for \nGW\n or \nBETHE_SALPETER\n calculations with PAW.\n\nThis variable defines the approach used for the evaluation of the oscillator\nmatrix elements within the PAW formalism. Possible values are 0,1,2.\n\nIf \npawoptosc\n=0 the code uses its internal default value (2 for SCREENING\ncalculations, 1 for SIGMA calculations, 2 for \nBETHE_SALPETER\n)\n\nIf \npawoptosc\n=1 the matrix elements are computed with the expression given\nby Arnaud and Alouani in PRB 62. 4464 The equation is exact provided that the\nset of PAW partial waves is complete.\n\nIf \npawoptosc\n=2 the matrix elements are computed with the approximated\nexpression proposed by Shishkin and Kresse in PRB 74. 035101\n\n\npawovlp\n\u00b6\n\n\nMnemonics: PAW - spheres OVerLaP allowed (in percentage)\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 5.0\n\nOnly relevant if \nusepaw\n==1  \n\n\nWhen PAW is activated, a localized atomic basis is added to describe wave\nfunctions. Spheres around atoms are defined and they are IN PRINCIPLE not\nallowed to overlap. However, a small overlap can be allowed without\ncompromising the accuracy of results. Be aware that too high overlaps can lead\nto unphysical results.\n\nWith the \npawovlp\n variable, the user can control the (voluminal) overlap\npercentage allowed without stopping the execution.\n\n\npawovlp\n is the value (in percentage: 0\u2026100%) obtained by dividing the\nvolume of the overlap of two spheres by the volume of the smallest sphere.\n\nThe following values are permitted for \npawovlp\n:  \n\n\n- \npawovlp\n<0. : overlap is always allowed\n\n- \npawovlp\n=0. : no overlap is allowed\n\n- \npawovlp\n>0. and <100. : overlap is allowed only if it is less\nthan \npawovlp\n %\n\n\npawprtden\n\u00b6\n\n\nMnemonics: PAW: PRinT total physical electron DENsity\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1  \n\n\n Deprecated : \n See the \nprtden\n. \n\n\npawprtdos\n\u00b6\n\n\nMnemonics: PAW: PRinT partial DOS contributions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1 and \nprtdos\n==3  \n\n\nThis input variable controls the computation and/or printing of contributions\nto the PAW partial DOS in _DOS file(s):  \n\n\n+ Plane-waves contribution\n\n+ \u201con-site\u201d all-electron contribution (phi)\n\n- \u201con-site\u201d pseudo contribution (phi_tild).  \n\n\nIf \n pawprtdos=0: \n\n- The 3 contributions are computed; only the total partial DOS is output in\n_DOS file.\n\nIf \n pawprtdos=1: \n\n- The 3 contributions are computed and output in _DOS file.\n\n- In that case, integrated DOS is not output.\n\nIf \n pawprtdos=2: \n\n- Only \u201con-site\u201d all-electron contribution is computed and output in _DOS\nfile.\n\n- This a (very) good approximation of total DOS, provided that (1) the PAW\nlocal basis is complete, (2) the electronic charge is mostly contained in PAW\nspheres.\n\n- In that case, the \nratsph\n variable is automatically set to the PAW\nradius.\n\n\npawprtvol\n\u00b6\n\n\nMnemonics: PAW: PRinT VOLume\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1  \n\n\nControl print volume and debugging output for PAW in log file or standard\noutput. If set to 0, the print volume is at its minimum.\n\n\npawprtvol\n can have values from -3 to 3:\n\n- \npawprtvol\n=-1 or 1: matrices rho_ij (atomic occupancies) and D_ij (psp\nstrength) are printed at each SCF cycle with details about their\ncontributions.\n\n- \npawprtvol\n=-2 or 2: like -1 or 1 plus additional printing: moments of\n\u201con-site\u201d densities, details about local exact exchange.\n\n- \npawprtvol\n=-3 or 3: like -2 or 2 plus additional printing: details about\nPAW+U, rotation matrices of sphercal harmonics.\n\nWhen \npawprtvol\n>=0, up to 12 components of rho_ij and D_ij matrices for\nthe 1st and last atom are printed.\n\nWhen \npawprtvol\n<0, all components of rho_ij and D_ij matrices for all\natoms are printed.  \n\n\npawprtwf\n\u00b6\n\n\nMnemonics: PAW: PRinT WaveFunctions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1  \n\n\nThis input variable controls the output of the full PAW wave functions\nincluding the on-site contribution inside each PAW sphere needed to\nreconstruct the correct nodal shape in the augmentation region. \n pawprtwf=1\n\n causes the generation of a file _AE_WFK that contains the full\nwavefunctions in real space on the fine FFT grid defined by \npawecutdg\n or\n\nngfftdg\n. Limitations: At present (v6.0), \n pawprtwf=1 \n is not\ncompatible neither with the k-point parallelism nor with the parallelism over\nG-vectors. Therefore the output of the _AE_WFK has to be done in sequential.\nMoreover, in order to use this feature, one has to enable the support for\nETSF-IO at configure-time as the _AW_WFK file is written using the NETCDF file\nformat following the ETSF-IO specification for wavefunctions in real space. If\nthe code is run entirely in serial, additional output is made of various\ncontributions to the all-electron wavefunction. By default the full available\nset of bands and k-points are ouput, but a single band and k-point index can\nbe requested by using the variables \npawprt_b\n and \npawprt_k\n.\n\n\npawspnorb\n\u00b6\n\n\nMnemonics: PAW - option for SPiN-ORBit coupling\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1 if \nnspinor\n==2,\n0 otherwise.\n\n\nOnly relevant if \nusepaw\n==1  \n\n\nWhen PAW is activated, the \n spin-orbit coupling \n can be added without the\nuse of specific PAW datasets (pseudopotentials).\n\nIf \npawspnorb\n=1, spin-orbit will be added.\n\nIf the wavefunction is spinorial (that is, if \nnspinor\n=2), there is no\nreason not to include the spin-orbit interaction, so that the default value of\n\npawspnorb\n becomes 1 when \nnspinor\n=2.\n\nNote that only the all-electron \u201con-site\u201d contribution to the Hamiltonian is\ntaken into account; this is a very good approximation but requires the\nfollowing conditions to be fullfilled:  \n\n\n1- the  ~  \u03c6 i  basis is complete enough\n\n2- the electronic density is mainly contained in the PAW sphere  \n\n\nAlso note that, when spin-orbit coupling is activated and there is some\nmagnetization \nnspden\n=4, the time-reversal symmetry is broken.\n\nThe use of \nkptopt\n=1 or \nkptopt\n=2 is thus forbidden. It is advised to\nuse \nkptopt\n=3 (no symmetry used to generate k-points) or \nkptopt\n=4 (only\nspatial symmetries used to generate k-points).\n\nBe careful if you choose to use \nkptopt\n=0 (k-points given by hand); Time-\nreversal symmetry has to be avoided.\n\nAn artificial scaling of the spin-orbit can be introduced thanks to the\n\nspnorbscl\n input variable.\n\n\npawstgylm\n\u00b6\n\n\nMnemonics: PAW - option for the STorage of G_l(r).YLM(r)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nusepaw\n=1  \n\n\nWhen PAW is activated, the computation of compensation charge density (so\ncalled \u201chat\u201d density) requires the computation of g_l(r).Y_lm(r) factors (and\ncartesian derivatives) at each point of real space contained in PAW spheres.\nThe number of atoms, of (l,m) quantum numbers and the sharpness of the real\nFFT grid can lead to a very big {g_l.Y_lm} datastructure. One can save memory\nby putting \npawstgylm\n=0; but, in that case, g_l(r).Y_lm(r) factors a re-\ncomputed each time they are needed and CPU time increases.  \n\n\nPossible choices:\n\n- \npawstgylm\n=0 : g_l(r).Y_lm(r) are not stored in memory and recomputed.\n\n- \npawstgylm\n=1 : g_l(r).Y_lm(r) are stored in memory.  \n\n\nNote:\n\ng_l(r) are shape functions (analytically known)\n\nY_lm(r) are real spherical harmonics\n\n\npawsushat\n\u00b6\n\n\nMnemonics: PAW - SUSceptibility, inclusion of HAT (compensation charge) contribution\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1 and \noptdriver\n==0   \n\n\nGround-State calculation only.\n\nWhen a sophisticated preconditioning scheme is selected for the SCF cycle of a\nGround-State calculation (\niprcel\n>0), the computation of the\nsusceptibility matrix is required several times during the cycle. This\ncomputation is computer time consuming, especially -- within PAW \u2013 because\nof the inclusion of additional terms due to the compensation charge density.\nAs only a crude valuation of the susceptibilty matrix is needed (to evaluate a\npreconditioning matrix), the compensation charge contribution can be neglected\nto save CPU time (select \npawsushat\n=0). This approximation could be\nunfavourable in some cases; in the latter, we advise to put \npawsushat\n=1.  \n\n\nPossible choices:\n\n- \npawsushat\n=0 : only plane-wave contribution to suscep. matrix is\ncomputed.\n\n- \npawsushat\n=1 : the whole suscep. matrix (PW + PAW on-site) is computed.  \n\n\npawusecp\n\u00b6\n\n\nMnemonics: PAW - option for the USE of CPrj in memory (cprj=WF projected with NL projector)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nusepaw\n==1  \n\n\nWhen PAW is activated, the computation of cprj arrays is memory and time\nconsuming.\n\nWhen \npawusecp\n=0, then the cprj are never kept in memory, they are\nrecomputed when needed (this is CPU-time consuming). When \npawusecp\n=1, then\nthe cprj are computed once and then kept in memory.\n\nChange the value of the keyword only if you are an experienced user\n(developper).\n\nRemember: cprj = (WF_n .dot. p_i) (WF_n=wave function, p_i=non-local\nprojector).  \n\n\nFor the time being, only activated for RF calculations.  \n\n\npawxcdev\n\u00b6\n\n\nMnemonics: PAW - choice for eXchange-Correlation DEVelopment (spherical part)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nusepaw\n==1  \n\n\n\n\nIf set to 0, the exchange-correlation term in the spherical part of energy is totally computed on the angular mesh \n\n\nIf set to 1, the exchange-correlation term in the spherical part of energy is developed onto lm-moments at order 1 \n\n\nIf set to 2, the exchange-correlation term in the spherical part of energy is developed onto lm-moments at order 2 (can be memory/CPU consuming) \n\n\n\n\nBe careful: GGA requires \npawxcdev\n > 0\n\n\nprtefg\n\u00b6\n\n\nMnemonics: PRint Electric Field Gradient\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1, \nquadmom\n  \n\n\n\n\nIf nonzero, calculate the electric field gradient at each atomic site in the unit cell. Using this option requires \nquadmom\n to be set as well. Values will be written to main output file (search for Electric Field Gradient). If prtefg=1, only the quadrupole coupling in MHz and asymmetry are reported. If prtefg=2, the full electric field gradient tensors in atomic units are also given, showing separate contributions from the valence electrons, the ion cores, and the PAW reconstruction. If prtefg=3, then in addition to the prtefg=2 output, the EFGs are computed using an ionic point charge model. This is useful for comparing the accurate PAW-based results to those of simple ion-only models. Use of prtefg=3 requires that the variable \nptcharge\n be set as well. \n\nThe option prtefg is compatible with spin polarized calculations (see\n\nnspden\n) and also LDA+U (see \nusepawu\n).\n\n\n\n\nprtfc\n\u00b6\n\n\nMnemonics: PRinT Fermi Contact term\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1  \n\n\n\n\nIf set to 1, print the Fermi contact interaction at each nuclear site, that is, the electron density at each site. The result appears in the main output file (search for FC). Note that this calculation is different than what is done by cut3d, because it also computes the PAW on-site corrections in addition to the contribution from the valence pseudo-wavefunctions. \n\n\n\n\nprtnabla\n\u00b6\n\n\nMnemonics: PRint NABLA\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1  \n\n\n\n\nIf set to 1, calculate the matrix elements <Psi_n|-inabla|Psi_m> and write it in file _OPT to be read by the code conducti. \n\n\n\n\nptcharge\n\u00b6\n\n\nMnemonics: PoinT CHARGEs\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: *0\n\nOnly relevant if \nusepaw\n==1 and \nprtefg\n>=3   \n\n\n\n\nArray of point charges, in atomic units, of the nuclei. In the normal computation of electric field gradients (see \nprtefg\n) the ionic contribution is calculated from the core charges of the atomic sites. Thus for example in a PAW data set for oxygen where the core is 1s2, the core charge is +6 (total nuclear charge minus core electron charge). In point charge models, which are much less accurate than PAW calculations, all atomic sites are treated as ions with charges determined by their valence states. In such a case oxygen almost always would have a point charge of -2. The present variable taken together with \nprtefg\n performs a full PAW computation of the electric field gradient and also a simple point charge computation. The user inputs whatever point charges he/she wishes for each atom type. \n\n\n\n\nquadmom\n\u00b6\n\n\nMnemonics: QUADrupole MOMents\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: *0\n\nOnly relevant if \nusepaw\n==1 and \nprtefg\n>=1   \n\n\n\n\nArray of quadrupole moments, in barns, of the nuclei. These values are used in conjunction with the electric field gradients computed with \nprtefg\n to calculate the quadrupole couplings in MHz, as well as the asymmetries. Note that the electric field gradient at a nuclear site is independent of the nuclear quadrupole moment, thus the quadrupole moment of a nucleus can be input as 0, and the option \nprtefg\n=2 used to determine the electric field gradient at the site. \n\n\n\n\nspnorbscl\n\u00b6\n\n\nMnemonics: SPin-ORBit SCaLing\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0\n\nOnly relevant if \nusepaw\n==1 and \npawspnorb\n>= 1   \n\n\nScaling of the spin-orbit interaction. The default values gives the first-\nprinciples value, while other values are used for the analysis of the effect\nof the spin-orbit interaction, but are not expected to correspond to any\nphysical situation.\n\n\nupawu\n\u00b6\n\n\nMnemonics: value of U for PAW+U\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: *0\n\nOnly relevant if \nusepaw\n==1 and \nusepawu\n==1  \n\n\nGives the value of the screened coulomb interaction between correlated\nelectrons corresponding to \nlpawu\n for each species.\n\nIn the case where \nlpawu\n =-1, the value is not used.\n\nIn the case of a \nGW\n calculation, the U interaction defined by \nupawu\n\nwill be REMOVED from the self energy. In particular, for G0 W0 calculations\n(perturbative calculations), the energy eigenvalues obtained after an\nunderlying DFT+U calculation will be\n\nE_\nGW\n = E_DFT+U + < phi | Self-energy - U | phi>\n\nActually, in order to perform a \nGW\n @ DFT+U calculation, one should define\nthe same value of U in the self-energy calculation, than the one defined in\nthe DFT calculation. The easiest is actually to define the value of U for the\nwhole set of calculations (for the different datasets), including the\nscreening, even if the U value does not play explicitly a role in the\ncomputation of the latter (well, the input wavefunctions will be different\nanyhow).\n\nIt is possible to perform calculations of the type \nGW\n+U_prime @ DFT+U , so\nkeeping a U interaction (usually smaller than the initial U) in the \nGW\n\ncalculation, by defining a smaller U than the one used in the DFT calculation.\nThis value will be subtracted in the \nGW\n correction calculation, as\noutlined above.\n\nExplicitly, in order to do a calculation of a material with a DFT U value of\n7.5 eV, followed by a \nGW\n calculation where there is a residual U value of\n2 eV, one has to define :\n\n\n  uldau1   7.5 eV   ! This is for the DFT calculation\n...\noptdriver4  4\nuldau4   5.5 eV   ! This is for the screening calculation\n\n\n\n\n\nusedmatpu\n\u00b6\n\n\nMnemonics: USE of an initial Density MATrix in Paw+U\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1 and \nusepawu\n==1  \n\n\nWhen \nusedmatpu\n/=0, an initial density matrix (given by \ndmatpawu\n\nkeyword) is used and kept fixed during the first ABS(\nusedmatpu\n) SCF steps.\n\nThis starting value of the density matrix can be useful to find the correct\nground state. Within LDA+U formalism, finding the minimal energy of the system\nis tricky; thus it is advised to test several values of the initial density\nmatrix.\n\nNote also that the density matrix has to respect some symmetry rules\ndetermined by the space group. If the symmetry is not respected in the input,\nthe matrix is however automatically symmetrised.  \n\n\nThe sign of \nusedmatpu\n has influence only when \nionmov\n/=0 (dynamics or\nrelaxation):\n\n- When \nusedmatpu\n>0, the density matrix is kept constant only at first\nionic step\n\n- When \nusedmatpu\n<0, the density matrix is kept constant at each ionic\nstep  \n\n\nuseexexch\n\u00b6\n\n\nMnemonics: USE of EXact EXCHange\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1  \n\n\nWhen \nuseexexch\n=1, the hybrid functional PBE0 is used in PAW, inside PAW\nspheres only, and only for correlated orbitals given by \nlexexch\n. To change\nthe ratio of exact exchange, see also \nexchmix\n.\n\n\nusepawu\n\u00b6\n\n\nMnemonics: USE PAW+U (spherical part)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nusepaw\n==1  \n\n\nMust be non-zero if a DFT+U calculation is done, or if a \nGW\n calculation\nfollowing a DFT+U calculation is done (important !).\n\n\n\n\n\n\nIf set to 0, the LDA+U method is not used.   \n\n\n\n\n\n\nIf set to 1 or 2, the LDA+U method (cf [1]) is used. The full rotationally invariant formulation is used (see Eq. (3) of Ref [2]) for the interaction term of the energy. Two choices are allowed concerning the double counting term:   \n\n\n\n\n\n\nIf \nusepawu\n=1, the Full Localized Limit (FLL) (or Atomic limit) double counting is used (cf Eq. (4) of Ref.[2] or Eq. (8) of Ref[3]).   \n\n\n\n\n\n\nIf \nusepawu\n=2, the Around Mean Field (AMF) double counting is used (cf Eq. (7) of Ref [3]). Not valid if nspinor=2.   \n\n\n\n\n\n\n\n\n\n\nIf LDA+U is activated (\nusepawu\n=1 or 2), the \nlpawu\n, \nupawu\n and\n\njpawu\n input variables are read.\n\nThe implementation is done inside PAW augmentation regions only (cf Ref [4]).\nThe initial density matrix can be given in the input file (see \nusedmatpu\n).\nThe expression of the density matrix is chosen thanks to \ndmatpuopt\n. See\nalso \n How_to_use_LDA_plus_U.txt \n .\nfor some informations.\n\nIn the case of a \nGW\n calculation on top of a DFT+U, the absence of\ndefinition of a U value in the self-energy will LEAVE the underlying U from\nthe DFT calculation. Thus, the code will actually do a \nGW\n+U @ DFT+U\ncalculation. Note that the screening calculation will not be affected by the\npresence/absence of a U value.\n\nActually, in order to perform a \nGW\n @ DFT+U calculation, one should define\nthe same value of U in the self-energy calculation, than the one defined in\nthe DFT calculation. The code will know that the interaction corresponding to\nthat value has to be SUBTRACTED inside the self-energy. The easiest is\nactually to define the presence of U for the whole set of calculations (for\nthe different datasets), including the screening, even if the U value does not\nplay explicitly a role in the computation of the latter (well, the input\nwavefunctions will be different anyhow).\n\nIt is possible to perform calculations of the type \nGW\n+U_prime @ DFT+U , so\nkeeping a smaller U interaction in the \nGW\n calculation, by subtracting a\nsmaller U than the one used in the DFT calculation. See the description of the\n\nupawu\n input variable.\n\nReferences:\n\n[1] V. I. Anisimov, J. Zaanen, and O. K. Andersen PRB 44, 943 (1991)\n\n[2] A.I. Lichtenstein, V.I. Anisimov and J. Zaanen PRB 52, 5467 (1995)\n\n[3] M. T. Czyzyk and G. A. Sawatzky PRB 49, 14211 (1994)\n\n[4] O. Bengone, M. Alouani, P. Blochl, and J. Hugel PRB 62, 16392 (2000)  \n\n\nSuggested acknowledgment:\n\n- B. Amadon, F. Jollet and M. Torrent, Phys. Rev. B 77, 155104 (2008).  \n\n\nusepotzero\n\u00b6\n\n\nMnemonics: USE POTential ZERO\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\n\n\nusepotzero\n=0, the usual convention: the smooth potential is set to zero averarage value. \n\n\nusepotzero\n=1, the new convention: the physical potential is set to zero average value. \n\n\nusepotzero\n=2, the PWscf convention: the potential of equivalent point charges is set to zero average value (convention also valid for NC pseudopotentials). \n\n\n\n\nusexcnhat\n\u00b6\n\n\nMnemonics: USE eXchange-Correlation with NHAT (compensation charge density)\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: -1\n\nOnly relevant if \nusepaw\n==1  \n\n\nThis flag determines how the exchange-correlation terms are computed for the\npseudo-density.\n\nWhen \nusexcnhat\n=0, exchange-correlation potential does not include the\ncompensation charge density, i.e. Vxc=Vxc(tild_Ncore + tild_Nvalence).\n\nWhen \nusexcnhat\n=1, exchange-correlation potential includes the compensation\ncharge density, i.e. Vxc=Vxc(tild_Ncore + tild_Nvalence + hat_N).\n\nWhen \nusexcnhat\n=-1,the value of \nusexcnhat\n is determined from the\nreading of the PAW dataset file (pseudopotential file). When PAW datasets with\ndifferent treatment of Vxc are used in the same run, the code stops.",
            "title": "PAW"
        },
        {
            "location": "/input_variables/varpaw/#bxctmindg",
            "text": "Mnemonics: BoX CuT-off MINimum for the Double Grid (PAW) \nVariable type: real \nDimensions: scalar \nDefault value: 2.0 \nOnly relevant if  usepaw ==1    The box cut-off ratio is the ratio between the wavefunction plane wave sphere\nradius, and the radius of the sphere that can be inserted in the FFT box, in\nreciprocal space. \nIf the density was generated only from wavefunctions, this ratio should be at\nleast two in order for the density to be exact. If one uses a smaller ratio,\none will gain speed, at the expense of accuracy. In case of pure ground state\ncalculation (e.g. for the determination of geometries), this is sensible.\nHowever, the wavefunctions that are obtained CANNOT be used for starting\nresponse function calculation. \nHowever, some augmentation charge is always added in PAW, and even with the\nbox cut-off ratio larger than two, the density is never exact. Sometimes, this\nratio must be much larger than two for the computation to be converged at the\nrequired level of accuracy.",
            "title": "bxctmindg"
        },
        {
            "location": "/input_variables/varpaw/#dmatpawu",
            "text": "Mnemonics: initial Density MATrix for PAW+U \nVariable type: real \nDimensions: (2 max( lpawu )+1,2 max( lpawu )+1,max( nsppol ,  nspinor ), natpawu ) \nDefault value: *-10.0 \nOnly relevant if  usepaw ==1 and  usepawu ==1 and  usedmatpu !=0    For Ground state calculations only. \nGives the value of an initial density matrix used in LDA+U and kept fixed\nduring the first abs( usedmatpu ) SCF iterations. \nOnly components corresponding to  lpawu  angular momentum are requested. \nRestriction: In order to use dmatpawu,  lpawu  must be identical for all\natom types (or -1). \nThe occupation matrix is in the basis of real spherical harmonics Slm (note\nthat this differs from the choice made when  prtdosm =1 , that is in the\nbasis of complex spherical harmonics). Their are ordered by increasing m, and\nare defined e.g. in the article \u201cEvaluation of the rotation matrices in the\nbasis of real spherical harmonics\u201d, by Miguel A. Blancoa, M. Floreza, M.\nBermejo, Journal of Molecular Structure (Theochem) 419, 19 (1997), that can be\ndownloaded from   the author Web site  . For the case l=2 (d states), the five columns corresponds\nrespectively to (the normalisation factor has been dropped)     m=-2, xy   m=-1, yz   m=0, 3z^2-r^2   m=1, xz   m=2, x^2-y^2    dmatpawu  must always be given as a \u201cspin-up\u201d occupation matrix (and\neventually a \u201cspin-down\u201d matrix). Be aware that its physical meaning depends\non the magnetic properties imposed to the system (with  nsppol , nspinor ,  nspden ):       Non-magnetic system   ( nsppol =1,  nspinor =1,  nspden =1):  \nOne (2lpawu+1)x(2lpawu+1)  dmatpawu  matrix is given for each atom on which\n+U is applied. \nIt contains the \u201cspin-up\u201d occupations.     Ferromagnetic spin-polarized (collinear) system   ( nsppol =2,  nspinor =1,  nspden =2):  \nTwo (2lpawu+1)x(2lpawu+1)  dmatpawu  matrices are given for each atom on\nwhich +U is applied. \nThey contain the \u201cspin-up\u201d and \u201cspin-down\u201d occupations.     Anti-ferromagnetic spin-polarized (collinear) system   ( nsppol =1,  nspinor =1,  nspden =2):  \nOne (2lpawu+1)x(2lpawu+1)  dmatpawu  matrix is given for each atom on which\n+U is applied. \nIt contains the \u201cspin-up\u201d occupations.     Non-collinear magnetic system   ( nsppol =1,  nspinor =2,  nspden =4):  \nTwo (2lpawu+1)x(2lpawu+1)  dmatpawu  matrices are given for each atom on\nwhich +U is applied. \nThey contains the \u201cspin-up\u201d and \u201cspin-down\u201d occupations (defined as\nn_up=(n+|m|)/2 and n_dn=(n-|m|)/2), where m is the integrated magnetization\nvector). \nThe direction of the magnetization (which is also the direction of n_up and\nn_dn) is given by  spinat . \n_ Warning: unlike collinear case, atoms having the same magnetization\nmagnitude with different directions must be given the same occupation matrix; \nthe magnetization will be oriented by the value of  spinat  (this is the\ncase for antiferro-magnetism). _     Non-collinear magnetic system with zero magnetization   ( nsppol =1,  nspinor =2,  nspden =1):  \nTwo (2lpawu+1)x(2lpawu+1)  dmatpawu  matrices are given for each atom on\nwhich +U is applied. \nThey contain the \u201cspin-up\u201d and \u201cspin-down\u201d occupations; \nBut, as \u201cspin-up\u201d and \u201cspin-down\u201d are constrained identical, the \u201cspin-down\u201d\none is ignored by the code.",
            "title": "dmatpawu"
        },
        {
            "location": "/input_variables/varpaw/#dmatpuopt",
            "text": "Mnemonics: Density MATrix for PAW+U OPTion \nVariable type: integer \nDimensions: scalar \nDefault value: 2 \nOnly relevant if  usepaw ==1 and  usepawu ==1    This option governs the way occupations of localized atomic levels are\ncomputed:      dmatpuopt =1: atomic occupations are projections on atomic orbitals (Eq. (6) of PRB 77, 155104 (2008)).       dmatpuopt =2: atomic occupations are integrated values in PAW spheres of angular-momentum-decomposed charge densities (Eq. (7) of PRB 77, 155104 (2008)).       dmatpuopt =3: only for tests       dmatpuopt =4: Extrapolations of occupancies outside the PAW-sphere. This Definition gives normalized operator for occupation.       In the general case  dmatpuopt =2 is suitable. The use of  dmatpuopt =1 is\nrestricted to PAW datasets in which the first atomic wavefunction of the\ncorrelated subspace is a normalized atomic eigenfunction.",
            "title": "dmatpuopt"
        },
        {
            "location": "/input_variables/varpaw/#dmatudiag",
            "text": "Mnemonics: Density MATrix for paw+U, DIAGonalization \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1 and  usepawu ==1 and  nspden  != 4    Relevant only for Ground-State calculations. \nThis option can be used to diagonalize the occupation matrix Nocc_{m,m_prime}. \nRelevant values are:     0: desactivated.   1: occupation matrix is diagonalized and printed in log file at each SCF cycle (eigenvectors are also given in the log file).   2: for testing purpose.",
            "title": "dmatudiag"
        },
        {
            "location": "/input_variables/varpaw/#f4of2_sla",
            "text": "Mnemonics: F4 Over F2 ratio of Slater integrals \nVariable type: real \nDimensions: scalar \nDefault value: [\u20180.625 for d electron\u2019, \u20180.6681 for f electron\u2019] \nOnly relevant if  usepaw ==1 and ( usepawu ==1 or  usedmft ==1)    This gives the ratio of Slater Integrals F4 and F2. It is used in DFT+U or\nDFT+DMFT for the calculation of the orbital dependent screened coulomb\ninteraction.",
            "title": "f4of2_sla"
        },
        {
            "location": "/input_variables/varpaw/#f6of2_sla",
            "text": "Mnemonics: F6 Over F2 ratio of Slater integrals \nVariable type: real \nDimensions: scalar \nDefault value: 0.4943 \nOnly relevant if ( usepawu ==1 or  usedmft ==1) and  lpawu =3    Gives the ratio of Slater Integrals F6 and F2. It is used with f4of2_sla ==3 in DFT+U or DFT+DMFT for the calculation of the orbital\ndependent screened coulomb interaction.",
            "title": "f6of2_sla"
        },
        {
            "location": "/input_variables/varpaw/#iboxcut",
            "text": "Mnemonics: Integer governing the internal use of BOXCUT - not a very good choice of variable name \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Concern all summations in the reciprocal space and is allowed in PAW and norm-\nconserving.   if set to 0 all reciprocal space summations are done in a sphere contained in the FFT box.   if set to 1 all reciprocal space summations are done in the whole FFT box (useful for tests).",
            "title": "iboxcut"
        },
        {
            "location": "/input_variables/varpaw/#jpawu",
            "text": "Mnemonics: value of J for PAW+U \nVariable type: real \nDimensions: ( ntypat ) \nDefault value: *0 \nOnly relevant if  usepaw ==1 and  usepawu ==1    Gives the value of the screened exchange interaction between correlated\nelectrons corresponding to  lpawu  for each species. \nIn the case where  lpawu  =-1, the value is not used.",
            "title": "jpawu"
        },
        {
            "location": "/input_variables/varpaw/#lexexch",
            "text": "Mnemonics: value of angular momentum L for EXact EXCHange \nVariable type: integer \nDimensions: ( ntypat ) \nDefault value: -1 \nOnly relevant if  useexexch ==1    Give for each species the value of the angular momentum (only values 2 or 3\nare allowed) on which to apply the exact exchange correction.",
            "title": "lexexch"
        },
        {
            "location": "/input_variables/varpaw/#lpawu",
            "text": "Mnemonics: value of angular momentum L for PAW+U \nVariable type: integer \nDimensions: ( ntypat ) \nDefault value: *-1 \nOnly relevant if  usepawu ==1 or  usepawu == 2    Give for each species the value of the angular momentum (only values 2 or 3\nare allowed)  on which to apply the LDA+U correction.     If equal to 2 (d-orbitals)  or 3 (f-orbitals), values of  upawu  and   jpawu  are used in the calculation.   If equal to -1: do not apply LDA+U correction on the species.",
            "title": "lpawu"
        },
        {
            "location": "/input_variables/varpaw/#mqgriddg",
            "text": "Mnemonics: Maximum number of Q-wavevectors for the 1-dimensional GRID  for the Double Grid in PAW \nVariable type: integer \nDimensions: scalar \nDefault value: 3001    Maximum number of wavevectors used to sample the local part of the potential,\nin PAW. Actually referred to as mqgrid_vl internally. Should change name to\nthe latter \u2026 See also  mqgrid",
            "title": "mqgriddg"
        },
        {
            "location": "/input_variables/varpaw/#ngfftdg",
            "text": "Mnemonics: Number of Grid points for Fast Fourier Transform : Double Grid \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  usepaw ==1    This variable has the same meaning as ngfft (gives the size of fast Fourier\ntransform (fft) grid in three dimensions) but concerns the \u201cdouble grid\u201d only\nused for PAW calculations.",
            "title": "ngfftdg"
        },
        {
            "location": "/input_variables/varpaw/#pawcpxocc",
            "text": "Mnemonics: PAW - use ComPleX rhoij OCCupancies \nVariable type: integer \nDimensions: scalar \nDefault value: 2 if  optdriver ==0 and  ionmov <6 and  pawspnorb ==1 and  iscf >=10 and ( kptopt  !=1 or  kptopt !=2) and  usepaw ==1,\n1 otherwise.  Only relevant if  usepaw ==1    The only possible values for  pawcpxocc  are 1 or 2. \nWhen    pawcpxocc ==1   , \u201cdirect\u201d decomposition of total energy cannot be\nprinted out. \nWhen    pawcpxocc ==2   , PAW augmentation occupancies are treated as\nCOMPLEX; else they are considered as REAL. \nThis is needed when time-reversal symmetry is broken (typically when spin-\norbit coupling is activated).    Note for ground-state calculations ( optdriver =0): \nThe imaginary part of PAW augmentation occupancies is only used for the\ncomputation of the total energy by \u201cdirect scheme\u201d; this is only necessary\nwhen SCF mixing on potential is chosen ( iscf <10). \nWhen SCF mixing on density is chosen ( iscf >=10), the \u201cdirect\u201d\ndecomposition of energy is only printed out without being used. It is thus\npossible to use  pawcpxocc =1 in the latter case. \nIn order to save CPU time, when molecular dynamics is selected\n( ionmov >=6) and SCF mixing done on density ( iscf >=10), pawcpxocc =2 is (by default) set to   1",
            "title": "pawcpxocc"
        },
        {
            "location": "/input_variables/varpaw/#pawcross",
            "text": "Mnemonics: PAW - add CROSS term in oscillator strengths \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if ( optdriver ==3 or  optdriver ==4) and  usepaw ==1    When   pawcross=1   , the overlap between the plane-wave part of one band\nand the on-site part of an other is taken into account in the computation of\nthe oscillator strengths. Hence, the completeness of the on-site basis is no\nlonger assumed.",
            "title": "pawcross"
        },
        {
            "location": "/input_variables/varpaw/#pawecutdg",
            "text": "Mnemonics: PAW - Energy CUToff for the Double Grid \nVariable type: real \nDimensions: scalar \nDefault value: -1 \nComment: pawecutdg MUST be specified for PAW calculations. \nOnly relevant if  usepaw ==1    Define the energy cut-off for the fine FFT grid (the \u201cdouble grid\u201d, that\nallows to transfer data from the normal, coarse, FFT grid to the spherical\ngrid around each atom).  pawecutdg  must be larger or equal to  ecut . If it is equal to it, then\nno fine grid is used. The results are not very accurate, but the computations\nproceed quite fast. \nFor typical PAW computations, where  ecut  is on the order of 15 Ha, pawecutdg  must be tested according to what you want to do. For\ncalculations that do not require a high accuracy (molecular dynamics for\ninstance) a value of 20 Ha is enough. For calculations that require a high\naccuracy (response fonctions for instance) it should be on the order of 30 Ha.\nChoosing a larger value should not increase the accuracy, but does not slow\ndown the computation either, only the memory. The choice made for this\nvariable DOES have a bearing on the numerical accuracy of the results, and, as\nsuch, should be the object of a convergence study. The convergence test might\nbe made on the total energy or derived quantities, like forces, but also on\nthe two values of the \u201cCompensation charge inside spheres\u201d, a quantity written\nin the log file.",
            "title": "pawecutdg"
        },
        {
            "location": "/input_variables/varpaw/#pawfatbnd",
            "text": "Mnemonics: PAW: print band structure in the FAT-BaND representation \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1     For Ground-State calculations and non self-consistent calculations only. \nThis option can be used to plot band structure. For each atom (specified by natsph  and  iatsph ), each angular momentum, and each spin polarisation,\nthe band structure is written in files (such as e.g.\nFATBANDS_at0001_Ni_is2_l2_m-1). Each file contains the eigenvalue, and the\ncontribution of angular momentum L, and projection of angular momentum M, (for\nthe corresponding wavefunction) to the PAW density inside the PAW sphere as a\nfunction of the index of the k-point. The output can be readily plotted with\nthe software   xmgrace   (e.g\nxmgrace FATBANDS_at0001_Ni_is2_l2_m-1). Relevant values are:     0: desactivated.   1: The fatbands are only resolved in L.   2: The fatbands are resolved in L and M.",
            "title": "pawfatbnd"
        },
        {
            "location": "/input_variables/varpaw/#pawlcutd",
            "text": "Mnemonics: PAW - L angular momentum used to CUT the development in moments of the Densitites \nVariable type: integer \nDimensions: scalar \nDefault value: 10 \nOnly relevant if  usepaw ==1    The expansion of the densities in angular momenta is performed up to\nl= pawlcutd . \nNote that, for a given system, the maximum value of  pawlcutd  is   2*l_max  , where l_max is the maximum l of the PAW partial waves basis.    The choice made for this variable DOES have a bearing on the numerical\naccuracy of the results, and, as such, should be the object of a convergence\nstudy. The convergence test might be made on the total energy or derived\nquantities, like forces, but also on the two values of the \u201cCompensation\ncharge inside spheres\u201d, a quantity written in the log file.",
            "title": "pawlcutd"
        },
        {
            "location": "/input_variables/varpaw/#pawlmix",
            "text": "Mnemonics: PAW - maximum L used in the spherical part MIXing \nVariable type: integer \nDimensions: scalar \nDefault value: 10 \nOnly relevant if  usepaw ==1    The choice made for this variable determine how the spherical part of the\ndensity is mixed during electronic iterations.    Only parts of rhoij quantities associated with l angular momenta up to\nl=pawlmix are mixed. Other parts of augmentation occupancies are not included\nin the mixing process. \nThis option is useful to save CPU time but DOES have a bearing on the\nnumerical accuracy of the results.",
            "title": "pawlmix"
        },
        {
            "location": "/input_variables/varpaw/#pawmixdg",
            "text": "Mnemonics: PAW - MIXing is done (or not) on the (fine) Double Grid \nVariable type: integer \nDimensions: scalar \nDefault value: 0 if  npfft ==1,\n1 otherwise.  Only relevant if  usepaw ==1    The choice made for this variable determines the grid on which the density (or\npotential) is mixed during the SCF cycle.    - If   pawmixdg=1   the density/potential is mixed in REAL space using the\nfine FFT grid (defined by  pawecutdg  or  ngfftdg ). \n- If   pawmixdg=0   the density/potential is mixed in RECIPROCAL space\nusing the coarse FFT grid (defined by  ecut  or  ngfft ). Only components\nof the coarse grid are mixed using the scheme defined by  iscf ; other\ncomponents are only precondionned by  diemix  and simply mixed. \nThis option is useful to save memory and does not affect numerical accuracy of\nconverged results. If   pawmixdg=1   , density and corresponding residual\nare stored for previous iterations and are REAL arrays of size  nfftdg . If  pawmixdg=0   , density and corresponding residual are stored for previous\niterations and are COMPLEX arrays of size  nfft . The memory saving is\nparticularly efficient when using the Pulay mixing ( iscf =7 or 17).    In   wavelet   calculations  usewvl =1: \n- pawmixdg is set to 1 by default. \n- A value of 0 is not allowed. \n- Density/potential is mixed in REAL space (Here only one grid is used).",
            "title": "pawmixdg"
        },
        {
            "location": "/input_variables/varpaw/#pawnhatxc",
            "text": "Mnemonics: PAW - Flag for exact computation of gradients of NHAT density in eXchange-Correlation. \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  usepaw ==1    Relevant only when a GGA exchange-correlation functional is used. \nWhen this flag is activated, the gradients of compensation charge density\n(n_hat) are exactly computed (i.e. analytically); when it is deactivated, they\nare computed with a numerical scheme in reciprocal space (which can produce\ninaccurate results if the compensation charge density is highly localized). \nAs analytical treatment of compensation charge density gradients is CPU time\ndemanding, it is possible to bypass it with  pawnhatxc =0; but the numerical\naccuracy can be affected by this choice. It is recommended to test the\nvalidity of this approximation before use.",
            "title": "pawnhatxc"
        },
        {
            "location": "/input_variables/varpaw/#pawnphi",
            "text": "Mnemonics: PAW - Number of PHI angles used to discretize the sphere around each atom. \nVariable type: integer \nDimensions: scalar \nDefault value: 13 \nOnly relevant if  usepaw ==1    Number of phi angles (longitude) used to discretize the data on the atomic\nspheres. This discretization is completely defined by  pawnphi  and pawntheta .",
            "title": "pawnphi"
        },
        {
            "location": "/input_variables/varpaw/#pawntheta",
            "text": "Mnemonics: PAW - Number of THETA angles used to discretize the sphere around each atom. \nVariable type: integer \nDimensions: scalar \nDefault value: 12 \nOnly relevant if  usepaw ==1    Number of theta angles (latitude) used to discretize the data on the atomic\nspheres. This discretization is completely defined by  pawntheta  and pawnphi .",
            "title": "pawntheta"
        },
        {
            "location": "/input_variables/varpaw/#pawnzlm",
            "text": "Mnemonics: PAW - only compute Non-Zero LM-moments of the contributions to the density from the spheres \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  usepaw ==1    Concerns the computation of the contributions to the density from the spheres\n(named rho_1 - rho_tild_1). \nIf set to 0, all lm-moments of the sphere contributions to the density are\ncomputed at each electronic iteration. \nIf set to 1, only non-zero lm-moments of the sphere contributions to the\ndensity are computed at each electronic iteration (they are all computed at\nthe first iteration then only those found to be non-zero will be computed ;\nthus the first iteration is more cpu intensive)",
            "title": "pawnzlm"
        },
        {
            "location": "/input_variables/varpaw/#pawoptmix",
            "text": "Mnemonics: PAW - OPTion for the MIXing of the spherical part \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1    In the case of PAW computations, during the self-consistent cycle, ABINIT\nmixes the density \u03c1(r)= \u223c\u03c1(r) +\u2227\u03c1(r) and the occupancy matrix \u03c1ij. (\u223c\u03c1(r) is\nthe pseudo density, \u2227\u03c1(r) is the compensation charge density). It can be\nredundant as \u03c1ij is contained in \u2227\u03c1(r).      If  pawoptmix =0: \nABINIT mixes \u03c1(r) and \u03c1ij but the residual used to control the mixing\nalgorithm is only based on \u03c1(r).    If  pawoptmix =1: \nABINIT mixes \u03c1(r) and \u03c1ij and the residual used to control the mixing\nalgorithm is based on \u03c1(r) and \u03c1ij.    This has only an influence on the efficiency of the mixing algorithm. \nIn cas of mixing problems, the first suggestion is to increase the size of the\nhistory (see  npulayit ). Then it is also possible to play with the\nparameters of the Kerker mixing:  diemix ,  diemac , etc\u2026",
            "title": "pawoptmix"
        },
        {
            "location": "/input_variables/varpaw/#pawoptosc",
            "text": "Mnemonics: PAW - OPTion for the computation of the OSCillator matrix elements \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Only relevant for  GW  or  BETHE_SALPETER  calculations with PAW. \nThis variable defines the approach used for the evaluation of the oscillator\nmatrix elements within the PAW formalism. Possible values are 0,1,2. \nIf  pawoptosc =0 the code uses its internal default value (2 for SCREENING\ncalculations, 1 for SIGMA calculations, 2 for  BETHE_SALPETER ) \nIf  pawoptosc =1 the matrix elements are computed with the expression given\nby Arnaud and Alouani in PRB 62. 4464 The equation is exact provided that the\nset of PAW partial waves is complete. \nIf  pawoptosc =2 the matrix elements are computed with the approximated\nexpression proposed by Shishkin and Kresse in PRB 74. 035101",
            "title": "pawoptosc"
        },
        {
            "location": "/input_variables/varpaw/#pawovlp",
            "text": "Mnemonics: PAW - spheres OVerLaP allowed (in percentage) \nVariable type: real \nDimensions: scalar \nDefault value: 5.0 \nOnly relevant if  usepaw ==1    When PAW is activated, a localized atomic basis is added to describe wave\nfunctions. Spheres around atoms are defined and they are IN PRINCIPLE not\nallowed to overlap. However, a small overlap can be allowed without\ncompromising the accuracy of results. Be aware that too high overlaps can lead\nto unphysical results. \nWith the  pawovlp  variable, the user can control the (voluminal) overlap\npercentage allowed without stopping the execution.  pawovlp  is the value (in percentage: 0\u2026100%) obtained by dividing the\nvolume of the overlap of two spheres by the volume of the smallest sphere. \nThe following values are permitted for  pawovlp :    -  pawovlp <0. : overlap is always allowed \n-  pawovlp =0. : no overlap is allowed \n-  pawovlp >0. and <100. : overlap is allowed only if it is less\nthan  pawovlp  %",
            "title": "pawovlp"
        },
        {
            "location": "/input_variables/varpaw/#pawprtden",
            "text": "Mnemonics: PAW: PRinT total physical electron DENsity \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1     Deprecated :   See the  prtden .",
            "title": "pawprtden"
        },
        {
            "location": "/input_variables/varpaw/#pawprtdos",
            "text": "Mnemonics: PAW: PRinT partial DOS contributions \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1 and  prtdos ==3    This input variable controls the computation and/or printing of contributions\nto the PAW partial DOS in _DOS file(s):    + Plane-waves contribution \n+ \u201con-site\u201d all-electron contribution (phi) \n- \u201con-site\u201d pseudo contribution (phi_tild).    If   pawprtdos=0:  \n- The 3 contributions are computed; only the total partial DOS is output in\n_DOS file. \nIf   pawprtdos=1:  \n- The 3 contributions are computed and output in _DOS file. \n- In that case, integrated DOS is not output. \nIf   pawprtdos=2:  \n- Only \u201con-site\u201d all-electron contribution is computed and output in _DOS\nfile. \n- This a (very) good approximation of total DOS, provided that (1) the PAW\nlocal basis is complete, (2) the electronic charge is mostly contained in PAW\nspheres. \n- In that case, the  ratsph  variable is automatically set to the PAW\nradius.",
            "title": "pawprtdos"
        },
        {
            "location": "/input_variables/varpaw/#pawprtvol",
            "text": "Mnemonics: PAW: PRinT VOLume \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1    Control print volume and debugging output for PAW in log file or standard\noutput. If set to 0, the print volume is at its minimum.  pawprtvol  can have values from -3 to 3: \n-  pawprtvol =-1 or 1: matrices rho_ij (atomic occupancies) and D_ij (psp\nstrength) are printed at each SCF cycle with details about their\ncontributions. \n-  pawprtvol =-2 or 2: like -1 or 1 plus additional printing: moments of\n\u201con-site\u201d densities, details about local exact exchange. \n-  pawprtvol =-3 or 3: like -2 or 2 plus additional printing: details about\nPAW+U, rotation matrices of sphercal harmonics. \nWhen  pawprtvol >=0, up to 12 components of rho_ij and D_ij matrices for\nthe 1st and last atom are printed. \nWhen  pawprtvol <0, all components of rho_ij and D_ij matrices for all\natoms are printed.",
            "title": "pawprtvol"
        },
        {
            "location": "/input_variables/varpaw/#pawprtwf",
            "text": "Mnemonics: PAW: PRinT WaveFunctions \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1    This input variable controls the output of the full PAW wave functions\nincluding the on-site contribution inside each PAW sphere needed to\nreconstruct the correct nodal shape in the augmentation region.   pawprtwf=1  causes the generation of a file _AE_WFK that contains the full\nwavefunctions in real space on the fine FFT grid defined by  pawecutdg  or ngfftdg . Limitations: At present (v6.0),   pawprtwf=1   is not\ncompatible neither with the k-point parallelism nor with the parallelism over\nG-vectors. Therefore the output of the _AE_WFK has to be done in sequential.\nMoreover, in order to use this feature, one has to enable the support for\nETSF-IO at configure-time as the _AW_WFK file is written using the NETCDF file\nformat following the ETSF-IO specification for wavefunctions in real space. If\nthe code is run entirely in serial, additional output is made of various\ncontributions to the all-electron wavefunction. By default the full available\nset of bands and k-points are ouput, but a single band and k-point index can\nbe requested by using the variables  pawprt_b  and  pawprt_k .",
            "title": "pawprtwf"
        },
        {
            "location": "/input_variables/varpaw/#pawspnorb",
            "text": "Mnemonics: PAW - option for SPiN-ORBit coupling \nVariable type: integer \nDimensions: scalar \nDefault value: 1 if  nspinor ==2,\n0 otherwise.  Only relevant if  usepaw ==1    When PAW is activated, the   spin-orbit coupling   can be added without the\nuse of specific PAW datasets (pseudopotentials). \nIf  pawspnorb =1, spin-orbit will be added. \nIf the wavefunction is spinorial (that is, if  nspinor =2), there is no\nreason not to include the spin-orbit interaction, so that the default value of pawspnorb  becomes 1 when  nspinor =2. \nNote that only the all-electron \u201con-site\u201d contribution to the Hamiltonian is\ntaken into account; this is a very good approximation but requires the\nfollowing conditions to be fullfilled:    1- the  ~  \u03c6 i  basis is complete enough \n2- the electronic density is mainly contained in the PAW sphere    Also note that, when spin-orbit coupling is activated and there is some\nmagnetization  nspden =4, the time-reversal symmetry is broken. \nThe use of  kptopt =1 or  kptopt =2 is thus forbidden. It is advised to\nuse  kptopt =3 (no symmetry used to generate k-points) or  kptopt =4 (only\nspatial symmetries used to generate k-points). \nBe careful if you choose to use  kptopt =0 (k-points given by hand); Time-\nreversal symmetry has to be avoided. \nAn artificial scaling of the spin-orbit can be introduced thanks to the spnorbscl  input variable.",
            "title": "pawspnorb"
        },
        {
            "location": "/input_variables/varpaw/#pawstgylm",
            "text": "Mnemonics: PAW - option for the STorage of G_l(r).YLM(r) \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  usepaw =1    When PAW is activated, the computation of compensation charge density (so\ncalled \u201chat\u201d density) requires the computation of g_l(r).Y_lm(r) factors (and\ncartesian derivatives) at each point of real space contained in PAW spheres.\nThe number of atoms, of (l,m) quantum numbers and the sharpness of the real\nFFT grid can lead to a very big {g_l.Y_lm} datastructure. One can save memory\nby putting  pawstgylm =0; but, in that case, g_l(r).Y_lm(r) factors a re-\ncomputed each time they are needed and CPU time increases.    Possible choices: \n-  pawstgylm =0 : g_l(r).Y_lm(r) are not stored in memory and recomputed. \n-  pawstgylm =1 : g_l(r).Y_lm(r) are stored in memory.    Note: \ng_l(r) are shape functions (analytically known) \nY_lm(r) are real spherical harmonics",
            "title": "pawstgylm"
        },
        {
            "location": "/input_variables/varpaw/#pawsushat",
            "text": "Mnemonics: PAW - SUSceptibility, inclusion of HAT (compensation charge) contribution \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1 and  optdriver ==0     Ground-State calculation only. \nWhen a sophisticated preconditioning scheme is selected for the SCF cycle of a\nGround-State calculation ( iprcel >0), the computation of the\nsusceptibility matrix is required several times during the cycle. This\ncomputation is computer time consuming, especially -- within PAW \u2013 because\nof the inclusion of additional terms due to the compensation charge density.\nAs only a crude valuation of the susceptibilty matrix is needed (to evaluate a\npreconditioning matrix), the compensation charge contribution can be neglected\nto save CPU time (select  pawsushat =0). This approximation could be\nunfavourable in some cases; in the latter, we advise to put  pawsushat =1.    Possible choices: \n-  pawsushat =0 : only plane-wave contribution to suscep. matrix is\ncomputed. \n-  pawsushat =1 : the whole suscep. matrix (PW + PAW on-site) is computed.",
            "title": "pawsushat"
        },
        {
            "location": "/input_variables/varpaw/#pawusecp",
            "text": "Mnemonics: PAW - option for the USE of CPrj in memory (cprj=WF projected with NL projector) \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  usepaw ==1    When PAW is activated, the computation of cprj arrays is memory and time\nconsuming. \nWhen  pawusecp =0, then the cprj are never kept in memory, they are\nrecomputed when needed (this is CPU-time consuming). When  pawusecp =1, then\nthe cprj are computed once and then kept in memory. \nChange the value of the keyword only if you are an experienced user\n(developper). \nRemember: cprj = (WF_n .dot. p_i) (WF_n=wave function, p_i=non-local\nprojector).    For the time being, only activated for RF calculations.",
            "title": "pawusecp"
        },
        {
            "location": "/input_variables/varpaw/#pawxcdev",
            "text": "Mnemonics: PAW - choice for eXchange-Correlation DEVelopment (spherical part) \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  usepaw ==1     If set to 0, the exchange-correlation term in the spherical part of energy is totally computed on the angular mesh   If set to 1, the exchange-correlation term in the spherical part of energy is developed onto lm-moments at order 1   If set to 2, the exchange-correlation term in the spherical part of energy is developed onto lm-moments at order 2 (can be memory/CPU consuming)    Be careful: GGA requires  pawxcdev  > 0",
            "title": "pawxcdev"
        },
        {
            "location": "/input_variables/varpaw/#prtefg",
            "text": "Mnemonics: PRint Electric Field Gradient \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1,  quadmom      If nonzero, calculate the electric field gradient at each atomic site in the unit cell. Using this option requires  quadmom  to be set as well. Values will be written to main output file (search for Electric Field Gradient). If prtefg=1, only the quadrupole coupling in MHz and asymmetry are reported. If prtefg=2, the full electric field gradient tensors in atomic units are also given, showing separate contributions from the valence electrons, the ion cores, and the PAW reconstruction. If prtefg=3, then in addition to the prtefg=2 output, the EFGs are computed using an ionic point charge model. This is useful for comparing the accurate PAW-based results to those of simple ion-only models. Use of prtefg=3 requires that the variable  ptcharge  be set as well.  \nThe option prtefg is compatible with spin polarized calculations (see nspden ) and also LDA+U (see  usepawu ).",
            "title": "prtefg"
        },
        {
            "location": "/input_variables/varpaw/#prtfc",
            "text": "Mnemonics: PRinT Fermi Contact term \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1     If set to 1, print the Fermi contact interaction at each nuclear site, that is, the electron density at each site. The result appears in the main output file (search for FC). Note that this calculation is different than what is done by cut3d, because it also computes the PAW on-site corrections in addition to the contribution from the valence pseudo-wavefunctions.",
            "title": "prtfc"
        },
        {
            "location": "/input_variables/varpaw/#prtnabla",
            "text": "Mnemonics: PRint NABLA \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1     If set to 1, calculate the matrix elements <Psi_n|-inabla|Psi_m> and write it in file _OPT to be read by the code conducti.",
            "title": "prtnabla"
        },
        {
            "location": "/input_variables/varpaw/#ptcharge",
            "text": "Mnemonics: PoinT CHARGEs \nVariable type: real \nDimensions: ( ntypat ) \nDefault value: *0 \nOnly relevant if  usepaw ==1 and  prtefg >=3      Array of point charges, in atomic units, of the nuclei. In the normal computation of electric field gradients (see  prtefg ) the ionic contribution is calculated from the core charges of the atomic sites. Thus for example in a PAW data set for oxygen where the core is 1s2, the core charge is +6 (total nuclear charge minus core electron charge). In point charge models, which are much less accurate than PAW calculations, all atomic sites are treated as ions with charges determined by their valence states. In such a case oxygen almost always would have a point charge of -2. The present variable taken together with  prtefg  performs a full PAW computation of the electric field gradient and also a simple point charge computation. The user inputs whatever point charges he/she wishes for each atom type.",
            "title": "ptcharge"
        },
        {
            "location": "/input_variables/varpaw/#quadmom",
            "text": "Mnemonics: QUADrupole MOMents \nVariable type: real \nDimensions: ( ntypat ) \nDefault value: *0 \nOnly relevant if  usepaw ==1 and  prtefg >=1      Array of quadrupole moments, in barns, of the nuclei. These values are used in conjunction with the electric field gradients computed with  prtefg  to calculate the quadrupole couplings in MHz, as well as the asymmetries. Note that the electric field gradient at a nuclear site is independent of the nuclear quadrupole moment, thus the quadrupole moment of a nucleus can be input as 0, and the option  prtefg =2 used to determine the electric field gradient at the site.",
            "title": "quadmom"
        },
        {
            "location": "/input_variables/varpaw/#spnorbscl",
            "text": "Mnemonics: SPin-ORBit SCaLing \nVariable type: real \nDimensions: scalar \nDefault value: 1.0 \nOnly relevant if  usepaw ==1 and  pawspnorb >= 1     Scaling of the spin-orbit interaction. The default values gives the first-\nprinciples value, while other values are used for the analysis of the effect\nof the spin-orbit interaction, but are not expected to correspond to any\nphysical situation.",
            "title": "spnorbscl"
        },
        {
            "location": "/input_variables/varpaw/#upawu",
            "text": "Mnemonics: value of U for PAW+U \nVariable type: real \nDimensions: ( ntypat ) \nDefault value: *0 \nOnly relevant if  usepaw ==1 and  usepawu ==1    Gives the value of the screened coulomb interaction between correlated\nelectrons corresponding to  lpawu  for each species. \nIn the case where  lpawu  =-1, the value is not used. \nIn the case of a  GW  calculation, the U interaction defined by  upawu \nwill be REMOVED from the self energy. In particular, for G0 W0 calculations\n(perturbative calculations), the energy eigenvalues obtained after an\nunderlying DFT+U calculation will be \nE_ GW  = E_DFT+U + < phi | Self-energy - U | phi> \nActually, in order to perform a  GW  @ DFT+U calculation, one should define\nthe same value of U in the self-energy calculation, than the one defined in\nthe DFT calculation. The easiest is actually to define the value of U for the\nwhole set of calculations (for the different datasets), including the\nscreening, even if the U value does not play explicitly a role in the\ncomputation of the latter (well, the input wavefunctions will be different\nanyhow). \nIt is possible to perform calculations of the type  GW +U_prime @ DFT+U , so\nkeeping a U interaction (usually smaller than the initial U) in the  GW \ncalculation, by defining a smaller U than the one used in the DFT calculation.\nThis value will be subtracted in the  GW  correction calculation, as\noutlined above. \nExplicitly, in order to do a calculation of a material with a DFT U value of\n7.5 eV, followed by a  GW  calculation where there is a residual U value of\n2 eV, one has to define :    uldau1   7.5 eV   ! This is for the DFT calculation\n...\noptdriver4  4\nuldau4   5.5 eV   ! This is for the screening calculation",
            "title": "upawu"
        },
        {
            "location": "/input_variables/varpaw/#usedmatpu",
            "text": "Mnemonics: USE of an initial Density MATrix in Paw+U \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1 and  usepawu ==1    When  usedmatpu /=0, an initial density matrix (given by  dmatpawu \nkeyword) is used and kept fixed during the first ABS( usedmatpu ) SCF steps. \nThis starting value of the density matrix can be useful to find the correct\nground state. Within LDA+U formalism, finding the minimal energy of the system\nis tricky; thus it is advised to test several values of the initial density\nmatrix. \nNote also that the density matrix has to respect some symmetry rules\ndetermined by the space group. If the symmetry is not respected in the input,\nthe matrix is however automatically symmetrised.    The sign of  usedmatpu  has influence only when  ionmov /=0 (dynamics or\nrelaxation): \n- When  usedmatpu >0, the density matrix is kept constant only at first\nionic step \n- When  usedmatpu <0, the density matrix is kept constant at each ionic\nstep",
            "title": "usedmatpu"
        },
        {
            "location": "/input_variables/varpaw/#useexexch",
            "text": "Mnemonics: USE of EXact EXCHange \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1    When  useexexch =1, the hybrid functional PBE0 is used in PAW, inside PAW\nspheres only, and only for correlated orbitals given by  lexexch . To change\nthe ratio of exact exchange, see also  exchmix .",
            "title": "useexexch"
        },
        {
            "location": "/input_variables/varpaw/#usepawu",
            "text": "Mnemonics: USE PAW+U (spherical part) \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  usepaw ==1    Must be non-zero if a DFT+U calculation is done, or if a  GW  calculation\nfollowing a DFT+U calculation is done (important !).    If set to 0, the LDA+U method is not used.       If set to 1 or 2, the LDA+U method (cf [1]) is used. The full rotationally invariant formulation is used (see Eq. (3) of Ref [2]) for the interaction term of the energy. Two choices are allowed concerning the double counting term:       If  usepawu =1, the Full Localized Limit (FLL) (or Atomic limit) double counting is used (cf Eq. (4) of Ref.[2] or Eq. (8) of Ref[3]).       If  usepawu =2, the Around Mean Field (AMF) double counting is used (cf Eq. (7) of Ref [3]). Not valid if nspinor=2.         If LDA+U is activated ( usepawu =1 or 2), the  lpawu ,  upawu  and jpawu  input variables are read. \nThe implementation is done inside PAW augmentation regions only (cf Ref [4]).\nThe initial density matrix can be given in the input file (see  usedmatpu ).\nThe expression of the density matrix is chosen thanks to  dmatpuopt . See\nalso   How_to_use_LDA_plus_U.txt   .\nfor some informations. \nIn the case of a  GW  calculation on top of a DFT+U, the absence of\ndefinition of a U value in the self-energy will LEAVE the underlying U from\nthe DFT calculation. Thus, the code will actually do a  GW +U @ DFT+U\ncalculation. Note that the screening calculation will not be affected by the\npresence/absence of a U value. \nActually, in order to perform a  GW  @ DFT+U calculation, one should define\nthe same value of U in the self-energy calculation, than the one defined in\nthe DFT calculation. The code will know that the interaction corresponding to\nthat value has to be SUBTRACTED inside the self-energy. The easiest is\nactually to define the presence of U for the whole set of calculations (for\nthe different datasets), including the screening, even if the U value does not\nplay explicitly a role in the computation of the latter (well, the input\nwavefunctions will be different anyhow). \nIt is possible to perform calculations of the type  GW +U_prime @ DFT+U , so\nkeeping a smaller U interaction in the  GW  calculation, by subtracting a\nsmaller U than the one used in the DFT calculation. See the description of the upawu  input variable. \nReferences: \n[1] V. I. Anisimov, J. Zaanen, and O. K. Andersen PRB 44, 943 (1991) \n[2] A.I. Lichtenstein, V.I. Anisimov and J. Zaanen PRB 52, 5467 (1995) \n[3] M. T. Czyzyk and G. A. Sawatzky PRB 49, 14211 (1994) \n[4] O. Bengone, M. Alouani, P. Blochl, and J. Hugel PRB 62, 16392 (2000)    Suggested acknowledgment: \n- B. Amadon, F. Jollet and M. Torrent, Phys. Rev. B 77, 155104 (2008).",
            "title": "usepawu"
        },
        {
            "location": "/input_variables/varpaw/#usepotzero",
            "text": "Mnemonics: USE POTential ZERO \nVariable type: integer \nDimensions: scalar \nDefault value: 0     usepotzero =0, the usual convention: the smooth potential is set to zero averarage value.   usepotzero =1, the new convention: the physical potential is set to zero average value.   usepotzero =2, the PWscf convention: the potential of equivalent point charges is set to zero average value (convention also valid for NC pseudopotentials).",
            "title": "usepotzero"
        },
        {
            "location": "/input_variables/varpaw/#usexcnhat",
            "text": "Mnemonics: USE eXchange-Correlation with NHAT (compensation charge density) \nVariable type: integer \nDimensions: scalar \nDefault value: -1 \nOnly relevant if  usepaw ==1    This flag determines how the exchange-correlation terms are computed for the\npseudo-density. \nWhen  usexcnhat =0, exchange-correlation potential does not include the\ncompensation charge density, i.e. Vxc=Vxc(tild_Ncore + tild_Nvalence). \nWhen  usexcnhat =1, exchange-correlation potential includes the compensation\ncharge density, i.e. Vxc=Vxc(tild_Ncore + tild_Nvalence + hat_N). \nWhen  usexcnhat =-1,the value of  usexcnhat  is determined from the\nreading of the PAW dataset file (pseudopotential file). When PAW datasets with\ndifferent treatment of Vxc are used in the same run, the code stops.",
            "title": "usexcnhat"
        },
        {
            "location": "/input_variables/varrf/",
            "text": "bdeigrf\n\u00b6\n\n\nMnemonics: BanD for second-order EIGenvalues from Response-Function\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: -1\n\nOnly relevant if \nieig2rf\n in [1,2,3,4,5]  \n\n\nthat is, if the user is performing second-order eigenvalue calculations using\nresponse-functions.  \n\n\nThe variable \nbdeigrf\n is the maximum number of bands for which the second-\norder eigenvalues must be calculated: the full number of bands is still used\nduring the computation of these corrections.  \n\n\nIf \nbdeigrf\n is set to -1, the code will automatically set \nbdeigrf\n equal\nto nband.\n\n\nd3e_pert1_atpol\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 1: limits of ATomic POLarisations\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: [1, 1]\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nControls the range of atoms for which displacements will be considered in non-\nlinear computations (using the 2n+1 theorem), for the 1st perturbation.\n\nMay take values from 1 to \nnatom\n, with\n\nd3e_pert1_atpol\n(1)<=\nd3e_pert1_atpol\n(2).\n\nSee \nrfatpol\n for additional details.\n\n\nd3e_pert1_dir\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 1: DIRections\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nGives the directions to be considered in non-linear computations (using the\n2n+1 theorem), for the 1st perturbation.\n\nThe three elements corresponds to the three primitive vectors, either in real\nspace (atomic displacement), or in reciprocal space (electric field\nperturbation).\n\nSee \nrfdir\n for additional details.\n\n\nd3e_pert1_elfd\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 1: ELectric FielD\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nTurns on electric field perturbation in non-linear computation, as 1st\nperturbation. Actually, such calculations requires first the non-self-\nconsistent calculation of derivatives with respect to k, independently of the\nelectric field perturbation itself.\n\nSee \nrfelfd\n for additional details.\n\n\nd3e_pert1_phon\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 1: PHONons\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nTurns on atomic displacement perturbation in non-linear computation, as 1st\nperturbation.\n\nSee \nrfphon\n for additional details.\n\n\nd3e_pert2_atpol\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 2: limits of ATomic POLarisations\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: [1, 1]\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nControls the range of atoms for which displacements will be considered in non-\nlinear computations (using the 2n+1 theorem), for the 2nd perturbation.\n\nMay take values from 1 to \nnatom\n, with\n\nd3e_pert2_atpol\n(1)<=\nd3e_pert2_atpol\n(2).\n\nSee \nrfatpol\n for additional details.\n\n\nd3e_pert2_dir\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 2: DIRections\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nGives the directions to be considered in non-linear computations (using the\n2n+1 theorem), for the 2nd perturbation.\n\nThe three elements corresponds to the three primitive vectors, either in real\nspace (atomic displacement), or in reciprocal space (electric field\nperturbation).\n\nSee \nrfdir\n for additional details.\n\n\nd3e_pert2_elfd\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 2: ELectric FielD\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nTurns on electric field perturbation in non-linear computation, as 2nd\nperturbation. Actually, such calculations requires first the non-self-\nconsistent calculation of derivatives with respect to k, independently of the\nelectric field perturbation itself.\n\nSee \nrfelfd\n for additional details.\n\n\nd3e_pert2_phon\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 2: PHONons\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nTurns on atomic displacement perturbation in non-linear computation, as 2nd\nperturbation.\n\nSee \nrfphon\n for additional details.\n\n\nd3e_pert3_atpol\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 3: limits of ATomic POLarisations\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: [1, 1]\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nControls the range of atoms for which displacements will be considered in non-\nlinear computations (using the 2n+1 theorem), for the 3rd perturbation.\n\nMay take values from 1 to \nnatom\n, with\n\nd3e_pert3_atpol\n(1)<=\nd3e_pert3_atpol\n(2).\n\nSee \nrfatpol\n for additional details.\n\n\nd3e_pert3_dir\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 3: DIRections\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nGives the directions to be considered in non-linear computations (using the\n2n+1 theorem), for the 3rd perturbation.\n\nThe three elements corresponds to the three primitive vectors, either in real\nspace (atomic displacement), or in reciprocal space (electric field\nperturbation).\n\nSee \nrfdir\n for additional details.\n\n\nd3e_pert3_elfd\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 3: ELectric FielD\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nTurns on electric field perturbation in non-linear computation, as 3rd\nperturbation. Actually, such calculations requires first the non-self-\nconsistent calculation of derivatives with respect to k, independently of the\nelectric field perturbation itself.\n\nSee \nrfelfd\n for additional details.\n\n\nd3e_pert3_phon\n\u00b6\n\n\nMnemonics: 3rd Derivative of Energy, mixed PERTurbation 3: PHONons\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \noptdriver\n==5 (non-linear response computations)  \n\n\nTurns on atomic displacement perturbation in non-linear computation, as 3rd\nperturbation.\n\nSee \nrfphon\n for additional details.\n\n\ndfpt_sciss\n\u00b6\n\n\nMnemonics: DFPT SCISSor operator\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIt is the value of the \u201cscissors operator\u201d, the shift of conduction band\neigenvalues, used in response function calculations.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \n ecut \n has\nthe \u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV)\n\nTypical use is for response to electric field (\nrfelfd\n=3), but NOT for d/dk\n(\nrfelfd\n=2) and phonon responses.\n\n\nefmas\n\u00b6\n\n\nMnemonics: EFfective MASs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nTurns on effective mass tensor calculations. Such calculations requires the\nnon-self-consistent calculation of derivatives with respect to k, in the same\ndataset. It must therefore be used with \nrfelfd\n=2.  \n\n\n\n\n0=>no effective mass tensor calculation \n\n\n1=>effective mass tensor calculation \n\n\n\n\nAt the present time, both norm-conserving (NC) and PAW calculations are\nsupported. Also, for PAW calculations only, \nnspinor\n==2 and\n\npawspnorb\n==1 (i.e. spin-orbit (SO) calculations) is supported. NC SO\ncalculations are NOT currently supported. Also, for both NC and PAW,\n\nnspden\n/=1 and \nnsppol\n/=1 are NOT supported.\n\n\nefmas_bands\n\u00b6\n\n\nMnemonics: EFfective MASs, BANDS to be treated.\n\nVariable type: integer\n\nDimensions: (2,\nnkpt\n)\n\nDefault value: The full range of band available in the calculation for each k-point.\n\nOnly relevant if \nefmas\n==1  \n\n\nThis variable controls the range of bands for which the effective mass is to\nbe calculated. If a band is degenerate, all other bands of the degenerate\ngroup will automatically be treated, even if they were not part of the user\nspecified range.\n\n\nefmas_calc_dirs\n\u00b6\n\n\nMnemonics: EFfective MASs, CALCulate along DIRectionS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nefmas\n==1  \n\n\nAllows the user to calculate the scalar effective mass of all bands specified\nby \nefmas_bands\n along specific directions in reciprocal space. This is\nparticularly useful when considering degenerate bands, which are usually\nwarped, and thus cannot have their dispersion (hessian) and effective mass\nexpressed as a tensor. This allows the user to see the more complex angular\nbehavior of effective masses in these cases, for instance.\n\n\nWhen \nefmas_calc_dirs\n==0, no directions are read from the input file (using\n\nefmas_dirs\n) and the effective masses along the 3 cartesian directions are\noutput by default.\n\n\nWhen \nefmas_calc_dirs\n==1, 2 or 3, \nefmas_n_dirs\n directions are read from\n\nefmas_dirs\n, assuming cartesian, reduced or angular (theta,phi)\ncoordinates, respectively. In the case \nefmas_calc_dirs\n==3, 2 real values\nper directions are read, whereas 3 real values are read in the two other\ncases.\n\n\nefmas_deg\n\u00b6\n\n\nMnemonics: EFfective MASs, activate DEGenerate formalism\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nefmas\n>0  \n\n\nActivate (==1) or not (==0) the treatment of degenerate bands (within a\ncriterion \nefmas_deg_tol\n) using the transport equivalent effective mass\nidea (see \nPRB 89 155131 (2014)\n).\n\n\nefmas_deg_tol\n\u00b6\n\n\nMnemonics: EFfective MASs, DEGeneracy TOLerance\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1e-05\n\nOnly relevant if \nefmas_deg\n==1  \n\n\nEnergy difference below which 2 bands are considered degenerate (and treated\nusing the formalism activated with \nefmas_deg\n==1). \nefmas_deg_tol\n has\nthe \u2018\nENERGY\n\u2018 characteristics.\n\n\nefmas_dim\n\u00b6\n\n\nMnemonics: EFfective MASs, DIMension of the effective mass tensor\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 3\n\nOnly relevant if \nefmas\n==1  \n\n\nFor 2D or 1D systems, the band dispersion goes to 0 perpendicular to the\nsystem, which causes the inverse effective mass to be singular, i.e. the\neffective mass to be NaN. This keyword circumvents the problem by eliminating\nthe troublesome dimensions from the inverse effective mass.\n\n\nIn 2D, the Z axis is ignored and, in 1D, the Z and Y axis are ignored.\n\n\nAlso, note that in the 2D degenerate case, a subtlety arises: the \u2018transport\nequivalent\u2019 effective mass does not determine the scale of the transport\ntensors (conductivity and others). Therefore, for this specific case, the\nfactor by which these transport tensors should be scaled once determined from\nthe \u2018transport equivatlent\u2019 effective mass tensor is output separately on the\nline immediately after the effective mass.\n\n\nefmas_dirs\n\u00b6\n\n\nMnemonics: EFfective MASs, DIRectionS to be calculated\n\nVariable type: real\n\nDimensions: (3 or 2,\nefmas_n_dirs\n)\n\nDefault value: 0\n\nOnly relevant if \nefmas_calc_dirs\n>0  \n\n\nList of \nefmas_n_dirs\n directions to be considered according to the value of\n\nefmas_calc_dirs\n. The directions are specified by 3 real values if\n\nefmas_calc_dirs\n==1 or 2 and by 2 real values if \nefmas_calc_dirs\n==3.\n\n\nefmas_n_dirs\n\u00b6\n\n\nMnemonics: EFfective MASs, Number of DIRectionS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nefmas_calc_dirs\n>0  \n\n\nNumber of directions in \nefmas_dirs\n, to be considered according to\n\nefmas_calc_dirs\n.\n\n\nefmas_ntheta\n\u00b6\n\n\nMnemonics: EFfective MASs, Number of points for integration w/r to THETA\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1000\n\nOnly relevant if \nefmas\n==1 and \nefmas_bands\n==(degenerate band index)  \n\n\nWhen a band is degenerate, the usual definition of effective mass becomes\ninvalid. However, it is still possible to define a \u2018transport equivalent mass\ntensor\u2019 that reproduces the contribution of the band to the conductivity\ntensor. To obtain this tensor, an integration over the solid sphere is\nrequired. The default value gives a tensor accurate to the 4th decimal in Ge.\n\n\nelph2_imagden\n\u00b6\n\n\nMnemonics: ELectron-PHonon interaction at 2nd order : IMAGinary shift of the DENominator\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \nieig2rf\n != 0  \n\n\nthat is, if the user is performing performing second-order eigenvalue\ncalculations using response-functions.  \n\n\nThe variable \nelph2_imagden\n determines the imaginary shift of the\ndenominator of the sum-over-states in the perturbation denominator,\n(e_{nk}-e_{n\u2019k\u2019}+i \nelph2_imagden\n). One should use a width comparable with\nthe Debye frequency or the maximum phonon frequency.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \n ecut \n has\nthe \u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV)\n\n\neph_task\n\u00b6\n\n\nMnemonics: Electron-PHonon: Task\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nWhen \noptdriver\n==7, select the task to be performed. The choice is among :\n\n\neph_task\n=1 : phonon linewidth\n\n\neph_task\n=2 : electron-phonon coupling elements\n\n\nesmear\n\u00b6\n\n\nMnemonics: Eigenvalue SMEARing\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.01\n\nOnly relevant if \nsmdelta\n != 0  \n\n\nthat is, if the user is performing simulations of the electronic lifetimes\ninduced by the electron-phonon coupling.  \n\n\nThe variable \nesmear\n determines the width of the functions approximating\nthe delta function, \\delta(e_{nk}-e_{n\u2019k\u2019}), present in the expression of the\nlifetimes. One should use a width comparable with the Debye frequency or the\nmaximum phonon frequency.\n\nCan be specified in Ha (the default), Ry, eV or Kelvin, since \n ecut \n has\nthe \u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV)\n\n\nfrzfermi\n\u00b6\n\n\nMnemonics: FReeZe FERMI energy\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nCan be used to suppress artificially the first-order change of Fermi energy,\nin case of Response Function calculation for metals at Q=0. The input variable\n\nfrzfermi\n, if set to 1, allows to suppress this contribution, but this is\nincorrect.\n\n\nieig2rf\n\u00b6\n\n\nMnemonics: Integer for second-order EIGenvalues from Response-Function\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf \nieig2rf\n is greater then 0, the code will produce a file, named with the\ntrailing suffix _EIGR2D, containing the second-order electronic eigenvalues\nfor the perturbation. These files are used in the calculation of the thermal\ncorrection to the electronic eigenvalues.  \n\n\n\n\nIf \nieig2rf\n is set to 1, the second-order electronic eigenvalues will be\n\n\ncalculated from the DFPT method (Sternheimer).\n\n\nIf \nieig2rf\n is set to 2, the second-order electronic eigenvalues will be\n\n\ncalculated from the Allen-Cardona method. (sum over states)\n\n\nIf \nieig2rf\n is set to 3, the second-order electronic eigenvalues will be\n\n\ncalculated from the DFPT method (sum over states) but using a different part\n\n\nof the code. This is equivalent to \nieig2rf\n = 1 [debuging]\n\n\nIf \nieig2rf\n is set to 4, the second-order electronic eigenvalues will be\n\n\ncalculated from the dynamical DFPT method (Sternheimer). The code will\n\n\ngenerate _EIGR2D.nc files that contain the electron-phonon matrix element\n\n\nsquared on the space orthogonal to the active space. The code will also\n\n\nproduce _FAN.nc files that contain the electron-phonon matrix elements\n\n\nsquared. Note that \nieig2rf\n=4 can only be used if Abinit is compiled with\n\n\nNETCDF support.\n\n\nIf \nieig2rf\n is set to 5, the second-order electronic eigenvalues will be\n\n\ncalculated from the dynamical DFPT method (Sternheimer). The code will\n\n\ngenerate _EIGR2D.nc files that contain the electron-phonon matrix element\n\n\nsquare on the space orthogonal to the active space. The code will also produce\n\n\n_GKK.nc files that contain electron-phonon matrix elements. This option is\n\n\npreferable for large system to \nieig2rf\n=4 as the GKK files take less much\n\n\nless disk space and memory (but run a little bit slower). Note that\n\n\nieig2rf\n=5 can only be used if Abinit is compiled with NETCDF support.\n\n\nRelated variables :\n\n\nbdeigrf\n,\nelph2_imagden\n,\ngetgam_eig2nkq\n,\nsmdelta\n Related variables\n\n\nbdeigrf\n,\nelph2_imagden\n,\ngetgam_eig2nkq\n,\nsmdelta\n\n\n\n\nph_ngqpt\n\u00b6\n\n\nMnemonics: PHonons: Number of Grid points for Q-PoinT mesh.\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [20, 20, 20]  \n\n\nThis variable defines the q-mesh used to compute the phonon DOS and the\nEliashberg function via Fourier interpolation. Related input variables:\n\nph_qshift\n and \nph_nqshift\n.\n\n\nph_qpath\n\u00b6\n\n\nMnemonics: Phonons: Q-PATH\n\nVariable type: real\n\nDimensions: (3,ph_nqpath)\n\nDefault value: None\n\nOnly relevant if specified(\nph_nqpath\n)  \n\n\nThis array contains the list of special q-points used to construct the q-path\nfor phonon band structures and phonon linewidths. See also \nph_nqpath\n and\n[\nph_ndivsm\n.\n\n\nprepanl\n\u00b6\n\n\nMnemonics: PREPAre Non-Linear response calculation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThe computation of third-order derivatives from the 2n+1 theorem requires the\nfirst-order wavefunctions and densities obtained from a linear response\ncalculation. The standard approach in a linear response calculation is (i) to\ncompute only the irreducible perturbations, and (ii) to use symmetries to\nreduce the number of k-points for the k-point integration.\n\nThis approach cannot be applied, presently (v4.1), if the first-order\nwavefunctions are to be used to compute third-order derivatives. First, for\nelectric fields, the code needs the derivatives along the three directions.\nStill, in case of phonons, only the irreducible perturbations are required.\nSecond, for both electric fields and phonons, the wavefunctions must be\navailable in half the BZ (kptopt=2), or the full BZ (kptopt=3).\n\nDuring the linear response calculation, in order to prepare a non-linear\ncalculation, one should put \nprepanl\n to 1 in order to force ABINIT (i) to\ncompute the electric field perturbation along the three directions explicitly,\nand (ii) to keep the full number of k-points.\n\n\nprepgkk\n\u00b6\n\n\nMnemonics: PREPAre GKK calculation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThe calculation of electron-phonon coupling quantities requires the presence\nof all the perturbations (all atoms in all directions) for the chosen set of\n(irreducible) q-points. To impose this and prevent ABINIT from using symmetry\nto reduce the number of perturbations, set \nprepgkk\n to 1. Use in\nconjunction with \nprtgkk\n.\n\n\nprtbbb\n\u00b6\n\n\nMnemonics: PRinT Band-By-Band decomposition\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIf \nprtbbb\n is 1, print the band-by-band decomposition of Born effective\ncharges and localization tensor, in case they are computed. See Ph. Ghosez and\nX. Gonze, J. Phys.: Condens. Matter 12, 9179 (2000).\n\n\nrf2_dkdk\n\u00b6\n\n\nMnemonics: Response Function : 2nd Derivative of wavefunctions with respect to K\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUNUSABLE (in development)\n\n\nActivates computation of second derivatives of wavefunctions with respect to\nwavevectors. This is not strictly a response function but is a needed\nauxiliary quantity in the calculations of 3rd-order derivatives of the energy\n(non-linear response). The directions for the derivatives are determined by\n\nrfdir\n (TO BE CORRECTED!).\n\n\n\n\n0=>no derivative calculation \n\n\n1=>calculation along diagonal directions (d2/(dk_i dk_i), natom+10 is activated) \n\n\n2=>calculation along off-diagonal directions (d2/(dk_i dk_j), natom+11 is activated) \n\n\n3=>calculation along all directions (both natom+10 and natom+11 are activated) \n\n\n\n\nrfasr\n\u00b6\n\n\nMnemonics: Response Function : Acoustic Sum Rule\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nControl the evaluation of the acoustic sum rule in effective charges and\ndynamical matrix at Gamma within a response function calculation (not active\nat the level of producing the DDB, but at the level of the phonon\neigenfrequencies output).\n\n\n\n\n0 => no acoustic sum rule imposed \n\n\n1 => acoustic sum rule imposed for dynamical matrix at Gamma, and charge neutrality imposed with extra charge evenly distributed among atoms \n\n\n2 => acoustic sum rule imposed for dynamical matrix at Gamma, and charge neutrality imposed with extra charge given proportionally to those atoms with the largest effective charge. \n\n\n\n\nThe treatment of the acoustic sum rule and charge neutrality sum rule is finer\nat the level of the ANADDB utility, with the two independent input variables \n\nasr \n and \n chneut\n\n .\n\n\nrfatpol\n\u00b6\n\n\nMnemonics: Response Function : ATomic POLarisation\n\nVariable type: integer\n\nDimensions: (2)\n\nDefault value: [1, 1]  \n\n\nControl the range of atoms for which displacements will be considered in\nphonon calculations (atomic polarizations), using the 2n+1 theorem.\n\nThese values are only relevant to phonon response function calculations.\n\nMay take values from 1 to \nnatom\n, with \n[rfatpol]\n<=\n[rfatpol]\n.\n\nThe atoms to be moved will be defined by the\n\ndo-loop variable iatpol :\n\ndo iatpol=\n[rfatpol]\n,\n[rfatpol]\n\nFor the calculation of a full dynamical matrix, use \n[rfatpol]\n=1 and\n\n[rfatpol]\n=\nnatom\n, together with \nrfdir\n 1 1 1 . For selected\nelements of the dynamical matrix, use different values of \nrfatpol\n and/or\n\nrfdir\n. The name \u2018iatpol\u2019 is used for the part of the internal variable\nipert when it runs from 1 to \nnatom\n. The internal variable ipert can also\nassume values larger than \nnatom\n, denoting perturbations of electric field\nor stress type (see \n the response function help file\n\n ).\n\n\nrfddk\n\u00b6\n\n\nMnemonics: Response Function with respect to Derivative with respect to K\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nActivates computation of derivatives of ground state wavefunctions with\nrespect to wavevectors. This is not strictly a response function but is a\nneeded auxiliary quantity in the electric field calculations (see \nrfelfd\n)\nThe directions for the derivatives are determined by \nrfdir\n.\n\n\n\n\n0=>no derivative calculation \n\n\n1=>calculation of first derivatives of wavefunctions with respect to k points (d/dk calculation). The exact same functionality is provided by \nrfelfd\n = 2. \n\n\n\n\nrfdir\n\u00b6\n\n\nMnemonics: Response Function : DIRections\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]  \n\n\nGives the directions to be considered for response function calculations (also\nfor the Berry phase computation of the polarization, see the \nberryopt\n\ninput variable).\n\nThe three elements corresponds to the three primitive vectors, either in real\nspace (phonon calculations), or in reciprocal space (d/dk, homogeneous\nelectric field, homogeneous magnetic field calculations). So, they generate a\nbasis for the generation of the dynamical matrix or the macroscopic dielectric\ntensor or magnetic susceptibility and magnetic shielding, or the effective\ncharge tensors.\n\nIf equal to 1, response functions, as defined by \nrfddk\n, \nrfelfd\n,\n\nrfphon\n, \nrfdir\n and \nrfatpol\n, are to be computed for the\ncorresponding direction. If 0, this direction should not be considered.\n\n\nrfelfd\n\u00b6\n\n\nMnemonics: Response Function with respect to the ELectric FielD\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nTurns on electric field response function calculations. Actually, such\ncalculations requires first the non-self-consistent calculation of derivatives\nwith respect to k, independently of the electric field perturbation itself.\n\n\n\n\n0=>no electric field perturbation \n\n\n1=>full calculation, with first the derivative of ground-state wavefunction with respect to k (d/dk calculation), by a non-self-consistent calculation, then the generation of the first-order response to an homogeneous electric field \n\n\n2=>only the derivative of ground-state wavefunctions with respect to k \n\n\n3=>only the generation of the first-order response to the electric field, assuming that the data on derivative of ground-state wavefunction with respect to k is available on disk. \n\n\n\n\n(Note : because the tolerances to be used for derivatives or homogeneous\nelectric field are different, one often does the calculation of derivatives in\na separate dataset, followed by calculation of electric field response as well\nas phonon.\n\nThe options 2 and 3 proves useful in that context ; also, in case a scissor\nshift is to be used, it is usually not applied for the d/dk response).\n\n\nrfmagn\n\u00b6\n\n\nMnemonics: Response Function with respect to MAGNetic B-field perturbation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIt must be equal to 1 to run response function calculations with respect to\nexternal magnetic field. Currently, orbital magnetism is not taken into\naccount and the perturbing potential has Zeeman form.\n\n\nrfmeth\n\u00b6\n\n\nMnemonics: Response Function METHod\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nSelects method used in response function calculations. Presently, only 1 is\nallowed.\n\n\nrfphon\n\u00b6\n\n\nMnemonics: Response Function with respect to PHONons\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nIt must be equal to 1 to run phonon response function calculations.\n\n\nrfstrs\n\u00b6\n\n\nMnemonics: Response Function with respect to STRainS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed to run strain response-function calculations (e.g. needed to get elastic\nconstants). Define, with \nrfdir\n, the set of perturbations.\n\n\n\n\n0=>no strain perturbation \n\n\n1=>only uniaxial strain(s) (ipert=natom+3 is activated) \n\n\n2=>only shear strain(s) (ipert=natom+4 is activated) \n\n\n3=>both uniaxial and shear strain(s) (both ipert=natom+3 and ipert=natom+4 are activated) \n\n\n\n\nSee the possible restrictions on the use of strain perturbations, in the \n\nrespfn help file \n .\n\n\nrfuser\n\u00b6\n\n\nMnemonics: Response Function, USER-defined\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nAvailable to the developpers, to activate the use of ipert=natom+6 and\nipert=natom+7, two sets of perturbations that the developpers can define.  \n\n\n\n\n0=>no computations for ipert=natom+6 or ipert=natom+7 \n\n\n1=>response with respect to perturbation natom+6 will be computed \n\n\n2=>response with respect to perturbation natom+7 will be computed \n\n\n3=>responses with respect to perturbations natom+6 and natom+7 will be computed \n\n\n\n\nIn order to define and use correctly the new perturbations, the developper\nmight have to include code lines or additional routines at the level of the\nfollowing routines : dfpt_cgwf.F90, dfpt_dyout.F90, dfpt_symph.F90,\ndfpt_dyout.F90, dfpt_etot.F90, littlegroup_pert.F90, dfpt_looppert.F90,\ndfpt_mkcor.F90, dfpt_nstdy.F90, dfpt_nstwf.F90, respfn.F90, dfpt_scfcv.F90,\nirreducible_set_pert.F90, dfpt_vloca.F90, dfpt_vtorho.F90, dfpt_vtowfk.F90. In\nthese routines, the developper should pay a particular attention to the rfpert\narray, defined in the routine respfn.F90 , as well as to the ipert local\nvariable.\n\n\nsmdelta\n\u00b6\n\n\nMnemonics: SMeared DELTA function\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nWhen \nsmdelta\n in non-zero, it will trigger the calculation of the imaginary\npart of the second-order electronic eigenvalues, which can be related to the\nelectronic lifetimes. The delta function is evaluated using:  \n\n\n\n\nwhen \nsmdelta\n == 1, Fermi-Dirac smearing : 0.25_dp/(cosh(xx/2.0_dp)**2 \n\n\nwhen \nsmdelta\n == 2, Cold smearing by Marzari using the parameter a=-.5634 (minimization of the bump): exp(-xx2)/sqrt(pi) * (1.5d0+xx\n(-a\n1.5d0+xx\n(-1.0d0+a\nxx))) \n\n\nwhen \nsmdelta\n == 3, Cold smearing by Marzari using the parameter a=-.8165 (monotonic function in the tail): as 2 but different a \n\n\nwhen \nsmdelta\n == 4, Smearing of Methfessel and Paxton (PRB40,3616(1989)) with Hermite polynomial of degree 2, corresponding to \u201cCold smearing\u201d of N. Marzari with a=0 (so, same smeared delta function as smdelta=2, with different a). \n\n\nwhen \nsmdelta\n == 5, Gaussian smearing : 1.0d0\nexp(-xx\n*2)/sqrt(pi) \n\n\n\n\ntd_maxene\n\u00b6\n\n\nMnemonics: Time-Dependent dft : MAXimal kohn-sham ENErgy difference\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nThe Matrix to be diagonalized in the Casida framework (see \u201cTime-Dependent\nDensity Functional Response Theory of Molecular systems: Theory, Computational\nMethods, and Functionals\u201d, by M.E. Casida, in Recent Developments and\nApplications of Modern Density Functional Theory, edited by J.M. Seminario\n(Elsevier, Amsterdam, 1996).) is a NxN matrix, where, by default, N is the\nproduct of the number of occupied states by the number of unoccupied states.\n\nThe input variable \ntd_maxene\n allows to diminish N : it selects only the\npairs of occupied and unoccupied states for which the Kohn-Sham energy\ndifference is less than \ntd_maxene\n. The default value 0.0 means that all\npairs are taken into account.\n\nSee \ntd_mexcit\n for an alternative way to decrease N.\n\n\ntd_mexcit\n\u00b6\n\n\nMnemonics: Time-Dependent dft : Maximal number of EXCITations\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThe Matrix to be diagonalized in the Casida framework (see \u201cTime-Dependent\nDensity Functional Response Theory of Molecular systems: Theory, Computational\nMethods, and Functionals\u201d, by M.E. Casida, in Recent Developments and\nApplications of Modern Density Functional Theory, edited by J.M. Seminario\n(Elsevier, Amsterdam, 1996).) is a NxN matrix, where, by default, N is the\nproduct of the number of occupied states by the number of unoccupied states.\n\nThe input variable \ntd_mexcit\n allows to diminish N : it selects the first\n\ntd_mexcit\n pairs of occupied and unoccupied states, ordered with respect to\nincreasing Kohn-Sham energy difference. However, when \ntd_mexcit\n is zero,\nall pairs are allowed.\n\nSee \ntd_maxene\n for an alternative way to decrease N.",
            "title": "RF"
        },
        {
            "location": "/input_variables/varrf/#bdeigrf",
            "text": "Mnemonics: BanD for second-order EIGenvalues from Response-Function \nVariable type: integer \nDimensions: scalar \nDefault value: -1 \nOnly relevant if  ieig2rf  in [1,2,3,4,5]    that is, if the user is performing second-order eigenvalue calculations using\nresponse-functions.    The variable  bdeigrf  is the maximum number of bands for which the second-\norder eigenvalues must be calculated: the full number of bands is still used\nduring the computation of these corrections.    If  bdeigrf  is set to -1, the code will automatically set  bdeigrf  equal\nto nband.",
            "title": "bdeigrf"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert1_atpol",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 1: limits of ATomic POLarisations \nVariable type: integer \nDimensions: (2) \nDefault value: [1, 1] \nOnly relevant if  optdriver ==5 (non-linear response computations)    Controls the range of atoms for which displacements will be considered in non-\nlinear computations (using the 2n+1 theorem), for the 1st perturbation. \nMay take values from 1 to  natom , with d3e_pert1_atpol (1)<= d3e_pert1_atpol (2). \nSee  rfatpol  for additional details.",
            "title": "d3e_pert1_atpol"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert1_dir",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 1: DIRections \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  optdriver ==5 (non-linear response computations)    Gives the directions to be considered in non-linear computations (using the\n2n+1 theorem), for the 1st perturbation. \nThe three elements corresponds to the three primitive vectors, either in real\nspace (atomic displacement), or in reciprocal space (electric field\nperturbation). \nSee  rfdir  for additional details.",
            "title": "d3e_pert1_dir"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert1_elfd",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 1: ELectric FielD \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==5 (non-linear response computations)    Turns on electric field perturbation in non-linear computation, as 1st\nperturbation. Actually, such calculations requires first the non-self-\nconsistent calculation of derivatives with respect to k, independently of the\nelectric field perturbation itself. \nSee  rfelfd  for additional details.",
            "title": "d3e_pert1_elfd"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert1_phon",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 1: PHONons \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==5 (non-linear response computations)    Turns on atomic displacement perturbation in non-linear computation, as 1st\nperturbation. \nSee  rfphon  for additional details.",
            "title": "d3e_pert1_phon"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert2_atpol",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 2: limits of ATomic POLarisations \nVariable type: integer \nDimensions: (2) \nDefault value: [1, 1] \nOnly relevant if  optdriver ==5 (non-linear response computations)    Controls the range of atoms for which displacements will be considered in non-\nlinear computations (using the 2n+1 theorem), for the 2nd perturbation. \nMay take values from 1 to  natom , with d3e_pert2_atpol (1)<= d3e_pert2_atpol (2). \nSee  rfatpol  for additional details.",
            "title": "d3e_pert2_atpol"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert2_dir",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 2: DIRections \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  optdriver ==5 (non-linear response computations)    Gives the directions to be considered in non-linear computations (using the\n2n+1 theorem), for the 2nd perturbation. \nThe three elements corresponds to the three primitive vectors, either in real\nspace (atomic displacement), or in reciprocal space (electric field\nperturbation). \nSee  rfdir  for additional details.",
            "title": "d3e_pert2_dir"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert2_elfd",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 2: ELectric FielD \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==5 (non-linear response computations)    Turns on electric field perturbation in non-linear computation, as 2nd\nperturbation. Actually, such calculations requires first the non-self-\nconsistent calculation of derivatives with respect to k, independently of the\nelectric field perturbation itself. \nSee  rfelfd  for additional details.",
            "title": "d3e_pert2_elfd"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert2_phon",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 2: PHONons \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==5 (non-linear response computations)    Turns on atomic displacement perturbation in non-linear computation, as 2nd\nperturbation. \nSee  rfphon  for additional details.",
            "title": "d3e_pert2_phon"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert3_atpol",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 3: limits of ATomic POLarisations \nVariable type: integer \nDimensions: (2) \nDefault value: [1, 1] \nOnly relevant if  optdriver ==5 (non-linear response computations)    Controls the range of atoms for which displacements will be considered in non-\nlinear computations (using the 2n+1 theorem), for the 3rd perturbation. \nMay take values from 1 to  natom , with d3e_pert3_atpol (1)<= d3e_pert3_atpol (2). \nSee  rfatpol  for additional details.",
            "title": "d3e_pert3_atpol"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert3_dir",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 3: DIRections \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  optdriver ==5 (non-linear response computations)    Gives the directions to be considered in non-linear computations (using the\n2n+1 theorem), for the 3rd perturbation. \nThe three elements corresponds to the three primitive vectors, either in real\nspace (atomic displacement), or in reciprocal space (electric field\nperturbation). \nSee  rfdir  for additional details.",
            "title": "d3e_pert3_dir"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert3_elfd",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 3: ELectric FielD \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==5 (non-linear response computations)    Turns on electric field perturbation in non-linear computation, as 3rd\nperturbation. Actually, such calculations requires first the non-self-\nconsistent calculation of derivatives with respect to k, independently of the\nelectric field perturbation itself. \nSee  rfelfd  for additional details.",
            "title": "d3e_pert3_elfd"
        },
        {
            "location": "/input_variables/varrf/#d3e_pert3_phon",
            "text": "Mnemonics: 3rd Derivative of Energy, mixed PERTurbation 3: PHONons \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  optdriver ==5 (non-linear response computations)    Turns on atomic displacement perturbation in non-linear computation, as 3rd\nperturbation. \nSee  rfphon  for additional details.",
            "title": "d3e_pert3_phon"
        },
        {
            "location": "/input_variables/varrf/#dfpt_sciss",
            "text": "Mnemonics: DFPT SCISSor operator \nVariable type: real \nDimensions: scalar \nDefault value: 0    It is the value of the \u201cscissors operator\u201d, the shift of conduction band\neigenvalues, used in response function calculations. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since   ecut   has\nthe \u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV) \nTypical use is for response to electric field ( rfelfd =3), but NOT for d/dk\n( rfelfd =2) and phonon responses.",
            "title": "dfpt_sciss"
        },
        {
            "location": "/input_variables/varrf/#efmas",
            "text": "Mnemonics: EFfective MASs \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Turns on effective mass tensor calculations. Such calculations requires the\nnon-self-consistent calculation of derivatives with respect to k, in the same\ndataset. It must therefore be used with  rfelfd =2.     0=>no effective mass tensor calculation   1=>effective mass tensor calculation    At the present time, both norm-conserving (NC) and PAW calculations are\nsupported. Also, for PAW calculations only,  nspinor ==2 and pawspnorb ==1 (i.e. spin-orbit (SO) calculations) is supported. NC SO\ncalculations are NOT currently supported. Also, for both NC and PAW, nspden /=1 and  nsppol /=1 are NOT supported.",
            "title": "efmas"
        },
        {
            "location": "/input_variables/varrf/#efmas_bands",
            "text": "Mnemonics: EFfective MASs, BANDS to be treated. \nVariable type: integer \nDimensions: (2, nkpt ) \nDefault value: The full range of band available in the calculation for each k-point. \nOnly relevant if  efmas ==1    This variable controls the range of bands for which the effective mass is to\nbe calculated. If a band is degenerate, all other bands of the degenerate\ngroup will automatically be treated, even if they were not part of the user\nspecified range.",
            "title": "efmas_bands"
        },
        {
            "location": "/input_variables/varrf/#efmas_calc_dirs",
            "text": "Mnemonics: EFfective MASs, CALCulate along DIRectionS \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  efmas ==1    Allows the user to calculate the scalar effective mass of all bands specified\nby  efmas_bands  along specific directions in reciprocal space. This is\nparticularly useful when considering degenerate bands, which are usually\nwarped, and thus cannot have their dispersion (hessian) and effective mass\nexpressed as a tensor. This allows the user to see the more complex angular\nbehavior of effective masses in these cases, for instance.  When  efmas_calc_dirs ==0, no directions are read from the input file (using efmas_dirs ) and the effective masses along the 3 cartesian directions are\noutput by default.  When  efmas_calc_dirs ==1, 2 or 3,  efmas_n_dirs  directions are read from efmas_dirs , assuming cartesian, reduced or angular (theta,phi)\ncoordinates, respectively. In the case  efmas_calc_dirs ==3, 2 real values\nper directions are read, whereas 3 real values are read in the two other\ncases.",
            "title": "efmas_calc_dirs"
        },
        {
            "location": "/input_variables/varrf/#efmas_deg",
            "text": "Mnemonics: EFfective MASs, activate DEGenerate formalism \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  efmas >0    Activate (==1) or not (==0) the treatment of degenerate bands (within a\ncriterion  efmas_deg_tol ) using the transport equivalent effective mass\nidea (see  PRB 89 155131 (2014) ).",
            "title": "efmas_deg"
        },
        {
            "location": "/input_variables/varrf/#efmas_deg_tol",
            "text": "Mnemonics: EFfective MASs, DEGeneracy TOLerance \nVariable type: real \nDimensions: scalar \nDefault value: 1e-05 \nOnly relevant if  efmas_deg ==1    Energy difference below which 2 bands are considered degenerate (and treated\nusing the formalism activated with  efmas_deg ==1).  efmas_deg_tol  has\nthe \u2018 ENERGY \u2018 characteristics.",
            "title": "efmas_deg_tol"
        },
        {
            "location": "/input_variables/varrf/#efmas_dim",
            "text": "Mnemonics: EFfective MASs, DIMension of the effective mass tensor \nVariable type: integer \nDimensions: scalar \nDefault value: 3 \nOnly relevant if  efmas ==1    For 2D or 1D systems, the band dispersion goes to 0 perpendicular to the\nsystem, which causes the inverse effective mass to be singular, i.e. the\neffective mass to be NaN. This keyword circumvents the problem by eliminating\nthe troublesome dimensions from the inverse effective mass.  In 2D, the Z axis is ignored and, in 1D, the Z and Y axis are ignored.  Also, note that in the 2D degenerate case, a subtlety arises: the \u2018transport\nequivalent\u2019 effective mass does not determine the scale of the transport\ntensors (conductivity and others). Therefore, for this specific case, the\nfactor by which these transport tensors should be scaled once determined from\nthe \u2018transport equivatlent\u2019 effective mass tensor is output separately on the\nline immediately after the effective mass.",
            "title": "efmas_dim"
        },
        {
            "location": "/input_variables/varrf/#efmas_dirs",
            "text": "Mnemonics: EFfective MASs, DIRectionS to be calculated \nVariable type: real \nDimensions: (3 or 2, efmas_n_dirs ) \nDefault value: 0 \nOnly relevant if  efmas_calc_dirs >0    List of  efmas_n_dirs  directions to be considered according to the value of efmas_calc_dirs . The directions are specified by 3 real values if efmas_calc_dirs ==1 or 2 and by 2 real values if  efmas_calc_dirs ==3.",
            "title": "efmas_dirs"
        },
        {
            "location": "/input_variables/varrf/#efmas_n_dirs",
            "text": "Mnemonics: EFfective MASs, Number of DIRectionS \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  efmas_calc_dirs >0    Number of directions in  efmas_dirs , to be considered according to efmas_calc_dirs .",
            "title": "efmas_n_dirs"
        },
        {
            "location": "/input_variables/varrf/#efmas_ntheta",
            "text": "Mnemonics: EFfective MASs, Number of points for integration w/r to THETA \nVariable type: integer \nDimensions: scalar \nDefault value: 1000 \nOnly relevant if  efmas ==1 and  efmas_bands ==(degenerate band index)    When a band is degenerate, the usual definition of effective mass becomes\ninvalid. However, it is still possible to define a \u2018transport equivalent mass\ntensor\u2019 that reproduces the contribution of the band to the conductivity\ntensor. To obtain this tensor, an integration over the solid sphere is\nrequired. The default value gives a tensor accurate to the 4th decimal in Ge.",
            "title": "efmas_ntheta"
        },
        {
            "location": "/input_variables/varrf/#elph2_imagden",
            "text": "Mnemonics: ELectron-PHonon interaction at 2nd order : IMAGinary shift of the DENominator \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  ieig2rf  != 0    that is, if the user is performing performing second-order eigenvalue\ncalculations using response-functions.    The variable  elph2_imagden  determines the imaginary shift of the\ndenominator of the sum-over-states in the perturbation denominator,\n(e_{nk}-e_{n\u2019k\u2019}+i  elph2_imagden ). One should use a width comparable with\nthe Debye frequency or the maximum phonon frequency. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since   ecut   has\nthe \u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV)",
            "title": "elph2_imagden"
        },
        {
            "location": "/input_variables/varrf/#eph_task",
            "text": "Mnemonics: Electron-PHonon: Task \nVariable type: integer \nDimensions: scalar \nDefault value: 1    When  optdriver ==7, select the task to be performed. The choice is among :  eph_task =1 : phonon linewidth  eph_task =2 : electron-phonon coupling elements",
            "title": "eph_task"
        },
        {
            "location": "/input_variables/varrf/#esmear",
            "text": "Mnemonics: Eigenvalue SMEARing \nVariable type: real \nDimensions: scalar \nDefault value: 0.01 \nOnly relevant if  smdelta  != 0    that is, if the user is performing simulations of the electronic lifetimes\ninduced by the electron-phonon coupling.    The variable  esmear  determines the width of the functions approximating\nthe delta function, \\delta(e_{nk}-e_{n\u2019k\u2019}), present in the expression of the\nlifetimes. One should use a width comparable with the Debye frequency or the\nmaximum phonon frequency. \nCan be specified in Ha (the default), Ry, eV or Kelvin, since   ecut   has\nthe \u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV)",
            "title": "esmear"
        },
        {
            "location": "/input_variables/varrf/#frzfermi",
            "text": "Mnemonics: FReeZe FERMI energy \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Can be used to suppress artificially the first-order change of Fermi energy,\nin case of Response Function calculation for metals at Q=0. The input variable frzfermi , if set to 1, allows to suppress this contribution, but this is\nincorrect.",
            "title": "frzfermi"
        },
        {
            "location": "/input_variables/varrf/#ieig2rf",
            "text": "Mnemonics: Integer for second-order EIGenvalues from Response-Function \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If  ieig2rf  is greater then 0, the code will produce a file, named with the\ntrailing suffix _EIGR2D, containing the second-order electronic eigenvalues\nfor the perturbation. These files are used in the calculation of the thermal\ncorrection to the electronic eigenvalues.     If  ieig2rf  is set to 1, the second-order electronic eigenvalues will be  calculated from the DFPT method (Sternheimer).  If  ieig2rf  is set to 2, the second-order electronic eigenvalues will be  calculated from the Allen-Cardona method. (sum over states)  If  ieig2rf  is set to 3, the second-order electronic eigenvalues will be  calculated from the DFPT method (sum over states) but using a different part  of the code. This is equivalent to  ieig2rf  = 1 [debuging]  If  ieig2rf  is set to 4, the second-order electronic eigenvalues will be  calculated from the dynamical DFPT method (Sternheimer). The code will  generate _EIGR2D.nc files that contain the electron-phonon matrix element  squared on the space orthogonal to the active space. The code will also  produce _FAN.nc files that contain the electron-phonon matrix elements  squared. Note that  ieig2rf =4 can only be used if Abinit is compiled with  NETCDF support.  If  ieig2rf  is set to 5, the second-order electronic eigenvalues will be  calculated from the dynamical DFPT method (Sternheimer). The code will  generate _EIGR2D.nc files that contain the electron-phonon matrix element  square on the space orthogonal to the active space. The code will also produce  _GKK.nc files that contain electron-phonon matrix elements. This option is  preferable for large system to  ieig2rf =4 as the GKK files take less much  less disk space and memory (but run a little bit slower). Note that  ieig2rf =5 can only be used if Abinit is compiled with NETCDF support.  Related variables :  bdeigrf , elph2_imagden , getgam_eig2nkq , smdelta  Related variables  bdeigrf , elph2_imagden , getgam_eig2nkq , smdelta",
            "title": "ieig2rf"
        },
        {
            "location": "/input_variables/varrf/#ph_ngqpt",
            "text": "Mnemonics: PHonons: Number of Grid points for Q-PoinT mesh. \nVariable type: integer \nDimensions: (3) \nDefault value: [20, 20, 20]    This variable defines the q-mesh used to compute the phonon DOS and the\nEliashberg function via Fourier interpolation. Related input variables: ph_qshift  and  ph_nqshift .",
            "title": "ph_ngqpt"
        },
        {
            "location": "/input_variables/varrf/#ph_qpath",
            "text": "Mnemonics: Phonons: Q-PATH \nVariable type: real \nDimensions: (3,ph_nqpath) \nDefault value: None \nOnly relevant if specified( ph_nqpath )    This array contains the list of special q-points used to construct the q-path\nfor phonon band structures and phonon linewidths. See also  ph_nqpath  and\n[ ph_ndivsm .",
            "title": "ph_qpath"
        },
        {
            "location": "/input_variables/varrf/#prepanl",
            "text": "Mnemonics: PREPAre Non-Linear response calculation \nVariable type: integer \nDimensions: scalar \nDefault value: 0    The computation of third-order derivatives from the 2n+1 theorem requires the\nfirst-order wavefunctions and densities obtained from a linear response\ncalculation. The standard approach in a linear response calculation is (i) to\ncompute only the irreducible perturbations, and (ii) to use symmetries to\nreduce the number of k-points for the k-point integration. \nThis approach cannot be applied, presently (v4.1), if the first-order\nwavefunctions are to be used to compute third-order derivatives. First, for\nelectric fields, the code needs the derivatives along the three directions.\nStill, in case of phonons, only the irreducible perturbations are required.\nSecond, for both electric fields and phonons, the wavefunctions must be\navailable in half the BZ (kptopt=2), or the full BZ (kptopt=3). \nDuring the linear response calculation, in order to prepare a non-linear\ncalculation, one should put  prepanl  to 1 in order to force ABINIT (i) to\ncompute the electric field perturbation along the three directions explicitly,\nand (ii) to keep the full number of k-points.",
            "title": "prepanl"
        },
        {
            "location": "/input_variables/varrf/#prepgkk",
            "text": "Mnemonics: PREPAre GKK calculation \nVariable type: integer \nDimensions: scalar \nDefault value: 0    The calculation of electron-phonon coupling quantities requires the presence\nof all the perturbations (all atoms in all directions) for the chosen set of\n(irreducible) q-points. To impose this and prevent ABINIT from using symmetry\nto reduce the number of perturbations, set  prepgkk  to 1. Use in\nconjunction with  prtgkk .",
            "title": "prepgkk"
        },
        {
            "location": "/input_variables/varrf/#prtbbb",
            "text": "Mnemonics: PRinT Band-By-Band decomposition \nVariable type: integer \nDimensions: scalar \nDefault value: 0    If  prtbbb  is 1, print the band-by-band decomposition of Born effective\ncharges and localization tensor, in case they are computed. See Ph. Ghosez and\nX. Gonze, J. Phys.: Condens. Matter 12, 9179 (2000).",
            "title": "prtbbb"
        },
        {
            "location": "/input_variables/varrf/#rf2_dkdk",
            "text": "Mnemonics: Response Function : 2nd Derivative of wavefunctions with respect to K \nVariable type: integer \nDimensions: scalar \nDefault value: 0    UNUSABLE (in development)  Activates computation of second derivatives of wavefunctions with respect to\nwavevectors. This is not strictly a response function but is a needed\nauxiliary quantity in the calculations of 3rd-order derivatives of the energy\n(non-linear response). The directions for the derivatives are determined by rfdir  (TO BE CORRECTED!).   0=>no derivative calculation   1=>calculation along diagonal directions (d2/(dk_i dk_i), natom+10 is activated)   2=>calculation along off-diagonal directions (d2/(dk_i dk_j), natom+11 is activated)   3=>calculation along all directions (both natom+10 and natom+11 are activated)",
            "title": "rf2_dkdk"
        },
        {
            "location": "/input_variables/varrf/#rfasr",
            "text": "Mnemonics: Response Function : Acoustic Sum Rule \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Control the evaluation of the acoustic sum rule in effective charges and\ndynamical matrix at Gamma within a response function calculation (not active\nat the level of producing the DDB, but at the level of the phonon\neigenfrequencies output).   0 => no acoustic sum rule imposed   1 => acoustic sum rule imposed for dynamical matrix at Gamma, and charge neutrality imposed with extra charge evenly distributed among atoms   2 => acoustic sum rule imposed for dynamical matrix at Gamma, and charge neutrality imposed with extra charge given proportionally to those atoms with the largest effective charge.    The treatment of the acoustic sum rule and charge neutrality sum rule is finer\nat the level of the ANADDB utility, with the two independent input variables  \nasr   and   chneut  .",
            "title": "rfasr"
        },
        {
            "location": "/input_variables/varrf/#rfatpol",
            "text": "Mnemonics: Response Function : ATomic POLarisation \nVariable type: integer \nDimensions: (2) \nDefault value: [1, 1]    Control the range of atoms for which displacements will be considered in\nphonon calculations (atomic polarizations), using the 2n+1 theorem. \nThese values are only relevant to phonon response function calculations. \nMay take values from 1 to  natom , with  [rfatpol] <= [rfatpol] . \nThe atoms to be moved will be defined by the \ndo-loop variable iatpol : \ndo iatpol= [rfatpol] , [rfatpol] \nFor the calculation of a full dynamical matrix, use  [rfatpol] =1 and [rfatpol] = natom , together with  rfdir  1 1 1 . For selected\nelements of the dynamical matrix, use different values of  rfatpol  and/or rfdir . The name \u2018iatpol\u2019 is used for the part of the internal variable\nipert when it runs from 1 to  natom . The internal variable ipert can also\nassume values larger than  natom , denoting perturbations of electric field\nor stress type (see   the response function help file  ).",
            "title": "rfatpol"
        },
        {
            "location": "/input_variables/varrf/#rfddk",
            "text": "Mnemonics: Response Function with respect to Derivative with respect to K \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Activates computation of derivatives of ground state wavefunctions with\nrespect to wavevectors. This is not strictly a response function but is a\nneeded auxiliary quantity in the electric field calculations (see  rfelfd )\nThe directions for the derivatives are determined by  rfdir .   0=>no derivative calculation   1=>calculation of first derivatives of wavefunctions with respect to k points (d/dk calculation). The exact same functionality is provided by  rfelfd  = 2.",
            "title": "rfddk"
        },
        {
            "location": "/input_variables/varrf/#rfdir",
            "text": "Mnemonics: Response Function : DIRections \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0]    Gives the directions to be considered for response function calculations (also\nfor the Berry phase computation of the polarization, see the  berryopt \ninput variable). \nThe three elements corresponds to the three primitive vectors, either in real\nspace (phonon calculations), or in reciprocal space (d/dk, homogeneous\nelectric field, homogeneous magnetic field calculations). So, they generate a\nbasis for the generation of the dynamical matrix or the macroscopic dielectric\ntensor or magnetic susceptibility and magnetic shielding, or the effective\ncharge tensors. \nIf equal to 1, response functions, as defined by  rfddk ,  rfelfd , rfphon ,  rfdir  and  rfatpol , are to be computed for the\ncorresponding direction. If 0, this direction should not be considered.",
            "title": "rfdir"
        },
        {
            "location": "/input_variables/varrf/#rfelfd",
            "text": "Mnemonics: Response Function with respect to the ELectric FielD \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Turns on electric field response function calculations. Actually, such\ncalculations requires first the non-self-consistent calculation of derivatives\nwith respect to k, independently of the electric field perturbation itself.   0=>no electric field perturbation   1=>full calculation, with first the derivative of ground-state wavefunction with respect to k (d/dk calculation), by a non-self-consistent calculation, then the generation of the first-order response to an homogeneous electric field   2=>only the derivative of ground-state wavefunctions with respect to k   3=>only the generation of the first-order response to the electric field, assuming that the data on derivative of ground-state wavefunction with respect to k is available on disk.    (Note : because the tolerances to be used for derivatives or homogeneous\nelectric field are different, one often does the calculation of derivatives in\na separate dataset, followed by calculation of electric field response as well\nas phonon. \nThe options 2 and 3 proves useful in that context ; also, in case a scissor\nshift is to be used, it is usually not applied for the d/dk response).",
            "title": "rfelfd"
        },
        {
            "location": "/input_variables/varrf/#rfmagn",
            "text": "Mnemonics: Response Function with respect to MAGNetic B-field perturbation \nVariable type: integer \nDimensions: scalar \nDefault value: 0    It must be equal to 1 to run response function calculations with respect to\nexternal magnetic field. Currently, orbital magnetism is not taken into\naccount and the perturbing potential has Zeeman form.",
            "title": "rfmagn"
        },
        {
            "location": "/input_variables/varrf/#rfmeth",
            "text": "Mnemonics: Response Function METHod \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Selects method used in response function calculations. Presently, only 1 is\nallowed.",
            "title": "rfmeth"
        },
        {
            "location": "/input_variables/varrf/#rfphon",
            "text": "Mnemonics: Response Function with respect to PHONons \nVariable type: integer \nDimensions: scalar \nDefault value: 0    It must be equal to 1 to run phonon response function calculations.",
            "title": "rfphon"
        },
        {
            "location": "/input_variables/varrf/#rfstrs",
            "text": "Mnemonics: Response Function with respect to STRainS \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used to run strain response-function calculations (e.g. needed to get elastic\nconstants). Define, with  rfdir , the set of perturbations.   0=>no strain perturbation   1=>only uniaxial strain(s) (ipert=natom+3 is activated)   2=>only shear strain(s) (ipert=natom+4 is activated)   3=>both uniaxial and shear strain(s) (both ipert=natom+3 and ipert=natom+4 are activated)    See the possible restrictions on the use of strain perturbations, in the  \nrespfn help file   .",
            "title": "rfstrs"
        },
        {
            "location": "/input_variables/varrf/#rfuser",
            "text": "Mnemonics: Response Function, USER-defined \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Available to the developpers, to activate the use of ipert=natom+6 and\nipert=natom+7, two sets of perturbations that the developpers can define.     0=>no computations for ipert=natom+6 or ipert=natom+7   1=>response with respect to perturbation natom+6 will be computed   2=>response with respect to perturbation natom+7 will be computed   3=>responses with respect to perturbations natom+6 and natom+7 will be computed    In order to define and use correctly the new perturbations, the developper\nmight have to include code lines or additional routines at the level of the\nfollowing routines : dfpt_cgwf.F90, dfpt_dyout.F90, dfpt_symph.F90,\ndfpt_dyout.F90, dfpt_etot.F90, littlegroup_pert.F90, dfpt_looppert.F90,\ndfpt_mkcor.F90, dfpt_nstdy.F90, dfpt_nstwf.F90, respfn.F90, dfpt_scfcv.F90,\nirreducible_set_pert.F90, dfpt_vloca.F90, dfpt_vtorho.F90, dfpt_vtowfk.F90. In\nthese routines, the developper should pay a particular attention to the rfpert\narray, defined in the routine respfn.F90 , as well as to the ipert local\nvariable.",
            "title": "rfuser"
        },
        {
            "location": "/input_variables/varrf/#smdelta",
            "text": "Mnemonics: SMeared DELTA function \nVariable type: integer \nDimensions: scalar \nDefault value: 0    When  smdelta  in non-zero, it will trigger the calculation of the imaginary\npart of the second-order electronic eigenvalues, which can be related to the\nelectronic lifetimes. The delta function is evaluated using:     when  smdelta  == 1, Fermi-Dirac smearing : 0.25_dp/(cosh(xx/2.0_dp)**2   when  smdelta  == 2, Cold smearing by Marzari using the parameter a=-.5634 (minimization of the bump): exp(-xx2)/sqrt(pi) * (1.5d0+xx (-a 1.5d0+xx (-1.0d0+a xx)))   when  smdelta  == 3, Cold smearing by Marzari using the parameter a=-.8165 (monotonic function in the tail): as 2 but different a   when  smdelta  == 4, Smearing of Methfessel and Paxton (PRB40,3616(1989)) with Hermite polynomial of degree 2, corresponding to \u201cCold smearing\u201d of N. Marzari with a=0 (so, same smeared delta function as smdelta=2, with different a).   when  smdelta  == 5, Gaussian smearing : 1.0d0 exp(-xx *2)/sqrt(pi)",
            "title": "smdelta"
        },
        {
            "location": "/input_variables/varrf/#td_maxene",
            "text": "Mnemonics: Time-Dependent dft : MAXimal kohn-sham ENErgy difference \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    The Matrix to be diagonalized in the Casida framework (see \u201cTime-Dependent\nDensity Functional Response Theory of Molecular systems: Theory, Computational\nMethods, and Functionals\u201d, by M.E. Casida, in Recent Developments and\nApplications of Modern Density Functional Theory, edited by J.M. Seminario\n(Elsevier, Amsterdam, 1996).) is a NxN matrix, where, by default, N is the\nproduct of the number of occupied states by the number of unoccupied states. \nThe input variable  td_maxene  allows to diminish N : it selects only the\npairs of occupied and unoccupied states for which the Kohn-Sham energy\ndifference is less than  td_maxene . The default value 0.0 means that all\npairs are taken into account. \nSee  td_mexcit  for an alternative way to decrease N.",
            "title": "td_maxene"
        },
        {
            "location": "/input_variables/varrf/#td_mexcit",
            "text": "Mnemonics: Time-Dependent dft : Maximal number of EXCITations \nVariable type: real \nDimensions: scalar \nDefault value: 0    The Matrix to be diagonalized in the Casida framework (see \u201cTime-Dependent\nDensity Functional Response Theory of Molecular systems: Theory, Computational\nMethods, and Functionals\u201d, by M.E. Casida, in Recent Developments and\nApplications of Modern Density Functional Theory, edited by J.M. Seminario\n(Elsevier, Amsterdam, 1996).) is a NxN matrix, where, by default, N is the\nproduct of the number of occupied states by the number of unoccupied states. \nThe input variable  td_mexcit  allows to diminish N : it selects the first td_mexcit  pairs of occupied and unoccupied states, ordered with respect to\nincreasing Kohn-Sham energy difference. However, when  td_mexcit  is zero,\nall pairs are allowed. \nSee  td_maxene  for an alternative way to decrease N.",
            "title": "td_mexcit"
        },
        {
            "location": "/input_variables/varrlx/",
            "text": "adpimd\n\u00b6\n\n\nMnemonics: ADiabatic Path-Integral Molecular Dynamics\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nimgmov\n==9 or \nimgmov\n==13  \n\n\nControls whether adiabatic Path-Integral Molecular Dynamics is performed or\nnot.\n\nThe corresponding adiabaticity parameter is given by \nadpimd_gamma\n.  \n\n\nIf equal to 0, no adiabatic Path-Integral Molecular Dynamics (standard PIMD)\nis performed.\n\nIf equal to 1, adiabatic Path-Integral Molecular Dynamics is activated.\n\nOnly relevant with \npitransform\n=1 (normal mode transformation). In that\ncase,\n\n- the mass associated with to the zero-frequency mode is the true mass\n\namu\n,\n\n- the mass associated to the other higher frequency modes of the polymer\nchains is equal to the normal mode mass divided by \nadpimd_gamma\n\n(adiabaticity parameter),\n\n- the equation of motion on the zero-frequency mode is not thermostated.\n\nNOT YET USABLE\n\n\nadpimd_gamma\n\u00b6\n\n\nMnemonics: ADiabatic Path-Integral Molecular Dynamics: GAMMA factor\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nadpimd\n==1 and \nimgmov\n in [9,13]  \n\n\nAdiabaticity parameter to be used in adiabatic Path-Integral Molecular\nDynamics.\n\nNOT YET USABLE\n\n\namu\n\u00b6\n\n\nMnemonics: Atomic Mass Units\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: None\n\nComment: provided by a database of atomic masses.  \n\n\nGives the masses in atomic mass units for each kind of atom in cell. These\nmasses are used in performing molecular dynamical atomic motion if\n\nionmov\n=1, 6, 7 or 8. They are also used in phonon calculations, in the\ndiagonalization of the dynamical matrix. Note that one may set all masses to 1\nfor certain cases in which merely structural relaxation is desired and not\nactual molecular dynamics.\n\n\nUsing 1986 recommended values, 1 atomic mass unit = 1.6605402e-27 kg. In this\nunit the mass of Carbon 12 is exactly 12.\n\n\nA database of atomic masses is provided, giving default values. Note that the\ndefault database uses mixed isotope masses (for Carbon the natural occurrence\nof Carbon 13 is taken into account). The values are those recommended by the\ncommission on Atomic Weights and Isotopic Abundances, Inorganic Chemistry\nDivision, IUPAC, in _ Pure Appl. Chem. _ \n 60 \n , 841 (1988). For Tc, Pm, Po\nto Ac, Pa and beyond U, none of the isotopes has a half-life greater than\n3.0d10 years, and the values provided in the database do not come from that\nsource.\n\n\nFor alchemical pseudoatoms, the masses of the constituents atoms are mixed,\naccording to the alchemical mixing coefficients \nmixalch\n\n\nIn most cases, the use of \namu\n will be as a static (non-evolving) variable.\nHowever, the possibility to have different values of \namu\n for different\nimages has been coded. A population of cells with different atomic\ncharacteristics can thus be considered, and can be made to evolve, e.g. with a\ngenetic algorithm (not coded in v7.0.0 though).\n\n\nbmass\n\u00b6\n\n\nMnemonics: Barostat MASS\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 10  \n\n\nbmass is the mass of the barostat when \nionmov\n=13 (constant pressure\nmolecular dynamics)\n\n\ncineb_start\n\u00b6\n\n\nMnemonics: Climbing-Image Nudged Elastic Band: STARTing iteration\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 7\n\nOnly relevant if \nimgmov\n== 5 and \nneb_algo\n==2  \n\n\nGives the index of the first CI-NEB iteration..\n\nThe CI-NEB method constitutes a small modification to the NEB method allowing\na rigorous convergence to the saddle point. As the image with the highest\nenergy has to be identified, the calculation begins with several iterations of\nthe standard NEB algorithm. The effective CI-NEB begins at the \ncineb_start\n\niteration.\n\n_ See: J. Chem. Phys. 113, 9901 (2000). _\n\n\ndelayperm\n\u00b6\n\n\nMnemonics: DELAY between trials to PERMUTE atoms\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nDelay (number of time steps) between trials to permute two atoms, in view of\naccelerated search of minima. Still in development. See the routine\nmoldyn.F90. See also \nsignperm\n. When \ndelayperm\n is zero, there is not\npermutation trials.\n\n\ndiismemory\n\u00b6\n\n\nMnemonics: Direct Inversion in the Iterative Subspace MEMORY\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 8  \n\n\nGives the maximum number of \u201ctime\u201d steps for which the forces and stresses are\nstored, and taken into account in the DIIS algorithm (\nionmov\n=20) to find\nzero-force and stress configurations.\n\n\ndilatmx\n\u00b6\n\n\nMnemonics: lattice DILATation : MaXimal value\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0  \n\n\nGives the maximal permitted scaling of the lattice parameters when the cell\nshape and dimension is varied (see variable \noptcell\n). It is used to define\nthe sphere of plane waves and FFT box coherent with the possible modifications\nof the cell (\nionmov\n==2 and [[optcell] /=0). For these definitions, it is\nequivalent to changing \necut\n by multiplying it by \ndilatmx\n  2  (the\nresult is an \u201ceffective ecut\u201d, called internally \u201cecut_eff\u201d, other uses of\n\necut\n being not modified when \ndilatmx\n>1.0 .\n\nUsing \ndilatmx\n<1.0 is equivalent to changing \necut\n in all its uses.\nThis is allowed, although its meaning is no longer related to a maximal\nexpected scaling.\n\nSetting \ndilatmx\n to a large value leads to waste of CPU time and memory.\nSupposing you think that the optimized \nacell\n values might be 10% larger\nthan your input values, use simply \ndilatmx\n 1.1 . This will already lead to\nan increase of the number of planewaves by a factor (1.1)  3  =1.331 , and a\ncorresponding increase in CPU time and memory.\n\nIt is possible to use \ndilatmx\n when \noptcell\n =0, but a value larger than\n1.0 will be a waste.\n\n\ndtion\n\u00b6\n\n\nMnemonics: Delta Time for IONs\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 100  \n\n\nUsed for controlling ion time steps. If \nionmov\n is set to 1, 6 or 7, then\nmolecular dynamics is  used to update atomic positions in response to forces.\nThe parameter \ndtion\n is a time step in atomic units of time. (One atomic\ntime unit is 2.418884e-17 seconds, which is the value of Planck\u2019s constant in\nhartree*sec.) In this case the atomic masses, in amu (given in array \u201d \namu\n\n\u201c), are used in Newton\u2019s equation and the viscosity (for \nionmov\n =1) and\nnumber of time steps are provided to the code using input variables \u201c\nvis\n\u201d\nand \u201c\nntime\n\u201d. The code actually converts from masses in amu to masses in\natomic units (in units of electron masses) but the user enters masses in\n\namu\n . (The conversion from amu to atomic units (electron masses) is\n1822.88851 electron masses/amu.)\n\nA typical good value for \ndtion\n is about 100. The user must try several\nvalues for \ndtion\n in order to establish the stable and efficient choice for\nthe accompanying amu, atom types and positions, and \nvis\n (viscosity).\n\nFor quenched dynamics (\nionmov\n=7), a larger time step might be taken, for\nexample 200.\n\nNo meaning for RF calculations.\n\n\ndynimage\n\u00b6\n\n\nMnemonics: DYNamics of the IMAGE\n\nVariable type: integer\n\nDimensions: (\nnimage\n)\n\nDefault value: *1\n\nComment: if \nimgmov\n in [2,5] (String Method, NEB), \ndynimage(1)\n=0 and \ndynimage(\nnimage\n)\n=0.  \n\n\nThis input variable is relevant when sets of images are activated (see\n\nimgmov\n). Not all images might be required to evolve from one time step to\nthe other. Indeed, in the String Method or the Nudged Elastic Band, one might\nimpose that the extremal configurations of the string are fixed. In case the\n\n[dynimage]\n=0, the image with index \u201ciimage\u201d will be consider as\nfixed. Thus, there is no need to compute forces and stresses for this image at\neach time step. The purpose of defining extremal images is to make the\ninput/output easier.  \n\n\nIn order to save CPU time, the computation of properties of static images\n(\n[dynimage]\n=0) can be avoided: see \nistatimg\n keyword.\n\n\necutsm\n\u00b6\n\n\nMnemonics: Energy CUToff SMearing\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nThis input variable is important when performing relaxation of unit cell size\nand shape (non-zero \noptcell\n). Using a non-zero \necutsm\n, the total\nenergy curves as a function of \necut\n, or \nacell\n, can be smoothed,\nkeeping consistency with the stress (and automatically including the Pulay\nstress). The recommended value is 0.5 Ha. Actually, when \noptcell\n/=0,\nABINIT requires \necutsm\n to be larger than zero. If you want to optimize\ncell shape and size without smoothing the total energy curve (a dangerous\nthing to do), use a very small \necutsm\n, on the order of one microHartree.\n\n\nTechnical information :\n\nSee Bernasconi et al, J. Phys. Chem. Solids 56, 501 (1995) for a related\nmethod.\n\n\necutsm\n allows to define an effective kinetic energy for plane waves, close\nto, but lower than the maximal kinetic energy \necut\n. For kinetic energies\nless than \necut\n-\necutsm\n, nothing is modified, while between\n\necut\n-\necutsm\n and \necut\n , the kinetic energy is multiplied by:\n\n1.0 / ( x  2  (3+x-6x  2  +3x  3  ))\n\nwhere x = (\necut\n - kinetic_energy)/\necutsm\n\nNote that x  2  ( 3+x-6x  2  +3x  3  ) is 0 at x=0, with vanishing derivative,\nand that at x=1 , it is 1, with also vanishing derivative.\n\nIf \necutsm\n is zero, the unmodified kinetic energy is used.\n\n\necutsm\n can be specified in Ha (the default), Ry, eV or Kelvin, since\n\necutsm\n has the \u2018\nENERGY\n\u2018 characteristics. (1 Ha=27.2113845 eV).\n\nA few test for Silicon (diamond structure, 2 k-points) have shown 0.5 Ha to be\nlargely enough for \necut\n between 2Ha and 6Ha, to get smooth curves. It is\nlikely that this value is OK as soon as \necut\n is larger than 4Ha.\n\n\nfriction\n\u00b6\n\n\nMnemonics: internal FRICTION coefficient\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.001  \n\n\nGives the internal friction coefficient (atomic units) for Langevin dynamics\n(when \nionmov\n=9): fixed temperature simulations with random forces.\n\n\nThe equation of motion is :\n\nM  I  d  2  R  I  /dt  2  = F  I  - \nfriction\n M  I  dR  I  /dt - F_random\nI\n\nwhere F_random  I  is a Gaussian random force with average zero, and variance\n2 \nfriction\n M  I  kT.\n\nThe atomic unit of friction is hartrees\nelectronic mass\n(atomic time\nunits)/Bohr  2  . See J. Chelikowsky, J. Phys. D : Appl Phys. 33(2000)R33.\n\n\nfxcartfactor\n\u00b6\n\n\nMnemonics: Forces to (X) CARTesian coordinates FACTOR\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1 (Bohr^2)/Hartree  \n\n\nThe forces multiplied by \nfxcartfactor\n will be treated like difference in\ncartesian coordinates in the process of optimization. This is a simple\npreconditioner.\n\nTO BE UPDATED See (\nionmov\n=2, non-zero \noptcell\n). For example, the\nstopping criterion defined by \ntolmxf\n relates to these scaled stresses.\n\n\nga_algor\n\u00b6\n\n\nMnemonics: Genetic Algorithm - ALGOrithm selection\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nChoosing method to make the structure selection. Only the enthalpy is used now\nbut we plan to include, energy, electronic band gap and alchemical potentials.\nRight now only value of 1 (enthalpy) works.\n\n\nga_fitness\n\u00b6\n\n\nMnemonics: Genetic Algorithm FITNESS function selection\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nDifferent methodologies to perform the roulette-wheel selection of parents.\nEven though, the objective function is the crystalline enthalpy (H_i), the\nweight of the population elements to be chosen from in a roulette-wheel\nselection can be given through different functions. We consider the following\ncases.\n\n1. F = H_i / Sum H_i\n\n2. F = exp(-(H_i-H_min)) / Sum exp(-(H_i-H_min))\n\n3. F = (1/n_i) / Sum (1/n_i). Where n_i is the position in the ordered list\nof enthalpies\n\n\nga_n_rules\n\u00b6\n\n\nMnemonics: Genetic Algorithm Number of RULES\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nDifferent genetic rules have been implemented and the user has the change to\nchoose between any of them. Right now we have 4 rules. See \nga_rules\n\n\nga_opt_percent\n\u00b6\n\n\nMnemonics: Genetic Algorithm OPTimal PERCENT\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.2  \n\n\nPercentage of the population that according to the fitness function passes to\nthe following iteration.\n\n\nga_rules\n\u00b6\n\n\nMnemonics: Genetic Algorithm RULES\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nDifferent genetic rules have been implemented and the user has the change to\nchoose between any of them. The chosen number of rules have been defined in\n[[ga_n_rules]  \n\n\nImplemented rules are\n\n1) crossover. Two parents are randomly chosen and two springs are mixed from\nthe two by (a) choosing randomly (through Fitness function) two parents and\nthen randomly rotating and shifting the coordinates withing that particular\ncell. (b) Slice every one of the unit cell of the parents along a random\ndirection and creating the spring offs from the pieces of the two parents.\n\n2) Vector flip mutation. From the coordinates from a given parent, a piece of\nit is inverted.\n\n3) random strain. A random anisotropic deformation is given to the unit cell.\n\n4) Coordinates mutation of 1/4 of the whole coordinates.  \n\n\ngetcell\n\u00b6\n\n\nMnemonics: GET CELL parameters from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThis variable is typically used to chain the calculations, in the multi-\ndataset mode (\nndtset\n>0), since it describes from which dataset\n\nacell\n and \nrprim\n are to be taken, as input of the present dataset. The\ncell parameters are \nEVOLVING\n variables, for which such a chain of\ncalculations is useful.\n\nIf ==0, no use of previously computed values must occur.\n\nIf it is positive, its value gives the index of the dataset from which the\ndata are to be used as input data. It must be the index of a dataset already\ncomputed in the SAME run.\n\nIf equal to -1, the output data of the previous dataset must be taken, which\nis a frequently occurring case. However, if the first dataset is treated, -1\nis equivalent to 0, since no dataset has yet been computed in the same run.\n\nIf another negative number, it indicates the number of datasets to go backward\nto find the needed data (once again, going back beyond the first dataset is\nequivalent to using a null get variable).\n\n\ngetvel\n\u00b6\n\n\nMnemonics: GET VEL from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThese variables are typically used to chain the calculations, in the multi-\ndataset mode (\nndtset\n>0) since they describe from which dataset the\ncorresponding output variables are to be taken, as input of the present\ndataset. The atomic positions and velocities are \nEVOLVING\n variables, for\nwhich such a chain of calculation is useful.\n\nNote that the use of \n getxcart \n and \n getxred \n differs when \nacell\n\nand \nrprim\n are different from one dataset to the other.\n\nIf ==0, no use of previously computed values must occur.\n\nIf it is positive, its value gives the index of the dataset from which the\ndata are to be used as input data. It must be the index of a dataset already\ncomputed in the SAME run.\n\nIf equal to -1, the output data of the previous dataset must be taken, which\nis a frequently occurring case. However, if the first dataset is treated, -1\nis equivalent to 0, since no dataset has yet been computed in the same run.\n\nIf another negative number, it indicates the number of datasets to go backward\nto find the needed data (once again, going back beyond the first dataset is\nequivalent to using a null get variable).\n\nNote : \n getxred \n and \n getxcart \n cannot be simultaneously non-zero for\nthe same dataset. On the other hand the use of \ngetvel\n with \n getxred \n\nis allowed, despite the different coordinate system.\n\n\ngetxcart\n\u00b6\n\n\nMnemonics: GET XCART from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThese variables are typically used to chain the calculations, in the multi-\ndataset mode (\nndtset\n>0) since they describe from which dataset the\ncorresponding output variables are to be taken, as input of the present\ndataset. The atomic positions and velocities are \nEVOLVING\n variables, for\nwhich such a chain of calculation is useful.\n\nNote that the use of \ngetxcart\n and \n getxred \n differs when \nacell\n and\n\nrprim\n are different from one dataset to the other.\n\nIf ==0, no use of previously computed values must occur.\n\nIf it is positive, its value gives the index of the dataset from which the\ndata are to be used as input data. It must be the index of a dataset already\ncomputed in the SAME run.\n\nIf equal to -1, the output data of the previous dataset must be taken, which\nis a frequently occurring case. However, if the first dataset is treated, -1\nis equivalent to 0, since no dataset has yet been computed in the same run.\n\nIf another negative number, it indicates the number of datasets to go backward\nto find the needed data (once again, going back beyond the first dataset is\nequivalent to using a null get variable).\n\nNote : \n getxred \n and \ngetxcart\n cannot be simultaneously non-zero for\nthe same dataset. On the other hand the use of \n getvel \n with \n getxred \n\nis allowed, despite the different coordinate system.\n\n\ngetxred\n\u00b6\n\n\nMnemonics: GET XRED from \u2026\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nThese variables are typically used to chain the calculations, in the multi-\ndataset mode (\nndtset\n>0) since they describe from which dataset the\ncorresponding output variables are to be taken, as input of the present\ndataset. The atomic positions and velocities are \nEVOLVING\n variables, for\nwhich such a chain of calculation is useful.\n\nNote that the use of \n getxcart \n and \ngetxred\n differs when \nacell\n and\n\nrprim\n are different from one dataset to the other.\n\nIf ==0, no use of previously computed values must occur.\n\nIf it is positive, its value gives the index of the dataset from which the\ndata are to be used as input data. It must be the index of a dataset already\ncomputed in the SAME run.\n\nIf equal to -1, the output data of the previous dataset must be taken, which\nis a frequently occurring case. However, if the first dataset is treated, -1\nis equivalent to 0, since no dataset has yet been computed in the same run.\n\nIf another negative number, it indicates the number of datasets to go backward\nto find the needed data (once again, going back beyond the first dataset is\nequivalent to using a null get variable).\n\nNote : \ngetxred\n and \n getxcart \n cannot be simultaneously non-zero for\nthe same dataset. On the other hand the use of \n getvel \n with \ngetxred\n\nis allowed, despite the different coordinate system.\n\n\ngoprecon\n\u00b6\n\n\nMnemonics: Geometry Optimization PRECONditioner equations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nSet the kind of preconditioner to be used for Geometry Optimization\n\n(Note : Under development now (2011.05.20))\n\n\n\n\ngoprecon\n=0 : No preconditioner \n\n\ngoprecon\n=[1-9] : Linear preconditioner \n\n\ngoprecon\n=[11-19] : Non-linear preconditioner \n\n\n\n\ngoprecprm\n\u00b6\n\n\nMnemonics: Geometry Optimization PREconditioner PaRaMeters equations\n\nVariable type: real\n\nDimensions: (3)\n\nDefault value: 0  \n\n\nSet the paramenters use by the preconditioner to be used for Geometry\nOptimization\n\n(Note : Under development now (2011.06.06))\n\n\niatcon\n\u00b6\n\n\nMnemonics: Indices of AToms in CONstraint equations\n\nVariable type: integer\n\nDimensions: (\nnatcon\n,\nnconeq\n)\n\nDefault value: 0  \n\n\nGives the indices of the atoms appearing in each of the \nnconeq\n independent\nequations constraining the motion of atoms during structural optimization or\nmolecular dynamics (see \nnconeq\n , \nnatcon\n, and \nwtatcon\n).\n\n(Note : combined with wtatcon to give internal representation of the latter -\nthis should be described)\n\n\niatfix\n\u00b6\n\n\nMnemonics: Indices of AToms that are FIXed \n\nVariable type: integer\n\nDimensions: (\nnatfix\n)\n\nDefault value: None\n\nOnly relevant if \nnatfix\n > 0  \n\n\nGive the index (in the range 1 to \nnatom\n ) of each atom which is to be held\nfixed for structural optimization or molecular dynamics. The variable\n\niatfix\n lists those fixed in the three directions, while the variables\n\niatfixx\n, \niatfixy\n, and \niatfixz\n, allow to fix some atoms along x, y\nor z directions, or a combination of these.\n\n\nWARNING : The implementation is inconsistent !! For \nionmov\n ==1, the fixing\nof directions was done in cartesian coordinates, while for the other values of\n\nionmov\n, it was done in reduced coordinates. Sorry for this.\n\n\nThere is no harm in fixing one atom in the three directions using \niatfix\n,\nthen fixing it again in other directions by mentioning it in \n iatfixx \n ,\n\n iatfixy \n or \n iatfixz \n .\n\nThe internal representation of these input data is done by the mean of one\nvariable \n[iatfix]\n, defined for each direction and each atom,\nbeing 0 if the atom is not fixed along the direction, and 1 if the atom is\nfixed along the direction. When some atoms are fixed along 1 or 2 directions,\nthe use of symmetries is restricted to symmetry operations whose (3x3)\nmatrices \nsymrel\n are diagonal.\n\nIf the geometry builder is used, \niatfix\n will be related to the\npreprocessed set of atoms, generated by the geometry builder. The user must\nthus foresee the effect of this geometry builder (see \nobjarf\n).\n\n\niatfixx\n\u00b6\n\n\nMnemonics: Indices of AToms that are FIXed along the X direction\n\nVariable type: integer\n\nDimensions: (\nnatfixx\n)\n\nDefault value: None\n\nOnly relevant if \nnatfixx\n > 0  \n\n\nGive the index (in the range 1 to \nnatom\n ) of each atom which is to be held\nfixed ALONG THE X direction for structural optimization or molecular dynamics.\nThe variable \niatfix\n lists those fixed in the three directions, while the\nvariables \niatfixx\n, \niatfixy\n, and \niatfixz\n, allow to fix some atoms\nalong x, y or z directions, or a combination of these. See the variable\n\niatfix\n for more information.\n\n\niatfixy\n\u00b6\n\n\nMnemonics: Indices of AToms that are FIXed along the Y direction\n\nVariable type: integer\n\nDimensions: (\nnatfixy\n)\n\nDefault value: None\n\nOnly relevant if \nnatfixy\n > 0  \n\n\nGive the index (in the range 1 to \nnatom\n ) of each atom which is to be held\nfixed ALONG THE Y direction for structural optimization or molecular dynamics.\nThe variable \niatfix\n lists those fixed in the three directions, while the\nvariables \niatfixx\n, \niatfixy\n, and \niatfixz\n, allow to fix some atoms\nalong x, y or z directions, or a combination of these. See the variable\n\niatfix\n for more information.\n\n\niatfixz\n\u00b6\n\n\nMnemonics: Indices of AToms that are FIXed along the Z direction\n\nVariable type: integer\n\nDimensions: (\nnatfixz\n)\n\nDefault value: None\n\nOnly relevant if \nnatfixz\n > 0  \n\n\nGive the index (in the range 1 to \nnatom\n ) of each atom which is to be held\nfixed ALONG THE Z direction for structural optimization or molecular dynamics.\nThe variable \niatfix\n lists those fixed in the three directions, while the\nvariables \niatfixx\n, \niatfixy\n, and \niatfixz\n, allow to fix some atoms\nalong x, y or z directions, or a combination of these. See the variable\n\niatfix\n for more information.\n\n\nimgmov\n\u00b6\n\n\nMnemonics: IMaGe MOVEs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nControl the collective changes of images (see \nnimage\n,\nnpimage\n,\n\ndynimage\n, \nntimimage\n, \ntolimg\n, \nistatimg\n, \nprtvolimg\n).\n\nSimilar to \nionmov\n in spirit, although here, a population of self-\nconsistent calculations for different geometries is managed, while with\n\nionmov\n, only one geometry for self-consistent calculation is managed.\n\nIn this respect the maximal number of time step for image propagation is\n\nntimimage\n, corresponding to the input variable \nntime\n of the single\ngeometry case. Also, the stopping criterion is governed by \ntolimg\n,\ncorresponding to the input variable \ntoldfe\n of the single geometry case.\nThe stopping condition is crude: the image propagation is stopped when the\nmean value (over dynamic images) of the absolute difference of total energy\n(previous and current time step) is less than \ntolimg\n.\n\n\nActually, there might be combinations of \nionmov\n and \nimgmov\n in which\nthe two mechanisms are at work. Usually, however, only one mechanism will be\nactivated (so, usually, either \nntimimage\n is bigger than one OR \nntime\n\nis bigger than one). In order for the user to acquire a mental representation\nof the interplay between \nionmov\n and \nimgmov\n, here is a F90 pseudo-code\npresenting the interplay between the different above-mentioned input\nvariables, as well as with the parallelism (see input variable \nnpimage\n).\n\n\ndo itimimage=1,ntimimage\n  do iimage=1,nimage\n    (possibly, parallelisation over images)\n    do itime=1,ntime\n      Compute the forces and stresses for image(iimage)\n      Examine whether the stopping criterion defined by tolmxf is fulfilled\n      Predict the next geometry for image(iimage) using ionmov\n    enddo\n  enddo\n  Examine whether the stopping criterion defined by tolimg is fulfilled\n  Predict the next geometries for all images using imgmov\nenddo\n\n\n\n\n\n\n\n= 0 => simply \n copy \n images from previous timimage step.\n\n\n= 1 => move images according to \n Steepest Descent \n following the (scaled) forces, the scaling factor being \nfxcartfactor\n. \n\n\n= 2 => \n String Method \n for finding Minimal Energy Path (MEP) connecting to minima (see PRB 66, 052301 (2002)); the algorithm variant can be selected with the \nstring_algo\n keyword (Simplified String Method by default). The solver for the Ordinary Differential Equation (ODE) can be selected with \nmep_solver\n (steepest-descent by default). See also \nmep_mxstep\n keyword.\n\n\n= 3 => (tentatively, not yet coded) \n Metadynamics \n.\n\n\n= 4 => (tentatively, not yet coded) \n Genetic Algorithm\n.\n\n\n= 5 => \n Nudged Elastic Band (NEB) \n for finding Minimal Energy Path (MEP) connecting two minima; the algorithm variant can be selected with the \nneb_algo\n keyword (NEB+improved tangent by default). The solver for the Ordinary Differential Equation (ODE) can be selected with \nmep_solver\n (steepest-descent by default). The spring constant connecting images along the path is defined by \nneb_spring\n. See also \nmep_mxstep\n keyword.\n\n\n= 9 or 13 => \n Path-Integral Molecular Dynamics \n (see e.g. [D. Marx and M. Parrinello, J. Chem. Phys. 104, 4077 (1996)]). Will use 9 for \n Langevin thermostat \n (associated friction coefficient given by \nvis\n) and 13 for \n Nose-Hoover thermostat chains \n (associated input variables are the number of thermostats in the chains, \nnnos\n, and the masses of these thermostats \nqmass\n). \nnimage\n is the Trotter number (no use of \ndynimage\n); possible transformations of coordinates are defined by \npitransform\n; Fictitious masses of the atoms (possibly different from the true masses given by \namu\n) can be specified by \npimass\n. At present, it is only possible to perform calculations in the (N,V,T) ensemble (\noptcell\n=0).\n\n\n\n\nNo meaning for RF calculations.\n\n\nionmov\n\u00b6\n\n\nMnemonics: IONic MOVEs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nChoice of algorithm to control the displacements of ions, and eventually (see\n\noptcell\n) changes of cell shape and size.\n\n\n\n\n\n\n0=> Do not move ions;   \n\n\n\n\n\n\n1=> Move atoms using molecular dynamics with optional viscous damping (friction linearly proportional to velocity). The viscous damping is controlled by the parameter \u201c\nvis\n\u201d. If actual undamped molecular dynamics is desired, set \nvis\n to 0. The implemented algorithm is the generalisation of the Numerov technique (6th order), but is NOT invariant upon time-reversal, so that the energy is not conserved. The value \nionmov\n=6 will usually be preferred, although the algorithm that is implemented is lower-order. The time step is governed by \ndtion\n. \n\n\n Purpose: \n Molecular dynamics (if \nvis\n=0), Structural optimization (if \nvis\n>0) \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n Viscous parameter \nvis\n, time step \ndtion\n, index of atoms fixed \niatfix\n   \n\n\n\n\n\n\n2=> Conduct structural optimization using the Broyden-Fletcher-Goldfarb-Shanno minimization (BFGS). This is much more efficient for structural optimization than viscous damping, when there are less than about 10 degrees of freedom to optimize. \n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n Yes (if \noptcell\n/=0) \n\n\n Related variables: \n   \n\n\n\n\n\n\n3=> Conduct structural optimization using the Broyden-Fletcher-Goldfarb-Shanno minimization (BFGS), modified to take into account the total energy as well as the gradients (as in usual BFGS). \n\nSee the paper by [Schlegel, J. Comp. Chem. 3, 214 (1982)]. Might be better\nthan \nionmov\n=2 for few degrees of freedom (less than 3 or 4). Can be very\nunstable - use with caution!\n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n Yes (if \noptcell\n/=0) \n\n\n Related variables: \n   \n\n\n\n\n\n\n4=> Conjugate gradient algorithm for simultaneous optimization of potential and ionic degrees of freedom. It can be used with \niscf\n=2 and \niscf\n =5 or 6 (WARNING : this is under development, and does not work very well in many cases). \n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n   \n\n\n\n\n\n\n5=> Simple relaxation of ionic positions according to (converged) forces. Equivalent to \nionmov\n=1 with zero masses, albeit the relaxation coefficient is not \nvis\n, but \niprcfc\n. \n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n   \n\n\n\n\n\n\n6=> Molecular dynamics using the Verlet algorithm, see [Allen & Tildesley \u201cComputer simulation of liquids\u201d 1987, p 81]. The only related parameter is the time step (\ndtion\n). \n\n\n Purpose: \n Molecular dynamics \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n time step \ndtion\n, index of atoms fixed \niatfix\n   \n\n\n\n\n\n\n7=> Quenched Molecular dynamics using the Verlet algorithm, and stopping each atom for which the scalar product of velocity and force is negative. The only related parameter is the time step (\ndtion\n). The goal is not to produce a realistic dynamics, but to go as fast as possible to the minimum. For this purpose, it is advised to set all the masses to the same value (for example, use the Carbon mass, i.e. set \namu\n to 12 for all type of atoms). \n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n time step \ndtion\n, index of atoms fixed \niatfix\n   \n\n\n\n\n\n\n8=> Molecular dynamics with Nose-Hoover thermostat, using the Verlet algorithm. \n\n\n Purpose: \n Molecular dynamics \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n time step (\ndtion\n), Temperatures (\nmdtemp\n), and thermostat mass (\nnoseinert\n).   \n\n\n\n\n\n\n9=> Langevin molecular dynamics. \n\n\n Purpose: \n Molecular dynamics \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n time step (\ndtion\n), temperatures (\nmdtemp\n) and friction coefficient (\nfriction\n).   \n\n\n\n\n\n\n10=> Delocalized internal coordinates. with BFGS simple \n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n   \n\n\n\n\n\n\n11=> Delocalized internal coordinates. with BFGS using total energy \n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n   \n\n\n\n\n\n\n12=> Isokinetic ensemble molecular dynamics. The equation of motion of the ions in contact with a thermostat are solved with the algorithm proposed by Zhang [J. Chem. Phys. 106, 6102 (1997)], as worked out by Minary et al [J. Chem. Phys. 188, 2510 (2003)]. The conservation of the kinetic energy is obtained within machine precision, at each step. \n\n~~ Related parameters : the time step (\ndtion\n), the temperatures\n(\nmdtemp\n), and the friction coefficient (\nfriction\n). ~~\n\n\n Purpose: \n Molecular dynamics \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n   \n\n\n\n\n\n\n13=> Isothermal/isenthalpic ensemble. The equation of motion of the ions in contact with a thermostat and a barostat are solved with the algorithm proposed by Martyna, Tuckermann Tobias and Klein [Mol. Phys., 1996, p. 1117]. \n\nIf optcell=1 or 2, the mass of the barostat (\nbmass\n) must be given in\naddition.\n\n\n Purpose: \n Molecular dynamics \n\n\n Cell optimization: \n Yes (if \noptcell\n/=0) \n\n\n Related variables: \n The time step (\ndtion\n), the temperatures (\nmdtemp\n), the number of thermostats (\nnnos\n), and the masses of thermostats (\nqmass\n).   \n\n\n\n\n\n\n14=> Simple molecular dynamics with a symplectic algorithm proposed by S.Blanes and P.C.Moans [called SRKNa14 in Practical symplectic partitioned Runge\u2013Kutta and Runge\u2013Kutta\u2013Nystrom methods, Journal of Computational and Applied Mathematics archive, volume 142, issue 2 (May 2002), pages 313 - 330] of the kind first published by H. Yoshida [Construction of higher order symplectic integrators, Physics Letters A, volume 150, number 5 to 7, pages 262 - 268]. This algorithm requires at least 14 evaluation of the forces (actually 15 are done within Abinit) per time step. At this cost it usually gives much better energy conservation than the verlet algorithm (\nionmov\n 6) for a 30 times bigger value of \ndtion\n. Notice that the potential energy of the initial atomic configuration is never evaluated using this algorithm. \n\n\n Purpose: \n Molecular dynamics \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n   \n\n\n\n\n\n\n20=> Direct inversion of the iterative subspace. Given a starting point \nxred\n that is a vector of length 3*\nnatom\n (reduced nuclei coordinates), and unit cell parameters (\nrprimd\n) this routine uses the DIIS (direct inversion of the iterative subspace) to minimize the gradient (forces) on atoms. The preconditioning used to compute errors from gradients is using an inverse hessian matrix obtained by a BFGS algorithm. This method is known to converge to the nearest point where gradients vanish. This is efficient to refine positions around a saddle point for instance. \n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n DIIS memory \ndiismemory\n   \n\n\n\n\n\n\n22=> Conduct structural optimization using the Limited-memory Broyden-Fletcher-Goldfarb-Shanno minimization (L-BFGS). The working routines were based on the original implementation of J. Nocera available on netlib.org. This algorithm can be much better than the native implementation of BFGS in ABINIT (\nionmov\n=2) when one approaches convergence, perhaps because of better treatment of numerical details.\n\n\n Purpose: \n Structural optimization \n\n\n Cell optimization: \n Yes (if \noptcell\n/=0) \n\n\n Related variables: \n   \n\n\n\n\n\n\n23=> Use of Learn on The Fly method (LOTF) for Molecular Dynamics. In the framework of isokinetic MD, the atomic forces and positions are computed by using LOTF interpolation. A SCF computation is performed only any \nlotf_nitex\n steps. The results of the SCF are used to compute the parameters of a short range classical potential (for the moment only the glue potential for gold is implemented). Then these parameters are continuously tuned to compute atomic trajectories. LOTF has to be enabled at configure time. If LOTF is not enabled and \nionmov\n=23, abinit will set automatically \nionmov\n=12. \n\nThe LOTF cycle is divided in the following steps:\n\na) Initialization (SFC at t=0) and computation of potential parameters.\n\nb) Extrapolation of the atomic forces and positions for \nlotf_nitex\n time\nstep. To perform this extrapolation, the potential computed in a) is used\n(Verlet algorithm).\n\nc) SFC at t=\nlotf_nitex\n. Computation of the potential parameters.\n\nd) LOTF interpolation, linear interpolation of the potential parameters and\ncomputation of the atomic forces and positions between t=0 and t=lotf_nitex.  \n\n\n\n\n\n\n Purpose: \n Molecular Dynamics \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n \ndtion\n, \nlotf_classic\n, \nlotf_nitex\n, \nlotf_nneigx\n, \nlotf_version\n.   \n\n\n\n\n\n\n24=> Simple constant energy molecular dynamics using the velocity Verlet symplectic algorithm (second order), see e.g. [E. Hairer et al. Acta Numerica. 12, 399 (2003)]. The only related parameter is the time step (\ndtion\n). \n\n\n Purpose: \n Molecular dynamics \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n time step \ndtion\n   \n\n\n\n\n\n\n25=> Hybrid Monte Carlo sampling of the ionic positions at fixed temperature and unit cell geometry (NVT ensemle). The underlying molecular dynamics corresponds to ionmov=24. The related parameters are the time step (\ndtion\n) and thermostat temperature (\nmdtemp\n). \n\n\n Purpose: \n Monte Carlo sampling \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n time step \ndtion\n, thermostat temperature \nmdtemp\n,   \n\n\n\n\n\n\n30=> Using a supercell, calculate a self consistent phonon structure as in PRL 100 095901 (2008). The initial phonon eigenvectors and eigenvalues are read in, and then atoms are displaced according to the normal modes populated at a given temperature until convergence of the vibrational free energy (or so I hope) \n\n\n Purpose: \n Phonon structure \n\n\n Cell optimization: \n No (Use \noptcell\n=0 only) \n\n\n Related variables: \n   \n\n\n\n\n\n\nNo meaning for RF calculations.\n\n\nistatimg\n\u00b6\n\n\nMnemonics: Integer governing the computation of STATic IMaGes\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nThis input variable is relevant when sets of images are activated (see\n\nimgmov\n).\n\nNot all images might be required to evolve from one time step to the other\n(see\ndynimage\n): these are static images.\n\nIf \nistatimg\n=0, the total energy of static images is not computed (but\nstatic images are used to make the dynamic images evolve). This can be useful\nto save CPU time.\n\nIf \nistatimg\n=1, the total energy of static images is computed.\n\n\nmdtemp\n\u00b6\n\n\nMnemonics: Molecular Dynamics TEMPeratures\n\nVariable type: real\n\nDimensions: (2)\n\nDefault value: [300, 300]  \n\n\nGive the initial and final temperature of the Nose-Hoover thermostat\n(\nionmov\n=8) and Langevin dynamics (\nionmov\n=9), in Kelvin. This\ntemperature will change linearly from the initial temperature \n mdtemp(1) \n\nat itime=1 to the final temperature \n mdtemp(2) \n at the end of the\n\nntime\n timesteps.\n\n\nmdwall\n\u00b6\n\n\nMnemonics: Molecular Dynamics WALL location\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 10000.0\n\nComment: the walls are extremely far away  \n\n\nGives the location (atomic units) of walls on which the atoms will bounce\nback. when \nionmov\n=6, 7, 8 or 9. For each cartesian direction idir=1, 2 or\n3, there is a pair of walls with coordinates xcart(idir)=-wall and\nxcart(idir)=rprimd(idir,idir)+wall . Supposing the particle will cross the\nwall, its velocity normal to the wall is reversed, so that it bounces back.\n\nBy default, given in Bohr atomic units (1 Bohr=0.5291772108 Angstroms),\nalthough Angstrom can be specified, if preferred, since \nmdwall\n has the\n\u2018\nLENGTH\n\u2018 characteristics.\n\n\nmep_mxstep\n\u00b6\n\n\nMnemonics: Minimal Energy Path search: MaXimum allowed STEP size\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.4 if \nimgmov\n==5,\n100.0 otherwise.\n\n\nRelevant only when \nimgmov\n=1 (Steepest-Descent), 2 (String Method) or 5\n(Nudged Elastic Band).\n\nThe optimizer used to solve the Ordinary Differential Equation (ODE) can be\nconstrained with a maximum allowed step size for each image. By default this\nfeature is only activated for Nudged Elastic Band (NEB) and the value is\ninspired by _ J. Chem. Phys. 128, 134106 (2008) _ .\n\nNote that the step size is defined for each image as _ step = SQRT[SUM(R_i dot\nR_i)] _ where the _ R_i _ are the positions of the atoms in the cell.\n\n\nmep_solver\n\u00b6\n\n\nMnemonics: Minimal Energy Path ordinary differential equation SOLVER\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: None  \n\n\nRelevant only when \nimgmov\n=2 (String Method) or 5 (Nudged Elastic Band).\n\nGives the algorithm used to solve the Ordinary Differential Equation (ODE)\nwhen searching for a Minimal Energy Path (MEP).\n\nPossible values can be:  \n\n\n\n\n\n\n0=> \n Steepest-Descent algorithm \n following the (scaled) forces, the scaling factor being \nfxcartfactor\n (forward Euler method). \n\nCompatible with all MEP search methods.\n\n\n\n\n\n\n1=> \n Quick-min optimizer \n following the (scaled) forces, the scaling factor being \nfxcartfactor\n. The \u201cquick minimizer\u201d improves upon the steepest-descent method by accelerating the system in the direction of the forces. The velocity (of the image) is projected long the force and cancelled if antiparallel to it. \n\nCompatible only with Nudged Elastic Band (\nimgmov\n=5).\n\n_ See, for instance: J. Chem. Phys. 128, 134106 (2008). _  \n\n\n\n\n\n\n2=> \n Local Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm \n ; each image along the band is minimized with a different instance of the BFGS optimizer. \n\nCompatible only with Nudged Elastic Band (\nimgmov\n=5).\n\n\n See, for instance: J. Chem. Phys. 128, 134106 (2008). \n\nIN \nDEVELOP\nPMENT - NOT RELIABLE\n\n\n\n\n\n\n3=> \n Global Broyden-Fletcher-Goldfarb-Shanno (GL-BFGS) algorithm \n ; all images along the band are minimized with a single instance of the BFGS optimizer. \n\nCompatible only with Nudged Elastic Band (\nimgmov\n=5).\n\n\n See, for instance: J. Chem. Phys. 128, 134106 (2008). \n\nIN \nDEVELOP\nPMENT - NOT RELIABLE\n\n\n\n\n\n\n4=> \n Fourth-order Runge-Kutta method \n ; the images along the band are moved every four steps (1<=istep<=\nntimimage\n) following the Runge-Kutta algorithm, the time step being \nfxcartfactor\n. \n\nCompatible only with Simplified String Method (\nimgmov\n=2 and\n\nstring_algo\n=1 or 2).\n\n_ See: J. Chem. Phys. 126, 164103 (2007). _\n\n\n\n\n\n\nAll of the optimizers can be constrained with a maximum allowed step size for\neach image; see \nmep_mxstep\n. This is by default the case of the Nudged\nElastic Band (\nimgmov\n=5).\n\n\nnatcon\n\u00b6\n\n\nMnemonics: Number of AToms in CONstraint equations\n\nVariable type: integer\n\nDimensions: (\nnconeq\n)\n\nDefault value: 0  \n\n\nGives the number of atoms appearing in each of the \nnconeq\n independent\nequations constraining the motion of atoms during structural optimization or\nmolecular dynamics (see \nnconeq\n , \niatcon\n, and \nwtatcon\n).\n\n\nnatfix\n\u00b6\n\n\nMnemonics: Number of Atoms that are FIXed\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nComment: (no atoms held fixed)  \n\n\nGives the number of atoms (not to exceed \nnatom\n) which are to be held fixed\nduring a structural optimization or molecular dynamics.\n\nWhen \nnatfix\n > 0, \nnatfix\n entries should be provided in array\n\niatfix\n .\n\n\nnatfixx\n\u00b6\n\n\nMnemonics: Number of Atoms that are FIXed along the X direction\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of atoms (not to exceed \nnatom\n) which are to be held fixed\nalong the X direction during a structural optimization or molecular dynamics.\n\nWhen \nnatfixx\n > 0, \nnatfixx\n entries should be provided in array\n\niatfixx\n.\n\n\nnatfixy\n\u00b6\n\n\nMnemonics: Number of Atoms that are FIXed along the Y direction\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of atoms (not to exceed \nnatom\n) which are to be held fixed\nalong the Y direction during a structural optimization or molecular dynamics.\n\nWhen \nnatfixy\n > 0, \nnatfixy\n entries should be provided in array\n\niatfixy\n\n\nnatfixz\n\u00b6\n\n\nMnemonics: Number of Atoms that are FIXed along the Z direction\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of atoms (not to exceed \nnatom\n) which are to be held fixed\nalong the Z direction during a structural optimization or molecular dynamics.\n\nWhen \nnatfixz\n > 0, \nnatfixz\n entries should be provided in array\n\niatfixz\n.\n\n\nnconeq\n\u00b6\n\n\nMnemonics: Number of CONstraint EQuations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of independent equations constraining the motion of atoms\nduring structural optimization or molecular dynamics (see \nnatcon\n ,\n\niatcon\n, and \nwtatcon\n).\n\n\nneb_algo\n\u00b6\n\n\nMnemonics: Nudged Elastic Band ALGOrithm\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nimgmov\n==5  \n\n\nGives the variant of the NEB method used.\n\nPossible values can be:  \n\n\n\n\n\n\n0=> \n Original NEB method \n . \n\n_ See: Classical and Quantum Dynamics in Condensed Phase Simulations, edited\nby Berne, Ciccotti, Coker (World Scientific, Singapore, 1998), pp. 385-404 _\n\n\n\n\n\n\n1=> \n NEB + improved tangent \n . \n\nThe Improved Tangent Method builds on the NEB with an improved estimate of the\ntangent direction and a resulting change of the component of the spring force\nacting on the images.\n\n_ See: J. Chem. Phys. 113, 9978 (2000). _\n\n\n\n\n\n\n2=> \n Climbing-Image NEB (CI-NEB) \n . \n\nThe CI-NEB method constitutes a small modification to the NEB method.\nInformation about the shape of the MEP is retained, but a rigorous convergence\nto a saddle point is also obtained. By default the spring constants are\nvariable (see \nneb_spring\n). As the image with the highest energy has to be\nidentified, the calculation begins with several iterations of the standard NEB\nalgorithm. The effective CI-NEB begins at the \ncineb_start\n iteration.\n\n_ See: J. Chem. Phys. 113, 9901 (2000). _\n\n\n\n\n\n\nNote that, in all cases, it is possible to define the value of the spring\nconstant connecting images with \nneb_spring\n, keeping it constant or\nallowing it to vary between 2 values (to have higher resolution close to the\nsaddle point).\n\n\nneb_spring\n\u00b6\n\n\nMnemonics: Nudged Elastic Band: SPRING constant\n\nVariable type: real\n\nDimensions: (2)\n\nDefault value: [0.02, 0.15] if \nneb_algo\n==2,\n[0.05, 0.05] otherwise.\n\n\nOnly relevant if \nimgmov\n==5  \n\n\nGives the minimal and maximal values of the spring constant connecting images\nfor the NEB method.\n\nIn the standard \u201cNudged Elastic Band\u201d method, the spring constant is constant\nalong the path, but, in order to have higher resolution close to the saddle\npoint, it can be better to have stronger springs close to it.\n\n_ See: J. Chem. Phys. 113, 9901 (2000). _\n\n\nnimage\n\u00b6\n\n\nMnemonics: Number of IMAGEs\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nGive the number of images (or replicas) of the system, for which the forces\nand stresses might be computed independently, in the context of the string\nmethod, the genetic algorithm, hyperdynamics or Path-Integral Molecular\nDynamics depending on the value of \nimgmov\n). Related input variables :\n\ndynimage\n, \nnpimage\n, \nntimimage\n and \nprtvolimg\n.\n\nImages might differ by the position of atoms in the unit cell, their velocity,\nas well as by their cell geometry. The following input variables might be used\nto define the images :\n\n\n\n\nacell\n \n\n\namu\n \n\n\nangdeg\n \n\n\ndmatpawu\n \n\n\njpawu\n \n\n\nmixalch\n \n\n\nrprim\n \n\n\nupawu\n \n\n\nvel\n \n\n\nvel_cell\n \n\n\nxangst\n \n\n\nxcart\n \n\n\nxred\n \n\n\n\n\nThese input variables, non-modified, will be used to define the image with\nindex 1. For the image with the last index, the input file might specify the\nvalues of such input variables, appended with \u201c_lastimg\u201d, e.g. :\n\n\n\n\nacell_lastimg \n\n\nrprim_lastimg \n\n\nxcart_lastimg \n\n\n\u2026 \n\n\n\n\nBy default, these values will be interpolated linearly to define values for\nthe other images, unless there exist specific values for some images, for\nwhich the string \u201clast\u201d has to be replaced by the index of the image, e.g. for\nthe image number 4 :\n\n\n\n\nacell_4img \n\n\nrprim_4img \n\n\nxcart_4img \n\n\n\u2026 \n\n\n\n\nIt is notably possible to specify the starting point and the end point of the\npath (of images), while specifying intermediate points.  \n\n\nIt usually happen that the images do not have the same symmetries and space\ngroup. ABINIT has not been designed to use different set of symmetries for\ndifferent images. ABINIT will use the symmetry and space group of the image\nnumber 2, that is expected to have a low number of symmetries. This might lead\nto erroneous calculations, in case some image has even less symmetry. By\ncontrast, there is no problem if some other image has more symmetries than\nthose of the second image.\n\n\nnnos\n\u00b6\n\n\nMnemonics: Number of NOSe masses\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of thermostats in the Martyna et al. chain of oscillators\nthermostats. The thermostat chains can be used either to perform Molecular\nDynamics (MD) (\nionmov\n=13) or to perform Path Integral Molecular Dynamics\n(PIMD) (\nimgmov\n=13).\n\nThe mass of these thermostats is given by \nqmass\n.  \n\n\nnoseinert\n\u00b6\n\n\nMnemonics: NOSE thermostat INERTia factor\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 100000\n\nOnly relevant if \nionmov\n==8  \n\n\nGive the inertia factor WT of the Nose-Hoover thermostat (when \nionmov\n=8),\nin atomic units of weight\nlength2, that is (electron mass)\n(Bohr)2. The\nequations of motion are : MI d2RI/dt2= FI - dX/dt MI dRI/dt and WT d2X/dt2=\nSum(I) MI (dRI/dt)2 - 3NkBT where I represent each nucleus, MI is the mass of\neach nucleus (see \namu\n), RI is the coordinate of each nucleus (see\n\nxcart\n), dX/dt is a dynamical friction coefficient, and T is the\ntemperature of the thermostat (see \nmdtemp\n).\n\n\nntime\n\u00b6\n\n\nMnemonics: Number of TIME steps\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nGives the number of molecular dynamics time steps or Broyden structural\noptimization steps to be done if \nionmov\n is non-zero.\n\nNote that at the present the option \nionmov\n=1 is initialized with four\nRunge-Kutta steps which costs some overhead in the startup. By contrast, the\ninitialisation of other \nionmov\n values is only one SCF call.\n\n\nntime\n is ignored if \nionmov\n=0.\n\n\nntimimage\n\u00b6\n\n\nMnemonics: Number of TIME steps for IMAGE propagation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nGives the maximal number of molecular dynamics time steps or structural\noptimization steps to be done for the set of images, referred to as \u2018image-\ntimesteps\u2019. At each image-timestep, all the images are propagated\nsimultaneously, each according to the algorithm determined by \nimgmov\n and\nthe usual accompanying input variables, and then the next positions and\nvelocities for each image are determined from the set of results obtained for\nall images.\n\n\noptcell\n\u00b6\n\n\nMnemonics: OPTimize the CELL shape and dimensions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nAllows to optimize the unit cell shape and dimensions, when \nionmov\n>=2 or\n3. The configuration for which the stress almost vanishes is iteratively\ndetermined, by using the same algorithms as for the nuclei positions. Will\neventually modify \nacell\n and/or \nrprim\n. The ionic positions are ALWAYS\nupdated, according to the forces. A target stress tensor might be defined, see\n\nstrtarget\n.\n\n\n\n\noptcell\n=0 : modify nuclear positions, since \nionmov\n=2 or 3, but no cell shape and dimension optimisation.\n\n\noptcell\n=1 : optimisation of volume only (do not modify \nrprim\n, and allow an homogeneous dilatation of the three components of \nacell\n)\n\n\noptcell\n=2 : full optimization of cell geometry (modify \nacell\n and \nrprim\n - normalize the vectors of \nrprim\n to generate the \nacell\n). This is the usual mode for cell shape and volume optimization. It takes into account the symmetry of the system, so that only the effectively relevant degrees of freedom are optimized.\n\n\noptcell\n=3 : constant-volume optimization of cell geometry (modify \nacell\n and \nrprim\n under constraint - normalize the vectors of \nrprim\n to generate the \nacell\n)\n\n\noptcell\n=4, 5 or 6 : optimize \n[acell]\n, \n[acell]\n, or \n[acell]\n, respectively (only works if the two other vectors are orthogonal to the optimized one, the latter being along its cartesian axis).\n\n\noptcell\n=7, 8 or 9 : optimize the cell geometry while keeping the first, second or third vector unchanged (only works if the two other vectors are orthogonal to the one left unchanged, the latter being along its cartesian axis).\n\n\n\n\nA few details require attention when performing unit cell optimisation :\n\n\n\n\none has to get rid of the discontinuities due to discrete changes of plane wave number with cell size, by using a suitable value of \necutsm\n;\n\n\none has to allow for the possibility of a larger sphere of plane waves, by using \ndilatmx\n;\n\n\none might have to adjust the scale of stresses to the scale of forces, by using \nstrfact\n.\n\n\nif all the reduced coordinates of atoms are fixed by symmetry, one cannot use \ntoldff\n to stop the SCF cycle. (Suggestion : use \ntoldfe\n with a small value, like 1.0d-10)\n\n\n\n\nIt is STRONGLY suggested first to optimize the ionic positions without cell\nshape and size optimization (\noptcell\n=0), then start the cell shape and\nsize optimization from the cell with relaxed ionic positions. Presently\n(v3.1), one cannot restart (\nrestartxf\n) a calculation with a non-zero\n\noptcell\n value from the (x,f) history of another run with a different non-\nzero \noptcell\n value. There are still a few problems at that level.\n\n\npimass\n\u00b6\n\n\nMnemonics: Path Integral fictitious MASSes\n\nVariable type: real\n\nDimensions: (\nntypat\n)\n\nDefault value: \nntypat\n\nOnly relevant if \nimgmov\n=9 or 13  \n\n\nOnly relevant if \nimgmov\n=9 or 13 (Path-Integral Molecular Dynamics).\n\nGives the fictitious masses ( _ D. Marx and M. Parrinello, J. Chem. Phys. 104,\n4077 (1996) _ ) in atomic mass units for each kind of atom in cell. These\nmasses are the inertial masses used in performing Path Integral Molecular\nDynamics (PIMD), they are different from the true masses (\namu\n) used to\ndefine the quantum spring that relates the different beads in PIMD. They can\nbe chosen arbitrarily, but an appropriate choice will lead the different\nvariables to move on the same time scale in order to optimize the sampling\nefficiency of the PIMD trajectory.\n\nIf \npitransform\n=1 (normal mode transformation), or \npitransform\n=2\n(staging transformation), \npimass\n is automatically set to its optimal\nvalue.  \n\n\npimd_constraint\n\u00b6\n\n\nMnemonics: Path-Integral Molecular Dynamics: CONSTRAINT to be applied on a reaction coordinate\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nimgmov\n=9 or 13  \n\n\nOnly relevant for Path-Integral Molecular Dynamics.\n\nSelects a constraint to be applied during the PIMD trajectory. The constraint\nis holonomic (it is a relation between the position variables).In practice,\nthe total forces applied to the atomic positions are modified so as to respect\nthe constraint.\n\nTo date, the available constraints are:  \n\n\n\n\n0\n: no constraint\n\n\n1\n: \n\u201cBlue Moon Ensemble\u201d method\n.\n\nThe constraint is a linear combination of the positions of atomic centroids\n(this linear combination is kept constant during the simulation).\n\nSum[W_i * X_i]=constant\n\nThe X_i are the coordinates of the atomic centroids. The weights W_i have to\nbe specified with the \n[wtatcon]\n,\n\n[iatcon]\n and \nnatcon\n input parameters (where \nnconeq\n is\nfixed to 1).\n\nMore details on the implementation in: \nY. Komeiji,Chem-Bio Informatics\nJournal 7, 12-23 (2007)\n.\n\n\n\n\npitransform\n\u00b6\n\n\nMnemonics: Path Integral coordinate TRANSFORMation\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nOnly relevant if \nimgmov\n=9 or 13 (Path-Integral Molecular Dynamics).\nCoordinate transformation used in the integration of the Path Integral\nMolecular Dynamics equations of motion. The transformation, with an\nappropriate choice of fictitious masses (\npimass\n), is used to force the\ndifferent modes to move on the same time scale, and thus optimize the\nefficiency of the statistical sampling in the corresponding statistical\nensemble. Available with a Langevin thermostat (\nimgmov\n=9) or with Nose-\nHoover chains (\nimgmov\n=13). See M. Tuckerman et al, J. Chem. Phys. 104,\n5579 (1996).\n\n\nIf equal to 0, no transformation is applied (primitive coordinates).\n\nIf equal to 1, normal mode transformation (in that case, \nnimage\n must be\nabsolutely EVEN).\n\nIf equal to 2, staging transformation.\n\n\nprtatlist\n\u00b6\n\n\nMnemonics: PRinT by ATom LIST of ATom\n\nVariable type: integer\n\nDefault value: 0  \n\n\nThis is an array of the numbers associated to the index atoms that the user\nwant to print in the output or log files, this is useful when you have a large\nnumber of atoms and you are only interested to follow specific atoms, the\nnumbers associated should be consistent with the list in \nxcart\n or\n\nxred\n. This input varible does not affect the contents of the \u201cOUT.nc\u201d or\n\u201cHIST.nc\u201d, those are NetCDF files containing the information about all the\natoms.\n\n\nqmass\n\u00b6\n\n\nMnemonics: Q thermostat MASS\n\nVariable type: real\n\nDimensions: (\nnnos\n)\n\nDefault value: *10.0  \n\n\nThis are the masses of the chains of \nnnos\n thermostats to be used when\n\nionmov\n=13 (Molecular Dynamics) or \nimgmov\n=13 (Path Integral Molecular\nDynamics).\n\n\nIf \nionmov\n=13 (Molecular Dynamics), this temperature control can be used\nwith  \noptcell\n =0, 1 (homogeneous cell deformation) or 2 (full cell\ndeformation).\n\nIf \nimgmov\n=13 (Path Integral Molecular Dynamics), this temperature control\ncan be used with  \noptcell\n =0 (NVT ensemble) or 2 (fully flexible NPT\nensemble). In that case, \noptcell\n=2 iS NOT USABLE yet.\n\n\nrandom_atpos\n\u00b6\n\n\nMnemonics: RANDOM ATomic POSitions\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nControl the inner coordinates, which can be generated randomly by using 4\ndifferent methods depending ont its value\n\n(0) if zero, no random generation and xred are taken as they have been\nintroduced by the user\n\n(1) if one, particles are generated completly random within the unit cell.\n\n(2) if two, particles are generated randomly but the inner particle distance\nis always larger than a factor of the sum of the covalent bonds between the\natoms (note : this is incompatible with the definition of alchemical mixing,\nin which \nntypat\n differs from \nnpsp\n)\n\n\nrestartxf\n\u00b6\n\n\nMnemonics: RESTART from (X,F) history\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nControl the restart of a molecular dynamics or structural optimization job.  \n\n\n restartxf>0 (Deprecated) \n :The code reads from the input wf file, the previous history of atomic coordinates and corresponding forces, in order to continue the work done by the job that produced this wf file. If \noptcell\n/=0, the history of \nacell\n and \nrprim\n variables is also taken into account. The code will take into consideration the whole history (if \nrestartxf\n=1), or discard the few first (x,f) pairs, and begin only at the pair whose number corresponds to \nrestartxf\n. \n\nWorks only for \nionmov\n=2 (Broyden) and when an input wavefunction file is\nspecified, thanks to the appropriate values of \nirdwfk\n or \ngetwfk\n.  \n\n\nNOTES :\n\n\n The input wf file must have been produced by a run that exited cleanly. It cannot be one of the temporary wf files that exist when a job crashed. \n\n\n One cannot restart a calculation with a non-zero \noptcell\n value from the (x,f) history of another run with a different non-zero \noptcell\n value. Starting a non-zero \noptcell\n run from a zero \noptcell\n run should work. \n\n* Deprecated, the use of the new options (-1 and -2) is preferred.   \n\n\n restartxf=0 (Default) \n : No restart procedure is enable and will start a Molecular dynamics or structural optimization from scratch.   \n\n\n restartxf=-1 (New) \n : Use the HIST file to reconstruct a partial calculation. It will reconstruct the different configurations using the forces and stress store in the HIST file, instead of calling the SCF procedure. \n\nEnable \n restartxf=-1 \n from the beginning is harmless. The only condition\nis to keep the input file the same in such a way that the same predictor is\nused and it will predict the same structure recorded in the HIST file.\n\nThis option will always compute extra \nntime\n iterations independent of the\nnumber of iterations recovered previously.  \n\n\n restartxf=-2 (New) \n :Read the HIST file and select the atomic positions and cell parameters with the lowest energy. Forget all the history and start the calculation using those values. The original atomic coordinates and cell parameters are irrelevant in that case.   \n\n\nNOTES:\n\n\n You can use \n restartxf=-1 or -2 \n for all predictiors that make no use of random numbers. \n\n\n You can use \n restartxf=-1 or -2 \n to restart a calculation that was not completed. The HIST file is written on each iteration. So you always have something to recover from. \n\n* You can take advantage of the appropriate values of \nirdwfk\n or \ngetwfk\n to get a good wave function to continue your job. \n\n\nsignperm\n\u00b6\n\n\nMnemonics: SIGN of PERMutation potential\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\n+1 favors alternation of species -1 favors segregation\n\n\nstrfact\n\u00b6\n\n\nMnemonics: STRess FACTor\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 100  \n\n\nThe stresses multiplied by \nstrfact\n will be treated like forces in the\nprocess of optimization (\nionmov\n=2, non-zero \noptcell\n).\n\nFor example, the stopping criterion defined by \ntolmxf\n relates to these\nscaled stresses.\n\n\nstring_algo\n\u00b6\n\n\nMnemonics: STRING method ALGOrithm\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1  \n\n\nRelevant only when \nimgmov\n=2 (String Method).\n\nGives the variant of the String Method method used.\n\nPossible values can be:  \n\n\n\n\n\n\n0=> \n Original String Method \n . \n\nNOT YET IMPLEMENTED\n\n_ See: Phys. Rev. B 66, 052301 (2002) _\n\n\n\n\n\n\n1=> \n Simplified String Method \n with parametrization by \n equal arc length \n . \n\nInstead of using the normal force (wr the band), the full force is used; the\nreparametrization is enforced by keeping the points of the string equally\nspaced.\n\n_ See: J. Chem. Phys. 126, 164103 (2007) _\n\n\n\n\n\n\n2=> \n Simplified String Method \n with parametrization by \n energy-weighted arc length \n . \n\nA variant of the Simplified String Method (like 2-); the reparametrization is\ndone by using energy-weight arc-lengths, giving a finer distribution near the\nsaddle point..\n\n\n See: J. Chem. Phys. 126, 164103 (2007) and J. Chem. Phys. 130, 244108 (2009)\n\n\n\n\n\n\n\nstrprecon\n\u00b6\n\n\nMnemonics: STRess PRECONditioner\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0  \n\n\nThis is a scaling factor to initialize the part of the Hessian related to the\ntreatment of the stresses (optimisation of the unit cell). In case there is an\ninstability, decrease the default value, e.g. set it to 0.1 .\n\n\nstrtarget\n\u00b6\n\n\nMnemonics: STRess TARGET\n\nVariable type: real\n\nDimensions: (6)\n\nDefault value: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n\n\nThe components of the stress tensor must be stored according to : (1,1)->1\n; (2,2)->2 ; (3,3)->3 ; (2,3)->4 ; (3,1)->5 ; (1,2)->6. The\nconversion factor between Ha/Bohr\n3 and GPa is : 1 Ha/Bohr\n3 = 29421.033d0\nGPa.\n\nNot used if \noptcell\n==0.\n\n\ntolimg\n\u00b6\n\n\nMnemonics: TOLerance on the mean total energy for IMaGes\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 5e-05  \n\n\nSets a maximal absolute energy tolerance (in hartree, averaged over dynamic\nimages) below which iterations on images (the one governed by the\n\nntimimage\n input variable) will stop.\n\nThis is to be used when trying to optimize a population of structures to their\nlowest energy configuration, taking into account the particular algorithm\ndefined by \nimgmov\n\nA value of about 5.0d-5 hartree or smaller is suggested (this corresponds to\nabout 3.7d-7 eV).\n\nNo meaning for RF calculations.\n\n\ntolmxde\n\u00b6\n\n\nMnemonics: TOLerance on the MaXimal Difference in Energy\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0  \n\n\nSets a maximal difference in energy with respect to the two previous steps\nbelow which BFGS structural relaxation iterations will stop.\n\nA value of about 0.0005 eV/atom or smaller is suggested.\n\nIn order to use tolmxde, you should explicitly set tolmxf to 0.0.\n\nNo meaning for RF calculations.\n\n\ntolmxf\n\u00b6\n\n\nMnemonics: TOLerance on the MaXimal Force\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 5e-05  \n\n\nSets a maximal absolute force tolerance (in hartree/Bohr) below which BFGS\nstructural relaxation iterations will stop.\n\nCan also control tolerance on stresses, when \noptcell\n /=0, using the\nconversion factor \nstrfact\n. This tolerance applies to any particular\ncartesian component of any atom, excluding fixed ones. See the parameter\n\nionmov\n.\n\nThis is to be used when trying to equilibrate a structure to its lowest energy\nconfiguration ( \nionmov\n =2).\n\nA value of about 5.0d-5 hartree/Bohr or smaller is suggested (this corresponds\nto about 2.5d-3 eV/Angstrom).\n\nNo meaning for RF calculations.\n\n\nvel\n\u00b6\n\n\nMnemonics: VELocity\n\nVariable type: real\n\nDimensions: (3,\nnatom\n)\n\ncommentdims It is represented internally as \n[vel]\n\nDefault value: *0\n\nOnly relevant if \nionmov\n > 0  \n\n\nGives the starting velocities of atoms, in cartesian coordinates, in\nBohr/atomic time units (atomic time units given where \ndtion\n is described).\n\nFor \nionmov\n=8 (Nose thermostat), if \nvel\n is not initialized, a random\ninitial velocity giving the right kinetic energy will be generated.\n\nIf the geometry builder is used, \nvel\n will be related to the preprocessed\nset of atoms, generated by the geometry builder. The user must thus foresee\nthe effect of this geometry builder (see \nobjarf\n).\n\nVelocities evolve is \nionmov\n==1.\n\n\nvel_cell\n\u00b6\n\n\nMnemonics: VELocity of the CELL parameters\n\nVariable type: real\n\nDimensions: (3,3)\n\ncommentdims It is represented internally as \n[vel_cell]\n \n\nDefault value: *3\n\nOnly relevant if \nimgmov\n in [9,13] and \noptcell\n > 0\n(Path-Integral Molecular Dynamics\nwith NPT algorithm)  \n\n\nIrrelevant unless \nimgmov\n=9 or 13 and \noptcell\n>0 (Path-Integral\nMolecular Dynamics with NPT algorithm).\n\nGives the starting velocities of the dimensional cell parameters in\nBohr/atomic time units (atomic time units given where \ndtion\n is described).\n\n\nvis\n\u00b6\n\n\nMnemonics: VIScosity\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 100  \n\n\nThe equation of motion is :\n\nM  I  d  2  R  I  /dt  2  = F  I  - \nvis\n dR  I  /dt  \n\n\nThe atomic unit of viscosity is hartrees*(atomic time units)/Bohr  2  . Units\nare not critical as this is a fictitious damping used to relax structures. A\ntypical value for silicon is 400 with \ndtion\n of 350 and atomic mass 28\n\namu\n. Critical damping is most desirable and is found only by optimizing\n\nvis\n for a given situation.  \n\n\nIn the case of Path-Integral Molecular Dynamics using the Langevin Thermostat\n(\nimgmov\n=9), \nvis\n defines the friction coefficient, in atomic units.\nTypical value range is 0.00001-0.001.\n\n\nwtatcon\n\u00b6\n\n\nMnemonics: WeighTs for AToms in CONstraint equations\n\nVariable type: real\n\nDimensions: (3,\nnatcon\n,\nnconeq\n)\n\nDefault value: 0  \n\n\nGives the weights determining how the motion of atoms is constrained during\nstructural optimization or molecular dynamics (see \nnconeq\n , \nnatcon\n,\nand \niatcon\n). For each of the \nnconeq\n independent constraint equations,\nwtatcon is a 3*\nnatcon\n array giving weights, W  I  , for the x, y, and z\ncomponents of each of the atoms (labeled by I) in the list of indices\n\niatcon\n. Prior to taking an atomic step, the calculated forces, F  I  , are\nreplaced by projected forces, F\u2019  I  , which satisfy the set of constraint\nequations  \n\n\nSum  mu=x,y,z; I=1,natcon  : W  mu,I  * F\u2019  mu,I  = 0 for each of the\n\nnconeq\n arrays W  I  .  \n\n\nDifferent types of motion constraints can be implemented this way. For\nexample,  \n\n\nnconeq 1 natcon 2 iatcon 1 2 wtatcon 0 0 +1 0 0 -1  \n\n\ncould be used to constrain the relative height difference of two adsorbate\natoms on a surface (assuming their masses are equal), since F\u2019  z,1  - F\u2019\nz,2  = 0 implies z  1  - z  2  = constant.",
            "title": "Relaxation"
        },
        {
            "location": "/input_variables/varrlx/#adpimd",
            "text": "Mnemonics: ADiabatic Path-Integral Molecular Dynamics \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  imgmov ==9 or  imgmov ==13    Controls whether adiabatic Path-Integral Molecular Dynamics is performed or\nnot. \nThe corresponding adiabaticity parameter is given by  adpimd_gamma .    If equal to 0, no adiabatic Path-Integral Molecular Dynamics (standard PIMD)\nis performed. \nIf equal to 1, adiabatic Path-Integral Molecular Dynamics is activated. \nOnly relevant with  pitransform =1 (normal mode transformation). In that\ncase, \n- the mass associated with to the zero-frequency mode is the true mass amu , \n- the mass associated to the other higher frequency modes of the polymer\nchains is equal to the normal mode mass divided by  adpimd_gamma \n(adiabaticity parameter), \n- the equation of motion on the zero-frequency mode is not thermostated. \nNOT YET USABLE",
            "title": "adpimd"
        },
        {
            "location": "/input_variables/varrlx/#adpimd_gamma",
            "text": "Mnemonics: ADiabatic Path-Integral Molecular Dynamics: GAMMA factor \nVariable type: real \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  adpimd ==1 and  imgmov  in [9,13]    Adiabaticity parameter to be used in adiabatic Path-Integral Molecular\nDynamics. \nNOT YET USABLE",
            "title": "adpimd_gamma"
        },
        {
            "location": "/input_variables/varrlx/#amu",
            "text": "Mnemonics: Atomic Mass Units \nVariable type: real \nDimensions: ( ntypat ) \nDefault value: None \nComment: provided by a database of atomic masses.    Gives the masses in atomic mass units for each kind of atom in cell. These\nmasses are used in performing molecular dynamical atomic motion if ionmov =1, 6, 7 or 8. They are also used in phonon calculations, in the\ndiagonalization of the dynamical matrix. Note that one may set all masses to 1\nfor certain cases in which merely structural relaxation is desired and not\nactual molecular dynamics.  Using 1986 recommended values, 1 atomic mass unit = 1.6605402e-27 kg. In this\nunit the mass of Carbon 12 is exactly 12.  A database of atomic masses is provided, giving default values. Note that the\ndefault database uses mixed isotope masses (for Carbon the natural occurrence\nof Carbon 13 is taken into account). The values are those recommended by the\ncommission on Atomic Weights and Isotopic Abundances, Inorganic Chemistry\nDivision, IUPAC, in _ Pure Appl. Chem. _   60   , 841 (1988). For Tc, Pm, Po\nto Ac, Pa and beyond U, none of the isotopes has a half-life greater than\n3.0d10 years, and the values provided in the database do not come from that\nsource.  For alchemical pseudoatoms, the masses of the constituents atoms are mixed,\naccording to the alchemical mixing coefficients  mixalch  In most cases, the use of  amu  will be as a static (non-evolving) variable.\nHowever, the possibility to have different values of  amu  for different\nimages has been coded. A population of cells with different atomic\ncharacteristics can thus be considered, and can be made to evolve, e.g. with a\ngenetic algorithm (not coded in v7.0.0 though).",
            "title": "amu"
        },
        {
            "location": "/input_variables/varrlx/#bmass",
            "text": "Mnemonics: Barostat MASS \nVariable type: real \nDimensions: scalar \nDefault value: 10    bmass is the mass of the barostat when  ionmov =13 (constant pressure\nmolecular dynamics)",
            "title": "bmass"
        },
        {
            "location": "/input_variables/varrlx/#cineb_start",
            "text": "Mnemonics: Climbing-Image Nudged Elastic Band: STARTing iteration \nVariable type: integer \nDimensions: scalar \nDefault value: 7 \nOnly relevant if  imgmov == 5 and  neb_algo ==2    Gives the index of the first CI-NEB iteration.. \nThe CI-NEB method constitutes a small modification to the NEB method allowing\na rigorous convergence to the saddle point. As the image with the highest\nenergy has to be identified, the calculation begins with several iterations of\nthe standard NEB algorithm. The effective CI-NEB begins at the  cineb_start \niteration. \n_ See: J. Chem. Phys. 113, 9901 (2000). _",
            "title": "cineb_start"
        },
        {
            "location": "/input_variables/varrlx/#delayperm",
            "text": "Mnemonics: DELAY between trials to PERMUTE atoms \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Delay (number of time steps) between trials to permute two atoms, in view of\naccelerated search of minima. Still in development. See the routine\nmoldyn.F90. See also  signperm . When  delayperm  is zero, there is not\npermutation trials.",
            "title": "delayperm"
        },
        {
            "location": "/input_variables/varrlx/#diismemory",
            "text": "Mnemonics: Direct Inversion in the Iterative Subspace MEMORY \nVariable type: integer \nDimensions: scalar \nDefault value: 8    Gives the maximum number of \u201ctime\u201d steps for which the forces and stresses are\nstored, and taken into account in the DIIS algorithm ( ionmov =20) to find\nzero-force and stress configurations.",
            "title": "diismemory"
        },
        {
            "location": "/input_variables/varrlx/#dilatmx",
            "text": "Mnemonics: lattice DILATation : MaXimal value \nVariable type: real \nDimensions: scalar \nDefault value: 1.0    Gives the maximal permitted scaling of the lattice parameters when the cell\nshape and dimension is varied (see variable  optcell ). It is used to define\nthe sphere of plane waves and FFT box coherent with the possible modifications\nof the cell ( ionmov ==2 and [[optcell] /=0). For these definitions, it is\nequivalent to changing  ecut  by multiplying it by  dilatmx   2  (the\nresult is an \u201ceffective ecut\u201d, called internally \u201cecut_eff\u201d, other uses of ecut  being not modified when  dilatmx >1.0 . \nUsing  dilatmx <1.0 is equivalent to changing  ecut  in all its uses.\nThis is allowed, although its meaning is no longer related to a maximal\nexpected scaling. \nSetting  dilatmx  to a large value leads to waste of CPU time and memory.\nSupposing you think that the optimized  acell  values might be 10% larger\nthan your input values, use simply  dilatmx  1.1 . This will already lead to\nan increase of the number of planewaves by a factor (1.1)  3  =1.331 , and a\ncorresponding increase in CPU time and memory. \nIt is possible to use  dilatmx  when  optcell  =0, but a value larger than\n1.0 will be a waste.",
            "title": "dilatmx"
        },
        {
            "location": "/input_variables/varrlx/#dtion",
            "text": "Mnemonics: Delta Time for IONs \nVariable type: real \nDimensions: scalar \nDefault value: 100    Used for controlling ion time steps. If  ionmov  is set to 1, 6 or 7, then\nmolecular dynamics is  used to update atomic positions in response to forces.\nThe parameter  dtion  is a time step in atomic units of time. (One atomic\ntime unit is 2.418884e-17 seconds, which is the value of Planck\u2019s constant in\nhartree*sec.) In this case the atomic masses, in amu (given in array \u201d  amu \n\u201c), are used in Newton\u2019s equation and the viscosity (for  ionmov  =1) and\nnumber of time steps are provided to the code using input variables \u201c vis \u201d\nand \u201c ntime \u201d. The code actually converts from masses in amu to masses in\natomic units (in units of electron masses) but the user enters masses in amu  . (The conversion from amu to atomic units (electron masses) is\n1822.88851 electron masses/amu.) \nA typical good value for  dtion  is about 100. The user must try several\nvalues for  dtion  in order to establish the stable and efficient choice for\nthe accompanying amu, atom types and positions, and  vis  (viscosity). \nFor quenched dynamics ( ionmov =7), a larger time step might be taken, for\nexample 200. \nNo meaning for RF calculations.",
            "title": "dtion"
        },
        {
            "location": "/input_variables/varrlx/#dynimage",
            "text": "Mnemonics: DYNamics of the IMAGE \nVariable type: integer \nDimensions: ( nimage ) \nDefault value: *1 \nComment: if  imgmov  in [2,5] (String Method, NEB),  dynimage(1) =0 and  dynimage( nimage ) =0.    This input variable is relevant when sets of images are activated (see imgmov ). Not all images might be required to evolve from one time step to\nthe other. Indeed, in the String Method or the Nudged Elastic Band, one might\nimpose that the extremal configurations of the string are fixed. In case the [dynimage] =0, the image with index \u201ciimage\u201d will be consider as\nfixed. Thus, there is no need to compute forces and stresses for this image at\neach time step. The purpose of defining extremal images is to make the\ninput/output easier.    In order to save CPU time, the computation of properties of static images\n( [dynimage] =0) can be avoided: see  istatimg  keyword.",
            "title": "dynimage"
        },
        {
            "location": "/input_variables/varrlx/#ecutsm",
            "text": "Mnemonics: Energy CUToff SMearing \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    This input variable is important when performing relaxation of unit cell size\nand shape (non-zero  optcell ). Using a non-zero  ecutsm , the total\nenergy curves as a function of  ecut , or  acell , can be smoothed,\nkeeping consistency with the stress (and automatically including the Pulay\nstress). The recommended value is 0.5 Ha. Actually, when  optcell /=0,\nABINIT requires  ecutsm  to be larger than zero. If you want to optimize\ncell shape and size without smoothing the total energy curve (a dangerous\nthing to do), use a very small  ecutsm , on the order of one microHartree.  Technical information : \nSee Bernasconi et al, J. Phys. Chem. Solids 56, 501 (1995) for a related\nmethod.  ecutsm  allows to define an effective kinetic energy for plane waves, close\nto, but lower than the maximal kinetic energy  ecut . For kinetic energies\nless than  ecut - ecutsm , nothing is modified, while between ecut - ecutsm  and  ecut  , the kinetic energy is multiplied by: \n1.0 / ( x  2  (3+x-6x  2  +3x  3  )) \nwhere x = ( ecut  - kinetic_energy)/ ecutsm \nNote that x  2  ( 3+x-6x  2  +3x  3  ) is 0 at x=0, with vanishing derivative,\nand that at x=1 , it is 1, with also vanishing derivative. \nIf  ecutsm  is zero, the unmodified kinetic energy is used.  ecutsm  can be specified in Ha (the default), Ry, eV or Kelvin, since ecutsm  has the \u2018 ENERGY \u2018 characteristics. (1 Ha=27.2113845 eV). \nA few test for Silicon (diamond structure, 2 k-points) have shown 0.5 Ha to be\nlargely enough for  ecut  between 2Ha and 6Ha, to get smooth curves. It is\nlikely that this value is OK as soon as  ecut  is larger than 4Ha.",
            "title": "ecutsm"
        },
        {
            "location": "/input_variables/varrlx/#friction",
            "text": "Mnemonics: internal FRICTION coefficient \nVariable type: real \nDimensions: scalar \nDefault value: 0.001    Gives the internal friction coefficient (atomic units) for Langevin dynamics\n(when  ionmov =9): fixed temperature simulations with random forces.  The equation of motion is : \nM  I  d  2  R  I  /dt  2  = F  I  -  friction  M  I  dR  I  /dt - F_random\nI \nwhere F_random  I  is a Gaussian random force with average zero, and variance\n2  friction  M  I  kT. \nThe atomic unit of friction is hartrees electronic mass (atomic time\nunits)/Bohr  2  . See J. Chelikowsky, J. Phys. D : Appl Phys. 33(2000)R33.",
            "title": "friction"
        },
        {
            "location": "/input_variables/varrlx/#fxcartfactor",
            "text": "Mnemonics: Forces to (X) CARTesian coordinates FACTOR \nVariable type: real \nDimensions: scalar \nDefault value: 1 (Bohr^2)/Hartree    The forces multiplied by  fxcartfactor  will be treated like difference in\ncartesian coordinates in the process of optimization. This is a simple\npreconditioner. \nTO BE UPDATED See ( ionmov =2, non-zero  optcell ). For example, the\nstopping criterion defined by  tolmxf  relates to these scaled stresses.",
            "title": "fxcartfactor"
        },
        {
            "location": "/input_variables/varrlx/#ga_algor",
            "text": "Mnemonics: Genetic Algorithm - ALGOrithm selection \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Choosing method to make the structure selection. Only the enthalpy is used now\nbut we plan to include, energy, electronic band gap and alchemical potentials.\nRight now only value of 1 (enthalpy) works.",
            "title": "ga_algor"
        },
        {
            "location": "/input_variables/varrlx/#ga_fitness",
            "text": "Mnemonics: Genetic Algorithm FITNESS function selection \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Different methodologies to perform the roulette-wheel selection of parents.\nEven though, the objective function is the crystalline enthalpy (H_i), the\nweight of the population elements to be chosen from in a roulette-wheel\nselection can be given through different functions. We consider the following\ncases. \n1. F = H_i / Sum H_i \n2. F = exp(-(H_i-H_min)) / Sum exp(-(H_i-H_min)) \n3. F = (1/n_i) / Sum (1/n_i). Where n_i is the position in the ordered list\nof enthalpies",
            "title": "ga_fitness"
        },
        {
            "location": "/input_variables/varrlx/#ga_n_rules",
            "text": "Mnemonics: Genetic Algorithm Number of RULES \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Different genetic rules have been implemented and the user has the change to\nchoose between any of them. Right now we have 4 rules. See  ga_rules",
            "title": "ga_n_rules"
        },
        {
            "location": "/input_variables/varrlx/#ga_opt_percent",
            "text": "Mnemonics: Genetic Algorithm OPTimal PERCENT \nVariable type: real \nDimensions: scalar \nDefault value: 0.2    Percentage of the population that according to the fitness function passes to\nthe following iteration.",
            "title": "ga_opt_percent"
        },
        {
            "location": "/input_variables/varrlx/#ga_rules",
            "text": "Mnemonics: Genetic Algorithm RULES \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Different genetic rules have been implemented and the user has the change to\nchoose between any of them. The chosen number of rules have been defined in\n[[ga_n_rules]    Implemented rules are \n1) crossover. Two parents are randomly chosen and two springs are mixed from\nthe two by (a) choosing randomly (through Fitness function) two parents and\nthen randomly rotating and shifting the coordinates withing that particular\ncell. (b) Slice every one of the unit cell of the parents along a random\ndirection and creating the spring offs from the pieces of the two parents. \n2) Vector flip mutation. From the coordinates from a given parent, a piece of\nit is inverted. \n3) random strain. A random anisotropic deformation is given to the unit cell. \n4) Coordinates mutation of 1/4 of the whole coordinates.",
            "title": "ga_rules"
        },
        {
            "location": "/input_variables/varrlx/#getcell",
            "text": "Mnemonics: GET CELL parameters from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    This variable is typically used to chain the calculations, in the multi-\ndataset mode ( ndtset >0), since it describes from which dataset acell  and  rprim  are to be taken, as input of the present dataset. The\ncell parameters are  EVOLVING  variables, for which such a chain of\ncalculations is useful. \nIf ==0, no use of previously computed values must occur. \nIf it is positive, its value gives the index of the dataset from which the\ndata are to be used as input data. It must be the index of a dataset already\ncomputed in the SAME run. \nIf equal to -1, the output data of the previous dataset must be taken, which\nis a frequently occurring case. However, if the first dataset is treated, -1\nis equivalent to 0, since no dataset has yet been computed in the same run. \nIf another negative number, it indicates the number of datasets to go backward\nto find the needed data (once again, going back beyond the first dataset is\nequivalent to using a null get variable).",
            "title": "getcell"
        },
        {
            "location": "/input_variables/varrlx/#getvel",
            "text": "Mnemonics: GET VEL from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    These variables are typically used to chain the calculations, in the multi-\ndataset mode ( ndtset >0) since they describe from which dataset the\ncorresponding output variables are to be taken, as input of the present\ndataset. The atomic positions and velocities are  EVOLVING  variables, for\nwhich such a chain of calculation is useful. \nNote that the use of   getxcart   and   getxred   differs when  acell \nand  rprim  are different from one dataset to the other. \nIf ==0, no use of previously computed values must occur. \nIf it is positive, its value gives the index of the dataset from which the\ndata are to be used as input data. It must be the index of a dataset already\ncomputed in the SAME run. \nIf equal to -1, the output data of the previous dataset must be taken, which\nis a frequently occurring case. However, if the first dataset is treated, -1\nis equivalent to 0, since no dataset has yet been computed in the same run. \nIf another negative number, it indicates the number of datasets to go backward\nto find the needed data (once again, going back beyond the first dataset is\nequivalent to using a null get variable). \nNote :   getxred   and   getxcart   cannot be simultaneously non-zero for\nthe same dataset. On the other hand the use of  getvel  with   getxred  \nis allowed, despite the different coordinate system.",
            "title": "getvel"
        },
        {
            "location": "/input_variables/varrlx/#getxcart",
            "text": "Mnemonics: GET XCART from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    These variables are typically used to chain the calculations, in the multi-\ndataset mode ( ndtset >0) since they describe from which dataset the\ncorresponding output variables are to be taken, as input of the present\ndataset. The atomic positions and velocities are  EVOLVING  variables, for\nwhich such a chain of calculation is useful. \nNote that the use of  getxcart  and   getxred   differs when  acell  and rprim  are different from one dataset to the other. \nIf ==0, no use of previously computed values must occur. \nIf it is positive, its value gives the index of the dataset from which the\ndata are to be used as input data. It must be the index of a dataset already\ncomputed in the SAME run. \nIf equal to -1, the output data of the previous dataset must be taken, which\nis a frequently occurring case. However, if the first dataset is treated, -1\nis equivalent to 0, since no dataset has yet been computed in the same run. \nIf another negative number, it indicates the number of datasets to go backward\nto find the needed data (once again, going back beyond the first dataset is\nequivalent to using a null get variable). \nNote :   getxred   and  getxcart  cannot be simultaneously non-zero for\nthe same dataset. On the other hand the use of   getvel   with   getxred  \nis allowed, despite the different coordinate system.",
            "title": "getxcart"
        },
        {
            "location": "/input_variables/varrlx/#getxred",
            "text": "Mnemonics: GET XRED from \u2026 \nVariable type: integer \nDimensions: scalar \nDefault value: 0    These variables are typically used to chain the calculations, in the multi-\ndataset mode ( ndtset >0) since they describe from which dataset the\ncorresponding output variables are to be taken, as input of the present\ndataset. The atomic positions and velocities are  EVOLVING  variables, for\nwhich such a chain of calculation is useful. \nNote that the use of   getxcart   and  getxred  differs when  acell  and rprim  are different from one dataset to the other. \nIf ==0, no use of previously computed values must occur. \nIf it is positive, its value gives the index of the dataset from which the\ndata are to be used as input data. It must be the index of a dataset already\ncomputed in the SAME run. \nIf equal to -1, the output data of the previous dataset must be taken, which\nis a frequently occurring case. However, if the first dataset is treated, -1\nis equivalent to 0, since no dataset has yet been computed in the same run. \nIf another negative number, it indicates the number of datasets to go backward\nto find the needed data (once again, going back beyond the first dataset is\nequivalent to using a null get variable). \nNote :  getxred  and   getxcart   cannot be simultaneously non-zero for\nthe same dataset. On the other hand the use of   getvel   with  getxred \nis allowed, despite the different coordinate system.",
            "title": "getxred"
        },
        {
            "location": "/input_variables/varrlx/#goprecon",
            "text": "Mnemonics: Geometry Optimization PRECONditioner equations \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Set the kind of preconditioner to be used for Geometry Optimization \n(Note : Under development now (2011.05.20))   goprecon =0 : No preconditioner   goprecon =[1-9] : Linear preconditioner   goprecon =[11-19] : Non-linear preconditioner",
            "title": "goprecon"
        },
        {
            "location": "/input_variables/varrlx/#goprecprm",
            "text": "Mnemonics: Geometry Optimization PREconditioner PaRaMeters equations \nVariable type: real \nDimensions: (3) \nDefault value: 0    Set the paramenters use by the preconditioner to be used for Geometry\nOptimization \n(Note : Under development now (2011.06.06))",
            "title": "goprecprm"
        },
        {
            "location": "/input_variables/varrlx/#iatcon",
            "text": "Mnemonics: Indices of AToms in CONstraint equations \nVariable type: integer \nDimensions: ( natcon , nconeq ) \nDefault value: 0    Gives the indices of the atoms appearing in each of the  nconeq  independent\nequations constraining the motion of atoms during structural optimization or\nmolecular dynamics (see  nconeq  ,  natcon , and  wtatcon ). \n(Note : combined with wtatcon to give internal representation of the latter -\nthis should be described)",
            "title": "iatcon"
        },
        {
            "location": "/input_variables/varrlx/#iatfix",
            "text": "Mnemonics: Indices of AToms that are FIXed  \nVariable type: integer \nDimensions: ( natfix ) \nDefault value: None \nOnly relevant if  natfix  > 0    Give the index (in the range 1 to  natom  ) of each atom which is to be held\nfixed for structural optimization or molecular dynamics. The variable iatfix  lists those fixed in the three directions, while the variables iatfixx ,  iatfixy , and  iatfixz , allow to fix some atoms along x, y\nor z directions, or a combination of these.  WARNING : The implementation is inconsistent !! For  ionmov  ==1, the fixing\nof directions was done in cartesian coordinates, while for the other values of ionmov , it was done in reduced coordinates. Sorry for this.  There is no harm in fixing one atom in the three directions using  iatfix ,\nthen fixing it again in other directions by mentioning it in   iatfixx   ,  iatfixy   or   iatfixz   . \nThe internal representation of these input data is done by the mean of one\nvariable  [iatfix] , defined for each direction and each atom,\nbeing 0 if the atom is not fixed along the direction, and 1 if the atom is\nfixed along the direction. When some atoms are fixed along 1 or 2 directions,\nthe use of symmetries is restricted to symmetry operations whose (3x3)\nmatrices  symrel  are diagonal. \nIf the geometry builder is used,  iatfix  will be related to the\npreprocessed set of atoms, generated by the geometry builder. The user must\nthus foresee the effect of this geometry builder (see  objarf ).",
            "title": "iatfix"
        },
        {
            "location": "/input_variables/varrlx/#iatfixx",
            "text": "Mnemonics: Indices of AToms that are FIXed along the X direction \nVariable type: integer \nDimensions: ( natfixx ) \nDefault value: None \nOnly relevant if  natfixx  > 0    Give the index (in the range 1 to  natom  ) of each atom which is to be held\nfixed ALONG THE X direction for structural optimization or molecular dynamics.\nThe variable  iatfix  lists those fixed in the three directions, while the\nvariables  iatfixx ,  iatfixy , and  iatfixz , allow to fix some atoms\nalong x, y or z directions, or a combination of these. See the variable iatfix  for more information.",
            "title": "iatfixx"
        },
        {
            "location": "/input_variables/varrlx/#iatfixy",
            "text": "Mnemonics: Indices of AToms that are FIXed along the Y direction \nVariable type: integer \nDimensions: ( natfixy ) \nDefault value: None \nOnly relevant if  natfixy  > 0    Give the index (in the range 1 to  natom  ) of each atom which is to be held\nfixed ALONG THE Y direction for structural optimization or molecular dynamics.\nThe variable  iatfix  lists those fixed in the three directions, while the\nvariables  iatfixx ,  iatfixy , and  iatfixz , allow to fix some atoms\nalong x, y or z directions, or a combination of these. See the variable iatfix  for more information.",
            "title": "iatfixy"
        },
        {
            "location": "/input_variables/varrlx/#iatfixz",
            "text": "Mnemonics: Indices of AToms that are FIXed along the Z direction \nVariable type: integer \nDimensions: ( natfixz ) \nDefault value: None \nOnly relevant if  natfixz  > 0    Give the index (in the range 1 to  natom  ) of each atom which is to be held\nfixed ALONG THE Z direction for structural optimization or molecular dynamics.\nThe variable  iatfix  lists those fixed in the three directions, while the\nvariables  iatfixx ,  iatfixy , and  iatfixz , allow to fix some atoms\nalong x, y or z directions, or a combination of these. See the variable iatfix  for more information.",
            "title": "iatfixz"
        },
        {
            "location": "/input_variables/varrlx/#imgmov",
            "text": "Mnemonics: IMaGe MOVEs \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Control the collective changes of images (see  nimage , npimage , dynimage ,  ntimimage ,  tolimg ,  istatimg ,  prtvolimg ). \nSimilar to  ionmov  in spirit, although here, a population of self-\nconsistent calculations for different geometries is managed, while with ionmov , only one geometry for self-consistent calculation is managed. \nIn this respect the maximal number of time step for image propagation is ntimimage , corresponding to the input variable  ntime  of the single\ngeometry case. Also, the stopping criterion is governed by  tolimg ,\ncorresponding to the input variable  toldfe  of the single geometry case.\nThe stopping condition is crude: the image propagation is stopped when the\nmean value (over dynamic images) of the absolute difference of total energy\n(previous and current time step) is less than  tolimg .  Actually, there might be combinations of  ionmov  and  imgmov  in which\nthe two mechanisms are at work. Usually, however, only one mechanism will be\nactivated (so, usually, either  ntimimage  is bigger than one OR  ntime \nis bigger than one). In order for the user to acquire a mental representation\nof the interplay between  ionmov  and  imgmov , here is a F90 pseudo-code\npresenting the interplay between the different above-mentioned input\nvariables, as well as with the parallelism (see input variable  npimage ).  do itimimage=1,ntimimage\n  do iimage=1,nimage\n    (possibly, parallelisation over images)\n    do itime=1,ntime\n      Compute the forces and stresses for image(iimage)\n      Examine whether the stopping criterion defined by tolmxf is fulfilled\n      Predict the next geometry for image(iimage) using ionmov\n    enddo\n  enddo\n  Examine whether the stopping criterion defined by tolimg is fulfilled\n  Predict the next geometries for all images using imgmov\nenddo   = 0 => simply   copy   images from previous timimage step.  = 1 => move images according to   Steepest Descent   following the (scaled) forces, the scaling factor being  fxcartfactor .   = 2 =>   String Method   for finding Minimal Energy Path (MEP) connecting to minima (see PRB 66, 052301 (2002)); the algorithm variant can be selected with the  string_algo  keyword (Simplified String Method by default). The solver for the Ordinary Differential Equation (ODE) can be selected with  mep_solver  (steepest-descent by default). See also  mep_mxstep  keyword.  = 3 => (tentatively, not yet coded)   Metadynamics  .  = 4 => (tentatively, not yet coded)   Genetic Algorithm .  = 5 =>   Nudged Elastic Band (NEB)   for finding Minimal Energy Path (MEP) connecting two minima; the algorithm variant can be selected with the  neb_algo  keyword (NEB+improved tangent by default). The solver for the Ordinary Differential Equation (ODE) can be selected with  mep_solver  (steepest-descent by default). The spring constant connecting images along the path is defined by  neb_spring . See also  mep_mxstep  keyword.  = 9 or 13 =>   Path-Integral Molecular Dynamics   (see e.g. [D. Marx and M. Parrinello, J. Chem. Phys. 104, 4077 (1996)]). Will use 9 for   Langevin thermostat   (associated friction coefficient given by  vis ) and 13 for   Nose-Hoover thermostat chains   (associated input variables are the number of thermostats in the chains,  nnos , and the masses of these thermostats  qmass ).  nimage  is the Trotter number (no use of  dynimage ); possible transformations of coordinates are defined by  pitransform ; Fictitious masses of the atoms (possibly different from the true masses given by  amu ) can be specified by  pimass . At present, it is only possible to perform calculations in the (N,V,T) ensemble ( optcell =0).   No meaning for RF calculations.",
            "title": "imgmov"
        },
        {
            "location": "/input_variables/varrlx/#ionmov",
            "text": "Mnemonics: IONic MOVEs \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Choice of algorithm to control the displacements of ions, and eventually (see optcell ) changes of cell shape and size.    0=> Do not move ions;       1=> Move atoms using molecular dynamics with optional viscous damping (friction linearly proportional to velocity). The viscous damping is controlled by the parameter \u201c vis \u201d. If actual undamped molecular dynamics is desired, set  vis  to 0. The implemented algorithm is the generalisation of the Numerov technique (6th order), but is NOT invariant upon time-reversal, so that the energy is not conserved. The value  ionmov =6 will usually be preferred, although the algorithm that is implemented is lower-order. The time step is governed by  dtion .    Purpose:   Molecular dynamics (if  vis =0), Structural optimization (if  vis >0)    Cell optimization:   No (Use  optcell =0 only)    Related variables:   Viscous parameter  vis , time step  dtion , index of atoms fixed  iatfix        2=> Conduct structural optimization using the Broyden-Fletcher-Goldfarb-Shanno minimization (BFGS). This is much more efficient for structural optimization than viscous damping, when there are less than about 10 degrees of freedom to optimize.    Purpose:   Structural optimization    Cell optimization:   Yes (if  optcell /=0)    Related variables:         3=> Conduct structural optimization using the Broyden-Fletcher-Goldfarb-Shanno minimization (BFGS), modified to take into account the total energy as well as the gradients (as in usual BFGS).  \nSee the paper by [Schlegel, J. Comp. Chem. 3, 214 (1982)]. Might be better\nthan  ionmov =2 for few degrees of freedom (less than 3 or 4). Can be very\nunstable - use with caution!   Purpose:   Structural optimization    Cell optimization:   Yes (if  optcell /=0)    Related variables:         4=> Conjugate gradient algorithm for simultaneous optimization of potential and ionic degrees of freedom. It can be used with  iscf =2 and  iscf  =5 or 6 (WARNING : this is under development, and does not work very well in many cases).    Purpose:   Structural optimization    Cell optimization:   No (Use  optcell =0 only)    Related variables:         5=> Simple relaxation of ionic positions according to (converged) forces. Equivalent to  ionmov =1 with zero masses, albeit the relaxation coefficient is not  vis , but  iprcfc .    Purpose:   Structural optimization    Cell optimization:   No (Use  optcell =0 only)    Related variables:         6=> Molecular dynamics using the Verlet algorithm, see [Allen & Tildesley \u201cComputer simulation of liquids\u201d 1987, p 81]. The only related parameter is the time step ( dtion ).    Purpose:   Molecular dynamics    Cell optimization:   No (Use  optcell =0 only)    Related variables:   time step  dtion , index of atoms fixed  iatfix        7=> Quenched Molecular dynamics using the Verlet algorithm, and stopping each atom for which the scalar product of velocity and force is negative. The only related parameter is the time step ( dtion ). The goal is not to produce a realistic dynamics, but to go as fast as possible to the minimum. For this purpose, it is advised to set all the masses to the same value (for example, use the Carbon mass, i.e. set  amu  to 12 for all type of atoms).    Purpose:   Structural optimization    Cell optimization:   No (Use  optcell =0 only)    Related variables:   time step  dtion , index of atoms fixed  iatfix        8=> Molecular dynamics with Nose-Hoover thermostat, using the Verlet algorithm.    Purpose:   Molecular dynamics    Cell optimization:   No (Use  optcell =0 only)    Related variables:   time step ( dtion ), Temperatures ( mdtemp ), and thermostat mass ( noseinert ).       9=> Langevin molecular dynamics.    Purpose:   Molecular dynamics    Cell optimization:   No (Use  optcell =0 only)    Related variables:   time step ( dtion ), temperatures ( mdtemp ) and friction coefficient ( friction ).       10=> Delocalized internal coordinates. with BFGS simple    Purpose:   Structural optimization    Cell optimization:   No (Use  optcell =0 only)    Related variables:         11=> Delocalized internal coordinates. with BFGS using total energy    Purpose:   Structural optimization    Cell optimization:   No (Use  optcell =0 only)    Related variables:         12=> Isokinetic ensemble molecular dynamics. The equation of motion of the ions in contact with a thermostat are solved with the algorithm proposed by Zhang [J. Chem. Phys. 106, 6102 (1997)], as worked out by Minary et al [J. Chem. Phys. 188, 2510 (2003)]. The conservation of the kinetic energy is obtained within machine precision, at each step.  \n~~ Related parameters : the time step ( dtion ), the temperatures\n( mdtemp ), and the friction coefficient ( friction ). ~~   Purpose:   Molecular dynamics    Cell optimization:   No (Use  optcell =0 only)    Related variables:         13=> Isothermal/isenthalpic ensemble. The equation of motion of the ions in contact with a thermostat and a barostat are solved with the algorithm proposed by Martyna, Tuckermann Tobias and Klein [Mol. Phys., 1996, p. 1117].  \nIf optcell=1 or 2, the mass of the barostat ( bmass ) must be given in\naddition.   Purpose:   Molecular dynamics    Cell optimization:   Yes (if  optcell /=0)    Related variables:   The time step ( dtion ), the temperatures ( mdtemp ), the number of thermostats ( nnos ), and the masses of thermostats ( qmass ).       14=> Simple molecular dynamics with a symplectic algorithm proposed by S.Blanes and P.C.Moans [called SRKNa14 in Practical symplectic partitioned Runge\u2013Kutta and Runge\u2013Kutta\u2013Nystrom methods, Journal of Computational and Applied Mathematics archive, volume 142, issue 2 (May 2002), pages 313 - 330] of the kind first published by H. Yoshida [Construction of higher order symplectic integrators, Physics Letters A, volume 150, number 5 to 7, pages 262 - 268]. This algorithm requires at least 14 evaluation of the forces (actually 15 are done within Abinit) per time step. At this cost it usually gives much better energy conservation than the verlet algorithm ( ionmov  6) for a 30 times bigger value of  dtion . Notice that the potential energy of the initial atomic configuration is never evaluated using this algorithm.    Purpose:   Molecular dynamics    Cell optimization:   No (Use  optcell =0 only)    Related variables:         20=> Direct inversion of the iterative subspace. Given a starting point  xred  that is a vector of length 3* natom  (reduced nuclei coordinates), and unit cell parameters ( rprimd ) this routine uses the DIIS (direct inversion of the iterative subspace) to minimize the gradient (forces) on atoms. The preconditioning used to compute errors from gradients is using an inverse hessian matrix obtained by a BFGS algorithm. This method is known to converge to the nearest point where gradients vanish. This is efficient to refine positions around a saddle point for instance.    Purpose:   Structural optimization    Cell optimization:   No (Use  optcell =0 only)    Related variables:   DIIS memory  diismemory        22=> Conduct structural optimization using the Limited-memory Broyden-Fletcher-Goldfarb-Shanno minimization (L-BFGS). The working routines were based on the original implementation of J. Nocera available on netlib.org. This algorithm can be much better than the native implementation of BFGS in ABINIT ( ionmov =2) when one approaches convergence, perhaps because of better treatment of numerical details.   Purpose:   Structural optimization    Cell optimization:   Yes (if  optcell /=0)    Related variables:         23=> Use of Learn on The Fly method (LOTF) for Molecular Dynamics. In the framework of isokinetic MD, the atomic forces and positions are computed by using LOTF interpolation. A SCF computation is performed only any  lotf_nitex  steps. The results of the SCF are used to compute the parameters of a short range classical potential (for the moment only the glue potential for gold is implemented). Then these parameters are continuously tuned to compute atomic trajectories. LOTF has to be enabled at configure time. If LOTF is not enabled and  ionmov =23, abinit will set automatically  ionmov =12.  \nThe LOTF cycle is divided in the following steps: \na) Initialization (SFC at t=0) and computation of potential parameters. \nb) Extrapolation of the atomic forces and positions for  lotf_nitex  time\nstep. To perform this extrapolation, the potential computed in a) is used\n(Verlet algorithm). \nc) SFC at t= lotf_nitex . Computation of the potential parameters. \nd) LOTF interpolation, linear interpolation of the potential parameters and\ncomputation of the atomic forces and positions between t=0 and t=lotf_nitex.       Purpose:   Molecular Dynamics    Cell optimization:   No (Use  optcell =0 only)    Related variables:    dtion ,  lotf_classic ,  lotf_nitex ,  lotf_nneigx ,  lotf_version .       24=> Simple constant energy molecular dynamics using the velocity Verlet symplectic algorithm (second order), see e.g. [E. Hairer et al. Acta Numerica. 12, 399 (2003)]. The only related parameter is the time step ( dtion ).    Purpose:   Molecular dynamics    Cell optimization:   No (Use  optcell =0 only)    Related variables:   time step  dtion        25=> Hybrid Monte Carlo sampling of the ionic positions at fixed temperature and unit cell geometry (NVT ensemle). The underlying molecular dynamics corresponds to ionmov=24. The related parameters are the time step ( dtion ) and thermostat temperature ( mdtemp ).    Purpose:   Monte Carlo sampling    Cell optimization:   No (Use  optcell =0 only)    Related variables:   time step  dtion , thermostat temperature  mdtemp ,       30=> Using a supercell, calculate a self consistent phonon structure as in PRL 100 095901 (2008). The initial phonon eigenvectors and eigenvalues are read in, and then atoms are displaced according to the normal modes populated at a given temperature until convergence of the vibrational free energy (or so I hope)    Purpose:   Phonon structure    Cell optimization:   No (Use  optcell =0 only)    Related variables:         No meaning for RF calculations.",
            "title": "ionmov"
        },
        {
            "location": "/input_variables/varrlx/#istatimg",
            "text": "Mnemonics: Integer governing the computation of STATic IMaGes \nVariable type: integer \nDimensions: scalar \nDefault value: 1    This input variable is relevant when sets of images are activated (see imgmov ). \nNot all images might be required to evolve from one time step to the other\n(see dynimage ): these are static images. \nIf  istatimg =0, the total energy of static images is not computed (but\nstatic images are used to make the dynamic images evolve). This can be useful\nto save CPU time. \nIf  istatimg =1, the total energy of static images is computed.",
            "title": "istatimg"
        },
        {
            "location": "/input_variables/varrlx/#mdtemp",
            "text": "Mnemonics: Molecular Dynamics TEMPeratures \nVariable type: real \nDimensions: (2) \nDefault value: [300, 300]    Give the initial and final temperature of the Nose-Hoover thermostat\n( ionmov =8) and Langevin dynamics ( ionmov =9), in Kelvin. This\ntemperature will change linearly from the initial temperature   mdtemp(1)  \nat itime=1 to the final temperature   mdtemp(2)   at the end of the ntime  timesteps.",
            "title": "mdtemp"
        },
        {
            "location": "/input_variables/varrlx/#mdwall",
            "text": "Mnemonics: Molecular Dynamics WALL location \nVariable type: real \nDimensions: scalar \nDefault value: 10000.0 \nComment: the walls are extremely far away    Gives the location (atomic units) of walls on which the atoms will bounce\nback. when  ionmov =6, 7, 8 or 9. For each cartesian direction idir=1, 2 or\n3, there is a pair of walls with coordinates xcart(idir)=-wall and\nxcart(idir)=rprimd(idir,idir)+wall . Supposing the particle will cross the\nwall, its velocity normal to the wall is reversed, so that it bounces back. \nBy default, given in Bohr atomic units (1 Bohr=0.5291772108 Angstroms),\nalthough Angstrom can be specified, if preferred, since  mdwall  has the\n\u2018 LENGTH \u2018 characteristics.",
            "title": "mdwall"
        },
        {
            "location": "/input_variables/varrlx/#mep_mxstep",
            "text": "Mnemonics: Minimal Energy Path search: MaXimum allowed STEP size \nVariable type: real \nDimensions: scalar \nDefault value: 0.4 if  imgmov ==5,\n100.0 otherwise.  Relevant only when  imgmov =1 (Steepest-Descent), 2 (String Method) or 5\n(Nudged Elastic Band). \nThe optimizer used to solve the Ordinary Differential Equation (ODE) can be\nconstrained with a maximum allowed step size for each image. By default this\nfeature is only activated for Nudged Elastic Band (NEB) and the value is\ninspired by _ J. Chem. Phys. 128, 134106 (2008) _ . \nNote that the step size is defined for each image as _ step = SQRT[SUM(R_i dot\nR_i)] _ where the _ R_i _ are the positions of the atoms in the cell.",
            "title": "mep_mxstep"
        },
        {
            "location": "/input_variables/varrlx/#mep_solver",
            "text": "Mnemonics: Minimal Energy Path ordinary differential equation SOLVER \nVariable type: integer \nDimensions: scalar \nDefault value: None    Relevant only when  imgmov =2 (String Method) or 5 (Nudged Elastic Band). \nGives the algorithm used to solve the Ordinary Differential Equation (ODE)\nwhen searching for a Minimal Energy Path (MEP). \nPossible values can be:      0=>   Steepest-Descent algorithm   following the (scaled) forces, the scaling factor being  fxcartfactor  (forward Euler method).  \nCompatible with all MEP search methods.    1=>   Quick-min optimizer   following the (scaled) forces, the scaling factor being  fxcartfactor . The \u201cquick minimizer\u201d improves upon the steepest-descent method by accelerating the system in the direction of the forces. The velocity (of the image) is projected long the force and cancelled if antiparallel to it.  \nCompatible only with Nudged Elastic Band ( imgmov =5). \n_ See, for instance: J. Chem. Phys. 128, 134106 (2008). _      2=>   Local Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm   ; each image along the band is minimized with a different instance of the BFGS optimizer.  \nCompatible only with Nudged Elastic Band ( imgmov =5).   See, for instance: J. Chem. Phys. 128, 134106 (2008).  \nIN  DEVELOP PMENT - NOT RELIABLE    3=>   Global Broyden-Fletcher-Goldfarb-Shanno (GL-BFGS) algorithm   ; all images along the band are minimized with a single instance of the BFGS optimizer.  \nCompatible only with Nudged Elastic Band ( imgmov =5).   See, for instance: J. Chem. Phys. 128, 134106 (2008).  \nIN  DEVELOP PMENT - NOT RELIABLE    4=>   Fourth-order Runge-Kutta method   ; the images along the band are moved every four steps (1<=istep<= ntimimage ) following the Runge-Kutta algorithm, the time step being  fxcartfactor .  \nCompatible only with Simplified String Method ( imgmov =2 and string_algo =1 or 2). \n_ See: J. Chem. Phys. 126, 164103 (2007). _    All of the optimizers can be constrained with a maximum allowed step size for\neach image; see  mep_mxstep . This is by default the case of the Nudged\nElastic Band ( imgmov =5).",
            "title": "mep_solver"
        },
        {
            "location": "/input_variables/varrlx/#natcon",
            "text": "Mnemonics: Number of AToms in CONstraint equations \nVariable type: integer \nDimensions: ( nconeq ) \nDefault value: 0    Gives the number of atoms appearing in each of the  nconeq  independent\nequations constraining the motion of atoms during structural optimization or\nmolecular dynamics (see  nconeq  ,  iatcon , and  wtatcon ).",
            "title": "natcon"
        },
        {
            "location": "/input_variables/varrlx/#natfix",
            "text": "Mnemonics: Number of Atoms that are FIXed \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nComment: (no atoms held fixed)    Gives the number of atoms (not to exceed  natom ) which are to be held fixed\nduring a structural optimization or molecular dynamics. \nWhen  natfix  > 0,  natfix  entries should be provided in array iatfix  .",
            "title": "natfix"
        },
        {
            "location": "/input_variables/varrlx/#natfixx",
            "text": "Mnemonics: Number of Atoms that are FIXed along the X direction \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of atoms (not to exceed  natom ) which are to be held fixed\nalong the X direction during a structural optimization or molecular dynamics. \nWhen  natfixx  > 0,  natfixx  entries should be provided in array iatfixx .",
            "title": "natfixx"
        },
        {
            "location": "/input_variables/varrlx/#natfixy",
            "text": "Mnemonics: Number of Atoms that are FIXed along the Y direction \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of atoms (not to exceed  natom ) which are to be held fixed\nalong the Y direction during a structural optimization or molecular dynamics. \nWhen  natfixy  > 0,  natfixy  entries should be provided in array iatfixy",
            "title": "natfixy"
        },
        {
            "location": "/input_variables/varrlx/#natfixz",
            "text": "Mnemonics: Number of Atoms that are FIXed along the Z direction \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of atoms (not to exceed  natom ) which are to be held fixed\nalong the Z direction during a structural optimization or molecular dynamics. \nWhen  natfixz  > 0,  natfixz  entries should be provided in array iatfixz .",
            "title": "natfixz"
        },
        {
            "location": "/input_variables/varrlx/#nconeq",
            "text": "Mnemonics: Number of CONstraint EQuations \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of independent equations constraining the motion of atoms\nduring structural optimization or molecular dynamics (see  natcon  , iatcon , and  wtatcon ).",
            "title": "nconeq"
        },
        {
            "location": "/input_variables/varrlx/#neb_algo",
            "text": "Mnemonics: Nudged Elastic Band ALGOrithm \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  imgmov ==5    Gives the variant of the NEB method used. \nPossible values can be:      0=>   Original NEB method   .  \n_ See: Classical and Quantum Dynamics in Condensed Phase Simulations, edited\nby Berne, Ciccotti, Coker (World Scientific, Singapore, 1998), pp. 385-404 _    1=>   NEB + improved tangent   .  \nThe Improved Tangent Method builds on the NEB with an improved estimate of the\ntangent direction and a resulting change of the component of the spring force\nacting on the images. \n_ See: J. Chem. Phys. 113, 9978 (2000). _    2=>   Climbing-Image NEB (CI-NEB)   .  \nThe CI-NEB method constitutes a small modification to the NEB method.\nInformation about the shape of the MEP is retained, but a rigorous convergence\nto a saddle point is also obtained. By default the spring constants are\nvariable (see  neb_spring ). As the image with the highest energy has to be\nidentified, the calculation begins with several iterations of the standard NEB\nalgorithm. The effective CI-NEB begins at the  cineb_start  iteration. \n_ See: J. Chem. Phys. 113, 9901 (2000). _    Note that, in all cases, it is possible to define the value of the spring\nconstant connecting images with  neb_spring , keeping it constant or\nallowing it to vary between 2 values (to have higher resolution close to the\nsaddle point).",
            "title": "neb_algo"
        },
        {
            "location": "/input_variables/varrlx/#neb_spring",
            "text": "Mnemonics: Nudged Elastic Band: SPRING constant \nVariable type: real \nDimensions: (2) \nDefault value: [0.02, 0.15] if  neb_algo ==2,\n[0.05, 0.05] otherwise.  Only relevant if  imgmov ==5    Gives the minimal and maximal values of the spring constant connecting images\nfor the NEB method. \nIn the standard \u201cNudged Elastic Band\u201d method, the spring constant is constant\nalong the path, but, in order to have higher resolution close to the saddle\npoint, it can be better to have stronger springs close to it. \n_ See: J. Chem. Phys. 113, 9901 (2000). _",
            "title": "neb_spring"
        },
        {
            "location": "/input_variables/varrlx/#nimage",
            "text": "Mnemonics: Number of IMAGEs \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Give the number of images (or replicas) of the system, for which the forces\nand stresses might be computed independently, in the context of the string\nmethod, the genetic algorithm, hyperdynamics or Path-Integral Molecular\nDynamics depending on the value of  imgmov ). Related input variables : dynimage ,  npimage ,  ntimimage  and  prtvolimg . \nImages might differ by the position of atoms in the unit cell, their velocity,\nas well as by their cell geometry. The following input variables might be used\nto define the images :   acell    amu    angdeg    dmatpawu    jpawu    mixalch    rprim    upawu    vel    vel_cell    xangst    xcart    xred     These input variables, non-modified, will be used to define the image with\nindex 1. For the image with the last index, the input file might specify the\nvalues of such input variables, appended with \u201c_lastimg\u201d, e.g. :   acell_lastimg   rprim_lastimg   xcart_lastimg   \u2026    By default, these values will be interpolated linearly to define values for\nthe other images, unless there exist specific values for some images, for\nwhich the string \u201clast\u201d has to be replaced by the index of the image, e.g. for\nthe image number 4 :   acell_4img   rprim_4img   xcart_4img   \u2026    It is notably possible to specify the starting point and the end point of the\npath (of images), while specifying intermediate points.    It usually happen that the images do not have the same symmetries and space\ngroup. ABINIT has not been designed to use different set of symmetries for\ndifferent images. ABINIT will use the symmetry and space group of the image\nnumber 2, that is expected to have a low number of symmetries. This might lead\nto erroneous calculations, in case some image has even less symmetry. By\ncontrast, there is no problem if some other image has more symmetries than\nthose of the second image.",
            "title": "nimage"
        },
        {
            "location": "/input_variables/varrlx/#nnos",
            "text": "Mnemonics: Number of NOSe masses \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of thermostats in the Martyna et al. chain of oscillators\nthermostats. The thermostat chains can be used either to perform Molecular\nDynamics (MD) ( ionmov =13) or to perform Path Integral Molecular Dynamics\n(PIMD) ( imgmov =13). \nThe mass of these thermostats is given by  qmass .",
            "title": "nnos"
        },
        {
            "location": "/input_variables/varrlx/#noseinert",
            "text": "Mnemonics: NOSE thermostat INERTia factor \nVariable type: real \nDimensions: scalar \nDefault value: 100000 \nOnly relevant if  ionmov ==8    Give the inertia factor WT of the Nose-Hoover thermostat (when  ionmov =8),\nin atomic units of weight length2, that is (electron mass) (Bohr)2. The\nequations of motion are : MI d2RI/dt2= FI - dX/dt MI dRI/dt and WT d2X/dt2=\nSum(I) MI (dRI/dt)2 - 3NkBT where I represent each nucleus, MI is the mass of\neach nucleus (see  amu ), RI is the coordinate of each nucleus (see xcart ), dX/dt is a dynamical friction coefficient, and T is the\ntemperature of the thermostat (see  mdtemp ).",
            "title": "noseinert"
        },
        {
            "location": "/input_variables/varrlx/#ntime",
            "text": "Mnemonics: Number of TIME steps \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Gives the number of molecular dynamics time steps or Broyden structural\noptimization steps to be done if  ionmov  is non-zero. \nNote that at the present the option  ionmov =1 is initialized with four\nRunge-Kutta steps which costs some overhead in the startup. By contrast, the\ninitialisation of other  ionmov  values is only one SCF call.  ntime  is ignored if  ionmov =0.",
            "title": "ntime"
        },
        {
            "location": "/input_variables/varrlx/#ntimimage",
            "text": "Mnemonics: Number of TIME steps for IMAGE propagation \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Gives the maximal number of molecular dynamics time steps or structural\noptimization steps to be done for the set of images, referred to as \u2018image-\ntimesteps\u2019. At each image-timestep, all the images are propagated\nsimultaneously, each according to the algorithm determined by  imgmov  and\nthe usual accompanying input variables, and then the next positions and\nvelocities for each image are determined from the set of results obtained for\nall images.",
            "title": "ntimimage"
        },
        {
            "location": "/input_variables/varrlx/#optcell",
            "text": "Mnemonics: OPTimize the CELL shape and dimensions \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Allows to optimize the unit cell shape and dimensions, when  ionmov >=2 or\n3. The configuration for which the stress almost vanishes is iteratively\ndetermined, by using the same algorithms as for the nuclei positions. Will\neventually modify  acell  and/or  rprim . The ionic positions are ALWAYS\nupdated, according to the forces. A target stress tensor might be defined, see strtarget .   optcell =0 : modify nuclear positions, since  ionmov =2 or 3, but no cell shape and dimension optimisation.  optcell =1 : optimisation of volume only (do not modify  rprim , and allow an homogeneous dilatation of the three components of  acell )  optcell =2 : full optimization of cell geometry (modify  acell  and  rprim  - normalize the vectors of  rprim  to generate the  acell ). This is the usual mode for cell shape and volume optimization. It takes into account the symmetry of the system, so that only the effectively relevant degrees of freedom are optimized.  optcell =3 : constant-volume optimization of cell geometry (modify  acell  and  rprim  under constraint - normalize the vectors of  rprim  to generate the  acell )  optcell =4, 5 or 6 : optimize  [acell] ,  [acell] , or  [acell] , respectively (only works if the two other vectors are orthogonal to the optimized one, the latter being along its cartesian axis).  optcell =7, 8 or 9 : optimize the cell geometry while keeping the first, second or third vector unchanged (only works if the two other vectors are orthogonal to the one left unchanged, the latter being along its cartesian axis).   A few details require attention when performing unit cell optimisation :   one has to get rid of the discontinuities due to discrete changes of plane wave number with cell size, by using a suitable value of  ecutsm ;  one has to allow for the possibility of a larger sphere of plane waves, by using  dilatmx ;  one might have to adjust the scale of stresses to the scale of forces, by using  strfact .  if all the reduced coordinates of atoms are fixed by symmetry, one cannot use  toldff  to stop the SCF cycle. (Suggestion : use  toldfe  with a small value, like 1.0d-10)   It is STRONGLY suggested first to optimize the ionic positions without cell\nshape and size optimization ( optcell =0), then start the cell shape and\nsize optimization from the cell with relaxed ionic positions. Presently\n(v3.1), one cannot restart ( restartxf ) a calculation with a non-zero optcell  value from the (x,f) history of another run with a different non-\nzero  optcell  value. There are still a few problems at that level.",
            "title": "optcell"
        },
        {
            "location": "/input_variables/varrlx/#pimass",
            "text": "Mnemonics: Path Integral fictitious MASSes \nVariable type: real \nDimensions: ( ntypat ) \nDefault value:  ntypat \nOnly relevant if  imgmov =9 or 13    Only relevant if  imgmov =9 or 13 (Path-Integral Molecular Dynamics). \nGives the fictitious masses ( _ D. Marx and M. Parrinello, J. Chem. Phys. 104,\n4077 (1996) _ ) in atomic mass units for each kind of atom in cell. These\nmasses are the inertial masses used in performing Path Integral Molecular\nDynamics (PIMD), they are different from the true masses ( amu ) used to\ndefine the quantum spring that relates the different beads in PIMD. They can\nbe chosen arbitrarily, but an appropriate choice will lead the different\nvariables to move on the same time scale in order to optimize the sampling\nefficiency of the PIMD trajectory. \nIf  pitransform =1 (normal mode transformation), or  pitransform =2\n(staging transformation),  pimass  is automatically set to its optimal\nvalue.",
            "title": "pimass"
        },
        {
            "location": "/input_variables/varrlx/#pimd_constraint",
            "text": "Mnemonics: Path-Integral Molecular Dynamics: CONSTRAINT to be applied on a reaction coordinate \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  imgmov =9 or 13    Only relevant for Path-Integral Molecular Dynamics. \nSelects a constraint to be applied during the PIMD trajectory. The constraint\nis holonomic (it is a relation between the position variables).In practice,\nthe total forces applied to the atomic positions are modified so as to respect\nthe constraint. \nTo date, the available constraints are:     0 : no constraint  1 :  \u201cBlue Moon Ensemble\u201d method . \nThe constraint is a linear combination of the positions of atomic centroids\n(this linear combination is kept constant during the simulation). \nSum[W_i * X_i]=constant \nThe X_i are the coordinates of the atomic centroids. The weights W_i have to\nbe specified with the  [wtatcon] , [iatcon]  and  natcon  input parameters (where  nconeq  is\nfixed to 1). \nMore details on the implementation in:  Y. Komeiji,Chem-Bio Informatics\nJournal 7, 12-23 (2007) .",
            "title": "pimd_constraint"
        },
        {
            "location": "/input_variables/varrlx/#pitransform",
            "text": "Mnemonics: Path Integral coordinate TRANSFORMation \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Only relevant if  imgmov =9 or 13 (Path-Integral Molecular Dynamics).\nCoordinate transformation used in the integration of the Path Integral\nMolecular Dynamics equations of motion. The transformation, with an\nappropriate choice of fictitious masses ( pimass ), is used to force the\ndifferent modes to move on the same time scale, and thus optimize the\nefficiency of the statistical sampling in the corresponding statistical\nensemble. Available with a Langevin thermostat ( imgmov =9) or with Nose-\nHoover chains ( imgmov =13). See M. Tuckerman et al, J. Chem. Phys. 104,\n5579 (1996).  If equal to 0, no transformation is applied (primitive coordinates). \nIf equal to 1, normal mode transformation (in that case,  nimage  must be\nabsolutely EVEN). \nIf equal to 2, staging transformation.",
            "title": "pitransform"
        },
        {
            "location": "/input_variables/varrlx/#prtatlist",
            "text": "Mnemonics: PRinT by ATom LIST of ATom \nVariable type: integer \nDefault value: 0    This is an array of the numbers associated to the index atoms that the user\nwant to print in the output or log files, this is useful when you have a large\nnumber of atoms and you are only interested to follow specific atoms, the\nnumbers associated should be consistent with the list in  xcart  or xred . This input varible does not affect the contents of the \u201cOUT.nc\u201d or\n\u201cHIST.nc\u201d, those are NetCDF files containing the information about all the\natoms.",
            "title": "prtatlist"
        },
        {
            "location": "/input_variables/varrlx/#qmass",
            "text": "Mnemonics: Q thermostat MASS \nVariable type: real \nDimensions: ( nnos ) \nDefault value: *10.0    This are the masses of the chains of  nnos  thermostats to be used when ionmov =13 (Molecular Dynamics) or  imgmov =13 (Path Integral Molecular\nDynamics).  If  ionmov =13 (Molecular Dynamics), this temperature control can be used\nwith   optcell  =0, 1 (homogeneous cell deformation) or 2 (full cell\ndeformation). \nIf  imgmov =13 (Path Integral Molecular Dynamics), this temperature control\ncan be used with   optcell  =0 (NVT ensemble) or 2 (fully flexible NPT\nensemble). In that case,  optcell =2 iS NOT USABLE yet.",
            "title": "qmass"
        },
        {
            "location": "/input_variables/varrlx/#random_atpos",
            "text": "Mnemonics: RANDOM ATomic POSitions \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Control the inner coordinates, which can be generated randomly by using 4\ndifferent methods depending ont its value \n(0) if zero, no random generation and xred are taken as they have been\nintroduced by the user \n(1) if one, particles are generated completly random within the unit cell. \n(2) if two, particles are generated randomly but the inner particle distance\nis always larger than a factor of the sum of the covalent bonds between the\natoms (note : this is incompatible with the definition of alchemical mixing,\nin which  ntypat  differs from  npsp )",
            "title": "random_atpos"
        },
        {
            "location": "/input_variables/varrlx/#restartxf",
            "text": "Mnemonics: RESTART from (X,F) history \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Control the restart of a molecular dynamics or structural optimization job.     restartxf>0 (Deprecated)   :The code reads from the input wf file, the previous history of atomic coordinates and corresponding forces, in order to continue the work done by the job that produced this wf file. If  optcell /=0, the history of  acell  and  rprim  variables is also taken into account. The code will take into consideration the whole history (if  restartxf =1), or discard the few first (x,f) pairs, and begin only at the pair whose number corresponds to  restartxf .  \nWorks only for  ionmov =2 (Broyden) and when an input wavefunction file is\nspecified, thanks to the appropriate values of  irdwfk  or  getwfk .    NOTES :   The input wf file must have been produced by a run that exited cleanly. It cannot be one of the temporary wf files that exist when a job crashed.    One cannot restart a calculation with a non-zero  optcell  value from the (x,f) history of another run with a different non-zero  optcell  value. Starting a non-zero  optcell  run from a zero  optcell  run should work.  \n* Deprecated, the use of the new options (-1 and -2) is preferred.      restartxf=0 (Default)   : No restart procedure is enable and will start a Molecular dynamics or structural optimization from scratch.      restartxf=-1 (New)   : Use the HIST file to reconstruct a partial calculation. It will reconstruct the different configurations using the forces and stress store in the HIST file, instead of calling the SCF procedure.  \nEnable   restartxf=-1   from the beginning is harmless. The only condition\nis to keep the input file the same in such a way that the same predictor is\nused and it will predict the same structure recorded in the HIST file. \nThis option will always compute extra  ntime  iterations independent of the\nnumber of iterations recovered previously.     restartxf=-2 (New)   :Read the HIST file and select the atomic positions and cell parameters with the lowest energy. Forget all the history and start the calculation using those values. The original atomic coordinates and cell parameters are irrelevant in that case.     NOTES:   You can use   restartxf=-1 or -2   for all predictiors that make no use of random numbers.    You can use   restartxf=-1 or -2   to restart a calculation that was not completed. The HIST file is written on each iteration. So you always have something to recover from.  \n* You can take advantage of the appropriate values of  irdwfk  or  getwfk  to get a good wave function to continue your job.",
            "title": "restartxf"
        },
        {
            "location": "/input_variables/varrlx/#signperm",
            "text": "Mnemonics: SIGN of PERMutation potential \nVariable type: integer \nDimensions: scalar \nDefault value: 1    +1 favors alternation of species -1 favors segregation",
            "title": "signperm"
        },
        {
            "location": "/input_variables/varrlx/#strfact",
            "text": "Mnemonics: STRess FACTor \nVariable type: real \nDimensions: scalar \nDefault value: 100    The stresses multiplied by  strfact  will be treated like forces in the\nprocess of optimization ( ionmov =2, non-zero  optcell ). \nFor example, the stopping criterion defined by  tolmxf  relates to these\nscaled stresses.",
            "title": "strfact"
        },
        {
            "location": "/input_variables/varrlx/#string_algo",
            "text": "Mnemonics: STRING method ALGOrithm \nVariable type: integer \nDimensions: scalar \nDefault value: 1    Relevant only when  imgmov =2 (String Method). \nGives the variant of the String Method method used. \nPossible values can be:      0=>   Original String Method   .  \nNOT YET IMPLEMENTED \n_ See: Phys. Rev. B 66, 052301 (2002) _    1=>   Simplified String Method   with parametrization by   equal arc length   .  \nInstead of using the normal force (wr the band), the full force is used; the\nreparametrization is enforced by keeping the points of the string equally\nspaced. \n_ See: J. Chem. Phys. 126, 164103 (2007) _    2=>   Simplified String Method   with parametrization by   energy-weighted arc length   .  \nA variant of the Simplified String Method (like 2-); the reparametrization is\ndone by using energy-weight arc-lengths, giving a finer distribution near the\nsaddle point..   See: J. Chem. Phys. 126, 164103 (2007) and J. Chem. Phys. 130, 244108 (2009)",
            "title": "string_algo"
        },
        {
            "location": "/input_variables/varrlx/#strprecon",
            "text": "Mnemonics: STRess PRECONditioner \nVariable type: real \nDimensions: scalar \nDefault value: 1.0    This is a scaling factor to initialize the part of the Hessian related to the\ntreatment of the stresses (optimisation of the unit cell). In case there is an\ninstability, decrease the default value, e.g. set it to 0.1 .",
            "title": "strprecon"
        },
        {
            "location": "/input_variables/varrlx/#strtarget",
            "text": "Mnemonics: STRess TARGET \nVariable type: real \nDimensions: (6) \nDefault value: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]    The components of the stress tensor must be stored according to : (1,1)->1\n; (2,2)->2 ; (3,3)->3 ; (2,3)->4 ; (3,1)->5 ; (1,2)->6. The\nconversion factor between Ha/Bohr 3 and GPa is : 1 Ha/Bohr 3 = 29421.033d0\nGPa. \nNot used if  optcell ==0.",
            "title": "strtarget"
        },
        {
            "location": "/input_variables/varrlx/#tolimg",
            "text": "Mnemonics: TOLerance on the mean total energy for IMaGes \nVariable type: real \nDimensions: scalar \nDefault value: 5e-05    Sets a maximal absolute energy tolerance (in hartree, averaged over dynamic\nimages) below which iterations on images (the one governed by the ntimimage  input variable) will stop. \nThis is to be used when trying to optimize a population of structures to their\nlowest energy configuration, taking into account the particular algorithm\ndefined by  imgmov \nA value of about 5.0d-5 hartree or smaller is suggested (this corresponds to\nabout 3.7d-7 eV). \nNo meaning for RF calculations.",
            "title": "tolimg"
        },
        {
            "location": "/input_variables/varrlx/#tolmxde",
            "text": "Mnemonics: TOLerance on the MaXimal Difference in Energy \nVariable type: real \nDimensions: scalar \nDefault value: 0.0    Sets a maximal difference in energy with respect to the two previous steps\nbelow which BFGS structural relaxation iterations will stop. \nA value of about 0.0005 eV/atom or smaller is suggested. \nIn order to use tolmxde, you should explicitly set tolmxf to 0.0. \nNo meaning for RF calculations.",
            "title": "tolmxde"
        },
        {
            "location": "/input_variables/varrlx/#tolmxf",
            "text": "Mnemonics: TOLerance on the MaXimal Force \nVariable type: real \nDimensions: scalar \nDefault value: 5e-05    Sets a maximal absolute force tolerance (in hartree/Bohr) below which BFGS\nstructural relaxation iterations will stop. \nCan also control tolerance on stresses, when  optcell  /=0, using the\nconversion factor  strfact . This tolerance applies to any particular\ncartesian component of any atom, excluding fixed ones. See the parameter ionmov . \nThis is to be used when trying to equilibrate a structure to its lowest energy\nconfiguration (  ionmov  =2). \nA value of about 5.0d-5 hartree/Bohr or smaller is suggested (this corresponds\nto about 2.5d-3 eV/Angstrom). \nNo meaning for RF calculations.",
            "title": "tolmxf"
        },
        {
            "location": "/input_variables/varrlx/#vel",
            "text": "Mnemonics: VELocity \nVariable type: real \nDimensions: (3, natom ) \ncommentdims It is represented internally as  [vel] \nDefault value: *0 \nOnly relevant if  ionmov  > 0    Gives the starting velocities of atoms, in cartesian coordinates, in\nBohr/atomic time units (atomic time units given where  dtion  is described). \nFor  ionmov =8 (Nose thermostat), if  vel  is not initialized, a random\ninitial velocity giving the right kinetic energy will be generated. \nIf the geometry builder is used,  vel  will be related to the preprocessed\nset of atoms, generated by the geometry builder. The user must thus foresee\nthe effect of this geometry builder (see  objarf ). \nVelocities evolve is  ionmov ==1.",
            "title": "vel"
        },
        {
            "location": "/input_variables/varrlx/#vel_cell",
            "text": "Mnemonics: VELocity of the CELL parameters \nVariable type: real \nDimensions: (3,3) \ncommentdims It is represented internally as  [vel_cell]   \nDefault value: *3 \nOnly relevant if  imgmov  in [9,13] and  optcell  > 0\n(Path-Integral Molecular Dynamics\nwith NPT algorithm)    Irrelevant unless  imgmov =9 or 13 and  optcell >0 (Path-Integral\nMolecular Dynamics with NPT algorithm). \nGives the starting velocities of the dimensional cell parameters in\nBohr/atomic time units (atomic time units given where  dtion  is described).",
            "title": "vel_cell"
        },
        {
            "location": "/input_variables/varrlx/#vis",
            "text": "Mnemonics: VIScosity \nVariable type: real \nDimensions: scalar \nDefault value: 100    The equation of motion is : \nM  I  d  2  R  I  /dt  2  = F  I  -  vis  dR  I  /dt    The atomic unit of viscosity is hartrees*(atomic time units)/Bohr  2  . Units\nare not critical as this is a fictitious damping used to relax structures. A\ntypical value for silicon is 400 with  dtion  of 350 and atomic mass 28 amu . Critical damping is most desirable and is found only by optimizing vis  for a given situation.    In the case of Path-Integral Molecular Dynamics using the Langevin Thermostat\n( imgmov =9),  vis  defines the friction coefficient, in atomic units.\nTypical value range is 0.00001-0.001.",
            "title": "vis"
        },
        {
            "location": "/input_variables/varrlx/#wtatcon",
            "text": "Mnemonics: WeighTs for AToms in CONstraint equations \nVariable type: real \nDimensions: (3, natcon , nconeq ) \nDefault value: 0    Gives the weights determining how the motion of atoms is constrained during\nstructural optimization or molecular dynamics (see  nconeq  ,  natcon ,\nand  iatcon ). For each of the  nconeq  independent constraint equations,\nwtatcon is a 3* natcon  array giving weights, W  I  , for the x, y, and z\ncomponents of each of the atoms (labeled by I) in the list of indices iatcon . Prior to taking an atomic step, the calculated forces, F  I  , are\nreplaced by projected forces, F\u2019  I  , which satisfy the set of constraint\nequations    Sum  mu=x,y,z; I=1,natcon  : W  mu,I  * F\u2019  mu,I  = 0 for each of the nconeq  arrays W  I  .    Different types of motion constraints can be implemented this way. For\nexample,    nconeq 1 natcon 2 iatcon 1 2 wtatcon 0 0 +1 0 0 -1    could be used to constrain the relative height difference of two adsorbate\natoms on a surface (assuming their masses are equal), since F\u2019  z,1  - F\u2019\nz,2  = 0 implies z  1  - z  2  = constant.",
            "title": "wtatcon"
        },
        {
            "location": "/input_variables/varvdw/",
            "text": "irdvdw\n\u00b6\n\n\nMnemonics: Integer that governs the ReaDing of _VDW files\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nUsed when \nvdw_xc\n>0, to read previously calculated vdW-DF variables.\n\nSupported values:\n\n\n\n\n0 => do not read vdW-DF variables \n\n\n1 => read vdW-DF variables \n\n\n\n\nprtvdw\n\u00b6\n\n\nMnemonics: PRinT Van Der Waals file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nPrint out a NetCDF file containing a vdW-DF kernel.\n\n\nvdw_df_acutmin\n\u00b6\n\n\nMnemonics: vdW-DF MINimum Angular CUT-off\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 10\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build angular meshes for the vdW-DF kernel.  \n\n\nvdw_df_aratio\n\u00b6\n\n\nMnemonics: vdW-DF Angle RATIO between the highest and\nlowest angles.\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 30\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build angular meshes for the vdW-DF kernel.  \n\n\nvdw_df_damax\n\u00b6\n\n\nMnemonics: vdW-DF Delta for Angles, MAXimum \n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.5\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build angular meshes for the vdW-DF kernel.  \n\n\nvdw_df_damin\n\u00b6\n\n\nMnemonics: vdW-DF Delta for Angles, MINimum\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.01\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build angular meshes for the vdW-DF kernel.  \n\n\nvdw_df_dcut\n\u00b6\n\n\nMnemonics: vdW-DF D-mesh CUT-off\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 30\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_dratio\n\u00b6\n\n\nMnemonics: vdW-DF, between the highest and\nlowest D, RATIO.\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 20\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_dsoft\n\u00b6\n\n\nMnemonics: vdW-DF Distance for SOFTening.\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1.0\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_gcut\n\u00b6\n\n\nMnemonics: vdW-DF G-space CUT-off\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 5\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to filter the vdW-DF kernel in reciprocal space.  \n\n\nvdw_df_ndpts\n\u00b6\n\n\nMnemonics: vdW-DF Number of D-mesh PoinTS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 20\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_ngpts\n\u00b6\n\n\nMnemonics: vdW-DF Number of G-mesh PoinTS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: -1\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_nqpts\n\u00b6\n\n\nMnemonics: vdW-DF Number of Q-mesh PoinTS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 30\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_nrpts\n\u00b6\n\n\nMnemonics: vdW-DF Number of R-PoinTS\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 2048\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to define the sampling of the vdW-DF-kernel in\nreal-space.  \n\n\nvdw_df_nsmooth\n\u00b6\n\n\nMnemonics: vdW-DF Number of SMOOTHening iterations\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 12\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to exponentially smoothen q near q0.  \n\n\nvdw_df_phisoft\n\u00b6\n\n\nMnemonics: vdW-DF PHI value SOFTening.\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: -1.0\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_qcut\n\u00b6\n\n\nMnemonics: vdW-DF Q-mesh CUT-off\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 5\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_qratio\n\u00b6\n\n\nMnemonics: vdW-DF, between highest and lowest Q, RATIO .\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 20\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, .  \n\n\nvdw_df_rcut\n\u00b6\n\n\nMnemonics: vdW-DF Real-space CUT-off\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 100\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to define the vdW-DF kernel cut-off radius.  \n\n\nvdw_df_rsoft\n\u00b6\n\n\nMnemonics: vdW-DF radius SOFTening.\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.0\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_threshold\n\u00b6\n\n\nMnemonics: vdW-DF energy calculation THRESHOLD\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 0.01\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nSets a threshold for the energy gradient that, when reached, will cause the\nvdW-DF interactions to be calculated.\n\nAdjust it to a big value (e.g. 1e12) to enable it all along the SCF\ncalculation. Too small values, as well as negative values, will result in the\nvdW-DF energy contributions never being calculated.\n\n\nvdw_df_tolerance\n\u00b6\n\n\nMnemonics: vdW-DF global TOLERANCE.\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1e-13\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.  \n\n\nvdw_df_tweaks\n\u00b6\n\n\nMnemonics: vdW-DF TWEAKS.\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, to build the vdW-DF kernel.\n\n\n _ IMPORTANT NOTE: modifying this variable will likely transform the calculated energies and their gradients into garbage. You have been warned! _ \n   \n\n\nvdw_df_zab\n\u00b6\n\n\nMnemonics: vdW-DF ZAB parameter\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: -0.8491\n\nOnly relevant if \nvdw_xc\n>0  \n\n\nUsed when \nvdw_xc\n>0, as introduced in \n\ndoi:10.1103/PhysRevLett.92.246401\n\n .  \n\n\nvdw_nfrag\n\u00b6\n\n\nMnemonics: Van Der Waals Number of interacting FRAGments\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nvdw_xc\n in [10,11]  \n\n\nThe absolute value of vdw_nfrag is the number of vdW interacting fragments in\nthe unit cell. As wannierization takes place in reciprocal space, the MLWF\ncenter positions could be translated by some lattice vector from the cell\nwhere atoms are placed. If \nvdw_nfrag\n >= 1 then MLWFs are translated to\nthe original unit cell, otherwise the program will keep the positions obtained\nby Wannier90. The later is usually correct if some atoms are located at the\ncorners or at limiting faces of the unit cell.\n\n\nvdw_supercell\n\u00b6\n\n\nMnemonics: Van Der Waals correction from Wannier functions in SUPERCELL\n\nVariable type: integer\n\nDimensions: (3)\n\nDefault value: [0, 0, 0]\n\nOnly relevant if \nvdw_xc\n in [10,11]  \n\n\nSet of dimensionless positive numbers which define the maximum multiples of\nthe primitive translations (\nrprimd\n) in the supercell construction. Each\ncomponent of vdw_supercell indicates the maximum number of cells along both\npositive or negative directions of the corresponding primitive vector i.e. the\ncomponents of \nrprimd\n. In the case of layered systems for which vdW\ninteractions occur between layers made of tightly bound atoms, the evaluation\nof vdW corrections coming from MLWFs in the same layer (fragment) must be\navoided. Both a negative or null value for one component of \nvdw_supercell\n\nwill indicate that the corresponding direction is normal to the layers.\n\n\nvdw_tol\n\u00b6\n\n\nMnemonics: Van Der Waals TOLerance\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: 1e-10\n\nOnly relevant if \nvdw_xc\n==5  \n\n\nThe DFT-D methods (S. Grimme approach) dispersion potentials, \nvdw_xc\n==5 or\n6 or 7, include a pair potential. The number of pairs of atoms contributing to\nthe potential is necessarily limited. To be included in the potential a pair\nof atom must have contribution to the energy larger than \nvdw_tol\n.\n\n\nvdw_tol_3bt\n\u00b6\n\n\nMnemonics: Van Der Waals TOLerance for 3-Body Term\n\nVariable type: real\n\nDimensions: scalar\n\nDefault value: -1\n\nComment: Do include the 3-body term in the correction\n\nOnly relevant if \nvdw_xc\n == 6  \n\n\nControl the computation of the 3-body correction inside DFT-D3 dispersion\ncorrection (Grimme approach) to the total energy:\n\n-If \n vdw_tol_3bt\n<0, no 3-body correction. \n\n-If \n vdw_tol_3bt\n>0, the 3-body term is included with a tolerance = \nvdw_tol_3bt\n   \n\n\nDFT-D3 as proposed by S. Grimme adds two contributions to the total energy in\norder to take into account of the dispersion:  \n\n\n\n\n\n\nA pair-wise potential for which the tolerance is controlled by \nvdw_tol\n \n\n\n\n\n\n\nA 3-body term which is obtained by summing over all triplets of atoms. Each individual contribution depends of the distances and angles between the three atoms. As it is impossible to sum over all the triplets in a periodic system, one has to define a stopping criterium which is here that an additional contribution to the energy must be higher than \nvdw_tol_3bt\n\n\n\n\n\n\nThe last term has been predicted to have an important effect for large\nmolecules (see for e.g. _ Grimme S., J. Chem. Phys. 132, 154104 (2010) \n). It\nis however quite costly in computational time for periodic systems and seems\nto lead to an overestimation of lattice parameters for weakly bound systems\n(see for e.g. _ Reckien W., J. Chem. Phys. 132, 154104(2010) \n). Still, its\ncontribution to energy, to forces and to stress is available (not planned for\nelastic constants, dynamical matrix and internal strains)\n\n\nvdw_typfrag\n\u00b6\n\n\nMnemonics: Van Der Waals TYPe of FRAGment\n\nVariable type: integer\n\nDimensions: (\nnatom\n)\n\nDefault value: 1*\nnatom\n\nOnly relevant if \nvdw_xc\n in [10,11]  \n\n\nThis array defines the interacting fragments by assigning to each atom an\ninteger index from 1 to \n vdw_nfrag \n . The ordering of \nvdw_typfrag\n is\nthe same as \ntypat\n or \nxcart\n. Internally each MLWF is assigned to a\ngiven fragment by computing the distance to the atoms. MLWFs belong to the\nsame fragment as their nearest atom. The resulting set of MLWFs in each\ninteracting fragment can be found in the output file in xyz format for easy\nvisualization.\n\n\nvdw_xc\n\u00b6\n\n\nMnemonics: Van Der Waals eXchange-Correlation functional\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0  \n\n\nSelects a van-der-Waals density functional to apply the corresponding\ncorrection to the exchange-correlation energy. If set to zero, no correction\nwill be applied.\n\nPossible values are:\n\n\n\n\n0: no correction. \n\n\n\n\n1: apply vdW-DF1 (DRSLL) from Dion _ et al. _ \n\n_ doi:10.1103/PhysRevLett.92.246401 _\n\n\n\n\n\n\n2: apply vdw-DF2 (LMKLL) from Lee _ et al. _ \n\n_ arXiv:1003.5255v1 _\n\n\n\n\n\n\n5: apply vdw-DFT-D2 as proposed by S. Grimme (adding a semi-empirical dispersion potential) \n\nAvailable only for ground-state calculations and response functions; see\n\nvdw_tol\n variable to control convergency\n\n_ J. Comp. Chem. 27, 1787 (2006) _\n\n\n\n\n\n\n6: apply vdw-DFT-D3 as proposed by S. Grimme (refined version of DFT-D2) \n\nAvailable only for ground-state calculations and response functions; see\n\nvdw_tol\n variable to control convergency and \nvdw_tol_3bt\n variable to\ninclude 3-body corrections\n\n_ J. Chem. Phys. 132, 154104 (2010) _\n\n\n\n\n\n\n7: apply vdw-DFT-D3(BJ) as proposed by Grimme (based on Becke-Jonhson method J. Chem. Phys. 2004-2006) \n\nAvailable only for ground-state calculations and response functions; see\n\nvdw_tol\n variable to control convergency\n\n_ J. Comput. Chem. 32, 1456 (2011) _\n\n\n\n\n\n\n10: evaluate the vdW correlation energy from maximally localized Wannier functions, as proposed by P. L. Silvestrelli, also known as vdW-WF1 method. \n\n\n doi:10.1103/PhysRevLett.100.053002. _ For details on this implementation\nplease check: _ doi:10.1016/j.cpc.2011.11.003 \n\nThe improvements introduced by Andrinopoulos _ et al. _ in _ J. Chem. Phys.\n135, 154105 (2011) _ namely the amalgamation procedure, splitting of p-like\nMLWFs into\n\ntwo s-like Wannier functions and fractional occupation of MLWFs are performed\nautomatically.  \n\n\n\n\n\n\n11: evaluate the vdW correlation energy from maximally localized Wannier functions, as proposed by A. Ambrosetti and P. L. Silvestrelli, also known as vdW-WF2 method. \n\n_ doi:10.1103/PhysRevB.85.073101 _\n\n\n\n\n\n\n14: apply DFT/vdW-QHO-WF method as proposed by Silvestrelli, which combines the quantum harmonic oscillator-model with localized Wannier functions. \n\n\n J. Chem. Phys. 139, 054106 (2013) \n\nFor periodic systems a supercell approach has to be used since \n\nvdw_supercell \n is not enabled in this case.\n\n\n\n\n\n\nFor \nvdw_xc\n=1 and \nvdw_xc\n=2, the implementation follows the strategy\ndevised in the article of Roman-Perez and Soler\n(\ndoi:10.1103/PhysRevLett.103.096102\n)",
            "title": "VdW"
        },
        {
            "location": "/input_variables/varvdw/#irdvdw",
            "text": "Mnemonics: Integer that governs the ReaDing of _VDW files \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Used when  vdw_xc >0, to read previously calculated vdW-DF variables. \nSupported values:   0 => do not read vdW-DF variables   1 => read vdW-DF variables",
            "title": "irdvdw"
        },
        {
            "location": "/input_variables/varvdw/#prtvdw",
            "text": "Mnemonics: PRinT Van Der Waals file \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Print out a NetCDF file containing a vdW-DF kernel.",
            "title": "prtvdw"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_acutmin",
            "text": "Mnemonics: vdW-DF MINimum Angular CUT-off \nVariable type: real \nDimensions: scalar \nDefault value: 10 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build angular meshes for the vdW-DF kernel.",
            "title": "vdw_df_acutmin"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_aratio",
            "text": "Mnemonics: vdW-DF Angle RATIO between the highest and\nlowest angles. \nVariable type: real \nDimensions: scalar \nDefault value: 30 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build angular meshes for the vdW-DF kernel.",
            "title": "vdw_df_aratio"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_damax",
            "text": "Mnemonics: vdW-DF Delta for Angles, MAXimum  \nVariable type: real \nDimensions: scalar \nDefault value: 0.5 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build angular meshes for the vdW-DF kernel.",
            "title": "vdw_df_damax"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_damin",
            "text": "Mnemonics: vdW-DF Delta for Angles, MINimum \nVariable type: real \nDimensions: scalar \nDefault value: 0.01 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build angular meshes for the vdW-DF kernel.",
            "title": "vdw_df_damin"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_dcut",
            "text": "Mnemonics: vdW-DF D-mesh CUT-off \nVariable type: real \nDimensions: scalar \nDefault value: 30 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_dcut"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_dratio",
            "text": "Mnemonics: vdW-DF, between the highest and\nlowest D, RATIO. \nVariable type: real \nDimensions: scalar \nDefault value: 20 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_dratio"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_dsoft",
            "text": "Mnemonics: vdW-DF Distance for SOFTening. \nVariable type: real \nDimensions: scalar \nDefault value: 1.0 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_dsoft"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_gcut",
            "text": "Mnemonics: vdW-DF G-space CUT-off \nVariable type: real \nDimensions: scalar \nDefault value: 5 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to filter the vdW-DF kernel in reciprocal space.",
            "title": "vdw_df_gcut"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_ndpts",
            "text": "Mnemonics: vdW-DF Number of D-mesh PoinTS \nVariable type: integer \nDimensions: scalar \nDefault value: 20 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_ndpts"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_ngpts",
            "text": "Mnemonics: vdW-DF Number of G-mesh PoinTS \nVariable type: integer \nDimensions: scalar \nDefault value: -1 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_ngpts"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_nqpts",
            "text": "Mnemonics: vdW-DF Number of Q-mesh PoinTS \nVariable type: integer \nDimensions: scalar \nDefault value: 30 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_nqpts"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_nrpts",
            "text": "Mnemonics: vdW-DF Number of R-PoinTS \nVariable type: integer \nDimensions: scalar \nDefault value: 2048 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to define the sampling of the vdW-DF-kernel in\nreal-space.",
            "title": "vdw_df_nrpts"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_nsmooth",
            "text": "Mnemonics: vdW-DF Number of SMOOTHening iterations \nVariable type: integer \nDimensions: scalar \nDefault value: 12 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to exponentially smoothen q near q0.",
            "title": "vdw_df_nsmooth"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_phisoft",
            "text": "Mnemonics: vdW-DF PHI value SOFTening. \nVariable type: real \nDimensions: scalar \nDefault value: -1.0 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_phisoft"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_qcut",
            "text": "Mnemonics: vdW-DF Q-mesh CUT-off \nVariable type: real \nDimensions: scalar \nDefault value: 5 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_qcut"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_qratio",
            "text": "Mnemonics: vdW-DF, between highest and lowest Q, RATIO . \nVariable type: real \nDimensions: scalar \nDefault value: 20 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, .",
            "title": "vdw_df_qratio"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_rcut",
            "text": "Mnemonics: vdW-DF Real-space CUT-off \nVariable type: real \nDimensions: scalar \nDefault value: 100 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to define the vdW-DF kernel cut-off radius.",
            "title": "vdw_df_rcut"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_rsoft",
            "text": "Mnemonics: vdW-DF radius SOFTening. \nVariable type: real \nDimensions: scalar \nDefault value: 0.0 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_rsoft"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_threshold",
            "text": "Mnemonics: vdW-DF energy calculation THRESHOLD \nVariable type: real \nDimensions: scalar \nDefault value: 0.01 \nOnly relevant if  vdw_xc >0    Sets a threshold for the energy gradient that, when reached, will cause the\nvdW-DF interactions to be calculated. \nAdjust it to a big value (e.g. 1e12) to enable it all along the SCF\ncalculation. Too small values, as well as negative values, will result in the\nvdW-DF energy contributions never being calculated.",
            "title": "vdw_df_threshold"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_tolerance",
            "text": "Mnemonics: vdW-DF global TOLERANCE. \nVariable type: real \nDimensions: scalar \nDefault value: 1e-13 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.",
            "title": "vdw_df_tolerance"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_tweaks",
            "text": "Mnemonics: vdW-DF TWEAKS. \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, to build the vdW-DF kernel.   _ IMPORTANT NOTE: modifying this variable will likely transform the calculated energies and their gradients into garbage. You have been warned! _",
            "title": "vdw_df_tweaks"
        },
        {
            "location": "/input_variables/varvdw/#vdw_df_zab",
            "text": "Mnemonics: vdW-DF ZAB parameter \nVariable type: real \nDimensions: scalar \nDefault value: -0.8491 \nOnly relevant if  vdw_xc >0    Used when  vdw_xc >0, as introduced in  \ndoi:10.1103/PhysRevLett.92.246401  .",
            "title": "vdw_df_zab"
        },
        {
            "location": "/input_variables/varvdw/#vdw_nfrag",
            "text": "Mnemonics: Van Der Waals Number of interacting FRAGments \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  vdw_xc  in [10,11]    The absolute value of vdw_nfrag is the number of vdW interacting fragments in\nthe unit cell. As wannierization takes place in reciprocal space, the MLWF\ncenter positions could be translated by some lattice vector from the cell\nwhere atoms are placed. If  vdw_nfrag  >= 1 then MLWFs are translated to\nthe original unit cell, otherwise the program will keep the positions obtained\nby Wannier90. The later is usually correct if some atoms are located at the\ncorners or at limiting faces of the unit cell.",
            "title": "vdw_nfrag"
        },
        {
            "location": "/input_variables/varvdw/#vdw_supercell",
            "text": "Mnemonics: Van Der Waals correction from Wannier functions in SUPERCELL \nVariable type: integer \nDimensions: (3) \nDefault value: [0, 0, 0] \nOnly relevant if  vdw_xc  in [10,11]    Set of dimensionless positive numbers which define the maximum multiples of\nthe primitive translations ( rprimd ) in the supercell construction. Each\ncomponent of vdw_supercell indicates the maximum number of cells along both\npositive or negative directions of the corresponding primitive vector i.e. the\ncomponents of  rprimd . In the case of layered systems for which vdW\ninteractions occur between layers made of tightly bound atoms, the evaluation\nof vdW corrections coming from MLWFs in the same layer (fragment) must be\navoided. Both a negative or null value for one component of  vdw_supercell \nwill indicate that the corresponding direction is normal to the layers.",
            "title": "vdw_supercell"
        },
        {
            "location": "/input_variables/varvdw/#vdw_tol",
            "text": "Mnemonics: Van Der Waals TOLerance \nVariable type: real \nDimensions: scalar \nDefault value: 1e-10 \nOnly relevant if  vdw_xc ==5    The DFT-D methods (S. Grimme approach) dispersion potentials,  vdw_xc ==5 or\n6 or 7, include a pair potential. The number of pairs of atoms contributing to\nthe potential is necessarily limited. To be included in the potential a pair\nof atom must have contribution to the energy larger than  vdw_tol .",
            "title": "vdw_tol"
        },
        {
            "location": "/input_variables/varvdw/#vdw_tol_3bt",
            "text": "Mnemonics: Van Der Waals TOLerance for 3-Body Term \nVariable type: real \nDimensions: scalar \nDefault value: -1 \nComment: Do include the 3-body term in the correction \nOnly relevant if  vdw_xc  == 6    Control the computation of the 3-body correction inside DFT-D3 dispersion\ncorrection (Grimme approach) to the total energy: \n-If   vdw_tol_3bt <0, no 3-body correction.  \n-If   vdw_tol_3bt >0, the 3-body term is included with a tolerance =  vdw_tol_3bt      DFT-D3 as proposed by S. Grimme adds two contributions to the total energy in\norder to take into account of the dispersion:      A pair-wise potential for which the tolerance is controlled by  vdw_tol      A 3-body term which is obtained by summing over all triplets of atoms. Each individual contribution depends of the distances and angles between the three atoms. As it is impossible to sum over all the triplets in a periodic system, one has to define a stopping criterium which is here that an additional contribution to the energy must be higher than  vdw_tol_3bt    The last term has been predicted to have an important effect for large\nmolecules (see for e.g. _ Grimme S., J. Chem. Phys. 132, 154104 (2010)  ). It\nis however quite costly in computational time for periodic systems and seems\nto lead to an overestimation of lattice parameters for weakly bound systems\n(see for e.g. _ Reckien W., J. Chem. Phys. 132, 154104(2010)  ). Still, its\ncontribution to energy, to forces and to stress is available (not planned for\nelastic constants, dynamical matrix and internal strains)",
            "title": "vdw_tol_3bt"
        },
        {
            "location": "/input_variables/varvdw/#vdw_typfrag",
            "text": "Mnemonics: Van Der Waals TYPe of FRAGment \nVariable type: integer \nDimensions: ( natom ) \nDefault value: 1* natom \nOnly relevant if  vdw_xc  in [10,11]    This array defines the interacting fragments by assigning to each atom an\ninteger index from 1 to   vdw_nfrag   . The ordering of  vdw_typfrag  is\nthe same as  typat  or  xcart . Internally each MLWF is assigned to a\ngiven fragment by computing the distance to the atoms. MLWFs belong to the\nsame fragment as their nearest atom. The resulting set of MLWFs in each\ninteracting fragment can be found in the output file in xyz format for easy\nvisualization.",
            "title": "vdw_typfrag"
        },
        {
            "location": "/input_variables/varvdw/#vdw_xc",
            "text": "Mnemonics: Van Der Waals eXchange-Correlation functional \nVariable type: integer \nDimensions: scalar \nDefault value: 0    Selects a van-der-Waals density functional to apply the corresponding\ncorrection to the exchange-correlation energy. If set to zero, no correction\nwill be applied. \nPossible values are:   0: no correction.    1: apply vdW-DF1 (DRSLL) from Dion _ et al. _  \n_ doi:10.1103/PhysRevLett.92.246401 _    2: apply vdw-DF2 (LMKLL) from Lee _ et al. _  \n_ arXiv:1003.5255v1 _    5: apply vdw-DFT-D2 as proposed by S. Grimme (adding a semi-empirical dispersion potential)  \nAvailable only for ground-state calculations and response functions; see vdw_tol  variable to control convergency \n_ J. Comp. Chem. 27, 1787 (2006) _    6: apply vdw-DFT-D3 as proposed by S. Grimme (refined version of DFT-D2)  \nAvailable only for ground-state calculations and response functions; see vdw_tol  variable to control convergency and  vdw_tol_3bt  variable to\ninclude 3-body corrections \n_ J. Chem. Phys. 132, 154104 (2010) _    7: apply vdw-DFT-D3(BJ) as proposed by Grimme (based on Becke-Jonhson method J. Chem. Phys. 2004-2006)  \nAvailable only for ground-state calculations and response functions; see vdw_tol  variable to control convergency \n_ J. Comput. Chem. 32, 1456 (2011) _    10: evaluate the vdW correlation energy from maximally localized Wannier functions, as proposed by P. L. Silvestrelli, also known as vdW-WF1 method.    doi:10.1103/PhysRevLett.100.053002. _ For details on this implementation\nplease check: _ doi:10.1016/j.cpc.2011.11.003  \nThe improvements introduced by Andrinopoulos _ et al. _ in _ J. Chem. Phys.\n135, 154105 (2011) _ namely the amalgamation procedure, splitting of p-like\nMLWFs into \ntwo s-like Wannier functions and fractional occupation of MLWFs are performed\nautomatically.      11: evaluate the vdW correlation energy from maximally localized Wannier functions, as proposed by A. Ambrosetti and P. L. Silvestrelli, also known as vdW-WF2 method.  \n_ doi:10.1103/PhysRevB.85.073101 _    14: apply DFT/vdW-QHO-WF method as proposed by Silvestrelli, which combines the quantum harmonic oscillator-model with localized Wannier functions.    J. Chem. Phys. 139, 054106 (2013)  \nFor periodic systems a supercell approach has to be used since  \nvdw_supercell   is not enabled in this case.    For  vdw_xc =1 and  vdw_xc =2, the implementation follows the strategy\ndevised in the article of Roman-Perez and Soler\n( doi:10.1103/PhysRevLett.103.096102 )",
            "title": "vdw_xc"
        },
        {
            "location": "/input_variables/varw90/",
            "text": "w90iniprj\n\u00b6\n\n\nMnemonics: Wannier90- INItial PROJections\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 1\n\nOnly relevant if \nprtwant\n==2 or \nprtwant\n==3  \n\n\nIn order to find the Maximally Localized Wannier Functions, the user has to\nprovide an initial guess. A set of localized trial orbitals is chosen\ncorresponding to some rough initial guess at the Wannier Functions, and these\nare projected onto the Bloch eigenstates. See Ivo Souza, Nicola Marzari, and\nDavid Vanderbilt. Phys. Rev. B, 65, 035109 (2001).\n\nThese initial projections are stored in a file .amn and the variable \n\nw90iniprj \n is used to construct them:\n\n\n\n\n\n\n w90iniprj \n =1: Random projections.   \n\n\n\n\n\n\n w90iniprj \n =2: The initial projections will be a linear combination of hydrogenic atomic orbitals. \n\nThe user has to define the projections in the secondary input file\nwannier90.win\n\nInformation about how to define them can be found in the manual of Wannier90.\nSee  \n www.wannier.org \n\n\n\n\n\n\nw90prtunk\n\u00b6\n\n\nMnemonics: Wannier90- PRINT UNKp.s file\n\nVariable type: integer\n\nDimensions: scalar\n\nDefault value: 0\n\nComment: The default is set to zero because UNKp.s files occupy a lot of\nmemory.\n\nOnly relevant if \nprtwant\n==2 or \nprtwant\n==3  \n\n\nDefines whether or not the UNKp.s file will be printed.\n\n\n\n\n\n\nw90prtunk\n=0: Do not print the UNKp.s files   \n\n\n\n\n\n\nw90prtunk\n=1: Print the UNKp.s files on a fine grid   \n\n\n\n\n\n\nw90prtunk\n>1: Print the UNKp.s files on a coarse grid \n\nInstead of printing every record we will print every w90prtunk records. This\nis useful to reduce the size of the UNKp.s files, but, the quality is also\nreduced.\n\n\n\n\n\n\nThese files contain the periodic part of the bloch states represented on a\nregular real space grid. They are indexed by k-point \n p \n (from 1 to nkpt)\nand spin \n s \n (\u20181\u2019 for \u2018up\u2019,\u20182\u2019 for \u2018down\u2019).  \n\n\nThe name of the wavefunction file is assumed to have the form:  \n\n\nwrite(wfnname,200) \n p \n , \n spin \n\n200 format (\u2018UNK\u2019,i5.5,\u2019.\u2019,i1)  \n\n\nThese file are unformatted. The first line of each file contains 5 integers:\nthe number of grid points in each direction ( \n n1 \n , \n n2 \n and \n n3 \n\n), the k-point number \n ikpt \n and the total number of bands mband in the\nfile. The following rows contain the wavefunctions in real space.\n\n\nThese files are written in the following way for the coarse grid:\n\n\n write(iun_plot) n1/w90prtunk,n2/w90prtunk,n3/w90prtunk,ikpt,nband\nwrite(iun_plot) (((fofr(1,jj1,jj2,jj3),fofr(2,jj1,jj2,jj3),&\n&      jj1=1,n1,w90prtunk),jj2=1,n2,w90prtunk),jj3=1,n3,w90prtunk)\n\n\n\n\n\nWhere \n fofr \n is a double precision variable which contains the\nwavefunctions in real space. Note that in order to reduce the size of the UNK\nfiles we are just including records in the wavefunctions for 1/(w90prtunk^3)\nof the grid points. That is why we divide n1, n2 and n3 by prtunk. The output\n.xsf files for plotting with XCrysDen will also be on the coarse grid. When\nthis does not produce an acceptable plot, prtunk can be set to 1 to output\nevery grid point. (You should try spline interpolation in XCrysDen first.)",
            "title": "Wannier90"
        },
        {
            "location": "/input_variables/varw90/#w90iniprj",
            "text": "Mnemonics: Wannier90- INItial PROJections \nVariable type: integer \nDimensions: scalar \nDefault value: 1 \nOnly relevant if  prtwant ==2 or  prtwant ==3    In order to find the Maximally Localized Wannier Functions, the user has to\nprovide an initial guess. A set of localized trial orbitals is chosen\ncorresponding to some rough initial guess at the Wannier Functions, and these\nare projected onto the Bloch eigenstates. See Ivo Souza, Nicola Marzari, and\nDavid Vanderbilt. Phys. Rev. B, 65, 035109 (2001). \nThese initial projections are stored in a file .amn and the variable  \nw90iniprj   is used to construct them:     w90iniprj   =1: Random projections.        w90iniprj   =2: The initial projections will be a linear combination of hydrogenic atomic orbitals.  \nThe user has to define the projections in the secondary input file\nwannier90.win \nInformation about how to define them can be found in the manual of Wannier90.\nSee    www.wannier.org",
            "title": "w90iniprj"
        },
        {
            "location": "/input_variables/varw90/#w90prtunk",
            "text": "Mnemonics: Wannier90- PRINT UNKp.s file \nVariable type: integer \nDimensions: scalar \nDefault value: 0 \nComment: The default is set to zero because UNKp.s files occupy a lot of\nmemory. \nOnly relevant if  prtwant ==2 or  prtwant ==3    Defines whether or not the UNKp.s file will be printed.    w90prtunk =0: Do not print the UNKp.s files       w90prtunk =1: Print the UNKp.s files on a fine grid       w90prtunk >1: Print the UNKp.s files on a coarse grid  \nInstead of printing every record we will print every w90prtunk records. This\nis useful to reduce the size of the UNKp.s files, but, the quality is also\nreduced.    These files contain the periodic part of the bloch states represented on a\nregular real space grid. They are indexed by k-point   p   (from 1 to nkpt)\nand spin   s   (\u20181\u2019 for \u2018up\u2019,\u20182\u2019 for \u2018down\u2019).    The name of the wavefunction file is assumed to have the form:    write(wfnname,200)   p   ,   spin  \n200 format (\u2018UNK\u2019,i5.5,\u2019.\u2019,i1)    These file are unformatted. The first line of each file contains 5 integers:\nthe number of grid points in each direction (   n1   ,   n2   and   n3  \n), the k-point number   ikpt   and the total number of bands mband in the\nfile. The following rows contain the wavefunctions in real space.  These files are written in the following way for the coarse grid:   write(iun_plot) n1/w90prtunk,n2/w90prtunk,n3/w90prtunk,ikpt,nband\nwrite(iun_plot) (((fofr(1,jj1,jj2,jj3),fofr(2,jj1,jj2,jj3),&\n&      jj1=1,n1,w90prtunk),jj2=1,n2,w90prtunk),jj3=1,n3,w90prtunk)  Where   fofr   is a double precision variable which contains the\nwavefunctions in real space. Note that in order to reduce the size of the UNK\nfiles we are just including records in the wavefunctions for 1/(w90prtunk^3)\nof the grid points. That is why we divide n1, n2 and n3 by prtunk. The output\n.xsf files for plotting with XCrysDen will also be on the coarse grid. When\nthis does not produce an acceptable plot, prtunk can be set to 1 to output\nevery grid point. (You should try spline interpolation in XCrysDen first.)",
            "title": "w90prtunk"
        },
        {
            "location": "/tutorials/welcome/",
            "text": "The lessons of this tutorial are aimed at teaching the use of ABINIT, in the\nUNIX/Linux OS and its variants (Mac OS X, AIX \u2026). They might be used for\nother operating systems, but the commands have to be adapted.\n\n\nNote that they can be accessed from the ABINIT web site as well as from your\nlocal ~abinit/doc/tutorial/generated_files/lesson_welcome.html file. The\nlatter solution is of course preferable, as the response time will not depend\non the network traffic.\n\n\nAt present, more than thirty lessons are available. Each of them is at most\ntwo hours of student work. Lessons 1-4 cover the basics, other lectures are\nmore specialized. There are dependencies between lessons. The following schema\nshould help you to understand these dependencies. In blue, one has the basic\nlessons. The blocks in red represents additional lessons related to ground-\nstate features of ABINIT. Response-function features of ABINIT are explained\nin the lessons in the green blocks. Finally, the Many-Body Perturbation Theory\ncapabilities are demonstrated in the lessons belonging to the violet blocks.\nThe right-hand side blocks gather the lessons related to the parallelism\ninside ABINIT.\n\n\n\n\n \n\n \n\n\n\n\n\n\n\n\n \n\n \n\n\n\n \n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore following the tutorials, you should have read the \n \u201cnew user\u2019s\nguide\u201d\n, as well as the pages\n1045-1058 of the paper \u201cIterative minimization techniques for ab initio total-\nenergy calculations: molecular dynamics and conjugate gradients\u201d, by M.C.\nPayne, M.P. Teter, D.C. Allan, T.A. Arias and J.D. Joannopoulos, Rev. Mod.\nPhys. 64, 1045 (1992) or, if you have more time, you should browse through the\nChaps. 1 to 13 , and appendices L and M of the book Electronic Structure.\nBasic Theory and Practical Methods. R. M. Martin. Cambridge University Press\n(2004) ISBN 0 521 78285 6. The latter reference is a must if you have not yet\nused another electronic structure code or a Quantum Chemistry package.\n\n\nAfter the tutorial, you might find it useful to learn about the test cases\ncontained in the subdirectories of ~abinit/tests/, e.g. the directories fast,\nv1, v2, \u2026 , that provide many example input files. You should have a look at\nthe README files of these directories.\n\n\nAdditional information can be found in the ~abinit/doc directory, including\nthe description of the ABINIT project, guide lines for developpers, more on\nthe use of the code (tuning) \u2026\n\n\n\n\nBrief description of each lesson\u2019s content\n\u00b6\n\n\nThe lessons 1-4 present the basic concepts, and form a global entity: you should not skip any of these.\n\n\n\n\nThe lesson 1\n deals with the H2 molecule : get the total energy, the electronic energies, the charge density, the bond length, the atomisation energy \n\n\nThe lesson 2\n deals again with the H2 molecule: convergence studies, LDA versus GGA \n\n\nThe lesson 3\n deals with crystalline silicon (an insulator): the definition of a k-point grid, the smearing of the cut-off energy, the computation of a band structure, and again, convergence studies \u2026\n\n\nThe lesson 4\n deals with crystalline aluminum (a metal), and its surface: occupation numbers, smearing the Fermi-Dirac distribution, the surface energy, and again, convergence studies \u2026\n\n\n\n\nOther lessons present more specialized topics.\n\n\nThere is a group of lessons that can be started without any other prerequisite than the lessons 1 to 4, and that you can do in any order (there are some exceptions, though):\n\n\n\n\nThe lesson on spin in ABINIT\n presents the properties related to spin: spin-polarized calculations and spin-orbit coupling. \n\n\nThe lesson on the use of PAW (PAW1)\n presents the Projector-Augmented Wave method, implemented in ABINIT as an alternative to norm-conserving pseudopotentials, with a sizeable accuracy and CPU time advantage.\n\n\nThe lesson on the generation of PAW atomic data files (PAW2)\n presents the generation of atomic data for use with the PAW method. Prerequisite : PAW1.\n\n\nThe lesson on the validation of a PAW atomic datafile (PAW3)\n demonstrates how to test a generated PAW dataset using ABINIT, against the ELK all-electron code, for diamond and magnesium. Prerequisite : PAW1 and PAW2.\n\n\nThe lesson on the properties of the nuclei\n shows how to compute the electric field gradient. Prerequisite : PAW1.\n\n\nThe lesson on Wannier90\n deals with the Wannier90 library to obtain Maximally Localized Wannier Functions.\n\n\nThe lesson on polarization and finite electric field\n deals with the computation of the polarization of an insulator (e.g. ferroelectric, or dielectric material) thanks to the Berry phase approach, and also presents the computation of materials properties in the presence of a finite electric field (also thanks to the Berry phase approach).\n\n\nThe lesson on Analysis Tools\n deals with the use of the CUT3D utility to analyse wavefunctions and densities.\n\n\nThe lesson on DFT+U\n shows how to perform a DFT+U calculation using ABINIT, and will lead to compute the projected DOS of NiO. Prerequisite : PAW1.\n\n\nThe lesson on DFT+DMFT\n shows how to perform a DFT+DMFT calculation on SrVO3 using projected Wannier functions. Prerequisite : DFT+U.\n\n\nThe lesson on the calculation of effective interactions U and J by the cRPA method\n shows how to determine the U value with the constrained Random Phase Approximation using projected Wannier orbitals. Prerequisite : DFT+U.\n\n\nThe lesson on the determination of U for DFT+U\n shows how to determine the U value with the linear response method, to be used in the DFT+U approach. Prerequisite : DFT+U.\n\n\nThe lesson on TDDFT\n deals with the computation of the excitation spectrum of finite systems, thanks to the Time-Dependent Density Functional Theory approach, in the Cassida formalism.\n\n\nThe lesson \u201cSource code\u201d\n introduces the user to the development of new functionalities in ABINIT: in this lesson, one learns how to add a new input variable \u2026\n\n\n\n\nThere is an additional group of lessons on response functions (phonons, optics, dielectric constant, electron-phonon interaction, elastic response, non-linear optics, Raman coefficients, piezoelectricity \u2026), for which some common additional information are needed:\n\n\n\n\nThe lesson Response-Function 1 (RF1)\n presents the basics of response-functions within ABINIT. The example given is the study of dynamical and dielectric properties of AlAs (an insulator): phonons at Gamma, dielectric constant, Born effective charges, LO-TO splitting, phonons in the whole Brillouin zone. The creation of the \u201cDerivative Data Base\u201d (DDB) is presented.\n\n\nThe lesson Response-Function 2 (RF2)\n presents the analysis of the DDBs that have been introduced in the preceeding lesson RF1. The computation of the interatomic forces and the computation of thermodynamical properties is an outcome of this lesson.\n\n\nThe additional information given by lesson RF1 opens the door to\n \nThe lesson on Optic\n, the utility that allows to obtain the frequency dependent linear optical dielectric function and the frequency dependent second order nonlinear optical susceptibility, in the simple \u201cSum-Over-State\u201d approximation.\n\n\nThe additional information given by lesson RF1 and RF2 opens the door to a group of lessons that can be followed independently of each other: \n \nThe lesson on the electron-phonon interaction\n presents the use of the utility MRGKK and ANADDB to examine the electron-phonon interaction and the subsequent calculation of superconductivity temperature (for bulk systems).\n\n\nThe lesson on the elastic properties\n presents the computation with respect to the strain perturbation and its responses: elastic constants, piezoelectricity.\n\n\nThe lesson on static non-linear properties\n presents the computation of responses beyond the linear order, within Density-Functional Perturbation Theory (beyond the simple Sum-Over-State approximation): Raman scattering efficiencies (non-resonant case), non-linear electronic susceptibility, electro-optic effect. Comparison with the finite field technique (combining the computation of linear response functions with finite difference calculations), is also provided.\n\n\n\n\nAn additional lesson has been developed outside the standard structure of the\nABINIT tutorial, in the experimental Wiki of ABINIT, \n the lesson on\ntemperature dependence of the electronic\nstructure\n.\n\n\nThere is another additional group of lessons on many-body perturbation theory (GW approximation, Bethe-Salpeter equation), to be done sequentially): \n\n\n\n\nThe first lesson on GW (GW1)\n deals with the computation of the quasi-particle band gap of Silicon (semiconductor), in the GW approximation (much better than the Kohn-Sham LDA band structure), with a plasmon-pole model. \n\n\nThe second lesson on GW (GW2)\n deals with the computation of the quasi-particle band structure of Aluminum, in the GW approximation (so, much better than the Kohn-Sham LDA band structure) without using the plasmon-pole model. \n\n\nThe lesson on the Bethe-Salpeter Equation (BSE)\n deals with the computation of the macroscopic dielectric function of Silicon within the Bethe-Salpeter equation. \n\n\n\n\nConcerning parallelism, there is another set of specialized lessons. For each of these lessons, you are supposed to be familiarized with the corresponding tutorial for the sequential calculation.\n\n\n\n\nAn introduction on ABINIT in Parallel\n should be read before going to the next lessons about parallelism. One simple example of parallelism in ABINIT will be shown.\n\n\nParallelism for ground-state calculations, with plane waves\n presents the combined k-point (K), plane-wave (G), band (B), spin/spinor parallelism of ABINIT (so, the \u201cKGB\u201d parallelism), for the computation of total energy, density, and ground state properties \n\n\nParallelism for molecular dynamics calculations\n\n\nParallelism based on \u201cimages\u201d, e.g. for the determination of transitions paths (string method)\n, that can be activated on top of the \u201cKGB\u201d parallelism for force calculations.\n\n\nParallelism for ground-state calculations, with wavelets\n presents the parallelism of ABINIT, when wavelets are used as a basis function instead of planewaves, for the computation of total energy, density, and ground state properties\n\n\nParallelism of response-function calculations\n - you need to be familiarized with the calculation of linear-response properties within ABINIT, see the tutorial \n Response-Function 1 (RF1)\n\n\nParallelism of Many-Body Perturbation calculations (GW)\n allows to speed up the calculation of accurate electronic structures (quasi-particle band structure, including many-body effects).\n\n\n\n\nNOTE that not all features of ABINIT are covered by these tutorials. For a\ncomplete feature list, please see the ~abinit/doc/features/ directory. For\nexamples on how to use these features, please see the ~abinit/tests/*\ndirectories and their accompanying README files.",
            "title": "Overview"
        },
        {
            "location": "/tutorials/welcome/#brief-description-of-each-lessons-content",
            "text": "The lessons 1-4 present the basic concepts, and form a global entity: you should not skip any of these.   The lesson 1  deals with the H2 molecule : get the total energy, the electronic energies, the charge density, the bond length, the atomisation energy   The lesson 2  deals again with the H2 molecule: convergence studies, LDA versus GGA   The lesson 3  deals with crystalline silicon (an insulator): the definition of a k-point grid, the smearing of the cut-off energy, the computation of a band structure, and again, convergence studies \u2026  The lesson 4  deals with crystalline aluminum (a metal), and its surface: occupation numbers, smearing the Fermi-Dirac distribution, the surface energy, and again, convergence studies \u2026   Other lessons present more specialized topics.  There is a group of lessons that can be started without any other prerequisite than the lessons 1 to 4, and that you can do in any order (there are some exceptions, though):   The lesson on spin in ABINIT  presents the properties related to spin: spin-polarized calculations and spin-orbit coupling.   The lesson on the use of PAW (PAW1)  presents the Projector-Augmented Wave method, implemented in ABINIT as an alternative to norm-conserving pseudopotentials, with a sizeable accuracy and CPU time advantage.  The lesson on the generation of PAW atomic data files (PAW2)  presents the generation of atomic data for use with the PAW method. Prerequisite : PAW1.  The lesson on the validation of a PAW atomic datafile (PAW3)  demonstrates how to test a generated PAW dataset using ABINIT, against the ELK all-electron code, for diamond and magnesium. Prerequisite : PAW1 and PAW2.  The lesson on the properties of the nuclei  shows how to compute the electric field gradient. Prerequisite : PAW1.  The lesson on Wannier90  deals with the Wannier90 library to obtain Maximally Localized Wannier Functions.  The lesson on polarization and finite electric field  deals with the computation of the polarization of an insulator (e.g. ferroelectric, or dielectric material) thanks to the Berry phase approach, and also presents the computation of materials properties in the presence of a finite electric field (also thanks to the Berry phase approach).  The lesson on Analysis Tools  deals with the use of the CUT3D utility to analyse wavefunctions and densities.  The lesson on DFT+U  shows how to perform a DFT+U calculation using ABINIT, and will lead to compute the projected DOS of NiO. Prerequisite : PAW1.  The lesson on DFT+DMFT  shows how to perform a DFT+DMFT calculation on SrVO3 using projected Wannier functions. Prerequisite : DFT+U.  The lesson on the calculation of effective interactions U and J by the cRPA method  shows how to determine the U value with the constrained Random Phase Approximation using projected Wannier orbitals. Prerequisite : DFT+U.  The lesson on the determination of U for DFT+U  shows how to determine the U value with the linear response method, to be used in the DFT+U approach. Prerequisite : DFT+U.  The lesson on TDDFT  deals with the computation of the excitation spectrum of finite systems, thanks to the Time-Dependent Density Functional Theory approach, in the Cassida formalism.  The lesson \u201cSource code\u201d  introduces the user to the development of new functionalities in ABINIT: in this lesson, one learns how to add a new input variable \u2026   There is an additional group of lessons on response functions (phonons, optics, dielectric constant, electron-phonon interaction, elastic response, non-linear optics, Raman coefficients, piezoelectricity \u2026), for which some common additional information are needed:   The lesson Response-Function 1 (RF1)  presents the basics of response-functions within ABINIT. The example given is the study of dynamical and dielectric properties of AlAs (an insulator): phonons at Gamma, dielectric constant, Born effective charges, LO-TO splitting, phonons in the whole Brillouin zone. The creation of the \u201cDerivative Data Base\u201d (DDB) is presented.  The lesson Response-Function 2 (RF2)  presents the analysis of the DDBs that have been introduced in the preceeding lesson RF1. The computation of the interatomic forces and the computation of thermodynamical properties is an outcome of this lesson.  The additional information given by lesson RF1 opens the door to   The lesson on Optic , the utility that allows to obtain the frequency dependent linear optical dielectric function and the frequency dependent second order nonlinear optical susceptibility, in the simple \u201cSum-Over-State\u201d approximation.  The additional information given by lesson RF1 and RF2 opens the door to a group of lessons that can be followed independently of each other:    The lesson on the electron-phonon interaction  presents the use of the utility MRGKK and ANADDB to examine the electron-phonon interaction and the subsequent calculation of superconductivity temperature (for bulk systems).  The lesson on the elastic properties  presents the computation with respect to the strain perturbation and its responses: elastic constants, piezoelectricity.  The lesson on static non-linear properties  presents the computation of responses beyond the linear order, within Density-Functional Perturbation Theory (beyond the simple Sum-Over-State approximation): Raman scattering efficiencies (non-resonant case), non-linear electronic susceptibility, electro-optic effect. Comparison with the finite field technique (combining the computation of linear response functions with finite difference calculations), is also provided.   An additional lesson has been developed outside the standard structure of the\nABINIT tutorial, in the experimental Wiki of ABINIT,   the lesson on\ntemperature dependence of the electronic\nstructure .  There is another additional group of lessons on many-body perturbation theory (GW approximation, Bethe-Salpeter equation), to be done sequentially):    The first lesson on GW (GW1)  deals with the computation of the quasi-particle band gap of Silicon (semiconductor), in the GW approximation (much better than the Kohn-Sham LDA band structure), with a plasmon-pole model.   The second lesson on GW (GW2)  deals with the computation of the quasi-particle band structure of Aluminum, in the GW approximation (so, much better than the Kohn-Sham LDA band structure) without using the plasmon-pole model.   The lesson on the Bethe-Salpeter Equation (BSE)  deals with the computation of the macroscopic dielectric function of Silicon within the Bethe-Salpeter equation.    Concerning parallelism, there is another set of specialized lessons. For each of these lessons, you are supposed to be familiarized with the corresponding tutorial for the sequential calculation.   An introduction on ABINIT in Parallel  should be read before going to the next lessons about parallelism. One simple example of parallelism in ABINIT will be shown.  Parallelism for ground-state calculations, with plane waves  presents the combined k-point (K), plane-wave (G), band (B), spin/spinor parallelism of ABINIT (so, the \u201cKGB\u201d parallelism), for the computation of total energy, density, and ground state properties   Parallelism for molecular dynamics calculations  Parallelism based on \u201cimages\u201d, e.g. for the determination of transitions paths (string method) , that can be activated on top of the \u201cKGB\u201d parallelism for force calculations.  Parallelism for ground-state calculations, with wavelets  presents the parallelism of ABINIT, when wavelets are used as a basis function instead of planewaves, for the computation of total energy, density, and ground state properties  Parallelism of response-function calculations  - you need to be familiarized with the calculation of linear-response properties within ABINIT, see the tutorial   Response-Function 1 (RF1)  Parallelism of Many-Body Perturbation calculations (GW)  allows to speed up the calculation of accurate electronic structures (quasi-particle band structure, including many-body effects).   NOTE that not all features of ABINIT are covered by these tutorials. For a\ncomplete feature list, please see the ~abinit/doc/features/ directory. For\nexamples on how to use these features, please see the ~abinit/tests/*\ndirectories and their accompanying README files.",
            "title": "Brief description of each lesson's content"
        },
        {
            "location": "/tutorials/base1/",
            "text": "This lesson aims at showing how to get the following physical properties:\n\n\n\n\nthe (pseudo)total energy \n\n\nthe bond length \n\n\nthe charge density \n\n\nthe atomisation energy \n\n\n\n\nYou will learn about the two input files, the basic input variables, the\nexistence of defaults, the actions of the parser, and the use of the multi-dataset feature. \nYou will also learn about the two output files as well as the density file.\n\n\nThis first lesson covers the sections 1, 3, 4 and 6 of the \nhelp_abinit\n.\n\n\nThe very first step is a detailed tour of the input and output files: you are\nlike a tourist, and you discover a town in a coach. You will have a bit more\nfreedom after that first step \u2026\n\nIt is supposed that you have some good knowledge of UNIX/Linux.\n\n\nThis lesson should take about 2 hours.\n\n\n\n\n\n\n1.1. The first step (the most important, and the most difficult !):\n\n\n1.2. Computation of the interatomic distance (method 1).\n\n\n1.3 Computation of the interatomic distance (method 2).\n\n\n1.4. Computation of the charge density.\n\n\n1.5. Computation of the atomisation energy.\n\n\nAnswers to the questions\n\n\n\n\n\n\n\n\n1.1. The first step (the most important, and the most difficult !):\n\u00b6\n\n\nComputing the (pseudo) total energy, and some associated quantities.\n\n\nNote that the present tutorial will use four different windows: one to\nvisualize the text of the tutorial (the present window), a second to run the\ncode, a third to visualize sections of the \nhelp_abinit\n (that will open\nautomatically), and a fourth one for the description of input variables (that\nwill also open automatically). Try to manage adequately these four windows \u2026\n\n\n1.1.a\n In addition to the present window, open the second window. \nGo to the Tutorial directory (that we refer as ~abinit/tests/tutorial/Input). \n\n\n    $ \ncd\n ~abinit/tests/tutorial/Input\n\n\n\n\n\nIn that directory, you will find the necessary input files to run the examples\nrelated to this tutorial. Take a few seconds to read the names of the files\nalready present in \n~abinit/tests/tutorial/Input\n. \nCompare with the lessons mentioned in the index of the \nTutorial home page\n.\nYou will find other input files, specific for the Density Functional\nPerturbation Theory (\u201cResponse functions\u201d) capabilities of ABINIT in the\ndirectory \n~abinit/tests/tutorespfn/Input\n.  \n\n\n1.1.b \nYou also need a working directory. So, you should create a subdirectory of this directory, \nwhose name might be \u201cWork\u201d (so ~abinit/tests/tutorial/Input/Work). Change the working directory of windows 2 to \u201cWork\u201d: \n\n\n    $ mkdir Work\n    $ \ncd\n Work\n\n\n\n\n\nYou will do most of the actions of this tutorial in this working directory.\nCopy the file tbase1_x.files in \u201cWork\u201d:\n\n\n    $ cp ../tbase1_x.files .\n\n\n\n\n\n1.1.c\n Edit the tbase1_x.files. It is not very long (only 6 lines). It gives the information needed for the code to build other file names \u2026 You will discover more about this file in the \nsection 1.1\n of the abinit_help file. Please, read it now (it will take one minute or so). \n\n\n1.1.d\n Modify the first and second lines of tbase1_x.files file, so that they read:  \n\n\ntbase1_1.in  \ntbase1_1.out\n\n\n\n\n\nLater, you will again modify these lines, to treat more cases. Make sure that\nthe last line, gives the correct location of the pseudopotential. Close the\ntbase1_x.files file. Then, copy the file [[tests/tutorial/Input/tbase1_1.in]]\nin \u201cWork\u201d:  \n\n\n    $ cp ../tbase1_1.in .\n\n\n\n\n\nAlso later, we will look at this file, and learn about its content. For now,\nyou will try to run the code. Its name is \nabinit\n. The place where it can be\nfound varies, according to the installation procedure. We will denote the\ndirectory where you have installed the package \n~abinit\n. Supposing that you\ndumped the binaries from the Web site, then \nabinit\n is to be found in the\npackage, with location \n~abinit/opt\n. If you dumped the sources from the Web\nsite, and issued \n./configure\n in the ~abinit directory, then it is located in\n\n~abinit/src/98_main\n. In what follows, we will suppose that you can call it by\nsimply typing \nabinit\n, even if the actual command must be something like\n\n../../../../opt/abinit\n or \n../../../../src/98_main/abinit\n. (Suggestion: create\nan alias with \nln -s\n, or copy the abinit executable, or declare the path with\nthe shell command \nexport PATH=~abinit/src/98_main:$PATH\n).\n\n\nSo, in the Work directory, type:  \n\n\n    $ abinit < tbase1_x.files >\n&\n log\n\n\n\n\n\nWait a few seconds \u2026 it\u2019s done ! You can look at the content of the Work directory.\n\n\n    $ ls\n\n\n\n\n\nYou should get something like\n\n\n    abinit  log  tbase1_1.in  tbase1_1.out  tbase1_x.files  tbase1_xo_DDB  tbase1_xo_DEN  \n    tbase1_xo_EIG.nc  tbase1_xo_GSR.nc  tbase1_xo_OUT.nc  tbase1_xo_WFK\n\n\n\n\n\n(if you declared the path, you will not find \nabinit\n in the list) Different\noutput files have been created, including a \nlog\n file and the output file\n\ntbase1_1.out\n. To check that everything is correct, you can make a diff of\n\ntbase1_1.out\n with a reference file [[tests/tutorial/Refs/tbase1_1.out]]\ncontained in the \n~abinit/tests/tutorial/Refs\n directory:\n\n\n    $ diff tbase1_1.out ../../Refs/tbase1_1.out \n|\n less\n\n\n\n\n\n(Perhaps you will need to ignore the blanks, with the command \ndiff -b\n\ninstead of \ndiff\n)\n\n\nThat reference file uses slightly different file names. You should get some\ndifference, but rather inoffensive ones, like differences in the name of input\nfiles or timing differences, e.g.:\n\n\n    2,3c2,3\n    < .Version 8.0.8 of ABINIT\n    < .(MPI version, prepared for a x86_64_linux_gnu5.4 computer)\n    ---\n    > .Version 8.0.7  of ABINIT\n    > .(MPI version, prepared for a x86_64_linux_gnu5.3 computer)\n    17c17\n    < .Starting date : Fri 27 May 2016.\n    ---\n    > .Starting date : Thu 26 May 2016.\n    27c27\n    < - input  file    -> tbase1_1.in\n    ---\n    > - input  file    -> ../tbase1_1.in\n    29,30c29,30\n    < - root for input  files -> tbase1_xi\n    < - root for output files -> tbase1_xo\n    ---\n    > - root for input  files -> tbase1_1i\n    > - root for output files -> tbase1_1o\n    92,93c92,93\n    < - pspini: atom type   1  psp file is ../../../Psps_for_tests/01h.pspgth\n    < - pspatm: opening atomic psp file    ../../../Psps_for_tests/01h.pspgth\n    ---\n    > - pspini: atom type   1  psp file is /home/gonze/ABINIT/ABINITv8.0.7/trunk/8.0.7-private/tests/Psps_for_tests/01h.pspgth\n    > - pspatm: opening atomic psp file    /home/gonze/ABINIT/ABINITv8.0.7/trunk/8.0.7-private/tests/Psps_for_tests/01h.pspgth\n    166c166\n    <  prteigrs : about to open file tbase1_xo_EIG\n    ---\n    >  prteigrs : about to open file tbase1_1o_EIG\n    214c214\n    < - Total cpu        time (s,m,h):          4.7        0.08      0.001\n    ---\n    > - Total cpu        time (s,m,h):          4.6        0.08      0.001\n    221,229c221,228\n\n\n\n\n\n(\u2026 and what comes after that is related only to timing \u2026).\n\n\nIf you do not run on a PC under Linux with GNU Fortran compiler, e.g. the\nIntel compiler, you might also have small numerical differences, on the order\nof 1.0d-10 at most. You might also have other differences in the paths of\nfiles. Finally, it might also be that the default FFT algorithm differs from\nthe one of the reference machine, in which case the line mentioning fftalg\nwill differ (ifftalg will not be 312). If you get something else, you should\nask for help!\n\n\nIn this part of the output file, note the dash \u201c-\u201d that is inserted in the\nfirst column. This is not important for the user: it is used to post-process\nthe output file using some automatic tool. As a rule, you should ignore\nsymbols placed in the first column of the ABINIT output file.\n\n\nSupposing everything went well, we will now detail the different steps that\ntook place: how to run the code, what is in the \u201ctbase1_1.in\u201d input file, and,\nlater, what is in the \u201ctbase1_1.out\u201d and \u201clog\u201d output files.\n\n\n1.1.e\n Running the code is described in the \nsection 1.2\n of the abinit_help file. Please, read it now (it will take 30 seconds or less).\n\n\n1.1.f\n It is now time to edit the tbase1_1.in file. You can have a first glance at it. It is not very long: about 50 lines, mostly comments. Do not try to understand everything immediately. After having gone through it, you should read general explanation about its content, and the format of such input files in the \nsection 3.1\n of the abinit_help file. \n\n\n1.1.g\n You might now examine in more details some input variables. An alphabetically ordered \nindex of all variables\n is provided, and their description is found in different files (non-exhaustive list): \n\n\n\n\nBasic variables, \nVARBAS\n\n\nFiles handling variables, \nVARFIL\n\n\nGround-state calculation variables, \nVARGS\n\n\nGW variables, \nVARGW\n\n\nParallelisation variables, \nVARPAR\n\n\nResponse Function variables, \nVARRF\n\n\n\n\nHowever, the number of such variables is rather large! Note that a dozen of\ninput variables were needed to run the first test case. This is possible\nbecause there are defaults values for the other input variables. When it\nexists, the default value is mentioned at the fourth line of the section\nrelated to each input variable, in the corresponding input variables file.\nSome input variables are also preprocessed, in order to derive convenient\nvalues for other input variables. Defaults are not existing or were avoided\nfor the few input variables that you find in tbase1_1.in . These are\nparticularly important input variables. So, take a few minutes to have a look\nat the input variables of tbase1_1.in:\n\n\n\n\nacell\n\n\nntypat\n\n\nznucl\n\n\nnatom\n\n\ntypat\n\n\nxcart\n\n\necut\n\n\nnkpt\n\n\nnstep\n\n\ntoldfe\n\n\ndiemac\n\n\n\n\nHave also a look at \nkpt\n and \niscf\n.\n\n\nIt is now time to have a look at the two output files of the run.\n\n\n1.1.h\n First, open the \u201clog\u201d file. You can begin to read it. It is nasty. Jump to its end. You will find there the number of WARNINGS and COMMENTS that were issued by the code during execution. You might try to find them in the file (localize the keywords \u201cWARNING\u201d or \u201cCOMMENT\u201d in this file). Some of them are for the experienced user. For the present time, we will ignore them. You can find more information about messages in the log file in the \nsection 6.1\n of the abinit_help file.\n\n\n1.1.i\n Then, open the [[tests/tutorial/Refs/tbase1_1.out]] file. You find some general information about the output file in \n section 6.2\n of the abinit_help file. You should also: \n\n\n\n\nexamine the header of \u201ctbase1_1.out\u201d \n\n\nexamine the report on memory needs (do not read each value of parameters) \n\n\nexamine the echo of preprocessed input data, \n\n\n\n\nuntil you reach the message:  \n\n\nchkinp\n:\n \nChecking\n \ninput\n \nparameters\n \nfor\n \nconsistency\n.\n\n\n\n\n\n\nIf the code does not stop there, the input parameters are consistent. At this\nstage, many default values have been provided, and the preprocessing is\nfinished.\n\n\nIt is worth to come back to the echo of preprocessed input data. You should\nfirst examine the \u201ctbase1_1.in\u201d file in more details, and read the meaning of\neach of its variables in the corresponding input variables file, if it has not\nyet been done. Then, you should examine some variables that were NOT defined\nin the input file, but that appear in the echo written in \u201ctbase1_1.out\u201d:  \n\n\n- \nnband\n: its value is 2.\n\nIt is the number of electronic states that will be treated by the code. It has\nbeen computed by counting the number of valence electrons in the unit cell\n(summing the valence electrons brought by each pseudopotential) then occupying\nthe lowest states (look at the \nocc\n variable), and adding some states (at\nleast one, maybe more, depending on the size of the system).  \n\n\n- \nngfft\n: its value is 30 30 30 .\n\nIt is the number of points of the three-dimensional FFT grid. It has been\nderived from \necut\n and the dimension of the cell (\nacell\n).  \n\n\nThe maximal number of plane waves \u201c\nmpw\n\u201d is mentioned in the memory\nevaluation section: it is \n752\n.\n\nWell, this is not completely right, as the code took advantage of the time-\nreversal symmetry, valid for the k-point (0 0 0), to decrease the number of\nplanewave by about a factor of two.\n\nThe full set of plane waves is \n1503\n (see later in the \u201ctbase1_1.out\u201d\nfile).\n\nThe code indicates the time-reversal symmetry by a value of \nistwfk\n=2 ,\ninstead of the usual \nistwfk\n=1 default.  \n\n\n- \nnsym\n: its value is 16.\n\nIt is the number of symmetries of the system. The 3x3 matrices \nsymrel\n\ndefine the symmetries operation. In this case, none of the symmetries is\naccompanied by a translation, that would appear in the variable \ntnons\n. The\ncode did an automatic analysis of symmetries.\n\nThey could alternatively be set by hand, or using the symmetry builder (to be\ndescribed later).  \n\n\n- \nxangst\n and \nxred\n are alternative ways to \nxcart\n to specify the\npositions of atoms within the primitive cell.\n\n\nNow, you can start reading the description of the remaining of the\ntbase1_1.out file, in the \n section 6.3\n\n of the abinit_help file.\nLook at the tbase1_1.out file at the same time.\n\n\n 1.1.j  \n You have read completely an output file! \n\n\nCould you answer the following questions?\n\n\n\n\nQ1. How many SCF cycles were needed to have the \ntoldfe\n criterion satisfied? \n\n\nQ2. Is the energy likely more converged than \ntoldfe\n? \n\n\nQ3. What is the value of the force on each atom, in Ha/Bohr? \n\n\nQ4. What is the difference of eigenenergies between the two electronic states? \n\n\nQ5. Can you insert \u2018\nprtvol\n 2\u2019 in the input file, run again abinit, and find where is located the maximum of the electronic density, and how much is it, in electrons/Bohr^3 ? \n\n\n\n\n(answers are given at the end of the present file)\n\n\n\n\n1.2. Computation of the interatomic distance (method 1). \n\u00b6\n\n\n1.2.a\n \nStarting from now, everytime a new input variable is mentioned, you should read the corresponding descriptive section in the ABINIT help.\n\n\nWe will now complete the description of the meaning of each term: there are\nstill a few indications that you should be aware of, even if you will not use\nthem in the tutorial. These might appear in the description of some input\nvariables \u2026 For this, you should read the \n section\n3.2\n of the\nabinit_help file.\n\n\n1.2.b\n There are three methodologies to compute the optimal distance between the two Hydrogen atoms: \n\n\n\n\none could compute the \nTOTAL ENERGY\n for different values of the interatomic distance, make a fit through the different points, and determine the minimum of the fitting function; \n\n\none could compute the \nFORCES\n for different values of the interatomic distance, make a fit through the different values, and determine the zero of the fitting function; \n\n\none could use an automatic algorithm for minimizing the energy (or finding the zero of forces). \nWe will begin with the computation of energy and forces for different values\nof the interatomic distance. This exercise will allow you to learn how to use\nmultiple datasets.\n\n\n\n\nThe interatomic distance in the tbase1_1.in file was 1.4 Bohr. Suppose you\ndecide to examine the interatomic distances from 1.0 Bohr to 2.0 Bohr, by\nsteps of 0.05 Bohr. That is, 21 calculations.\n\nIf you are a UNIX guru, it will be easy for you to write a script that will\ndrive these 21 calculations, changing automatically the variable \nxcart\n in\nthe input file, and then gather all the data, in a convenient form to be\nplotted.\n\nWell, are you a UNIX guru? If not, there is an easier path, all within ABINIT!\n\n\nThis is the multi-dataset mode. Detailed explanations about it can be found in\nsections \n3.3\n,\n\n3.4\n,\n\n3.5\n and\n\n3.6\n, of the abinit_help\nfile.\n\n\n1.2.c\n Now, can you write an input file that will do the computation described above (interatomic distances from 1.0 Bohr to 2.0 Bohr, by steps of 0.05 Bohr)? You might start from tbase1_1.in. Try to define a series, and to use the \ngetwfk\n input variable (the latter will make the computation much faster). \n\n\nYou should likely have a look at the section that describes the \nirdwfk\n and\n\ngetwfk\n input variables: in particular, look at the meaning of \ngetwfk\n-1\n\n\nAlso, define explicitly the number of states (or supercell \u201cbands\u201d) to be one,\nusing the input variable \nnband\n. The input file\n[[tests/tutorial/Input/tbase1_2.in]] is an example of file that will do the\njob, while [[tests/tutorial/Refs/tbase1_2.out]] is an example of output file.\nIf you decide to use the ~abinit/tests/tutorial/Input/tbase1_2.in file, do not\nforget to change the file names in the \u201ctbase1_x.files\u201d file \u2026\n\n\nSo, you run the code with your input file (this might take fifteen seconds or\nso on a PC at 3 GHz), examine the output file quickly (there are many\nrepetition of sections, for the different datasets), and get the output\nenergies gathered in the final echo of variables:\n\n\n        etotal1  -1.0368223891E+00\n        etotal2  -1.0538645433E+00\n        etotal3  -1.0674504851E+00\n        etotal4  -1.0781904896E+00\n        etotal5  -1.0865814785E+00\n        etotal6  -1.0930286804E+00\n        etotal7  -1.0978628207E+00\n        etotal8  -1.1013539124E+00\n        etotal9  -1.1037224213E+00\n        etotal10 -1.1051483730E+00\n        etotal11 -1.1057788247E+00\n        etotal12 -1.1057340254E+00\n        etotal13 -1.1051125108E+00\n        etotal14 -1.1039953253E+00\n        etotal15 -1.1024495225E+00\n        etotal16 -1.1005310615E+00\n        etotal17 -1.0982871941E+00\n        etotal18 -1.0957584182E+00\n        etotal19 -1.0929800578E+00\n        etotal20 -1.0899835224E+00\n        etotal21 -1.0867972868E+00\n\n\n\n\n\nYou might try to plot these data. \n\n\n \n\n\nThe minimum of energy in the above list is clearly between dataset 11 and 12, that is:\n\n\n         xcart11 -7.5000000000E-01  0.0000000000E+00  0.0000000000E+00\n                  7.5000000000E-01  0.0000000000E+00  0.0000000000E+00\n         xcart12 -7.7500000000E-01  0.0000000000E+00  0.0000000000E+00\n                  7.7500000000E-01  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\ncorresponding to a distance of H atoms between 1.5 Bohr and 1.55 Bohr. The\nforces vanish also between 1.5 Bohr and 1.55 Bohr:\n\n\n     fcart11 -5.4945071285E-03  0.0000000000E+00  0.0000000000E+00\n              5.4945071285E-03  0.0000000000E+00  0.0000000000E+00\n     fcart12  6.9603067838E-03  0.0000000000E+00  0.0000000000E+00\n             -6.9603067838E-03  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\nFrom these two values, using a linear interpolation, one get the optimal value\nof 1.522 Bohr .\n\nNote that \nthe number of SCF cycles drops from 6 to 5 when the wavefunctions\nare read from the previous dataset.\n\n\n\n\n1.3 Computation of the interatomic distance (method 2). \n\u00b6\n\n\n1.3.a\n The other methodology is based on an automatic computation of the minimum. \n\nThere are different algorithms to do that. See the input variable \nionmov\n,\nwith values 2 and 7. In the present case, with only one degree of freedom to\nbe optimized, the best choice is \nionmov\n 2 .\n\n\nYou have also to define the maximal number of timesteps for this optimization.\nSet the input variable \nntime\n to 10, it will be largely enough. For the\nstopping criterion \ntolmxf\n, use the reasonable value of 5.0d-4 Ha/Bohr.\nThis defines the force threshold to consider that the geometry is converged.\nThe code will stop if the residual forces are below that value before reaching\n\nntime\n.\n\n\nIt is also worth to change the stopping criterion for the SCF cycle, in order\nto be sure that the forces generated for each trial interatomic distance are\nsufficiently converged. Indeed, the value used for \ntoldfe\n, namely 1.0d-6,\nmight be sufficient for total energy calculations, but definitely not for the\naccurate computation of other properties. So, change \ntoldfe\n in \ntoldff\n,\nand set the latter input variable to ten times smaller than \ntolmxf\n. The\ninput file [[tests/tutorial/Input/tbase1_3.in]] is an example of file that\nwill do the job, while [[tests/tutorial/Refs/tbase1_3.out]] is an example of\noutput file. If you decide to use these files, do not forget to change the\nfile names in the \u201ctbase1_x.files\u201d file \u2026 So, you run the code with your\ninput file (a few seconds), examine quietly this file (which is much smaller\nthan the tbase1_2.out file), and get some significant output data gathered in\nthe final echo of variables:\n\n\n    etotal   -1.1058360644E+00\n     fcart    1.8270533893E-04  0.0000000000E+00  0.0000000000E+00\n             -1.8270533893E-04  0.0000000000E+00  0.0000000000E+00\n      ...\n     xcart   -7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n              7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\nAccording to these data (see \nxcart\n), the optimal interatomic distance is\nabout 1.522 Bohr, in good agreement with the estimation of tbase1_2.out . If\nyou have time (this is to be done at home), you might try to change the\nstopping criteria, and redo the calculation, to see the level of convergence\nof the interatomic distance.\n\n\nNote that the final value of fcart in your run might differ slightly from the\none shown above (less than one percent change). Such a fluctuation is quite\noften observed for a value converging to zero (remember, we ask the code to\ndetermine the equilibrium geometry, that is, forces should be zero) when the\nsame computation is done on different platforms.\n\n\n\n\n1.4. Computation of the charge density.\n\u00b6\n\n\nThe charge density has already been computed, for all geometries, in the\nabove-mentioned runs. Here, we will print this quantity.\n\n\n1.4.a\n We start from the optimized interatomic distance 1.522 Bohr, and make a run at fixed geometry. The input variable \nprtden\n must be set to 1. To understand correctly the content of the \nprtden\n description, it is worth to read a much more detailed description of the \u201cfiles\u201d file, in \nsection 4 \n of the abinit_help file. \n\n\n1.4.b\n The input file [[tests/tutorial/Input/tbase1_4.in]] is an example of input file for a run that will print a density. If you decide to use this file, do not forget to change the file names in tbase1_x.files. The run will take a few seconds. \n\n\nThe density will be output in the \ntbase1_xo_DEN\n file. Try to edit it \u2026\nNo luck ! This file is unformatted, not written using the ASCII code. Even if\nyou cannot read it, its description is provided in the abinit_help. It\ncontains first a header, then the density numbers. The description of the\nheader is presented in \nsection\n6.4\n of the abinit_help\nfile, while the body of the _DEN file is presented in \nsection\n6.5\n. It is the\nappropriate time to read also the description of the potential files and\nwavefunctions files, as these files contain the same header as the density\nfile, see sections\n\n6.6\n and\n\n6.7\n\n\n1.4.c\n Such a density file can be read by ABINIT, to restart a calculation (see the input variable \niscf\n, when its value is -2), but more usually, by an utility called \u201ccut3d\u201d. This utility is available in the ABINIT package. You might try to use it now, to generate two-dimensional cuts in the density, and visualize the charge density contours. \n\nRead the corresponding \nCut3D help\nfile\n. Then, try to run cut3d to\nanalyse \ntbase1_xo_DEN\n. You should first try to translate the unformatted\ndensity data to indexed formatted data, by using option 6 in the adequate\nmenu. Save the indexed formatted data to file \ntbase1_xo_DEN_indexed\n. Then,\nedit this file, to have an idea of the content of the _DEN files.\n\nFor further treatment, you might choose to select another option than 6. In\nparticular, if you have access to MATLAB, choose option 5. With minor\nmodifications (set ngx=ngy=ngz to 30) you will be able to use the file dim.m\npresent in ~abinit/doc/tutorial/documents/lesson_base1 to visualize the\n3-Dimensional isosurfaces. Another option might be to use the XCrysDen\nsoftware, for which you need to use option 9.\n\n\n\n\n1.5. Computation of the atomisation energy.\n\u00b6\n\n\n1.5.a\n The atomisation energy is the energy needed to separate a molecule in its constituent atoms, each being neutral. \n\nIn the present case, one must compute first the total energy of an isolated\nhydrogen atom. The atomisation energy will be the difference between the total\nenergy of H2 and twice the total energy of H.\n\nThere are some subtleties in the calculation of an isolated atom.\n\n\n\n\nin many cases, the ground state of an isolated atom is spin-polarized, see the variables \nnsppol\n and \nspinat\n ; \n\n\nthe highest occupied level might be degenerate with the lowest unoccupied level of the same spin, in which case the techniques usually appropriate for metals are to be used (see \nlesson_base4\n) \n\n\nalso often, the symmetry of the ground-state charge density will NOT be spherical, so that the automatic determination of symmetries by the code, based on the atomic coordinates, should be disabled, see the input variable \nnsym\n, to be set to 1 in this case. \n\n\n\n\nFor Hydrogen, we are lucky that the ground state is spherical (1s orbital),\nand that the highest occupied level and lowest unoccupied level, although\ndegenerate, have a different spin. We will define by hand the occupation of\neach spin, see the input variables \noccopt\n (to be set to 2), and \nocc\n .\n\nFinally, in order to make numerical errors cancel, it is important to compute\nthe above-mentioned difference in the same box, for the same cut-off, and even\nfor a location in the box that is similar to the molecule case (although the\nlatter might not be so important).\n\n\nThe input file [[tests/tutorial/Input/tbase1_5.in]] is an example of file that\nwill do the job, while [[tests/tutorial/Refs/tbase1_5.out]] is an example of\noutput file. If you decide to use the tbase1_5.in file, do not forget to\nchange the file names in the tbase1_x.files file. The run lasts a few seconds.\n\n\nYou should read the output file, and note the tiny differences related with\nthe spin-polarisation:\n\n\n\n\nthe electronic eigenvalues are now given for both spin up and spin down cases: \n\n\n\n\n         Eigenvalues (hartree) for nkpt=   1  k points, SPIN UP:\n     kpt#   1, nband=  1, wtk=  1.00000, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n      -0.26414\n     Eigenvalues (hartree) for nkpt=   1  k points, SPIN DOWN:\n     kpt#   1, nband=  1, wtk=  1.00000, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n      -0.11112\n\n\n\n\n\n\n\nIf you run again, while having inserted in the input file \u2018\nprtvol\n 2\u2019, because \noccopt\n, the charge density and spin polarisation at each point of the FFT grid is also analyzed: \n\n\n\n\n         Total charge density [el/Bohr^3]\n          Maximum=    1.4053E-01  at reduced coord.    0.0000    0.0000    0.0000\n     Next maximum=    1.2019E-01  at reduced coord.    0.0000    0.0000    0.9667\n          Minimum=    3.4544E-06  at reduced coord.    0.4667    0.4333    0.4333\n     Next minimum=    3.4544E-06  at reduced coord.    0.5333    0.4333    0.4333\n     Spin up density      [el/Bohr^3]\n          Maximum=    1.4053E-01  at reduced coord.    0.0000    0.0000    0.0000\n     Next maximum=    1.2019E-01  at reduced coord.    0.0000    0.0000    0.9667\n          Minimum=    3.4544E-06  at reduced coord.    0.4667    0.4333    0.4333\n     Next minimum=    3.4544E-06  at reduced coord.    0.5333    0.4333    0.4333\n     Spin down density    [el/Bohr^3]\n          Maximum=    0.0000E+00  at reduced coord.    0.9667    0.9667    0.9667\n     Next maximum=    0.0000E+00  at reduced coord.    0.9333    0.9667    0.9667\n          Minimum=    0.0000E+00  at reduced coord.    0.0000    0.0000    0.0000\n     Next minimum=    0.0000E+00  at reduced coord.    0.0333    0.0000    0.0000\n     Magnetization (spin up - spin down) [el/Bohr^3]\n          Maximum=    1.4053E-01  at reduced coord.    0.0000    0.0000    0.0000\n     Next maximum=    1.2019E-01  at reduced coord.    0.0000    0.0000    0.9667\n          Minimum=    3.4544E-06  at reduced coord.    0.4667    0.4333    0.4333\n     Next minimum=    3.4544E-06  at reduced coord.    0.5333    0.4333    0.4333\n     Relative magnetization (=zeta, between -1 and 1)\n          Maximum=    1.0000E+00  at reduced coord.    0.9667    0.9667    0.9667\n     Next maximum=    1.0000E+00  at reduced coord.    0.9333    0.9667    0.9667\n          Minimum=    1.0000E+00  at reduced coord.    0.0000    0.0000    0.0000\n     Next minimum=    1.0000E+00  at reduced coord.    0.0333    0.0000    0.0000\n\n\n\n\n\nThe \nzeta\n variable is the ratio between the spin-density difference and the\ncharge density. It varies between +1 and -1. In the present case of Hydrogen,\nthere is no spin down density, so the zeta variable is +1.\n\n(Comment: in this part of the output file, note the comma \u201c,\u201d that is inserted\nin the first column. This is not important for the user: it is used to post-\nprocess the output file using some automatic tool. As a rule, you should\nignore symbols placed in the first column of the ABINIT output file.)\n\n\nThe total energy is\n\n\n    etotal   -4.7010531489E-01\n\n\n\n\n\nwhile the total energy of the H2 molecule is (see test 13):\n\n\n    etotal   -1.1058360644E+00\n\n\n\n\n\nThe atomisation energy is thus 0.1656 Ha (The difference between the total\nenergy of the H2 molecule and twice the energy of an isolated Hydrogen atom).\n\n\nAt this stage, we can compare our results:\n\n\n\n\nbond length: 1.522 Bohr \n\n\natomisation energy at that bond length: 0.1656 Ha = 4.506 eV \n\n\n\n\nwith the experimental data as well as theoretical data using a much more\naccurate technique (see Kolos and Roothaan, Rev. Mod. Phys. 32, 219 (1960),\nespecially p.225)\n\n\n\n\nbond length: 1.401 Bohr \n\n\natomisation energy: 4.747 eV \n\n\n\n\nThe bond length is awful (nearly 10% off), and the atomisation energy is a bit too low, 5 % off.\n\n\nWhat is wrong??\n\nWell, are you sure that the input parameters that we did not discuss are correct? \nThese are:\n\n\n\n\necut\n (the plane-wave kinetic energy cut-off) \n\n\nacell\n (the supercell size) \n\n\nixc\n (not even mentioned until now, this input variable specifies what kind of \n    exchange-correlation functional is to be used \u2026) \n\n\nthe pseudopotential \n\n\n\n\nWe used 10 Ha as cut-off energy, a 10x10x10 Bohr^3 supercell, the local-\ndensity approximation (as well as the local-spin-density approximation) in the\nTeter parametrization, and a pseudopotential from the Goedecker-Hutter-Teter\ntable (Phys. Rev. B 54, 1703 (1996)).\n\n\nWe will see in the \nnext lesson\n how to address the choice\nof these parameters (except the pseudopotential).\n\n\n\n\nAnswers to the questions\n\u00b6\n\n\n\n\nQ1. How many SCF cycles were needed to have the \ntoldfe\n criterion satisfied? \n\n\nQ2. Is the energy likely more converged than \ntoldfe\n? \n\n\nQ3. What is the value of the force on each atom, in Ha/Bohr? \n\n\nQ4. What is the difference of eigenenergies between the two electronic states? \n\n\nQ5. Where is located the maximum of the electronic density, and how much is it, in electrons/Bohr^3 ? \n\n\n\n\nNOTE: \nthere might be numerical differences, from platform to platform, in the\nquoted results !\n\n\nQ1.\n 6 SCF cycles were needed: \n\n\n         iter   Etot(hartree)      deltaE(h)  residm     vres2\n     ETOT  1  -1.1013391225242    -1.101E+00 4.220E-04 8.396E+00\n     ETOT  2  -1.1036939626391    -2.355E-03 7.374E-09 2.840E-01\n     ETOT  3  -1.1037170965209    -2.313E-05 7.389E-08 1.549E-02\n     ETOT  4  -1.1037223548790    -5.258E-06 4.146E-07 2.715E-04\n     ETOT  5  -1.1037224212232    -6.634E-08 4.091E-09 5.700E-06\n     ETOT  6  -1.1037224213136    -9.037E-11 5.808E-12 3.076E-07\n\n     At SCF step    6, etot is converged :\n      for the second time, diff in etot=  9.038E-11 < toldfe=  1.000E-06\n\n\n\n\n\nNote that the number of steps that were allowed, \nnstep\n=10, is larger than\nthe number of steps effectively needed to reach the stopping criterion. As a\nrule, you should always check that the number of steps that you allowed was\nsufficient to reach the target tolerance. You might now play a bit with nstep,\nas e.g. set it to 5, to see how ABINIT reacts.\n\n\nSide note: in most of the tutorial examples, \nnstep\n will be enough to reach\nthe target tolerance, defined by one of the \u201ctolXXX\u201d input variables. However,\nthis is not always the case (e.g. the test case 1 of the \nlesson response-\nfunction 1\n), because of some portability problems, that\ncould only be solved by stopping the SCF cycles before the required tolerance.\n\n\nQ2.\n The information is contained in the same piece of the output file. Yes, the energy is more converged than \ntoldfe\n, since the stopping criterion asked for the difference between successive evaluations of the energy to be smaller than \ntoldfe\n twice in a row, while the evolution of the energy is nice, and always decreasing by smaller and smaller amounts. \n\n\nQ3.\n These values are: \n\n\n     cartesian forces (hartree/bohr) at end:\n        1     -0.03740558871217     0.00000000000000     0.00000000000000\n        2      0.03740558871217     0.00000000000000     0.00000000000000\n     frms,max,avg= 2.1596127E-02 3.7405589E-02   0.000E+00  0.000E+00  0.000E+00 h/b\n\n\n\n\n\nOn the first atom (located at -0.7 0 0 in cartesian coordinates, in Bohr), the\nforce vector is pointing in the minus x direction, and in the plus x direction\nfor the second atom located at +0.7 0 0 .\n\nThe H2 molecule would like to expand \u2026\n\n\nQ4.\n The eigenvalues (in Hartree) are mentioned at the lines \n\n\n     Eigenvalues (hartree) for nkpt=   1  k points:\n     kpt#   1, nband=  2, wtk=  1.00000, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n      -0.36525  -0.01379\n\n\n\n\n\nAs mentioned in the\n\nabinit_help\n file,\nthe absolute value of eigenenergies is not meaningful. Only differences of\neigenenergies, as well as differences with the potential.\n\nThe difference is 0.35147 Hartree, that is 9.564 eV .\n\nMoreover, remember that Kohn-Sham eigenenergies are formally NOT connected to\nexperimental excitation energies !\n\n(Well, more is to be said later about this \u2026).\n\n\nQ5.\n The maximum electronic density in electron per Bohr cube is reached at the mid-point between the two H atoms : \n\n\n     Total charge density [el/Bohr^3]\n    ,     Maximum=    2.6907E-01  at reduced coord.    0.0000    0.0000    0.0000",
            "title": "Base1"
        },
        {
            "location": "/tutorials/base1/#11-the-first-step-the-most-important-and-the-most-difficult",
            "text": "Computing the (pseudo) total energy, and some associated quantities.  Note that the present tutorial will use four different windows: one to\nvisualize the text of the tutorial (the present window), a second to run the\ncode, a third to visualize sections of the  help_abinit  (that will open\nautomatically), and a fourth one for the description of input variables (that\nwill also open automatically). Try to manage adequately these four windows \u2026  1.1.a  In addition to the present window, open the second window. \nGo to the Tutorial directory (that we refer as ~abinit/tests/tutorial/Input).       $  cd  ~abinit/tests/tutorial/Input  In that directory, you will find the necessary input files to run the examples\nrelated to this tutorial. Take a few seconds to read the names of the files\nalready present in  ~abinit/tests/tutorial/Input . \nCompare with the lessons mentioned in the index of the  Tutorial home page .\nYou will find other input files, specific for the Density Functional\nPerturbation Theory (\u201cResponse functions\u201d) capabilities of ABINIT in the\ndirectory  ~abinit/tests/tutorespfn/Input .    1.1.b  You also need a working directory. So, you should create a subdirectory of this directory, \nwhose name might be \u201cWork\u201d (so ~abinit/tests/tutorial/Input/Work). Change the working directory of windows 2 to \u201cWork\u201d:       $ mkdir Work\n    $  cd  Work  You will do most of the actions of this tutorial in this working directory.\nCopy the file tbase1_x.files in \u201cWork\u201d:      $ cp ../tbase1_x.files .  1.1.c  Edit the tbase1_x.files. It is not very long (only 6 lines). It gives the information needed for the code to build other file names \u2026 You will discover more about this file in the  section 1.1  of the abinit_help file. Please, read it now (it will take one minute or so).   1.1.d  Modify the first and second lines of tbase1_x.files file, so that they read:    tbase1_1.in  \ntbase1_1.out  Later, you will again modify these lines, to treat more cases. Make sure that\nthe last line, gives the correct location of the pseudopotential. Close the\ntbase1_x.files file. Then, copy the file [[tests/tutorial/Input/tbase1_1.in]]\nin \u201cWork\u201d:        $ cp ../tbase1_1.in .  Also later, we will look at this file, and learn about its content. For now,\nyou will try to run the code. Its name is  abinit . The place where it can be\nfound varies, according to the installation procedure. We will denote the\ndirectory where you have installed the package  ~abinit . Supposing that you\ndumped the binaries from the Web site, then  abinit  is to be found in the\npackage, with location  ~abinit/opt . If you dumped the sources from the Web\nsite, and issued  ./configure  in the ~abinit directory, then it is located in ~abinit/src/98_main . In what follows, we will suppose that you can call it by\nsimply typing  abinit , even if the actual command must be something like ../../../../opt/abinit  or  ../../../../src/98_main/abinit . (Suggestion: create\nan alias with  ln -s , or copy the abinit executable, or declare the path with\nthe shell command  export PATH=~abinit/src/98_main:$PATH ).  So, in the Work directory, type:        $ abinit < tbase1_x.files > &  log  Wait a few seconds \u2026 it\u2019s done ! You can look at the content of the Work directory.      $ ls  You should get something like      abinit  log  tbase1_1.in  tbase1_1.out  tbase1_x.files  tbase1_xo_DDB  tbase1_xo_DEN  \n    tbase1_xo_EIG.nc  tbase1_xo_GSR.nc  tbase1_xo_OUT.nc  tbase1_xo_WFK  (if you declared the path, you will not find  abinit  in the list) Different\noutput files have been created, including a  log  file and the output file tbase1_1.out . To check that everything is correct, you can make a diff of tbase1_1.out  with a reference file [[tests/tutorial/Refs/tbase1_1.out]]\ncontained in the  ~abinit/tests/tutorial/Refs  directory:      $ diff tbase1_1.out ../../Refs/tbase1_1.out  |  less  (Perhaps you will need to ignore the blanks, with the command  diff -b \ninstead of  diff )  That reference file uses slightly different file names. You should get some\ndifference, but rather inoffensive ones, like differences in the name of input\nfiles or timing differences, e.g.:      2,3c2,3\n    < .Version 8.0.8 of ABINIT\n    < .(MPI version, prepared for a x86_64_linux_gnu5.4 computer)\n    ---\n    > .Version 8.0.7  of ABINIT\n    > .(MPI version, prepared for a x86_64_linux_gnu5.3 computer)\n    17c17\n    < .Starting date : Fri 27 May 2016.\n    ---\n    > .Starting date : Thu 26 May 2016.\n    27c27\n    < - input  file    -> tbase1_1.in\n    ---\n    > - input  file    -> ../tbase1_1.in\n    29,30c29,30\n    < - root for input  files -> tbase1_xi\n    < - root for output files -> tbase1_xo\n    ---\n    > - root for input  files -> tbase1_1i\n    > - root for output files -> tbase1_1o\n    92,93c92,93\n    < - pspini: atom type   1  psp file is ../../../Psps_for_tests/01h.pspgth\n    < - pspatm: opening atomic psp file    ../../../Psps_for_tests/01h.pspgth\n    ---\n    > - pspini: atom type   1  psp file is /home/gonze/ABINIT/ABINITv8.0.7/trunk/8.0.7-private/tests/Psps_for_tests/01h.pspgth\n    > - pspatm: opening atomic psp file    /home/gonze/ABINIT/ABINITv8.0.7/trunk/8.0.7-private/tests/Psps_for_tests/01h.pspgth\n    166c166\n    <  prteigrs : about to open file tbase1_xo_EIG\n    ---\n    >  prteigrs : about to open file tbase1_1o_EIG\n    214c214\n    < - Total cpu        time (s,m,h):          4.7        0.08      0.001\n    ---\n    > - Total cpu        time (s,m,h):          4.6        0.08      0.001\n    221,229c221,228  (\u2026 and what comes after that is related only to timing \u2026).  If you do not run on a PC under Linux with GNU Fortran compiler, e.g. the\nIntel compiler, you might also have small numerical differences, on the order\nof 1.0d-10 at most. You might also have other differences in the paths of\nfiles. Finally, it might also be that the default FFT algorithm differs from\nthe one of the reference machine, in which case the line mentioning fftalg\nwill differ (ifftalg will not be 312). If you get something else, you should\nask for help!  In this part of the output file, note the dash \u201c-\u201d that is inserted in the\nfirst column. This is not important for the user: it is used to post-process\nthe output file using some automatic tool. As a rule, you should ignore\nsymbols placed in the first column of the ABINIT output file.  Supposing everything went well, we will now detail the different steps that\ntook place: how to run the code, what is in the \u201ctbase1_1.in\u201d input file, and,\nlater, what is in the \u201ctbase1_1.out\u201d and \u201clog\u201d output files.  1.1.e  Running the code is described in the  section 1.2  of the abinit_help file. Please, read it now (it will take 30 seconds or less).  1.1.f  It is now time to edit the tbase1_1.in file. You can have a first glance at it. It is not very long: about 50 lines, mostly comments. Do not try to understand everything immediately. After having gone through it, you should read general explanation about its content, and the format of such input files in the  section 3.1  of the abinit_help file.   1.1.g  You might now examine in more details some input variables. An alphabetically ordered  index of all variables  is provided, and their description is found in different files (non-exhaustive list):    Basic variables,  VARBAS  Files handling variables,  VARFIL  Ground-state calculation variables,  VARGS  GW variables,  VARGW  Parallelisation variables,  VARPAR  Response Function variables,  VARRF   However, the number of such variables is rather large! Note that a dozen of\ninput variables were needed to run the first test case. This is possible\nbecause there are defaults values for the other input variables. When it\nexists, the default value is mentioned at the fourth line of the section\nrelated to each input variable, in the corresponding input variables file.\nSome input variables are also preprocessed, in order to derive convenient\nvalues for other input variables. Defaults are not existing or were avoided\nfor the few input variables that you find in tbase1_1.in . These are\nparticularly important input variables. So, take a few minutes to have a look\nat the input variables of tbase1_1.in:   acell  ntypat  znucl  natom  typat  xcart  ecut  nkpt  nstep  toldfe  diemac   Have also a look at  kpt  and  iscf .  It is now time to have a look at the two output files of the run.  1.1.h  First, open the \u201clog\u201d file. You can begin to read it. It is nasty. Jump to its end. You will find there the number of WARNINGS and COMMENTS that were issued by the code during execution. You might try to find them in the file (localize the keywords \u201cWARNING\u201d or \u201cCOMMENT\u201d in this file). Some of them are for the experienced user. For the present time, we will ignore them. You can find more information about messages in the log file in the  section 6.1  of the abinit_help file.  1.1.i  Then, open the [[tests/tutorial/Refs/tbase1_1.out]] file. You find some general information about the output file in   section 6.2  of the abinit_help file. You should also:    examine the header of \u201ctbase1_1.out\u201d   examine the report on memory needs (do not read each value of parameters)   examine the echo of preprocessed input data,    until you reach the message:    chkinp :   Checking   input   parameters   for   consistency .   If the code does not stop there, the input parameters are consistent. At this\nstage, many default values have been provided, and the preprocessing is\nfinished.  It is worth to come back to the echo of preprocessed input data. You should\nfirst examine the \u201ctbase1_1.in\u201d file in more details, and read the meaning of\neach of its variables in the corresponding input variables file, if it has not\nyet been done. Then, you should examine some variables that were NOT defined\nin the input file, but that appear in the echo written in \u201ctbase1_1.out\u201d:    -  nband : its value is 2. \nIt is the number of electronic states that will be treated by the code. It has\nbeen computed by counting the number of valence electrons in the unit cell\n(summing the valence electrons brought by each pseudopotential) then occupying\nthe lowest states (look at the  occ  variable), and adding some states (at\nleast one, maybe more, depending on the size of the system).    -  ngfft : its value is 30 30 30 . \nIt is the number of points of the three-dimensional FFT grid. It has been\nderived from  ecut  and the dimension of the cell ( acell ).    The maximal number of plane waves \u201c mpw \u201d is mentioned in the memory\nevaluation section: it is  752 . \nWell, this is not completely right, as the code took advantage of the time-\nreversal symmetry, valid for the k-point (0 0 0), to decrease the number of\nplanewave by about a factor of two. \nThe full set of plane waves is  1503  (see later in the \u201ctbase1_1.out\u201d\nfile). \nThe code indicates the time-reversal symmetry by a value of  istwfk =2 ,\ninstead of the usual  istwfk =1 default.    -  nsym : its value is 16. \nIt is the number of symmetries of the system. The 3x3 matrices  symrel \ndefine the symmetries operation. In this case, none of the symmetries is\naccompanied by a translation, that would appear in the variable  tnons . The\ncode did an automatic analysis of symmetries. \nThey could alternatively be set by hand, or using the symmetry builder (to be\ndescribed later).    -  xangst  and  xred  are alternative ways to  xcart  to specify the\npositions of atoms within the primitive cell.  Now, you can start reading the description of the remaining of the\ntbase1_1.out file, in the   section 6.3  of the abinit_help file.\nLook at the tbase1_1.out file at the same time.   1.1.j    You have read completely an output file!   Could you answer the following questions?   Q1. How many SCF cycles were needed to have the  toldfe  criterion satisfied?   Q2. Is the energy likely more converged than  toldfe ?   Q3. What is the value of the force on each atom, in Ha/Bohr?   Q4. What is the difference of eigenenergies between the two electronic states?   Q5. Can you insert \u2018 prtvol  2\u2019 in the input file, run again abinit, and find where is located the maximum of the electronic density, and how much is it, in electrons/Bohr^3 ?    (answers are given at the end of the present file)",
            "title": "1.1. The first step (the most important, and the most difficult !):"
        },
        {
            "location": "/tutorials/base1/#12-computation-of-the-interatomic-distance-method-1",
            "text": "1.2.a   Starting from now, everytime a new input variable is mentioned, you should read the corresponding descriptive section in the ABINIT help.  We will now complete the description of the meaning of each term: there are\nstill a few indications that you should be aware of, even if you will not use\nthem in the tutorial. These might appear in the description of some input\nvariables \u2026 For this, you should read the   section\n3.2  of the\nabinit_help file.  1.2.b  There are three methodologies to compute the optimal distance between the two Hydrogen atoms:    one could compute the  TOTAL ENERGY  for different values of the interatomic distance, make a fit through the different points, and determine the minimum of the fitting function;   one could compute the  FORCES  for different values of the interatomic distance, make a fit through the different values, and determine the zero of the fitting function;   one could use an automatic algorithm for minimizing the energy (or finding the zero of forces). \nWe will begin with the computation of energy and forces for different values\nof the interatomic distance. This exercise will allow you to learn how to use\nmultiple datasets.   The interatomic distance in the tbase1_1.in file was 1.4 Bohr. Suppose you\ndecide to examine the interatomic distances from 1.0 Bohr to 2.0 Bohr, by\nsteps of 0.05 Bohr. That is, 21 calculations. \nIf you are a UNIX guru, it will be easy for you to write a script that will\ndrive these 21 calculations, changing automatically the variable  xcart  in\nthe input file, and then gather all the data, in a convenient form to be\nplotted. \nWell, are you a UNIX guru? If not, there is an easier path, all within ABINIT!  This is the multi-dataset mode. Detailed explanations about it can be found in\nsections  3.3 , 3.4 , 3.5  and 3.6 , of the abinit_help\nfile.  1.2.c  Now, can you write an input file that will do the computation described above (interatomic distances from 1.0 Bohr to 2.0 Bohr, by steps of 0.05 Bohr)? You might start from tbase1_1.in. Try to define a series, and to use the  getwfk  input variable (the latter will make the computation much faster).   You should likely have a look at the section that describes the  irdwfk  and getwfk  input variables: in particular, look at the meaning of  getwfk\n-1  Also, define explicitly the number of states (or supercell \u201cbands\u201d) to be one,\nusing the input variable  nband . The input file\n[[tests/tutorial/Input/tbase1_2.in]] is an example of file that will do the\njob, while [[tests/tutorial/Refs/tbase1_2.out]] is an example of output file.\nIf you decide to use the ~abinit/tests/tutorial/Input/tbase1_2.in file, do not\nforget to change the file names in the \u201ctbase1_x.files\u201d file \u2026  So, you run the code with your input file (this might take fifteen seconds or\nso on a PC at 3 GHz), examine the output file quickly (there are many\nrepetition of sections, for the different datasets), and get the output\nenergies gathered in the final echo of variables:          etotal1  -1.0368223891E+00\n        etotal2  -1.0538645433E+00\n        etotal3  -1.0674504851E+00\n        etotal4  -1.0781904896E+00\n        etotal5  -1.0865814785E+00\n        etotal6  -1.0930286804E+00\n        etotal7  -1.0978628207E+00\n        etotal8  -1.1013539124E+00\n        etotal9  -1.1037224213E+00\n        etotal10 -1.1051483730E+00\n        etotal11 -1.1057788247E+00\n        etotal12 -1.1057340254E+00\n        etotal13 -1.1051125108E+00\n        etotal14 -1.1039953253E+00\n        etotal15 -1.1024495225E+00\n        etotal16 -1.1005310615E+00\n        etotal17 -1.0982871941E+00\n        etotal18 -1.0957584182E+00\n        etotal19 -1.0929800578E+00\n        etotal20 -1.0899835224E+00\n        etotal21 -1.0867972868E+00  You might try to plot these data.      The minimum of energy in the above list is clearly between dataset 11 and 12, that is:           xcart11 -7.5000000000E-01  0.0000000000E+00  0.0000000000E+00\n                  7.5000000000E-01  0.0000000000E+00  0.0000000000E+00\n         xcart12 -7.7500000000E-01  0.0000000000E+00  0.0000000000E+00\n                  7.7500000000E-01  0.0000000000E+00  0.0000000000E+00  corresponding to a distance of H atoms between 1.5 Bohr and 1.55 Bohr. The\nforces vanish also between 1.5 Bohr and 1.55 Bohr:       fcart11 -5.4945071285E-03  0.0000000000E+00  0.0000000000E+00\n              5.4945071285E-03  0.0000000000E+00  0.0000000000E+00\n     fcart12  6.9603067838E-03  0.0000000000E+00  0.0000000000E+00\n             -6.9603067838E-03  0.0000000000E+00  0.0000000000E+00  From these two values, using a linear interpolation, one get the optimal value\nof 1.522 Bohr . \nNote that  the number of SCF cycles drops from 6 to 5 when the wavefunctions\nare read from the previous dataset.",
            "title": "1.2. Computation of the interatomic distance (method 1)."
        },
        {
            "location": "/tutorials/base1/#13-computation-of-the-interatomic-distance-method-2",
            "text": "1.3.a  The other methodology is based on an automatic computation of the minimum.  \nThere are different algorithms to do that. See the input variable  ionmov ,\nwith values 2 and 7. In the present case, with only one degree of freedom to\nbe optimized, the best choice is  ionmov  2 .  You have also to define the maximal number of timesteps for this optimization.\nSet the input variable  ntime  to 10, it will be largely enough. For the\nstopping criterion  tolmxf , use the reasonable value of 5.0d-4 Ha/Bohr.\nThis defines the force threshold to consider that the geometry is converged.\nThe code will stop if the residual forces are below that value before reaching ntime .  It is also worth to change the stopping criterion for the SCF cycle, in order\nto be sure that the forces generated for each trial interatomic distance are\nsufficiently converged. Indeed, the value used for  toldfe , namely 1.0d-6,\nmight be sufficient for total energy calculations, but definitely not for the\naccurate computation of other properties. So, change  toldfe  in  toldff ,\nand set the latter input variable to ten times smaller than  tolmxf . The\ninput file [[tests/tutorial/Input/tbase1_3.in]] is an example of file that\nwill do the job, while [[tests/tutorial/Refs/tbase1_3.out]] is an example of\noutput file. If you decide to use these files, do not forget to change the\nfile names in the \u201ctbase1_x.files\u201d file \u2026 So, you run the code with your\ninput file (a few seconds), examine quietly this file (which is much smaller\nthan the tbase1_2.out file), and get some significant output data gathered in\nthe final echo of variables:      etotal   -1.1058360644E+00\n     fcart    1.8270533893E-04  0.0000000000E+00  0.0000000000E+00\n             -1.8270533893E-04  0.0000000000E+00  0.0000000000E+00\n      ...\n     xcart   -7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n              7.6091015760E-01  0.0000000000E+00  0.0000000000E+00  According to these data (see  xcart ), the optimal interatomic distance is\nabout 1.522 Bohr, in good agreement with the estimation of tbase1_2.out . If\nyou have time (this is to be done at home), you might try to change the\nstopping criteria, and redo the calculation, to see the level of convergence\nof the interatomic distance.  Note that the final value of fcart in your run might differ slightly from the\none shown above (less than one percent change). Such a fluctuation is quite\noften observed for a value converging to zero (remember, we ask the code to\ndetermine the equilibrium geometry, that is, forces should be zero) when the\nsame computation is done on different platforms.",
            "title": "1.3 Computation of the interatomic distance (method 2)."
        },
        {
            "location": "/tutorials/base1/#14-computation-of-the-charge-density",
            "text": "The charge density has already been computed, for all geometries, in the\nabove-mentioned runs. Here, we will print this quantity.  1.4.a  We start from the optimized interatomic distance 1.522 Bohr, and make a run at fixed geometry. The input variable  prtden  must be set to 1. To understand correctly the content of the  prtden  description, it is worth to read a much more detailed description of the \u201cfiles\u201d file, in  section 4   of the abinit_help file.   1.4.b  The input file [[tests/tutorial/Input/tbase1_4.in]] is an example of input file for a run that will print a density. If you decide to use this file, do not forget to change the file names in tbase1_x.files. The run will take a few seconds.   The density will be output in the  tbase1_xo_DEN  file. Try to edit it \u2026\nNo luck ! This file is unformatted, not written using the ASCII code. Even if\nyou cannot read it, its description is provided in the abinit_help. It\ncontains first a header, then the density numbers. The description of the\nheader is presented in  section\n6.4  of the abinit_help\nfile, while the body of the _DEN file is presented in  section\n6.5 . It is the\nappropriate time to read also the description of the potential files and\nwavefunctions files, as these files contain the same header as the density\nfile, see sections 6.6  and 6.7  1.4.c  Such a density file can be read by ABINIT, to restart a calculation (see the input variable  iscf , when its value is -2), but more usually, by an utility called \u201ccut3d\u201d. This utility is available in the ABINIT package. You might try to use it now, to generate two-dimensional cuts in the density, and visualize the charge density contours.  \nRead the corresponding  Cut3D help\nfile . Then, try to run cut3d to\nanalyse  tbase1_xo_DEN . You should first try to translate the unformatted\ndensity data to indexed formatted data, by using option 6 in the adequate\nmenu. Save the indexed formatted data to file  tbase1_xo_DEN_indexed . Then,\nedit this file, to have an idea of the content of the _DEN files. \nFor further treatment, you might choose to select another option than 6. In\nparticular, if you have access to MATLAB, choose option 5. With minor\nmodifications (set ngx=ngy=ngz to 30) you will be able to use the file dim.m\npresent in ~abinit/doc/tutorial/documents/lesson_base1 to visualize the\n3-Dimensional isosurfaces. Another option might be to use the XCrysDen\nsoftware, for which you need to use option 9.",
            "title": "1.4. Computation of the charge density."
        },
        {
            "location": "/tutorials/base1/#15-computation-of-the-atomisation-energy",
            "text": "1.5.a  The atomisation energy is the energy needed to separate a molecule in its constituent atoms, each being neutral.  \nIn the present case, one must compute first the total energy of an isolated\nhydrogen atom. The atomisation energy will be the difference between the total\nenergy of H2 and twice the total energy of H. \nThere are some subtleties in the calculation of an isolated atom.   in many cases, the ground state of an isolated atom is spin-polarized, see the variables  nsppol  and  spinat  ;   the highest occupied level might be degenerate with the lowest unoccupied level of the same spin, in which case the techniques usually appropriate for metals are to be used (see  lesson_base4 )   also often, the symmetry of the ground-state charge density will NOT be spherical, so that the automatic determination of symmetries by the code, based on the atomic coordinates, should be disabled, see the input variable  nsym , to be set to 1 in this case.    For Hydrogen, we are lucky that the ground state is spherical (1s orbital),\nand that the highest occupied level and lowest unoccupied level, although\ndegenerate, have a different spin. We will define by hand the occupation of\neach spin, see the input variables  occopt  (to be set to 2), and  occ  . \nFinally, in order to make numerical errors cancel, it is important to compute\nthe above-mentioned difference in the same box, for the same cut-off, and even\nfor a location in the box that is similar to the molecule case (although the\nlatter might not be so important).  The input file [[tests/tutorial/Input/tbase1_5.in]] is an example of file that\nwill do the job, while [[tests/tutorial/Refs/tbase1_5.out]] is an example of\noutput file. If you decide to use the tbase1_5.in file, do not forget to\nchange the file names in the tbase1_x.files file. The run lasts a few seconds.  You should read the output file, and note the tiny differences related with\nthe spin-polarisation:   the electronic eigenvalues are now given for both spin up and spin down cases:             Eigenvalues (hartree) for nkpt=   1  k points, SPIN UP:\n     kpt#   1, nband=  1, wtk=  1.00000, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n      -0.26414\n     Eigenvalues (hartree) for nkpt=   1  k points, SPIN DOWN:\n     kpt#   1, nband=  1, wtk=  1.00000, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n      -0.11112   If you run again, while having inserted in the input file \u2018 prtvol  2\u2019, because  occopt , the charge density and spin polarisation at each point of the FFT grid is also analyzed:             Total charge density [el/Bohr^3]\n          Maximum=    1.4053E-01  at reduced coord.    0.0000    0.0000    0.0000\n     Next maximum=    1.2019E-01  at reduced coord.    0.0000    0.0000    0.9667\n          Minimum=    3.4544E-06  at reduced coord.    0.4667    0.4333    0.4333\n     Next minimum=    3.4544E-06  at reduced coord.    0.5333    0.4333    0.4333\n     Spin up density      [el/Bohr^3]\n          Maximum=    1.4053E-01  at reduced coord.    0.0000    0.0000    0.0000\n     Next maximum=    1.2019E-01  at reduced coord.    0.0000    0.0000    0.9667\n          Minimum=    3.4544E-06  at reduced coord.    0.4667    0.4333    0.4333\n     Next minimum=    3.4544E-06  at reduced coord.    0.5333    0.4333    0.4333\n     Spin down density    [el/Bohr^3]\n          Maximum=    0.0000E+00  at reduced coord.    0.9667    0.9667    0.9667\n     Next maximum=    0.0000E+00  at reduced coord.    0.9333    0.9667    0.9667\n          Minimum=    0.0000E+00  at reduced coord.    0.0000    0.0000    0.0000\n     Next minimum=    0.0000E+00  at reduced coord.    0.0333    0.0000    0.0000\n     Magnetization (spin up - spin down) [el/Bohr^3]\n          Maximum=    1.4053E-01  at reduced coord.    0.0000    0.0000    0.0000\n     Next maximum=    1.2019E-01  at reduced coord.    0.0000    0.0000    0.9667\n          Minimum=    3.4544E-06  at reduced coord.    0.4667    0.4333    0.4333\n     Next minimum=    3.4544E-06  at reduced coord.    0.5333    0.4333    0.4333\n     Relative magnetization (=zeta, between -1 and 1)\n          Maximum=    1.0000E+00  at reduced coord.    0.9667    0.9667    0.9667\n     Next maximum=    1.0000E+00  at reduced coord.    0.9333    0.9667    0.9667\n          Minimum=    1.0000E+00  at reduced coord.    0.0000    0.0000    0.0000\n     Next minimum=    1.0000E+00  at reduced coord.    0.0333    0.0000    0.0000  The  zeta  variable is the ratio between the spin-density difference and the\ncharge density. It varies between +1 and -1. In the present case of Hydrogen,\nthere is no spin down density, so the zeta variable is +1. \n(Comment: in this part of the output file, note the comma \u201c,\u201d that is inserted\nin the first column. This is not important for the user: it is used to post-\nprocess the output file using some automatic tool. As a rule, you should\nignore symbols placed in the first column of the ABINIT output file.)  The total energy is      etotal   -4.7010531489E-01  while the total energy of the H2 molecule is (see test 13):      etotal   -1.1058360644E+00  The atomisation energy is thus 0.1656 Ha (The difference between the total\nenergy of the H2 molecule and twice the energy of an isolated Hydrogen atom).  At this stage, we can compare our results:   bond length: 1.522 Bohr   atomisation energy at that bond length: 0.1656 Ha = 4.506 eV    with the experimental data as well as theoretical data using a much more\naccurate technique (see Kolos and Roothaan, Rev. Mod. Phys. 32, 219 (1960),\nespecially p.225)   bond length: 1.401 Bohr   atomisation energy: 4.747 eV    The bond length is awful (nearly 10% off), and the atomisation energy is a bit too low, 5 % off.  What is wrong?? \nWell, are you sure that the input parameters that we did not discuss are correct? \nThese are:   ecut  (the plane-wave kinetic energy cut-off)   acell  (the supercell size)   ixc  (not even mentioned until now, this input variable specifies what kind of \n    exchange-correlation functional is to be used \u2026)   the pseudopotential    We used 10 Ha as cut-off energy, a 10x10x10 Bohr^3 supercell, the local-\ndensity approximation (as well as the local-spin-density approximation) in the\nTeter parametrization, and a pseudopotential from the Goedecker-Hutter-Teter\ntable (Phys. Rev. B 54, 1703 (1996)).  We will see in the  next lesson  how to address the choice\nof these parameters (except the pseudopotential).",
            "title": "1.5. Computation of the atomisation energy."
        },
        {
            "location": "/tutorials/base1/#answers-to-the-questions",
            "text": "Q1. How many SCF cycles were needed to have the  toldfe  criterion satisfied?   Q2. Is the energy likely more converged than  toldfe ?   Q3. What is the value of the force on each atom, in Ha/Bohr?   Q4. What is the difference of eigenenergies between the two electronic states?   Q5. Where is located the maximum of the electronic density, and how much is it, in electrons/Bohr^3 ?    NOTE:  there might be numerical differences, from platform to platform, in the\nquoted results !  Q1.  6 SCF cycles were needed:            iter   Etot(hartree)      deltaE(h)  residm     vres2\n     ETOT  1  -1.1013391225242    -1.101E+00 4.220E-04 8.396E+00\n     ETOT  2  -1.1036939626391    -2.355E-03 7.374E-09 2.840E-01\n     ETOT  3  -1.1037170965209    -2.313E-05 7.389E-08 1.549E-02\n     ETOT  4  -1.1037223548790    -5.258E-06 4.146E-07 2.715E-04\n     ETOT  5  -1.1037224212232    -6.634E-08 4.091E-09 5.700E-06\n     ETOT  6  -1.1037224213136    -9.037E-11 5.808E-12 3.076E-07\n\n     At SCF step    6, etot is converged :\n      for the second time, diff in etot=  9.038E-11 < toldfe=  1.000E-06  Note that the number of steps that were allowed,  nstep =10, is larger than\nthe number of steps effectively needed to reach the stopping criterion. As a\nrule, you should always check that the number of steps that you allowed was\nsufficient to reach the target tolerance. You might now play a bit with nstep,\nas e.g. set it to 5, to see how ABINIT reacts.  Side note: in most of the tutorial examples,  nstep  will be enough to reach\nthe target tolerance, defined by one of the \u201ctolXXX\u201d input variables. However,\nthis is not always the case (e.g. the test case 1 of the  lesson response-\nfunction 1 ), because of some portability problems, that\ncould only be solved by stopping the SCF cycles before the required tolerance.  Q2.  The information is contained in the same piece of the output file. Yes, the energy is more converged than  toldfe , since the stopping criterion asked for the difference between successive evaluations of the energy to be smaller than  toldfe  twice in a row, while the evolution of the energy is nice, and always decreasing by smaller and smaller amounts.   Q3.  These values are:        cartesian forces (hartree/bohr) at end:\n        1     -0.03740558871217     0.00000000000000     0.00000000000000\n        2      0.03740558871217     0.00000000000000     0.00000000000000\n     frms,max,avg= 2.1596127E-02 3.7405589E-02   0.000E+00  0.000E+00  0.000E+00 h/b  On the first atom (located at -0.7 0 0 in cartesian coordinates, in Bohr), the\nforce vector is pointing in the minus x direction, and in the plus x direction\nfor the second atom located at +0.7 0 0 . \nThe H2 molecule would like to expand \u2026  Q4.  The eigenvalues (in Hartree) are mentioned at the lines        Eigenvalues (hartree) for nkpt=   1  k points:\n     kpt#   1, nband=  2, wtk=  1.00000, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n      -0.36525  -0.01379  As mentioned in the abinit_help  file,\nthe absolute value of eigenenergies is not meaningful. Only differences of\neigenenergies, as well as differences with the potential. \nThe difference is 0.35147 Hartree, that is 9.564 eV . \nMoreover, remember that Kohn-Sham eigenenergies are formally NOT connected to\nexperimental excitation energies ! \n(Well, more is to be said later about this \u2026).  Q5.  The maximum electronic density in electron per Bohr cube is reached at the mid-point between the two H atoms :        Total charge density [el/Bohr^3]\n    ,     Maximum=    2.6907E-01  at reduced coord.    0.0000    0.0000    0.0000",
            "title": "Answers to the questions"
        },
        {
            "location": "/tutorials/base2/",
            "text": "This lesson aims at showing how to get converged values for the following\nphysical properties:\n\n\n\n\nthe bond length \n\n\nthe atomisation energy \nYou will learn about the numerical quality of the calculations, then make\nconvergence studies with respect to the number of planewaves and the size of\nthe supercell, and finally consider the effect of the XC functional. The\nproblems related to the use of different pseudopotential are not examined.\n\n\n\n\nYou will also finish to read the abinit_help file.\n\n\nThis lesson should take about 1 hour.\n\n\n\n\n2.0 Summary of the previous lesson\n\n\n2.1 The convergence in \necut\n\n\n2.2 The convergence in \necut\n\n\n2.3 The convergence in \nacell\n\n\n2.4 The final calculation in Local (Spin) Density Approximation.\n\n\n2.5 The use of the Generalized Gradient Approximation.\n\n\n\n\n\n\n\u00b6\n\n\n2.0. Summary of the previous lesson.\n\u00b6\n\n\nWe studied the H2 molecule in a big box. We used 10 Ha as cut-off energy, a\n10x10x10 Bohr^3 supercell, the local-density approximation (as well as the\nlocal-spin-density approximation) in the Teter parametrization (\nixc\n=1, the\ndefault), and a pseudopotential from the Goedecker-Hutter-Teter table.\n\n\nAt this stage, we compared our results:\n\n\n\n\nbond length: 1.522 Bohr\n\n\natomisation energy at that bond length: 0.1656 Ha = 4.506 eV\n\n\n\n\nwith the experimental data (as well as theoretical data using a much more\naccurate technique than DFT)\n\n\n\n\nbond length: 1.401 Bohr\n\n\natomisation energy: 4.747 eV\n\n\n\n\nThe bond length is awful (nearly 10% off), and the atomisation energy is a bit\ntoo low, 5 % off.\n\n\n\u00b6\n\n\n\n\n2.1 and 2.2 The convergence in ecut\n\u00b6\n\n\n2.1.a\n Computing the bond length and corresponding atomisation energy in one run.\n\n\n_Before beginning, you might consider to work in a different subdirectory as\nfor lesson_base1. Why not \u201cWork2\u201d? _  \n\n\nBecause we will compute many times the bond length and atomisation energy, it\nis worth to make a single input file that will do all the associated\noperations. You should try to use 2 datasets (try to combine\n~abinit/tests/tutorial/Input/tbase1_3.in with\n~abinit/tests/tutorial/Input/tbase1_5.in!). Do not try to have the same\nposition of the H atom as one of the H2 atoms in the optimized geometry.\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase2_1.in is an example of file\nthat will do the job, while ~abinit/tests/tutorial/Refs/tbase2_1.out is an\nexample of output file. You might use\n~abinit/tests/tutorial/Input/tbase2_x.files as \u201cfiles\u201d file (do not forget to\nmodify it, like in lesson 1), although it does not differ from\n~abinit/tests/tutorial/Input/tbase1_x.files. The run should take less than one\nminute.\n\n\nYou should obtain the values:\n\n\n    etotal1  -1.1058360644E+00\n    etotal2  -4.7010531489E-01\n\n\n\n\n\nand\n\n\n    xcart1  -7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n             7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\nThese are similar to those determined in \nlesson 1\n,\nalthough they have been obtained in one run. You can also check that the\nresidual forces are lower than \n5.0d-4\n. Convergence issues are discussed in\n\nsection 7\n of the abinit_help\nfile.\n\nYou should read it. By the way, you have read many parts of the abinit_help\nfile! You are missing the sections\n\n2\n,\n\n5\n,\n\n8\n. You are also missing the\ndescription of many input variables. We suggest that you finish reading\nentirely the abinit_help file now, while the knowledge of the input variables\nwill come in the long run.\n\n\n2.1.b\n Many convergence parameters have already been identified. We will focus only on \necut\n and \nacell\n. This is because \n\n\n\n\nthe convergence of the SCF cycle and geometry determination are well under control thanks to \ntoldfe\n, \ntoldff\n and \ntolmxf\n (this might not be the case for other physical properties)\n\n\nthere is no k point convergence study to be done for an isolated system in a big box: no additional information is gained by adding a k-point beyond one\n\n\nthe boxcut value is automatically chosen larger than 2 by ABINIT, see the determination of the input variable \nngfft\n by preprocessing\n\n\nwe are using \nionmov\n=2 for the determination of the geometry.\n\n\n\n\nFor the check of convergence with respect to \necut\n, you have the choice\nbetween doing different runs of the tbase2_1.in file with different values of\n\necut\n, or doing a double loop of datasets, as proposed in\n~abinit/tests/tutorial/Input/tbase2_2.in . The values of \necut\n have been\nchosen between 10Ha and 35Ha, by step of 5 Ha. If you want to make a double\nloop, you might benefit of reading again the \ndouble-loop\nsection\n of the abinit_help\nfile.\n\n\n2.2.a\n You have likely seen a big increase of the CPU time needed to do the calculation. You should also look at the increase of the memory needed to do the calculation (go back to the beginning of the output file). The output data are as follows: \n\n\n    etotal11 -1.1058360644E+00\n    etotal12 -4.7010531489E-01\n    etotal21 -1.1218716100E+00\n    etotal22 -4.7529731401E-01\n    etotal31 -1.1291943792E+00\n    etotal32 -4.7773586424E-01\n    etotal41 -1.1326879404E+00\n    etotal42 -4.7899908214E-01\n    etotal51 -1.1346739190E+00\n    etotal52 -4.7972721653E-01\n    etotal61 -1.1359660026E+00\n    etotal62 -4.8022016459E-01\n\n     xcart11 -7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n              7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n     xcart12  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart21 -7.5104912643E-01  0.0000000000E+00  0.0000000000E+00\n              7.5104912643E-01  0.0000000000E+00  0.0000000000E+00\n     xcart22  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart31 -7.3977108831E-01  0.0000000000E+00  0.0000000000E+00\n              7.3977108831E-01  0.0000000000E+00  0.0000000000E+00\n     xcart32  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart41 -7.3304273322E-01  0.0000000000E+00  0.0000000000E+00\n              7.3304273322E-01  0.0000000000E+00  0.0000000000E+00\n     xcart42  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart51 -7.3001570260E-01  0.0000000000E+00  0.0000000000E+00\n              7.3001570260E-01  0.0000000000E+00  0.0000000000E+00\n     xcart52  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart61 -7.2955902118E-01  0.0000000000E+00  0.0000000000E+00\n              7.2955902118E-01  0.0000000000E+00  0.0000000000E+00\n     xcart62  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\nThe corresponding atomisation energies and interatomic distances are:\n\n\necut    atomisation   interatomic distance\n(Ha)    energy (Ha)      (Bohr)\n\n10       .1656          1.522\n15       .1713          1.502\n20       .1737          1.480\n25       .1747          1.466\n30       .1753          1.460\n35       .1756          1.459\n\n\n\n\n\nIn order to obtain 0.2% relative accuracy on the bond length or atomisation\nenergy, one should use a kinetic cut-off energy of 30 Ha. We will keep in mind\nthis value for the final run.\n\n\nWell, 30 Ha is a large kinetic energy cut-off! The pseudopotential that we are\nusing for Hydrogen is rather \u201chard\u201d \u2026\n\n\n\n\n\u00b6\n\n\n2.3 The convergence in acell\n\n\nThe same technique as for \necut\n should be now used for the convergence in\n\nacell\n. We will explore \nacell\n starting from \n8 8 8\n to \n18 18 18\n, by\nstep of \n2 2 2\n. We keep \necut\n 10 for this study. Indeed, it is a rather\ngeneral rule that there is little cross-influence between the convergence of\n\necut\n and the convergence of \nacell\n. The file\n~abinit/tests/tutorial/Input/tbase2_3.in can be used as an example. The output\ndata (~abinit/tests/tutorial/Refs/tbase2_3.out) are as follows:\n\n\n    etotal11   -1.1188124709E+00\n    etotal12   -4.8074164402E-01\n    etotal21   -1.1058360838E+00\n    etotal22   -4.7010531489E-01\n    etotal31   -1.1039109527E+00\n    etotal32   -4.6767804802E-01\n    etotal41   -1.1039012868E+00\n    etotal42   -4.6743724199E-01\n    etotal51   -1.1041439411E+00\n    etotal52   -4.6735895176E-01\n    etotal61   -1.1042058281E+00\n    etotal62   -4.6736729718E-01\n\n     xcart11   -7.8330751426E-01  0.0000000000E+00  0.0000000000E+00\n                7.8330751426E-01  0.0000000000E+00  0.0000000000E+00\n     xcart12    0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart21   -7.6024281092E-01  0.0000000000E+00  0.0000000000E+00\n                7.6024281092E-01  0.0000000000E+00  0.0000000000E+00\n     xcart22    0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart31   -7.5428234893E-01  0.0000000000E+00  0.0000000000E+00\n                7.5428234893E-01  0.0000000000E+00  0.0000000000E+00\n     xcart32    0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart41   -7.5446921004E-01  0.0000000000E+00  0.0000000000E+00\n                7.5446921004E-01  0.0000000000E+00  0.0000000000E+00\n     xcart42    0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart51   -7.5384974520E-01  0.0000000000E+00  0.0000000000E+00\n                7.5384974520E-01  0.0000000000E+00  0.0000000000E+00\n     xcart52    0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart61   -7.5373336127E-01  0.0000000000E+00  0.0000000000E+00\n                7.5373336127E-01  0.0000000000E+00  0.0000000000E+00\n     xcart62    0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\nThe corresponding atomisation energies and interatomic distances are:\n\n\nacell\n\n(Bohr)\n\n\n|\n\n\natomisation\n\nenergy (Ha)\n\n\n|\n\n\ninteratomic distance\n\n(Bohr)  \n\n\n\u2014|\u2014|\u2014  \n\n\n8\n\n\n|\n\n\n.1574\n\n\n|\n\n\n1.568  \n\n\n10\n\n\n|\n\n\n.1656\n\n\n|\n\n\n1.522  \n\n\n12\n\n\n|\n\n\n.1686\n\n\n|\n\n\n1.509  \n\n\n14\n\n\n|\n\n\n.1691\n\n\n|\n\n\n1.510  \n\n\n16\n\n\n|\n\n\n.1694\n\n\n|\n\n\n1.508  \n\n\n18\n\n\n|\n\n\n.1695\n\n\n|\n\n\n1.508  \n\n\nIn order to reach 0.2% convergence on the interatomic distance, one needs \nacell 12 12 12\n. The atomisation energy needs \nacell 14 14 14\n to be converged\nat that level. At \n12 12 12\n, the difference is \n.0009 Ha=0.024eV\n, which is\nsufficiently small for practical purposes. We will use \nacell 12 12 12\n for\nthe final run.\n\n\nFor most solids the size of the unit cell will be smaller than that. We are\ntreating a lot of vacuum in this supercell! So, the H2 study, with this\npseudopotential, turns out to be not really easy. Of course, the number of\nstates to be treated is minimal! This allows to have reasonable CPU time\nstill.\n\n\n\n\n2.4 The final calculation in Local (Spin) Density Approximation.\n\u00b6\n\n\nWe now use the correct values of both \necut\n and \nacell\n. Well, you should\nmodify the tbase2_3.in file to make a calculation with \nacell 12 12 12\n and\n\necut 30\n. You can still use the double loop feature with \n[[udtset]] 1 2\n\n(which reduces to a single loop), to minimize the modifications to the file.\nThe file ~abinit/tests/tutorial/Input/tbase2_4.in can be taken as an example\nof input file, and ~abinit/tests/tutorial/Refs/tbase2_4.out as an example of\noutput file.\n\n\nSince we are doing the calculation at a single (\necut\n, \nacell\n) pair, the\ntotal CPU time is not as much as for the previous determinations of optimal\nvalues through series calculations. However, the memory needs have still\nincreased a bit.\n\n\nThe output data are:\n\n\n    etotal11 -1.1329369190E+00\n    etotal12 -4.7765320721E-01\n\n     xcart11 -7.2594741339E-01  0.0000000000E+00  0.0000000000E+00\n              7.2594741339E-01  0.0000000000E+00  0.0000000000E+00\n     xcart12  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\n\n\nThe corresponding atomisation energy is \n0.1776 Ha = 4.833 eV\n\n\nThe interatomic distance is 1.452 Bohr. \n\n\nThese are our final data for the local (spin) density approximation. \nWe have used \n[[ixc]]=1\n . Other expressions for the local (spin) density\napproximation \n[[ixc]]=2, 3 .. 7\n are possible. The values 1, 2, 3 and 7\nshould give about the same results, since they all start from the XC energy of\nthe homogeneous electron gas, as determined by Quantum Monte Carlo\ncalculations.\n\nOther possibilities \n[[ixc]]=4, 5, 6\n are older local density functionals,\nthat could not rely on these data.\n\n\n\n\n\n\n2.5 The use of the Generalized Gradient Approximation.\n\u00b6\n\n\nWe will use the Perdew-Burke-Ernzerhof functional, proposed in Phys. Rev.\nLett. 77, 3865 (1996).\n\n\nIn principle, for GGA, one should use another pseudopotential than for LDA.\nHowever, for the special case of Hydrogen, and in general pseudopotentials\nwith a very small core (including only the 1s orbital), pseudopotentials\nissued from the LDA and from the GGA are very similar.\n\n\nSo, we will not change our pseudopotential. This will save us lot of time, as\nwe should not redo an \necut\n convergence test (ecut is often characteristic\nof the pseudopotentials that are used in a calculation).\n\n\nIndependently of the pseudopotential, an \nacell\n convergence test should not\nbe done again, since the vacuum is treated similarly in LDA or GGA.\n\n\nSo, our final values within GGA will be easily obtained, by setting \nixc\n to\n11 in the input file tbase2_4.in. See ~abinit/tests/tutorial/Input/tbase2_5.in\nfor an example.\n\n\n    etotal11 -1.1621428376E+00\n    etotal12 -4.9869631917E-01\n\n     xcart11 -7.1190611804E-01  0.0000000000E+00  0.0000000000E+00\n              7.1190611804E-01  0.0000000000E+00  0.0000000000E+00\n     xcart12  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\n\n\nThe corresponding atomisation energy is \n0.1648 Ha = 4.483 eV\n\n\nThe interatomic distance is \n1.424 Bohr\n. \n\n\n\n\nThese are our final data for the generalized gradient approximation. \nOnce more, here are the experimental data:\n\n\n\n\n\n\nbond length: 1.401 Bohr \n\n\n\n\natomisation energy: 4.747 eV \nIn GGA, we are within 2% of the experimental bond length, but 5% of the\nexperimental atomisation energy. In LDA, we were within 4% of the experimental\nbond length, and within 2% of the experimental atomisation energy.\n\n\n\n\nDo not forget that the typical accuracy of LDA and GGA varies with the class\nof materials studied\u2026",
            "title": "Base2"
        },
        {
            "location": "/tutorials/base2/#20-summary-of-the-previous-lesson",
            "text": "We studied the H2 molecule in a big box. We used 10 Ha as cut-off energy, a\n10x10x10 Bohr^3 supercell, the local-density approximation (as well as the\nlocal-spin-density approximation) in the Teter parametrization ( ixc =1, the\ndefault), and a pseudopotential from the Goedecker-Hutter-Teter table.  At this stage, we compared our results:   bond length: 1.522 Bohr  atomisation energy at that bond length: 0.1656 Ha = 4.506 eV   with the experimental data (as well as theoretical data using a much more\naccurate technique than DFT)   bond length: 1.401 Bohr  atomisation energy: 4.747 eV   The bond length is awful (nearly 10% off), and the atomisation energy is a bit\ntoo low, 5 % off.",
            "title": "2.0. Summary of the previous lesson."
        },
        {
            "location": "/tutorials/base2/#21-and-22-the-convergence-in-ecut",
            "text": "2.1.a  Computing the bond length and corresponding atomisation energy in one run.  _Before beginning, you might consider to work in a different subdirectory as\nfor lesson_base1. Why not \u201cWork2\u201d? _    Because we will compute many times the bond length and atomisation energy, it\nis worth to make a single input file that will do all the associated\noperations. You should try to use 2 datasets (try to combine\n~abinit/tests/tutorial/Input/tbase1_3.in with\n~abinit/tests/tutorial/Input/tbase1_5.in!). Do not try to have the same\nposition of the H atom as one of the H2 atoms in the optimized geometry.  The input file ~abinit/tests/tutorial/Input/tbase2_1.in is an example of file\nthat will do the job, while ~abinit/tests/tutorial/Refs/tbase2_1.out is an\nexample of output file. You might use\n~abinit/tests/tutorial/Input/tbase2_x.files as \u201cfiles\u201d file (do not forget to\nmodify it, like in lesson 1), although it does not differ from\n~abinit/tests/tutorial/Input/tbase1_x.files. The run should take less than one\nminute.  You should obtain the values:      etotal1  -1.1058360644E+00\n    etotal2  -4.7010531489E-01  and      xcart1  -7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n             7.6091015760E-01  0.0000000000E+00  0.0000000000E+00  These are similar to those determined in  lesson 1 ,\nalthough they have been obtained in one run. You can also check that the\nresidual forces are lower than  5.0d-4 . Convergence issues are discussed in section 7  of the abinit_help\nfile. \nYou should read it. By the way, you have read many parts of the abinit_help\nfile! You are missing the sections 2 , 5 , 8 . You are also missing the\ndescription of many input variables. We suggest that you finish reading\nentirely the abinit_help file now, while the knowledge of the input variables\nwill come in the long run.  2.1.b  Many convergence parameters have already been identified. We will focus only on  ecut  and  acell . This is because    the convergence of the SCF cycle and geometry determination are well under control thanks to  toldfe ,  toldff  and  tolmxf  (this might not be the case for other physical properties)  there is no k point convergence study to be done for an isolated system in a big box: no additional information is gained by adding a k-point beyond one  the boxcut value is automatically chosen larger than 2 by ABINIT, see the determination of the input variable  ngfft  by preprocessing  we are using  ionmov =2 for the determination of the geometry.   For the check of convergence with respect to  ecut , you have the choice\nbetween doing different runs of the tbase2_1.in file with different values of ecut , or doing a double loop of datasets, as proposed in\n~abinit/tests/tutorial/Input/tbase2_2.in . The values of  ecut  have been\nchosen between 10Ha and 35Ha, by step of 5 Ha. If you want to make a double\nloop, you might benefit of reading again the  double-loop\nsection  of the abinit_help\nfile.  2.2.a  You have likely seen a big increase of the CPU time needed to do the calculation. You should also look at the increase of the memory needed to do the calculation (go back to the beginning of the output file). The output data are as follows:       etotal11 -1.1058360644E+00\n    etotal12 -4.7010531489E-01\n    etotal21 -1.1218716100E+00\n    etotal22 -4.7529731401E-01\n    etotal31 -1.1291943792E+00\n    etotal32 -4.7773586424E-01\n    etotal41 -1.1326879404E+00\n    etotal42 -4.7899908214E-01\n    etotal51 -1.1346739190E+00\n    etotal52 -4.7972721653E-01\n    etotal61 -1.1359660026E+00\n    etotal62 -4.8022016459E-01\n\n     xcart11 -7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n              7.6091015760E-01  0.0000000000E+00  0.0000000000E+00\n     xcart12  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart21 -7.5104912643E-01  0.0000000000E+00  0.0000000000E+00\n              7.5104912643E-01  0.0000000000E+00  0.0000000000E+00\n     xcart22  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart31 -7.3977108831E-01  0.0000000000E+00  0.0000000000E+00\n              7.3977108831E-01  0.0000000000E+00  0.0000000000E+00\n     xcart32  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart41 -7.3304273322E-01  0.0000000000E+00  0.0000000000E+00\n              7.3304273322E-01  0.0000000000E+00  0.0000000000E+00\n     xcart42  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart51 -7.3001570260E-01  0.0000000000E+00  0.0000000000E+00\n              7.3001570260E-01  0.0000000000E+00  0.0000000000E+00\n     xcart52  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n     xcart61 -7.2955902118E-01  0.0000000000E+00  0.0000000000E+00\n              7.2955902118E-01  0.0000000000E+00  0.0000000000E+00\n     xcart62  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  The corresponding atomisation energies and interatomic distances are:  ecut    atomisation   interatomic distance\n(Ha)    energy (Ha)      (Bohr)\n\n10       .1656          1.522\n15       .1713          1.502\n20       .1737          1.480\n25       .1747          1.466\n30       .1753          1.460\n35       .1756          1.459  In order to obtain 0.2% relative accuracy on the bond length or atomisation\nenergy, one should use a kinetic cut-off energy of 30 Ha. We will keep in mind\nthis value for the final run.  Well, 30 Ha is a large kinetic energy cut-off! The pseudopotential that we are\nusing for Hydrogen is rather \u201chard\u201d \u2026",
            "title": "2.1 and 2.2 The convergence in ecut"
        },
        {
            "location": "/tutorials/base2/#24-the-final-calculation-in-local-spin-density-approximation",
            "text": "We now use the correct values of both  ecut  and  acell . Well, you should\nmodify the tbase2_3.in file to make a calculation with  acell 12 12 12  and ecut 30 . You can still use the double loop feature with  [[udtset]] 1 2 \n(which reduces to a single loop), to minimize the modifications to the file.\nThe file ~abinit/tests/tutorial/Input/tbase2_4.in can be taken as an example\nof input file, and ~abinit/tests/tutorial/Refs/tbase2_4.out as an example of\noutput file.  Since we are doing the calculation at a single ( ecut ,  acell ) pair, the\ntotal CPU time is not as much as for the previous determinations of optimal\nvalues through series calculations. However, the memory needs have still\nincreased a bit.  The output data are:      etotal11 -1.1329369190E+00\n    etotal12 -4.7765320721E-01\n\n     xcart11 -7.2594741339E-01  0.0000000000E+00  0.0000000000E+00\n              7.2594741339E-01  0.0000000000E+00  0.0000000000E+00\n     xcart12  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00   The corresponding atomisation energy is  0.1776 Ha = 4.833 eV  The interatomic distance is 1.452 Bohr.   These are our final data for the local (spin) density approximation. \nWe have used  [[ixc]]=1  . Other expressions for the local (spin) density\napproximation  [[ixc]]=2, 3 .. 7  are possible. The values 1, 2, 3 and 7\nshould give about the same results, since they all start from the XC energy of\nthe homogeneous electron gas, as determined by Quantum Monte Carlo\ncalculations. \nOther possibilities  [[ixc]]=4, 5, 6  are older local density functionals,\nthat could not rely on these data.",
            "title": "2.4 The final calculation in Local (Spin) Density Approximation."
        },
        {
            "location": "/tutorials/base2/#25-the-use-of-the-generalized-gradient-approximation",
            "text": "We will use the Perdew-Burke-Ernzerhof functional, proposed in Phys. Rev.\nLett. 77, 3865 (1996).  In principle, for GGA, one should use another pseudopotential than for LDA.\nHowever, for the special case of Hydrogen, and in general pseudopotentials\nwith a very small core (including only the 1s orbital), pseudopotentials\nissued from the LDA and from the GGA are very similar.  So, we will not change our pseudopotential. This will save us lot of time, as\nwe should not redo an  ecut  convergence test (ecut is often characteristic\nof the pseudopotentials that are used in a calculation).  Independently of the pseudopotential, an  acell  convergence test should not\nbe done again, since the vacuum is treated similarly in LDA or GGA.  So, our final values within GGA will be easily obtained, by setting  ixc  to\n11 in the input file tbase2_4.in. See ~abinit/tests/tutorial/Input/tbase2_5.in\nfor an example.      etotal11 -1.1621428376E+00\n    etotal12 -4.9869631917E-01\n\n     xcart11 -7.1190611804E-01  0.0000000000E+00  0.0000000000E+00\n              7.1190611804E-01  0.0000000000E+00  0.0000000000E+00\n     xcart12  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00   The corresponding atomisation energy is  0.1648 Ha = 4.483 eV  The interatomic distance is  1.424 Bohr .    These are our final data for the generalized gradient approximation. \nOnce more, here are the experimental data:    bond length: 1.401 Bohr    atomisation energy: 4.747 eV \nIn GGA, we are within 2% of the experimental bond length, but 5% of the\nexperimental atomisation energy. In LDA, we were within 4% of the experimental\nbond length, and within 2% of the experimental atomisation energy.   Do not forget that the typical accuracy of LDA and GGA varies with the class\nof materials studied\u2026",
            "title": "2.5 The use of the Generalized Gradient Approximation."
        },
        {
            "location": "/tutorials/base3/",
            "text": "This lesson aims at showing you how to get the following physical properties,\nfor an insulator:\n\n\n\n\nthe total energy \n\n\nthe lattice parameter \n\n\nthe band structure (actually, the Kohn-Sham band structure) \nYou will learn about the use of k-points, as well as the smearing of the\nplane-wave kinetic energy cut-off.\n\n\n\n\nThis lesson should take about 1 hour.\n\n\n\n\n3.1 Computing the total energy of silicon at fixed number of k points.\n\n\n3.2 Starting the convergence study with respect to k points\n\n\n3.3 Actually performing the convergence study with respect to k points\n\n\n3.4 Determination of the lattice parameters\n\n\n3.5 Computing the band structure\n\n\n\n\n\n\n** 3.1. Computing the total energy of silicon at fixed number of k points.\n\u00b6\n\n\n**\n\n\nBefore beginning, you might consider to work in a different subdirectory as\nfor lesson_base1 or lesson_base2 . Why not \u201cWork3\u201d ?\n\n\nThe file ~abinit/tests/tutorial/Input/tbase3_x.files lists the file names and\nroot names. You can copy it in the Work3 directory and change it as you did\nfor the tbase1_x.files and tbase2_x.files files. You can also copy the file\n~abinit/tests/tutorial/Input/tbase3_1.in in Work3. This is your input file.\nYou should edit it, read it carefully, have a look at the following \u201cnew\u201d\ninput variables, and their explanation :\n\n\n\n\nrprim\n \n\n\nxred\n (used instead of xcart) \n\n\nkptopt\n, \nngkpt\n, \nnshiftk\n, \nshiftk\n, \nkptrlatt\n, (not easy \u2026 take your time !) \n\n\ndiemac\n (compared to isolated molecules, another value is used, while \ndiemix\n has been suppressed). \n\n\n\n\nNote also the following: you will work at fixed \necut\n (=8Ha). It is\nimplicit that in \u201creal life\u201d, you should do a convergence test with respect to\n\necut\n \u2026\n\nHere, a suitable \necut\n is given to you. It will allow to obtain 0.2%\nrelative accuracy on lattice parameters.\n\n\nWhen you have read the input file, you can run the code, as usual (it will run\nfor a few seconds).\n\nThen, read the output file, and note the total energy.\n\n\n   etotal   -8.8662238960E+00\n\n\n\n\n\n\n\n 3.2. Starting the convergence study with respect to k points \n\u00b6\n\n\nThere is of course a convergence study associated with the sampling of the\nBrillouin zone. You should examine different grids, of increasing resolution.\nYou might try the following series of grids:\n\n\nngkpt1  2 2 2\nngkpt2  4 4 4\nngkpt3  6 6 6\nngkpt4  8 8 8\n\n\n\n\n\nHowever, the associated number of k points in the irreducible Brillouin zone\ngrows very fast. It is\n\n\nnkpt1  2\nnkpt2 10\nnkpt3 28\nnkpt4 60\n\n\n\n\n\nABINIT computes automatically this number of k points, from the definition of\nthe grid and the symmetries.\n\nYou might nevertheless define an input nkpt value in the input file, in which\ncase ABINIT will compare its computed value (from the grid) with this input\nvalue. We take this opportunity to examine the behaviour of ABINIT when a\nproblem is detected. Let\u2019s suppose that with \nngkpt1 4 4 4\n , one mentions\n\nnkpt1 2\n . The input file ~abinit/tests/tutorial/Input/tbase3_2.in is an\nexample. Do not forget to change tbase3_x.files, if you are using that file\nname . The message that you get a few dozen of lines before the end of the log\nfile is :\n\n\n--- !BUG\n\nmessage: |\n    The argument nkpt=     2, does not match\n      the number of k points generated by kptopt, kptrlatt, shiftk,\n      and the eventual symmetries, that is, nkpt=    10.\n      However, note that it might be due to the user,\n      if nkpt is explicitely defined in the input file.\n      In this case, please check your input file.\nsrc_file: getkgrid.F90\nsrc_line: 415\n...\n\n  Action : contact ABINIT group.\n\n\n\n\n\nThis is a typical ABINIT error message. It states what is the problem that\ncauses the stop of ABINIT, then suggests that it might be due to an error in\nthe input file, namely, an erroneous value of nkpt. The expected value,\n\nnkpt\n 10. is mentioned before the notice that the input file might be\nerroneous. Then, the file at which the problem occured is mentioned, as well\nas the number of the line in that file.\n\n\nAs the computation of \nnkpt\n for specific grids of k points is not an easy\ntask, while the even more important selection of specific economical grids\n(the best ratio between the accuracy of the integration in the Brillouin zone\nand the number of k-points) is more difficult, some help to the user is\nprovided by ABINIT. ABINIT is able to examine automatically different k point\ngrids, and to propose the best grids for integration. This is described in the\nabinit_help file, see the input variable \nprtkpt\n, and the associated\ncharacterisation of the integral accuracy, described in \nkptrlen\n. The\ngeneration of lists of k-point sets is done in different test cases, in the\ndirectory ~abinit/tests/v2 . You can directly have a look at the output files\nin ~abinit/tests/v2/Refs , the output files for the tests 61 to 73.\n\n\nWhen one begins the study of a new material, it is strongly advised to examine\nfirst the list of k points grids, and select (at least) three efficient ones,\nfor the k point convergence study. Do not forget that the CPU time will be\nlinearly proportional to the number of k points to be treated: using 10 k\npoints will take five more time than using 2 k points. Even for a similar\naccuracy of the Brillouin zone integration (about the same value of\n\nkptrlen\n), it might be easy to generate a grid that will fold to 10 k\npoints in the irreducible Brillouin zone, as well as one that will fold to 2 k\npoints in the irreducible Brillouin zone. The latter is clearly to be\npreferred !\n\n\n\n\n** 3.3. Actually performing the convergence study with respect to k points\n\u00b6\n\n\n**\n\n\nIn order to understand k-point grids, you should read the Monkhorst and Pack\npaper, Phys. Rev. B 13, 5188 (1976) \u2026 Well, maybe not immediately \u2026 In the\nmeantime, you can try the above-mentioned convergence study.\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase3_3.in is an example, while\n~abinit/tests/tutorial/Refs/tbase3_3.out is a reference output file. In this\noutput file, you should have a look at the echo of input variables. As you\nknow, these are preprocessed, and, in particular, \nngkpt\n and \nshiftk\n are\nused to generate the list of k points (\nkpt\n) and their weights (\nwtk\n).\nYou should read the information about \nkpt\n and \nwtk\n.\n\n\nFrom the output file, here is the evolution of total energy per unit cell:\n\n\n    etotal1  -8.8662238960E+00\n    etotal2  -8.8724909739E+00\n    etotal3  -8.8726017432E+00\n    etotal4  -8.8726056405E+00\n\n\n\n\n\nThe difference between dataset 3 and dataset 4 is rather small. Even the\ndataset 2 gives an accuracy of about 0.0001 Ha\n\nSo, our converged value for the total energy, at fixed \nacell\n, fixed\n\necut\n, is -8.8726 Ha .\n\n\n\n\n 3.4. Determination of the lattice parameters. \n\u00b6\n\n\nThe input variable \noptcell\n governs the automatic optimisation of cell\nshape and volume.\n\nFor the automatic optimisation of cell volume, use:\n\n\noptcell 1\nionmov 2\nntime 10\ndilatmx 1.05\necutsm 0.5\n\n\n\n\n\nYou should read the indications about \ndilatmx\n and \necutsm\n.\n\nDo not test all the k point grids, only those with nkpt 2 and 10.\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase3_4.in is an example, while\n~abinit/tests/tutorial/Refs/tbase3_4.out is a reference output file.  \n\n\nYou should obtain the following evolution of the lattice parameters:\n\n\n     acell1   1.0233363682E+01  1.0233363682E+01  1.0233363682E+01 Bohr\n     acell2   1.0216447241E+01  1.0216447241E+01  1.0216447241E+01 Bohr\n\n\n\n\n\nwith the following very small residual stresses:\n\n\n    strten1   1.8591719160E-07  1.8591719160E-07  1.8591719160E-07\n              0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n    strten2  -2.8279720007E-08 -2.8279720007E-08 -2.8279720007E-08\n              0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n\n\n\n\n\nThe stress tensor is given in Hartree/Bohr^3, and the order of the components\nis\n\n\n                        11  22  33\n                        23  13  12\n\n\n\n\n\nThere is only a 0.13% relative difference between \nacell\n1 and \nacell\n2 .\n\nSo, our converged LDA value for Silicon, with the 14si.pspnc pseudopotential\n(see the tbase3_x.files file) is 10.216 Bohr (actually 10.21644\u2026), that is\n5.406 Angstrom. The experimental value is \n5.431 Angstrom at 25 degree\nCelsius\n, see R.W.G. Wyckoff, Crystal structures Ed. Wiley and sons, New-York\n(1963).\n\n\n\n\n3.5. Computing the band structure\n\u00b6\n\n\nWe fix the parameters \nacell\n to the theoretical value of 3*10.216, and we\nfix also the grid of k points (the 4x4x4 FCC grid, equivalent to a 8x8x8\nMonkhorst-pack grid)\n\nWe will ask for 8 bands (4 valence and 4 conduction).\n\n\nA band structure can be computed by solving the Kohn-Sham equation for many\ndifferent k points, along different lines of the Brillouin zone.\n\nThe potential that enters the Kohn-Sham must be derived from a previous self-\nconsistent calculation, and will not vary during the scan of different k-point\nlines.\n\nSuppose that you want to make a L-Gamma-X-(U-)Gamma circuit, with 10, 12 and\n17 divisions for each line (each segment has a different length in reciprocal\nspace, and these divisions give approximately the same distance between points\nalong a line).\n\nThe circuit will be obtained easily by the following choice of segment end\npoints:\n\n\nL     (1/2 0 0)\nGamma (0 0 0)\nX     (0 1/2 1/2)\nGamma (1 1 1)\n\n\n\n\n\n_Note:\n\n\n\n\nthe last Gamma point is in another cell of the reciprocal space than the first one, this choice allows to construct the X-U-Gamma line easily ;\n\n\nthe k-points are specified using reduced coordinates - in agreement with the input setting of the primitive 2-atom unit cell - in standard textbooks, you will often find the L, Gamma or X point given in coordinates of the conventional 8-atom cell: the above-mentioned circuit is then (1/2 1/2 1/2)-(0 0 0)-(1 0 0)-(1 1 1), but such (conventional) coordinates cannot be used with the 2-atom (non-conventional) cell.\n\n\n\n\n_\n\n\nSo, you should set up in your input file, for the first dataset, a usual SCF\ncalculation in which you output the density (\nprtden\n 1), and, for the\nsecond dataset:\n\n\n\n\nfix \niscf\n to -2, to make a non-self-consistent calculation ; \n\n\ndefine \ngetden\n -1, to take the output density of dataset 1 ; \n\n\nset \nnband\n to 8 ; \n\n\nset \nkptopt\n to -3, to define three segments in the brillouin Zone ; \n\n\nset \nndivk\n to 10 12 17 (this means a circuit defined by 4 points, with 10 divisions of the first segment, 12 divisions of the second, 17 divisions of the third) \n\n\n\n\nset \nkptbounds\n to \n\n\n                0.5  0.0  0.0 # L point\n            0.0  0.0  0.0 # Gamma point\n            0.0  0.5  0.5 # X point\n            1.0  1.0  1.0 # Gamma point in another cell.\n\n\n\n\n\n\n\n\n\nset \nenunit\n to 1, in order to have eigenenergies in eV \n\n\n\n\nthe only tolerance criterion admitted for non-self-consistent calculations is \ntolwfr\n. You should set it to 1.0d-10 (or so), and suppress \ntoldfe\n. \n\n\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase3_5.in is an example, while\n~abinit/tests/tutorial/Refs/tbase3_5.out is a reference output file.\n\n\nYou should find the band structure starting at (second dataset):\n\n\n Eigenvalues (   eV  ) for nkpt=  40  k points:\n kpt#   1, nband=  8, wtk=  1.00000, kpt=  0.5000  0.0000  0.0000 (reduced coord)\n  -3.78815  -1.15872   4.69668   4.69668   7.38795   9.23867   9.23867  13.45707\n kpt#   2, nband=  8, wtk=  1.00000, kpt=  0.4500  0.0000  0.0000 (reduced coord)\n  -3.92759  -0.95774   4.71292   4.71292   7.40692   9.25561   9.25561  13.48927\n kpt#   3, nband=  8, wtk=  1.00000, kpt=  0.4000  0.0000  0.0000 (reduced coord)\n  -4.25432  -0.44393   4.76726   4.76726   7.46846   9.31193   9.31193  13.57737\n kpt#   4, nband=  8, wtk=  1.00000, kpt=  0.3500  0.0000  0.0000 (reduced coord)\n  -4.64019   0.24941   4.85732   4.85732   7.56855   9.38323   9.38323  13.64601\n ....\n\n\n\n\n\nOne needs a graphical tool to represent all these data \u2026 (For the MAPR 2451\nlecture: try with MATLAB). In a separate file (_EIG), you will find the list\nof k-points and eigenenergies (the input variable \nprteig\n is set by default\nto 1).\n\n\nEven without a graphical tool we will have a quick look at the values at L,\nGamma, X and Gamma again:\n\n\n kpt#   1, nband=  8, wtk=  1.00000, kpt=  0.5000  0.0000  0.0000 (reduced coord)\n  -3.78815  -1.15872   4.69668   4.69668   7.38795   9.23867   9.23867  13.45707\n\n kpt#  11, nband=  8, wtk=  1.00000, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n  -6.17005   5.91814   5.91814   5.91814   8.44836   8.44836   8.44836   9.17755\n\n kpt#  23, nband=  8, wtk=  1.00000, kpt=  0.0000  0.5000  0.5000 (reduced coord)\n  -1.96393  -1.96393   3.00569   3.00569   6.51173   6.51173  15.95524  15.95524\n\n kpt#  40, nband=  8, wtk=  1.00000, kpt=  1.0000  1.0000  1.0000 (reduced coord)\n  -6.17005   5.91814   5.91814   5.91814   8.44836   8.44836   8.44836   9.17755\n\n\n\n\n\nThe last gamma is exactly equivalent to the first gamma. It can be checked\nthat the top of the valence band is obtained at Gamma (=5.91814 eV). The width\nof the valence band is 12.09 eV, the lowest unoccupied state at X is 0.594 eV\nhigher than the top of the valence band, at Gamma. The Si is described as an\nindirect band gap material (this is correct), with a band-gap of about 0.594\neV (this is quantitatively quite wrong: the experimental value 1.17 eV is at\n25 degree Celsius). The minimum of the conduction band is even slightly\ndisplaced with respect to X, see kpt # 21 . This underestimation of the band\ngap is well-known (the famous DFT band-gap problem). In order to obtain\ncorrect band gaps, you need to go beyond the Kohn-Sham Density Functional\nTheory: use the GW approximation. This is described in \nthe first lesson on\nthe GW approximation\n.\n\n\nFor experimental data and band structure representation, see\n\nM.L. Cohen and J.R. Chelikowski\n\nElectronic structure and optical properties of semiconductors\n\nSpringer-Verlag New-York (1988).\n\n\nThere is a subtlety that is worth to comment about. In non-self-consistent\ncalculations, like those performed in the present band structure calculation,\nwith \niscf\n=-2, not all bands are converged within the tolerance \ntolwfr\n.\nIndeed, the two upper bands (by default) have not been taken into account to\napply this convergence criterion: they constitute a \u201cbuffer\u201d. The number of\nsuch \u201cbuffer\u201d bands is governed by the input variable \nnbdbuf\n.\n\n\nIt can happen that the highest (or two highest) band(s), if not separated by a\ngap from non-treated bands, can exhibit a very slow convergence rate. This\nbuffer allows to achieve convergence of \u201cimportant\u201d, non-buffer bands. In the\npresent case, 6 bands have been converged with a residual better than\n\ntolwfr\n, while the two upper bands are less converged (still sufficiently\nfor graphical representation of the band structure). In order to achieve the\nsame convergence for all 8 bands, it is advised to use \nnband\n=10 (that is,\n8 + 2).",
            "title": "Base3"
        },
        {
            "location": "/tutorials/base3/#31-computing-the-total-energy-of-silicon-at-fixed-number-of-k-points",
            "text": "**  Before beginning, you might consider to work in a different subdirectory as\nfor lesson_base1 or lesson_base2 . Why not \u201cWork3\u201d ?  The file ~abinit/tests/tutorial/Input/tbase3_x.files lists the file names and\nroot names. You can copy it in the Work3 directory and change it as you did\nfor the tbase1_x.files and tbase2_x.files files. You can also copy the file\n~abinit/tests/tutorial/Input/tbase3_1.in in Work3. This is your input file.\nYou should edit it, read it carefully, have a look at the following \u201cnew\u201d\ninput variables, and their explanation :   rprim    xred  (used instead of xcart)   kptopt ,  ngkpt ,  nshiftk ,  shiftk ,  kptrlatt , (not easy \u2026 take your time !)   diemac  (compared to isolated molecules, another value is used, while  diemix  has been suppressed).    Note also the following: you will work at fixed  ecut  (=8Ha). It is\nimplicit that in \u201creal life\u201d, you should do a convergence test with respect to ecut  \u2026 \nHere, a suitable  ecut  is given to you. It will allow to obtain 0.2%\nrelative accuracy on lattice parameters.  When you have read the input file, you can run the code, as usual (it will run\nfor a few seconds). \nThen, read the output file, and note the total energy.     etotal   -8.8662238960E+00",
            "title": "** 3.1. Computing the total energy of silicon at fixed number of k points."
        },
        {
            "location": "/tutorials/base3/#32-starting-the-convergence-study-with-respect-to-k-points",
            "text": "There is of course a convergence study associated with the sampling of the\nBrillouin zone. You should examine different grids, of increasing resolution.\nYou might try the following series of grids:  ngkpt1  2 2 2\nngkpt2  4 4 4\nngkpt3  6 6 6\nngkpt4  8 8 8  However, the associated number of k points in the irreducible Brillouin zone\ngrows very fast. It is  nkpt1  2\nnkpt2 10\nnkpt3 28\nnkpt4 60  ABINIT computes automatically this number of k points, from the definition of\nthe grid and the symmetries. \nYou might nevertheless define an input nkpt value in the input file, in which\ncase ABINIT will compare its computed value (from the grid) with this input\nvalue. We take this opportunity to examine the behaviour of ABINIT when a\nproblem is detected. Let\u2019s suppose that with  ngkpt1 4 4 4  , one mentions nkpt1 2  . The input file ~abinit/tests/tutorial/Input/tbase3_2.in is an\nexample. Do not forget to change tbase3_x.files, if you are using that file\nname . The message that you get a few dozen of lines before the end of the log\nfile is :  --- !BUG \nmessage: |\n    The argument nkpt=     2, does not match\n      the number of k points generated by kptopt, kptrlatt, shiftk,\n      and the eventual symmetries, that is, nkpt=    10.\n      However, note that it might be due to the user,\n      if nkpt is explicitely defined in the input file.\n      In this case, please check your input file.\nsrc_file: getkgrid.F90\nsrc_line: 415\n...\n\n  Action : contact ABINIT group.  This is a typical ABINIT error message. It states what is the problem that\ncauses the stop of ABINIT, then suggests that it might be due to an error in\nthe input file, namely, an erroneous value of nkpt. The expected value, nkpt  10. is mentioned before the notice that the input file might be\nerroneous. Then, the file at which the problem occured is mentioned, as well\nas the number of the line in that file.  As the computation of  nkpt  for specific grids of k points is not an easy\ntask, while the even more important selection of specific economical grids\n(the best ratio between the accuracy of the integration in the Brillouin zone\nand the number of k-points) is more difficult, some help to the user is\nprovided by ABINIT. ABINIT is able to examine automatically different k point\ngrids, and to propose the best grids for integration. This is described in the\nabinit_help file, see the input variable  prtkpt , and the associated\ncharacterisation of the integral accuracy, described in  kptrlen . The\ngeneration of lists of k-point sets is done in different test cases, in the\ndirectory ~abinit/tests/v2 . You can directly have a look at the output files\nin ~abinit/tests/v2/Refs , the output files for the tests 61 to 73.  When one begins the study of a new material, it is strongly advised to examine\nfirst the list of k points grids, and select (at least) three efficient ones,\nfor the k point convergence study. Do not forget that the CPU time will be\nlinearly proportional to the number of k points to be treated: using 10 k\npoints will take five more time than using 2 k points. Even for a similar\naccuracy of the Brillouin zone integration (about the same value of kptrlen ), it might be easy to generate a grid that will fold to 10 k\npoints in the irreducible Brillouin zone, as well as one that will fold to 2 k\npoints in the irreducible Brillouin zone. The latter is clearly to be\npreferred !",
            "title": "3.2. Starting the convergence study with respect to k points"
        },
        {
            "location": "/tutorials/base3/#33-actually-performing-the-convergence-study-with-respect-to-k-points",
            "text": "**  In order to understand k-point grids, you should read the Monkhorst and Pack\npaper, Phys. Rev. B 13, 5188 (1976) \u2026 Well, maybe not immediately \u2026 In the\nmeantime, you can try the above-mentioned convergence study.  The input file ~abinit/tests/tutorial/Input/tbase3_3.in is an example, while\n~abinit/tests/tutorial/Refs/tbase3_3.out is a reference output file. In this\noutput file, you should have a look at the echo of input variables. As you\nknow, these are preprocessed, and, in particular,  ngkpt  and  shiftk  are\nused to generate the list of k points ( kpt ) and their weights ( wtk ).\nYou should read the information about  kpt  and  wtk .  From the output file, here is the evolution of total energy per unit cell:      etotal1  -8.8662238960E+00\n    etotal2  -8.8724909739E+00\n    etotal3  -8.8726017432E+00\n    etotal4  -8.8726056405E+00  The difference between dataset 3 and dataset 4 is rather small. Even the\ndataset 2 gives an accuracy of about 0.0001 Ha \nSo, our converged value for the total energy, at fixed  acell , fixed ecut , is -8.8726 Ha .",
            "title": "** 3.3. Actually performing the convergence study with respect to k points"
        },
        {
            "location": "/tutorials/base3/#34-determination-of-the-lattice-parameters",
            "text": "The input variable  optcell  governs the automatic optimisation of cell\nshape and volume. \nFor the automatic optimisation of cell volume, use:  optcell 1\nionmov 2\nntime 10\ndilatmx 1.05\necutsm 0.5  You should read the indications about  dilatmx  and  ecutsm . \nDo not test all the k point grids, only those with nkpt 2 and 10.  The input file ~abinit/tests/tutorial/Input/tbase3_4.in is an example, while\n~abinit/tests/tutorial/Refs/tbase3_4.out is a reference output file.    You should obtain the following evolution of the lattice parameters:       acell1   1.0233363682E+01  1.0233363682E+01  1.0233363682E+01 Bohr\n     acell2   1.0216447241E+01  1.0216447241E+01  1.0216447241E+01 Bohr  with the following very small residual stresses:      strten1   1.8591719160E-07  1.8591719160E-07  1.8591719160E-07\n              0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n    strten2  -2.8279720007E-08 -2.8279720007E-08 -2.8279720007E-08\n              0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  The stress tensor is given in Hartree/Bohr^3, and the order of the components\nis                          11  22  33\n                        23  13  12  There is only a 0.13% relative difference between  acell 1 and  acell 2 . \nSo, our converged LDA value for Silicon, with the 14si.pspnc pseudopotential\n(see the tbase3_x.files file) is 10.216 Bohr (actually 10.21644\u2026), that is\n5.406 Angstrom. The experimental value is  5.431 Angstrom at 25 degree\nCelsius , see R.W.G. Wyckoff, Crystal structures Ed. Wiley and sons, New-York\n(1963).",
            "title": "3.4. Determination of the lattice parameters."
        },
        {
            "location": "/tutorials/base3/#35-computing-the-band-structure",
            "text": "We fix the parameters  acell  to the theoretical value of 3*10.216, and we\nfix also the grid of k points (the 4x4x4 FCC grid, equivalent to a 8x8x8\nMonkhorst-pack grid) \nWe will ask for 8 bands (4 valence and 4 conduction).  A band structure can be computed by solving the Kohn-Sham equation for many\ndifferent k points, along different lines of the Brillouin zone. \nThe potential that enters the Kohn-Sham must be derived from a previous self-\nconsistent calculation, and will not vary during the scan of different k-point\nlines. \nSuppose that you want to make a L-Gamma-X-(U-)Gamma circuit, with 10, 12 and\n17 divisions for each line (each segment has a different length in reciprocal\nspace, and these divisions give approximately the same distance between points\nalong a line). \nThe circuit will be obtained easily by the following choice of segment end\npoints:  L     (1/2 0 0)\nGamma (0 0 0)\nX     (0 1/2 1/2)\nGamma (1 1 1)  _Note:   the last Gamma point is in another cell of the reciprocal space than the first one, this choice allows to construct the X-U-Gamma line easily ;  the k-points are specified using reduced coordinates - in agreement with the input setting of the primitive 2-atom unit cell - in standard textbooks, you will often find the L, Gamma or X point given in coordinates of the conventional 8-atom cell: the above-mentioned circuit is then (1/2 1/2 1/2)-(0 0 0)-(1 0 0)-(1 1 1), but such (conventional) coordinates cannot be used with the 2-atom (non-conventional) cell.   _  So, you should set up in your input file, for the first dataset, a usual SCF\ncalculation in which you output the density ( prtden  1), and, for the\nsecond dataset:   fix  iscf  to -2, to make a non-self-consistent calculation ;   define  getden  -1, to take the output density of dataset 1 ;   set  nband  to 8 ;   set  kptopt  to -3, to define three segments in the brillouin Zone ;   set  ndivk  to 10 12 17 (this means a circuit defined by 4 points, with 10 divisions of the first segment, 12 divisions of the second, 17 divisions of the third)    set  kptbounds  to                   0.5  0.0  0.0 # L point\n            0.0  0.0  0.0 # Gamma point\n            0.0  0.5  0.5 # X point\n            1.0  1.0  1.0 # Gamma point in another cell.    set  enunit  to 1, in order to have eigenenergies in eV    the only tolerance criterion admitted for non-self-consistent calculations is  tolwfr . You should set it to 1.0d-10 (or so), and suppress  toldfe .    The input file ~abinit/tests/tutorial/Input/tbase3_5.in is an example, while\n~abinit/tests/tutorial/Refs/tbase3_5.out is a reference output file.  You should find the band structure starting at (second dataset):   Eigenvalues (   eV  ) for nkpt=  40  k points:\n kpt#   1, nband=  8, wtk=  1.00000, kpt=  0.5000  0.0000  0.0000 (reduced coord)\n  -3.78815  -1.15872   4.69668   4.69668   7.38795   9.23867   9.23867  13.45707\n kpt#   2, nband=  8, wtk=  1.00000, kpt=  0.4500  0.0000  0.0000 (reduced coord)\n  -3.92759  -0.95774   4.71292   4.71292   7.40692   9.25561   9.25561  13.48927\n kpt#   3, nband=  8, wtk=  1.00000, kpt=  0.4000  0.0000  0.0000 (reduced coord)\n  -4.25432  -0.44393   4.76726   4.76726   7.46846   9.31193   9.31193  13.57737\n kpt#   4, nband=  8, wtk=  1.00000, kpt=  0.3500  0.0000  0.0000 (reduced coord)\n  -4.64019   0.24941   4.85732   4.85732   7.56855   9.38323   9.38323  13.64601\n ....  One needs a graphical tool to represent all these data \u2026 (For the MAPR 2451\nlecture: try with MATLAB). In a separate file (_EIG), you will find the list\nof k-points and eigenenergies (the input variable  prteig  is set by default\nto 1).  Even without a graphical tool we will have a quick look at the values at L,\nGamma, X and Gamma again:   kpt#   1, nband=  8, wtk=  1.00000, kpt=  0.5000  0.0000  0.0000 (reduced coord)\n  -3.78815  -1.15872   4.69668   4.69668   7.38795   9.23867   9.23867  13.45707\n\n kpt#  11, nband=  8, wtk=  1.00000, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n  -6.17005   5.91814   5.91814   5.91814   8.44836   8.44836   8.44836   9.17755\n\n kpt#  23, nband=  8, wtk=  1.00000, kpt=  0.0000  0.5000  0.5000 (reduced coord)\n  -1.96393  -1.96393   3.00569   3.00569   6.51173   6.51173  15.95524  15.95524\n\n kpt#  40, nband=  8, wtk=  1.00000, kpt=  1.0000  1.0000  1.0000 (reduced coord)\n  -6.17005   5.91814   5.91814   5.91814   8.44836   8.44836   8.44836   9.17755  The last gamma is exactly equivalent to the first gamma. It can be checked\nthat the top of the valence band is obtained at Gamma (=5.91814 eV). The width\nof the valence band is 12.09 eV, the lowest unoccupied state at X is 0.594 eV\nhigher than the top of the valence band, at Gamma. The Si is described as an\nindirect band gap material (this is correct), with a band-gap of about 0.594\neV (this is quantitatively quite wrong: the experimental value 1.17 eV is at\n25 degree Celsius). The minimum of the conduction band is even slightly\ndisplaced with respect to X, see kpt # 21 . This underestimation of the band\ngap is well-known (the famous DFT band-gap problem). In order to obtain\ncorrect band gaps, you need to go beyond the Kohn-Sham Density Functional\nTheory: use the GW approximation. This is described in  the first lesson on\nthe GW approximation .  For experimental data and band structure representation, see \nM.L. Cohen and J.R. Chelikowski \nElectronic structure and optical properties of semiconductors \nSpringer-Verlag New-York (1988).  There is a subtlety that is worth to comment about. In non-self-consistent\ncalculations, like those performed in the present band structure calculation,\nwith  iscf =-2, not all bands are converged within the tolerance  tolwfr .\nIndeed, the two upper bands (by default) have not been taken into account to\napply this convergence criterion: they constitute a \u201cbuffer\u201d. The number of\nsuch \u201cbuffer\u201d bands is governed by the input variable  nbdbuf .  It can happen that the highest (or two highest) band(s), if not separated by a\ngap from non-treated bands, can exhibit a very slow convergence rate. This\nbuffer allows to achieve convergence of \u201cimportant\u201d, non-buffer bands. In the\npresent case, 6 bands have been converged with a residual better than tolwfr , while the two upper bands are less converged (still sufficiently\nfor graphical representation of the band structure). In order to achieve the\nsame convergence for all 8 bands, it is advised to use  nband =10 (that is,\n8 + 2).",
            "title": "3.5. Computing the band structure"
        },
        {
            "location": "/tutorials/base4/",
            "text": "This lesson aims at showing how to get the following physical properties, for\na metal, and for a surface:\n\n\n\n\nthe total energy \n\n\nthe lattice parameter \n\n\nthe relaxation of surface atoms \n\n\nthe surface energy \nYou will learn about the smearing of the Brillouin zone integration, and also\na bit about preconditioning the SCF cycle.\n\n\n\n\nThis lesson should take about 1 hour and 30 minutes.\n\n\n\n\n4.1. Computing the total energy and lattice parameters of aluminum for a fixed smearing and number of k points.\n\n\n4.2. The convergence study with respect to k points.\n\n\n4.3. The convergence study with respect to both number of k points AND broadening factor (tsmear).\n\n\n4.4. Determination of the surface energy of aluminum (100): changing the orientation of the unit cell.\n\n\n4.5. Determination of the surface energy: a (3 aluminum layer + 1 vacuum layer) slab calculation.\n\n\n4.6. Determination of the surface energy: increasing the number of vacuum layers.\n\n\n4.7. Determination of the surface energy: increasing the number of aluminum layers.\n\n\n\n\n\n\n** 4.1. Computing the total energy and lattice parameters of aluminum for\n\u00b6\n\n\na fixed smearing and number of k points. **\n\n\n_Before beginning, you might consider to work in a different subdirectory as\nfor lesson 1, 2 or 3 . Why not \u201cWork4\u201d ? _\n\n\nThe file ~abinit/tests/tutorial/Input/tbase4_x.files lists the file names and\nroot names. You can copy it in the Work4 directory (and change it, as usual).\nYou can also copy the file ~abinit/tests/tutorial/Input/tbase4_1.in in Work4.\nThis is your input file. You should edit it, read it carefully, and have a\nlook at the following \u201cnew\u201d input variables, and their explanation:\n\n\n\n\noccopt\n \n\n\ntsmear\n \nNote also the following:\n\n1) You will work at fixed \necut\n (=6Ha). It is implicit that in \u201creal life\u201d,\nyou should do a convergence test with respect to \necut\n \u2026 Here, a suitable\n\necut\n is given to you. It will allow to obtain 0.2% relative accuracy on\nlattice parameters. Note that this is the softer pseudopotential of those that\nwe have used until now: the 01h.pspgth for H needed 30 Ha (it was rather\nhard), the 14si.pspnc for Si needed 8 Ha.\n\n2) The input variable diemac has been suppressed. Aluminum is a metal, and the\ndefault is tailored for that case.\n\n\n\n\nWhen you have read the input file, you can run the code, as usual (it will\ntake a few seconds). Then, read the output file quietly.\n\nYou should note that the Fermi energy and occupation numbers have been\ncomputed automatically:\n\n\n Fermi (or HOMO) energy (hartree) =   0.26847   Average Vxc (hartree)=  -0.34746\n Eigenvalues (hartree) for nkpt=   2  k points:\n kpt#   1, nband=  3, wtk=  0.75000, kpt= -0.2500  0.5000  0.0000 (reduced coord)\n   0.09425   0.25438   0.41909\n      occupation numbers for kpt#   1\n   2.00003   1.33307   0.00014\n prteigrs : prtvol=0 or 1, do not print more k-points.\n\n\n\n\n\nYou should also note that the components of the total energy include an\nentropy term:\n\n\n Components of total free energy (in Hartree):\n\n    Kinetic energy  =  8.70954971782498E-01\n    Hartree energy  =  3.84986358590396E-03\n    XC energy       = -8.08434339502224E-01\n    Ewald energy    = -2.72948286712169E+00\n    PspCore energy  =  3.78721653637092E-02\n    Loc. psp. energy=  8.26684645838168E-02\n    NL   psp  energy=  4.52588269933839E-01\n    >>>>> Internal E= -2.08998347137414E+00\n\n    -kT*entropy     = -7.99729047978171E-03\n    >>>>>>>>> Etotal= -2.09798076185393E+00\n\n Other information on the energy :\n    Total energy(eV)= -5.70889598417024E+01 ; Band energy (Ha)=   3.6059822203E-01\n\n\n\n\n\n\n\n 4.2. The convergence study with respect to k points \n\u00b6\n\n\nThere is of course a convergence study associated to the sampling of the\nBrillouin zone. You should examine different grids, of increasing resolution.\nYou might try the following series of grids:\n\n\n  ngkpt1  2 2 2\n  ngkpt2  4 4 4\n  ngkpt3  6 6 6\n  ngkpt4  8 8 8\n\n\n\n\n\nwith the associated \nnkpt\n:\n\n\n  nkpt1  2\n  nkpt2 10\n  nkpt3 28\n  nkpt4 60\n\n\n\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase4_2.in is an example, while\n~abinit/tests/tutorial/Refs/tbase4_2.out is a reference output file. The run\nmight take about thirty seconds on a PC 3 GHz.\n\n\nYou will see that, FOR THE PARTICULAR VALUE OF \ntsmear\n=0.05 Ha, the lattice\nparameter is already converged with \nnkpt\n=10 :\n\n\n            acell1     7.5588968086E+00  7.5588968086E+00  7.5588968086E+00 Bohr\n            acell2     7.5070431499E+00  7.5070431499E+00  7.5070431499E+00 Bohr\n            acell3     7.5016877756E+00  7.5016877756E+00  7.5016877756E+00 Bohr\n            acell4     7.4992662653E+00  7.4992662653E+00  7.4992662653E+00 Bohr\n\n\n\n\n\nNote that there is usually a STRONG cross-convergence effect between the\nnumber of k points and the value of the broadening, \ntsmear\n.\n\nThe right procedure is: for each value of \ntsmear\n, to get the convergence\nwith respect to the number of k points, then to compare the k-point converged\nvalues for different values of \ntsmear\n.\n\n\nIn what follows, we will restrict ourselves to the grids with \nnkpt\n=2, 10\nand 28.\n\n\n\n\n** 4.3. The convergence study with respect to both number of k points AND\n\u00b6\n\n\nbroadening factor (tsmear). **\n\n\nThe theoretical convergence rate for \ntsmear\n ending to 0, in the case of\n\noccopt\n=4, is quartic. This is obtained in the hypothesis of infinitely\ndense k point grid. We will check the evolution of \nacell\n as a function of\n\ntsmear\n, for the following values of \ntsmear\n : 0.01, 0.02, 0.03 and\n0.04. Use the double-loop capability of the multi-dataset mode, with the\n\ntsmear\n changes in the INNER loop. This will saves CPU time, as the\nwavefunctions of the previous dataset will be excellent (no transfer to\ndifferent k points).\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase4_3.in is an example, while\n~abinit/tests/tutorial/Refs/tbase4_3.out is a reference output file.\n\n\nFrom the output file, here is the evolution of \nacell\n :\n\n\n            acell11    7.5587661702E+00  7.5587661702E+00  7.5587661702E+00 Bohr\n            acell12    7.5587696944E+00  7.5587696944E+00  7.5587696944E+00 Bohr\n            acell13    7.5587696871E+00  7.5587696871E+00  7.5587696871E+00 Bohr\n            acell14    7.5587710578E+00  7.5587710578E+00  7.5587710578E+00 Bohr\n            acell21    7.5055168997E+00  7.5055168997E+00  7.5055168997E+00 Bohr\n            acell22    7.5056781966E+00  7.5056781966E+00  7.5056781966E+00 Bohr\n            acell23    7.5018335937E+00  7.5018335937E+00  7.5018335937E+00 Bohr\n            acell24    7.5041510220E+00  7.5041510220E+00  7.5041510220E+00 Bohr\n            acell31    7.4963466654E+00  7.4963466654E+00  7.4963466654E+00 Bohr\n            acell32    7.4957099831E+00  7.4957099831E+00  7.4957099831E+00 Bohr\n            acell33    7.4969520318E+00  7.4969520318E+00  7.4969520318E+00 Bohr\n            acell34    7.4993529673E+00  7.4993529673E+00  7.4993529673E+00 Bohr\n\n\n\n\n\nThese data should be analyzed properly.\n\n\nFor \ntsmear\n=0.01, the converged value, contained in acell31, must be\ncompared to acell11 and acell21: between acell21 and acell31, the difference\nis below 0.2%. acell31 can be considered to be converged with respect to the\nnumber of k-points, at fixed \ntsmear\n.\n\nThis tsmear being the lowest one, it is usually the most difficult to\nconverge, and the values acell31,32,33 and 34 are indeed well-converged with\nrespect to the k-point number.\n\nThe use of the largest \n[tsmear]\n, giving acell34, induces only a small\nerror in the lattice parameter. For that particular value of \ntsmear\n, one\ncan use the second k-point grid, giving acell24.\n\n\nSo to \nsummarize\n:\n\nwe can choose to work with a 10 k-point grid in the irreducible Brillouin\nzone, and the associated \ntsmear\n=0.04, with less than 0.1% error on the\nlattice parameter.\n\nNOTE that this error due to the Brillouin zone sampling could add to the error\ndue to the choice of \necut\n (that was mentioned previously to be on the\norder of 0.2%).\n\n\nIn what follows, we will stick to these values of \necut\n and \ntsmear\n, and\ntry to use k-point grids with a similar resolution.\n\n\nOur final value for the aluminum lattice parameter, in the LDA, using the\n13al.981214.fhi pseudopotential, is thus 7.5041 Bohr. Note: for historical\nreasons (consistency with older versions of the tutorial), we will work on the\nfollowing, with a slightly different value, of 7.5056 Bohr, that is 3.9718\nAngstrom.\n\nThe experimental value at 25 degree Celsius is 4.04958 Angstrom.\n\n\nThe associated total energy and accuracy can be deduced from\n\n\n           etotal11   -2.0916027819E+00\n           etotal12   -2.0931968906E+00\n           etotal13   -2.0947909992E+00\n           etotal14   -2.0963851177E+00\n           etotal21   -2.0969713557E+00\n           etotal22   -2.0975525285E+00\n           etotal23   -2.0978233733E+00\n           etotal24   -2.0979980153E+00\n           etotal31   -2.0983520905E+00\n           etotal32   -2.0983215368E+00\n           etotal33   -2.0983305960E+00\n           etotal34   -2.0984218116E+00\n\n\n\n\n\netotal\n24 is -2.0979980153E+00 Ha, with an accuracy of 0.0005 Ha .\n\n\n\n\n** 4.4. Determination of the surface energy of aluminum (100): changing\n\u00b6\n\n\nthe orientation of the unit cell. **\n\n\nIn order to study the Aluminum (100) surface, we will have to set up a\nsupercell representing a slab. This supercell should be chosen as to be\ncompatible with the primitive surface unit cell.\n\nThe corresponding directions are \n[-1 1 0]\n and \n[1 1 0]\n. The direction\nperpendicular to the surface is \n[0 0 1]\n. There is no primitive cell of bulk\naluminum based on these vectors, but a doubled cell. We will first compute the\ntotal energy associated with this doubled cell. This is not strictly needed,\nbut it is a valuable intermediate step towards the study of the surface.\n\n\nYou might start from tbase4_3.in.\n\nYou have to change \nrprim\n. Still, try to keep \nacell\n at the values of\nbulk aluminum that were determined previously. But it is not all: the most\ndifficult part in the passage to this doubled cell is the definition of the\nk-point grid. Of course, one could just take a homogeneous simple cubic grid\nof k points, but this will not correspond exactly to the k-point grid used in\nthe primitive cell in tbase4_3.in . This would not be a big problem, but you\nwould miss some error cancellation.\n\n\nThe answer to this problem is given in the input file\n~abinit/tests/tutorial/Input/tbase4_4.in.\n\nThe procedure to do the exact translation of the k-point grid will not be\nexplained here (sorry for this). If you do not see how to do it, just use\nhomogeneous simple cubic grids, with about the same resolution as for the\nprimitive cell case. There is a simple rule to estimate ROUGHLY whether two\ngrids for different cells have the same resolution: simply multiply the linear\ndimensions of the k-point grids, by the number of sublattices, by the number\nof atoms in the cell. For example, the corresponding product for the usual 10\nk-point grid is \n4x4x4 x 4 x 1 = 256\n . In the file tbase4_4.in, one has\n\n4x4x4 x 2 x 2 = 256\n . The grids of k points should not be too anisotropic\nfor this rough estimation to be valid.\n\n\nNote also the input variables \nrprim\n and \nchkprim\n in this input file.\n\n\nSo, you run tbase4_4.in (only a few seconds, the reference file is\n~abinit/tests/tutorial/Refs/tbase4_4.out), and you find the following total\nenergy:\n\n\n           etotal     -4.1962972610E+00\n\n\n\n\n\nIt is not exactly twice the total energy for the primitive cell, mentioned\nabove, but the difference is less than 0.0005 Ha. It is due to the different\nFFT grids used in the two runs, and affect the exchange-correlation energy.\nThese grids are always homogeneous primitive 3D grids, so that changing the\norientation of the lattice will give mutually incompatible lattices.\nIncreasing the size of the FFT grid would improve the agreement.\n\n\n\n\n** 4.5. Determination of the surface energy : a (3 aluminum layer + 1\n\u00b6\n\n\nvacuum layer) slab calculation. **\n\n\nWe will first compute the total energy associated with only three layers of\naluminum, separated by only one layer of vacuum. This is kind of a minimal\nslab:\n\n\n\n\none surface layer \n\n\none \u201cbulk\u201d layer \n\n\none surface layer \n\n\none vacuum layer \n\n\n\u2026 \nIt is convenient to take the vacuum region as having a multiple of the width\nof the aluminum layers, but this is not mandatory. The supercell to use is the\ndouble of the previous cell (that had two layers of Aluminum atoms along the\n\n[0 0 1]\n direction). Of course, the relaxation of the surface might give an\nimportant contribution to the total energy.\n\n\n\n\nYou should start from tbase4_4.in .\n\nYou have to modify \nrprim\n (double the cell along \n[0 0 1]\n), the atomic\npositions, as well as the k point mesh. For the latter, it is supposed that\nthe electrons cannot propagate from one slab to its image in the \n[0 0 1]\n\ndirection, so that the k_z component of the special k points can be taken 0:\nonly one layer of k points is needed along the z-direction. You should also\nallow the relaxation of atomic positions, but not the relaxation of lattice\nparameters (the lattice parameters along x or y must be considered fixed to\nthe bulk value, while, for the z direction, there is no interest to allow the\nvacuum region to collapse !\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase4_5.in is an example, while\n~abinit/tests/tutorial/Refs/tbase4_5.out is a reference output file. The run\nmight last one minute.\n\n\nThe total energy after the first SCF cycle, when the atomic positions are\nequal to their starting values, is:\n\n\n ETOT  6  -6.2619738807344\n\n\n\n\n\nNote that the total energy of three aluminum atoms in the bulk, (from section\n4.3, etotal24 multiplied by three) is\n\n\n   -6.293994 Ha\n\n\n\n\n\nso that the non-relaxed surface energy, per surface unit cell (there are two\nsurfaces in our simulation cell !) is\n\n\n  0.016010 Ha = 0.436 eV .\n\n\n\n\n\nThe total energy after the Broyden relaxation is:\n\n\n           etotal     -6.2622251508E+00\n\n\n\n\n\nso that the relaxed surface energy, per surface unit cell is\n\n\n0.015885 Ha = 0.432eV .\n\n\n\n\n\nIt seems that the relaxation energy is very small, compared to the surface\nenergy, but we need to do the convergence studies.\n\n\n\n\n** 4.6. Determination of the surface energy: increasing the number of\n\u00b6\n\n\nvacuum layers. **\n\n\nOne should now increase the number of vacuum layers: 2 and 3 layers instead of\nonly 1.\n\nIt is preferable to define atomic positions in Cartesian coordinates. The same\ncoordinates will work for both 2 and 3 vacuum layers, while this is not the\ncase for reduced coordinates, as the cell size increases.\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase4_6.in is an example input\nfile, while ~abinit/tests/tutorial/Refs/tbase4_6.out is a reference output\nfile. The run is on the order of thirty seconds on a PC 3 GHz.\n\n\nIn the Broyden step 0 of the first dataset, you will notice the WARNING:\n\n\n scprqt:  WARNING -\n  nstep=    6 was not enough SCF cycles to converge;\n  maximum force difference=  5.493E-05 exceeds toldff=  5.000E-05\n\n\n\n\n\nThe input variable \nnstep\n was intentionally set to the rather low value of\n6, to warn you about possible convergence difficulties. The SCF convergence\nmight indeed get more and more difficult with cell size. This is because the\ndefault preconditioner (see the notice of the input variable \ndielng\n) is\nnot very good for the metal+vacuum case.\n\nFor the interpretation of the present run, this is not critical, as the\nconvergence criterion was close of being fulfilled, but one should keep this\nin mind, as you will see \u2026\n\n\nFor the 2 vacuum layer case, one has the non-relaxed total energy:\n\n\n ETOT  6  -6.2539524271719\n\n\n\n\n\ngiving the unrelaxed surface energy\n\n\n  0.0200 Ha = 0.544 eV ;\n\n\n\n\n\nand for the relaxed case:\n\n\n           etotal1    -6.2547006435E+00\n\n\n\n\n\n(this one is converged to the required level) giving the relaxed surface\nenergy\n\n\n  0.0196 Ha = 0.533 eV\n\n\n\n\n\nNote that the difference between unrelaxed and relaxed case is a bit larger\nthan in the case of one vacuum layer. This is because there was some\ninteraction between slabs of different supercells.\n\n\nFor the 3 vacuum layer case, the self-consistency is slightly more difficult\nthan with 2 vacuum layers: the Broyden step 0 is not sufficiently converged\n(one might set nstep to a larger value, but the best is to change the\npreconditioner, as described below)\u2026\n\nHowever, for the Broyden steps number 2 and beyond, because one takes\nadvantage of the previous wavefunctions, a sufficient convergence is reached.\nThe total energy, in the relaxed case, is:\n\n\n           etotal2    -6.2559103620E+00\n\n\n\n\n\ngiving the relaxed surface energy \n0.0190 Ha = 0.515 eV\n There is a rather\nsmall 0.018 eV difference with the 2 vacuum layer case.\n\n\nFor the next run, we will keep the 2 vacuum layer case, and we know that the\naccuracy of the coming calculation cannot be better than 0.016 eV. One might\ninvestigate the 4 vacuum layer case, but this is not worth, in the present\ntutorial \u2026\n\n\n\n\n** 4.7. Determination of the surface energy: increasing the number of\n\u00b6\n\n\naluminum layers. **\n\n\nOne should now increase the number of aluminum layers, while keeping 2 vacuum\nlayers. We will consider 4 and 5 aluminum layers. This is rather\nstraightforward to set up, but will also change the preconditioner. One could\nuse an effective dielectric constant of about 3 or 5, with a rather small\nmixing coefficient, on the order of 0.2. However, there is also another\npossibility, using an estimation of the dielectric matrix governed by\n\niprcel\n=45 . For comparison with the previous treatment of SCF, one can\nrecompute the result with 3 aluminum layers.\n\n\nThe input file ~abinit/tests/tutorial/Input/tbase4_7.in is an example, while\n~abinit/tests/tutorial/Refs/tbase4_7.out is a reference output file. This run\nmight take about one minute, and is the longer of the four basic lessons. You\nshould start it now.\n\n\nYou can monitor its evolution by editing from time to time the tbase4_7_STATUS\nfile that the code updates regularly. The status file, that refer to the\nskeleton of the code, is described in the\n~abinit/doc/developers/programmer_guide.txt . You might take advantage of the\ntime of the run to explore the files contained in the ~abinit/doc/users\ndirectory and the ~abinit/doc/developers directory. The README files provided\ninteresting entry points in the documentation of the code.\n\n\nComing back to the file tbase4_7.out \u2026\n\nYou will notice that the SCF convergence is rather satisfactory, for all the\ncases (3, 4 or 5 metal layers).\n\n\nFor the 3 aluminum layer case, one has the non-relaxed total energy:\n\n\n ETOT  6  -6.2539524363433\n\n\n\n\n\n(this quantity is converged, unlike in test 4.6)\n\ngiving the unrelaxed surface energy 0.0200 Ha = 0.544 eV ; and for the relaxed\ncase:\n\n\n           etotal1    -6.2547008127E+00\n\n\n\n\n\n(by contrast the difference with test 4.6 is less than 1 microHa)\n\ngiving the relaxed surface energy 0.0196 Ha = 0.533 eV .\n\n\nFor the 4 aluminum layer case, one has the non-relaxed total energy:\n\n\n ETOT  6  -8.3546873357119\n\n\n\n\n\ngiving the unrelaxed surface energy 0.0186Ha = 0.506 eV ;\n\nand for the relaxed case:\n\n\n           etotal2    -8.3565593186E+00\n\n\n\n\n\ngiving the relaxed surface energy 0.0183 Ha = 0.498 eV .\n\n\nFor the 5 aluminum layer case, one has the non-relaxed total energy:\n\n\n ETOT  6  -10.453642176439\n\n\n\n\n\ngiving the unrelaxed surface energy 0.0183Ha = 0.498 eV ;\n\nand for the relaxed case:\n\n\n           etotal3    -1.0454163186E+01\n\n\n\n\n\ngiving the relaxed surface energy 0.0180 Ha = 0.490 eV .\n\n\nThe relative difference in the surface energy of the 4 and 5 layer cases is on\nthe order of 1.5%.\n\n\nIn the framework of this tutorial, we will not pursue this investigation,\nwhich is a simple application of the concepts already explored.\n\n\nJust for your information, and as an additional warning, when the work\naccomplished until now is completed with 6 and 7 layers without relaxation\n(see ~abinit/tests/tutorial/Input/tbase4_8.in and\n~abinit/tests/tutorial/Refs/tbase4_8.out where 5, 6 and 7 layers are treated),\nthis non-relaxed energy surface energy behaves as follows:  \n\n\nnumber of\n\naluminum layers\n\n\n|\n\n\nsurface energy  \n\n\n\u2014|\u2014  \n\n\n3\n\n\n|\n\n\n0.544 eV  \n\n\n4\n\n\n|\n\n\n0.506 eV  \n\n\n5\n\n\n|\n\n\n0.498 eV  \n\n\n6\n\n\n|\n\n\n0.449 eV  \n\n\n7\n\n\n|\n\n\n0.463 eV  \n\n\nSo, the surface energy convergence is rather difficult to reach.\n\nOur values, with a \n4x4x1\n grid, a smearing of 0.04 Ha, a kinetic energy cut-\noff of 6 Ha, the 13al.981214.fhi pseudopotential, still oscillate between 0.45\neV and 0.51 eV. Increasing the k point sampling might decrease slightly the\noscillations, but note that this effect is intrinsic to the computation of\nproperties of a metallic surface : the electrons are confined inside the slab\npotential, with subbands in the direction normal to the surface, and the Fermi\nenergy oscillates with the width of the slab. This effect might be understood\nbased on a comparison with the behaviour of a jellium slab.\n\nAn error on the order of 0.016 eV is due to the thin vacuum layer. Other\nsources of errors might have to be rechecked, seeing the kind of accuracy that\nis needed.\n\n\nExperimental data give a surface energy around 0.55 eV (sorry, the reference\nis to be provided).",
            "title": "Base4"
        },
        {
            "location": "/tutorials/base4/#41-computing-the-total-energy-and-lattice-parameters-of-aluminum-for",
            "text": "a fixed smearing and number of k points. **  _Before beginning, you might consider to work in a different subdirectory as\nfor lesson 1, 2 or 3 . Why not \u201cWork4\u201d ? _  The file ~abinit/tests/tutorial/Input/tbase4_x.files lists the file names and\nroot names. You can copy it in the Work4 directory (and change it, as usual).\nYou can also copy the file ~abinit/tests/tutorial/Input/tbase4_1.in in Work4.\nThis is your input file. You should edit it, read it carefully, and have a\nlook at the following \u201cnew\u201d input variables, and their explanation:   occopt    tsmear  \nNote also the following: \n1) You will work at fixed  ecut  (=6Ha). It is implicit that in \u201creal life\u201d,\nyou should do a convergence test with respect to  ecut  \u2026 Here, a suitable ecut  is given to you. It will allow to obtain 0.2% relative accuracy on\nlattice parameters. Note that this is the softer pseudopotential of those that\nwe have used until now: the 01h.pspgth for H needed 30 Ha (it was rather\nhard), the 14si.pspnc for Si needed 8 Ha. \n2) The input variable diemac has been suppressed. Aluminum is a metal, and the\ndefault is tailored for that case.   When you have read the input file, you can run the code, as usual (it will\ntake a few seconds). Then, read the output file quietly. \nYou should note that the Fermi energy and occupation numbers have been\ncomputed automatically:   Fermi (or HOMO) energy (hartree) =   0.26847   Average Vxc (hartree)=  -0.34746\n Eigenvalues (hartree) for nkpt=   2  k points:\n kpt#   1, nband=  3, wtk=  0.75000, kpt= -0.2500  0.5000  0.0000 (reduced coord)\n   0.09425   0.25438   0.41909\n      occupation numbers for kpt#   1\n   2.00003   1.33307   0.00014\n prteigrs : prtvol=0 or 1, do not print more k-points.  You should also note that the components of the total energy include an\nentropy term:   Components of total free energy (in Hartree):\n\n    Kinetic energy  =  8.70954971782498E-01\n    Hartree energy  =  3.84986358590396E-03\n    XC energy       = -8.08434339502224E-01\n    Ewald energy    = -2.72948286712169E+00\n    PspCore energy  =  3.78721653637092E-02\n    Loc. psp. energy=  8.26684645838168E-02\n    NL   psp  energy=  4.52588269933839E-01\n    >>>>> Internal E= -2.08998347137414E+00\n\n    -kT*entropy     = -7.99729047978171E-03\n    >>>>>>>>> Etotal= -2.09798076185393E+00\n\n Other information on the energy :\n    Total energy(eV)= -5.70889598417024E+01 ; Band energy (Ha)=   3.6059822203E-01",
            "title": "** 4.1. Computing the total energy and lattice parameters of aluminum for"
        },
        {
            "location": "/tutorials/base4/#42-the-convergence-study-with-respect-to-k-points",
            "text": "There is of course a convergence study associated to the sampling of the\nBrillouin zone. You should examine different grids, of increasing resolution.\nYou might try the following series of grids:    ngkpt1  2 2 2\n  ngkpt2  4 4 4\n  ngkpt3  6 6 6\n  ngkpt4  8 8 8  with the associated  nkpt :    nkpt1  2\n  nkpt2 10\n  nkpt3 28\n  nkpt4 60  The input file ~abinit/tests/tutorial/Input/tbase4_2.in is an example, while\n~abinit/tests/tutorial/Refs/tbase4_2.out is a reference output file. The run\nmight take about thirty seconds on a PC 3 GHz.  You will see that, FOR THE PARTICULAR VALUE OF  tsmear =0.05 Ha, the lattice\nparameter is already converged with  nkpt =10 :              acell1     7.5588968086E+00  7.5588968086E+00  7.5588968086E+00 Bohr\n            acell2     7.5070431499E+00  7.5070431499E+00  7.5070431499E+00 Bohr\n            acell3     7.5016877756E+00  7.5016877756E+00  7.5016877756E+00 Bohr\n            acell4     7.4992662653E+00  7.4992662653E+00  7.4992662653E+00 Bohr  Note that there is usually a STRONG cross-convergence effect between the\nnumber of k points and the value of the broadening,  tsmear . \nThe right procedure is: for each value of  tsmear , to get the convergence\nwith respect to the number of k points, then to compare the k-point converged\nvalues for different values of  tsmear .  In what follows, we will restrict ourselves to the grids with  nkpt =2, 10\nand 28.",
            "title": "4.2. The convergence study with respect to k points"
        },
        {
            "location": "/tutorials/base4/#43-the-convergence-study-with-respect-to-both-number-of-k-points-and",
            "text": "broadening factor (tsmear). **  The theoretical convergence rate for  tsmear  ending to 0, in the case of occopt =4, is quartic. This is obtained in the hypothesis of infinitely\ndense k point grid. We will check the evolution of  acell  as a function of tsmear , for the following values of  tsmear  : 0.01, 0.02, 0.03 and\n0.04. Use the double-loop capability of the multi-dataset mode, with the tsmear  changes in the INNER loop. This will saves CPU time, as the\nwavefunctions of the previous dataset will be excellent (no transfer to\ndifferent k points).  The input file ~abinit/tests/tutorial/Input/tbase4_3.in is an example, while\n~abinit/tests/tutorial/Refs/tbase4_3.out is a reference output file.  From the output file, here is the evolution of  acell  :              acell11    7.5587661702E+00  7.5587661702E+00  7.5587661702E+00 Bohr\n            acell12    7.5587696944E+00  7.5587696944E+00  7.5587696944E+00 Bohr\n            acell13    7.5587696871E+00  7.5587696871E+00  7.5587696871E+00 Bohr\n            acell14    7.5587710578E+00  7.5587710578E+00  7.5587710578E+00 Bohr\n            acell21    7.5055168997E+00  7.5055168997E+00  7.5055168997E+00 Bohr\n            acell22    7.5056781966E+00  7.5056781966E+00  7.5056781966E+00 Bohr\n            acell23    7.5018335937E+00  7.5018335937E+00  7.5018335937E+00 Bohr\n            acell24    7.5041510220E+00  7.5041510220E+00  7.5041510220E+00 Bohr\n            acell31    7.4963466654E+00  7.4963466654E+00  7.4963466654E+00 Bohr\n            acell32    7.4957099831E+00  7.4957099831E+00  7.4957099831E+00 Bohr\n            acell33    7.4969520318E+00  7.4969520318E+00  7.4969520318E+00 Bohr\n            acell34    7.4993529673E+00  7.4993529673E+00  7.4993529673E+00 Bohr  These data should be analyzed properly.  For  tsmear =0.01, the converged value, contained in acell31, must be\ncompared to acell11 and acell21: between acell21 and acell31, the difference\nis below 0.2%. acell31 can be considered to be converged with respect to the\nnumber of k-points, at fixed  tsmear . \nThis tsmear being the lowest one, it is usually the most difficult to\nconverge, and the values acell31,32,33 and 34 are indeed well-converged with\nrespect to the k-point number. \nThe use of the largest  [tsmear] , giving acell34, induces only a small\nerror in the lattice parameter. For that particular value of  tsmear , one\ncan use the second k-point grid, giving acell24.  So to  summarize : \nwe can choose to work with a 10 k-point grid in the irreducible Brillouin\nzone, and the associated  tsmear =0.04, with less than 0.1% error on the\nlattice parameter. \nNOTE that this error due to the Brillouin zone sampling could add to the error\ndue to the choice of  ecut  (that was mentioned previously to be on the\norder of 0.2%).  In what follows, we will stick to these values of  ecut  and  tsmear , and\ntry to use k-point grids with a similar resolution.  Our final value for the aluminum lattice parameter, in the LDA, using the\n13al.981214.fhi pseudopotential, is thus 7.5041 Bohr. Note: for historical\nreasons (consistency with older versions of the tutorial), we will work on the\nfollowing, with a slightly different value, of 7.5056 Bohr, that is 3.9718\nAngstrom. \nThe experimental value at 25 degree Celsius is 4.04958 Angstrom.  The associated total energy and accuracy can be deduced from             etotal11   -2.0916027819E+00\n           etotal12   -2.0931968906E+00\n           etotal13   -2.0947909992E+00\n           etotal14   -2.0963851177E+00\n           etotal21   -2.0969713557E+00\n           etotal22   -2.0975525285E+00\n           etotal23   -2.0978233733E+00\n           etotal24   -2.0979980153E+00\n           etotal31   -2.0983520905E+00\n           etotal32   -2.0983215368E+00\n           etotal33   -2.0983305960E+00\n           etotal34   -2.0984218116E+00  etotal 24 is -2.0979980153E+00 Ha, with an accuracy of 0.0005 Ha .",
            "title": "** 4.3. The convergence study with respect to both number of k points AND"
        },
        {
            "location": "/tutorials/base4/#44-determination-of-the-surface-energy-of-aluminum-100-changing",
            "text": "the orientation of the unit cell. **  In order to study the Aluminum (100) surface, we will have to set up a\nsupercell representing a slab. This supercell should be chosen as to be\ncompatible with the primitive surface unit cell. \nThe corresponding directions are  [-1 1 0]  and  [1 1 0] . The direction\nperpendicular to the surface is  [0 0 1] . There is no primitive cell of bulk\naluminum based on these vectors, but a doubled cell. We will first compute the\ntotal energy associated with this doubled cell. This is not strictly needed,\nbut it is a valuable intermediate step towards the study of the surface.  You might start from tbase4_3.in. \nYou have to change  rprim . Still, try to keep  acell  at the values of\nbulk aluminum that were determined previously. But it is not all: the most\ndifficult part in the passage to this doubled cell is the definition of the\nk-point grid. Of course, one could just take a homogeneous simple cubic grid\nof k points, but this will not correspond exactly to the k-point grid used in\nthe primitive cell in tbase4_3.in . This would not be a big problem, but you\nwould miss some error cancellation.  The answer to this problem is given in the input file\n~abinit/tests/tutorial/Input/tbase4_4.in. \nThe procedure to do the exact translation of the k-point grid will not be\nexplained here (sorry for this). If you do not see how to do it, just use\nhomogeneous simple cubic grids, with about the same resolution as for the\nprimitive cell case. There is a simple rule to estimate ROUGHLY whether two\ngrids for different cells have the same resolution: simply multiply the linear\ndimensions of the k-point grids, by the number of sublattices, by the number\nof atoms in the cell. For example, the corresponding product for the usual 10\nk-point grid is  4x4x4 x 4 x 1 = 256  . In the file tbase4_4.in, one has 4x4x4 x 2 x 2 = 256  . The grids of k points should not be too anisotropic\nfor this rough estimation to be valid.  Note also the input variables  rprim  and  chkprim  in this input file.  So, you run tbase4_4.in (only a few seconds, the reference file is\n~abinit/tests/tutorial/Refs/tbase4_4.out), and you find the following total\nenergy:             etotal     -4.1962972610E+00  It is not exactly twice the total energy for the primitive cell, mentioned\nabove, but the difference is less than 0.0005 Ha. It is due to the different\nFFT grids used in the two runs, and affect the exchange-correlation energy.\nThese grids are always homogeneous primitive 3D grids, so that changing the\norientation of the lattice will give mutually incompatible lattices.\nIncreasing the size of the FFT grid would improve the agreement.",
            "title": "** 4.4. Determination of the surface energy of aluminum (100): changing"
        },
        {
            "location": "/tutorials/base4/#45-determination-of-the-surface-energy-a-3-aluminum-layer-1",
            "text": "vacuum layer) slab calculation. **  We will first compute the total energy associated with only three layers of\naluminum, separated by only one layer of vacuum. This is kind of a minimal\nslab:   one surface layer   one \u201cbulk\u201d layer   one surface layer   one vacuum layer   \u2026 \nIt is convenient to take the vacuum region as having a multiple of the width\nof the aluminum layers, but this is not mandatory. The supercell to use is the\ndouble of the previous cell (that had two layers of Aluminum atoms along the [0 0 1]  direction). Of course, the relaxation of the surface might give an\nimportant contribution to the total energy.   You should start from tbase4_4.in . \nYou have to modify  rprim  (double the cell along  [0 0 1] ), the atomic\npositions, as well as the k point mesh. For the latter, it is supposed that\nthe electrons cannot propagate from one slab to its image in the  [0 0 1] \ndirection, so that the k_z component of the special k points can be taken 0:\nonly one layer of k points is needed along the z-direction. You should also\nallow the relaxation of atomic positions, but not the relaxation of lattice\nparameters (the lattice parameters along x or y must be considered fixed to\nthe bulk value, while, for the z direction, there is no interest to allow the\nvacuum region to collapse !  The input file ~abinit/tests/tutorial/Input/tbase4_5.in is an example, while\n~abinit/tests/tutorial/Refs/tbase4_5.out is a reference output file. The run\nmight last one minute.  The total energy after the first SCF cycle, when the atomic positions are\nequal to their starting values, is:   ETOT  6  -6.2619738807344  Note that the total energy of three aluminum atoms in the bulk, (from section\n4.3, etotal24 multiplied by three) is     -6.293994 Ha  so that the non-relaxed surface energy, per surface unit cell (there are two\nsurfaces in our simulation cell !) is    0.016010 Ha = 0.436 eV .  The total energy after the Broyden relaxation is:             etotal     -6.2622251508E+00  so that the relaxed surface energy, per surface unit cell is  0.015885 Ha = 0.432eV .  It seems that the relaxation energy is very small, compared to the surface\nenergy, but we need to do the convergence studies.",
            "title": "** 4.5. Determination of the surface energy : a (3 aluminum layer + 1"
        },
        {
            "location": "/tutorials/base4/#46-determination-of-the-surface-energy-increasing-the-number-of",
            "text": "vacuum layers. **  One should now increase the number of vacuum layers: 2 and 3 layers instead of\nonly 1. \nIt is preferable to define atomic positions in Cartesian coordinates. The same\ncoordinates will work for both 2 and 3 vacuum layers, while this is not the\ncase for reduced coordinates, as the cell size increases.  The input file ~abinit/tests/tutorial/Input/tbase4_6.in is an example input\nfile, while ~abinit/tests/tutorial/Refs/tbase4_6.out is a reference output\nfile. The run is on the order of thirty seconds on a PC 3 GHz.  In the Broyden step 0 of the first dataset, you will notice the WARNING:   scprqt:  WARNING -\n  nstep=    6 was not enough SCF cycles to converge;\n  maximum force difference=  5.493E-05 exceeds toldff=  5.000E-05  The input variable  nstep  was intentionally set to the rather low value of\n6, to warn you about possible convergence difficulties. The SCF convergence\nmight indeed get more and more difficult with cell size. This is because the\ndefault preconditioner (see the notice of the input variable  dielng ) is\nnot very good for the metal+vacuum case. \nFor the interpretation of the present run, this is not critical, as the\nconvergence criterion was close of being fulfilled, but one should keep this\nin mind, as you will see \u2026  For the 2 vacuum layer case, one has the non-relaxed total energy:   ETOT  6  -6.2539524271719  giving the unrelaxed surface energy    0.0200 Ha = 0.544 eV ;  and for the relaxed case:             etotal1    -6.2547006435E+00  (this one is converged to the required level) giving the relaxed surface\nenergy    0.0196 Ha = 0.533 eV  Note that the difference between unrelaxed and relaxed case is a bit larger\nthan in the case of one vacuum layer. This is because there was some\ninteraction between slabs of different supercells.  For the 3 vacuum layer case, the self-consistency is slightly more difficult\nthan with 2 vacuum layers: the Broyden step 0 is not sufficiently converged\n(one might set nstep to a larger value, but the best is to change the\npreconditioner, as described below)\u2026 \nHowever, for the Broyden steps number 2 and beyond, because one takes\nadvantage of the previous wavefunctions, a sufficient convergence is reached.\nThe total energy, in the relaxed case, is:             etotal2    -6.2559103620E+00  giving the relaxed surface energy  0.0190 Ha = 0.515 eV  There is a rather\nsmall 0.018 eV difference with the 2 vacuum layer case.  For the next run, we will keep the 2 vacuum layer case, and we know that the\naccuracy of the coming calculation cannot be better than 0.016 eV. One might\ninvestigate the 4 vacuum layer case, but this is not worth, in the present\ntutorial \u2026",
            "title": "** 4.6. Determination of the surface energy: increasing the number of"
        },
        {
            "location": "/tutorials/base4/#47-determination-of-the-surface-energy-increasing-the-number-of",
            "text": "aluminum layers. **  One should now increase the number of aluminum layers, while keeping 2 vacuum\nlayers. We will consider 4 and 5 aluminum layers. This is rather\nstraightforward to set up, but will also change the preconditioner. One could\nuse an effective dielectric constant of about 3 or 5, with a rather small\nmixing coefficient, on the order of 0.2. However, there is also another\npossibility, using an estimation of the dielectric matrix governed by iprcel =45 . For comparison with the previous treatment of SCF, one can\nrecompute the result with 3 aluminum layers.  The input file ~abinit/tests/tutorial/Input/tbase4_7.in is an example, while\n~abinit/tests/tutorial/Refs/tbase4_7.out is a reference output file. This run\nmight take about one minute, and is the longer of the four basic lessons. You\nshould start it now.  You can monitor its evolution by editing from time to time the tbase4_7_STATUS\nfile that the code updates regularly. The status file, that refer to the\nskeleton of the code, is described in the\n~abinit/doc/developers/programmer_guide.txt . You might take advantage of the\ntime of the run to explore the files contained in the ~abinit/doc/users\ndirectory and the ~abinit/doc/developers directory. The README files provided\ninteresting entry points in the documentation of the code.  Coming back to the file tbase4_7.out \u2026 \nYou will notice that the SCF convergence is rather satisfactory, for all the\ncases (3, 4 or 5 metal layers).  For the 3 aluminum layer case, one has the non-relaxed total energy:   ETOT  6  -6.2539524363433  (this quantity is converged, unlike in test 4.6) \ngiving the unrelaxed surface energy 0.0200 Ha = 0.544 eV ; and for the relaxed\ncase:             etotal1    -6.2547008127E+00  (by contrast the difference with test 4.6 is less than 1 microHa) \ngiving the relaxed surface energy 0.0196 Ha = 0.533 eV .  For the 4 aluminum layer case, one has the non-relaxed total energy:   ETOT  6  -8.3546873357119  giving the unrelaxed surface energy 0.0186Ha = 0.506 eV ; \nand for the relaxed case:             etotal2    -8.3565593186E+00  giving the relaxed surface energy 0.0183 Ha = 0.498 eV .  For the 5 aluminum layer case, one has the non-relaxed total energy:   ETOT  6  -10.453642176439  giving the unrelaxed surface energy 0.0183Ha = 0.498 eV ; \nand for the relaxed case:             etotal3    -1.0454163186E+01  giving the relaxed surface energy 0.0180 Ha = 0.490 eV .  The relative difference in the surface energy of the 4 and 5 layer cases is on\nthe order of 1.5%.  In the framework of this tutorial, we will not pursue this investigation,\nwhich is a simple application of the concepts already explored.  Just for your information, and as an additional warning, when the work\naccomplished until now is completed with 6 and 7 layers without relaxation\n(see ~abinit/tests/tutorial/Input/tbase4_8.in and\n~abinit/tests/tutorial/Refs/tbase4_8.out where 5, 6 and 7 layers are treated),\nthis non-relaxed energy surface energy behaves as follows:    number of \naluminum layers  |  surface energy    \u2014|\u2014    3  |  0.544 eV    4  |  0.506 eV    5  |  0.498 eV    6  |  0.449 eV    7  |  0.463 eV    So, the surface energy convergence is rather difficult to reach. \nOur values, with a  4x4x1  grid, a smearing of 0.04 Ha, a kinetic energy cut-\noff of 6 Ha, the 13al.981214.fhi pseudopotential, still oscillate between 0.45\neV and 0.51 eV. Increasing the k point sampling might decrease slightly the\noscillations, but note that this effect is intrinsic to the computation of\nproperties of a metallic surface : the electrons are confined inside the slab\npotential, with subbands in the direction normal to the surface, and the Fermi\nenergy oscillates with the width of the slab. This effect might be understood\nbased on a comparison with the behaviour of a jellium slab. \nAn error on the order of 0.016 eV is due to the thin vacuum layer. Other\nsources of errors might have to be rechecked, seeing the kind of accuracy that\nis needed.  Experimental data give a surface energy around 0.55 eV (sorry, the reference\nis to be provided).",
            "title": "** 4.7. Determination of the surface energy: increasing the number of"
        },
        {
            "location": "/tutorials/rf1/",
            "text": "This lesson aims at showing how to get the following physical properties, for\nan insulator :\n\n\n\n\nthe phonon frequencies and eigenvectors at Gamma \n\n\nthe dielectric constant \n\n\nthe Born effective charges \n\n\nthe LO-TO splitting \n\n\nthe phonon frequencies and eigenvectors at other q-points in the Brillouin Zone \nYou will learn to use of response-function features of ABINIT. In order to\nlearn the use of the associated codes Mrgddb and Anaddb, to produce\nefficiently phonon band structures and the associated thermodynamical\nproperties, please see the \n tutorial response-function 2\n.\n\n\n\n\nThis lesson should take about 2 hours.\n\n\n\n\n1 The ground-state geometry of AlAs.\n\n\n2 Frozen-phonon calculation of a second derivative of the total energy.\n\n\n3 Response-function calculation of a second derivative of the total energy.\n\n\n4 Response-function calculation of the dynamical matrix at Gamma.\n\n\n5 Response-function calculation of the effect of an homogeneous electric field.\n\n\n6 Response-function calculation of phonon frequencies at non-zero q.\n\n\n\n\n\n\n1. The ground-state geometry of AlAs.\n\u00b6\n\n\n\u00b6\n\n\n_Before beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not create \u201cWork_rf1\u201d in\n~abinit/tests/tutorespfn/Input ? _  \n\n\nNOTE : the reference directory that contains the example files for the\ntutorial is no more ~abinit/tests/tutorial (as for the basic lessons and the\nspecialized, non-response ones), but ~abinit/tests/tutorespfn . This will be\nthe case for all the response-function based part of the tutorial.\n\n\nThe file ~abinit/tests/tutorespfn/Input/trf1_x.files lists the file names and\nroot names. You can copy it in the Work_rf1 directory (and change it, as\nusual). Note that two pseudopotentials are mentioned in this \u201cfiles\u201d file: one\nfor the Aluminum atom, and one for the Arsenic atom. The first to be\nmentioned, for Al, will define the first type of atom. The second to be\nmentioned, for As, will define the second type of atom. It might the first\ntime that you encounter this situation (more than one type of atoms) in the\ntutorials, at variance with the four \u201cbasic\u201d lessons.\n\n\nYou can also copy the file ~abinit/tests/tutorespfn/Input/trf1_1.in in\nWork_rf1. This is your input file. You should edit it, and read it carefully.\n\n\nBecause of the use of two types of atoms, have a look at the following input\nvariables :\n\n\n\n\nntypat\n \n\n\ntypat\n \n\n\n\n\nNote that the value of \ntolvrs\n is rather stringent. This is because the\nwavefunctions determined by the present run will be used later as starting\npoint of the response-function calculation. However, the number of steps,\n\nnstep\n, in this example file has been set to 15, and you will see that this\nis not enough to reach the target \ntolvrs\n. In production runs, you should\nchoose a larger value of \nnstep\n, sufficient to reach your target\n\ntolvrs\n. In the present tutorial, due to portability concerns related to\nautomatic testing, we could not allow a larger \nnstep\n value. This minor\nproblem with some tutorial examples was mentioned briefly in \na side note to\nthe answer to question 1 of lesson 1\n. So, do not\nfollow blindly all examples in the tutorials : check by yourself the\nconvergence of your runs !\n\n\nYou will work at fixed \necut\n (=3Ha) and k-point grid, defined by\n\nkptrlatt\n (the 8x8x8 Monkhorst-Pack grid). It is implicit that in \u201creal\nlife\u201d, you should do a convergence test with respect to both convergence\nparameters. We postpone the discussion of the accuracy of these choices and\nthe choice of pseudopotential to the end of the fifth section of this\ntutorial. They give acceptable results, not very accurate, but, more\nimportant, the speed is reasonable for a tutorial.  \n\n\nYou should make the run (a few seconds), and obtain the following value for\nthe energy, in the final echo section :\n\n\n etotal   -9.7626837450E+00\n\n\n\n\n\nHowever, we will rely later on a more accurate (more digits) value of this\ntotal energy, that can be found about a dozen of lines before this final echo\n:\n\n\n    >>>>>>>>> Etotal= -9.76268374500280E+00\n\n\n\n\n\nThe output file also mentions that the forces on both atoms vanish.\n\n\nThe run that you just made will be considered as defining a ground-state\nconfiguration, on top of which response functions will be computed. The main\noutput of this ground-state run is the wavefunction file trf1_1o_WFK, that you\ncan already rename as trf1_1i_WFK. Indeed, it will be used in the next runs,\nas an input file. \nSo, in the corresponding \u201cfiles\u201d file for all the\nfollowing runs, at third line, pay attention TO KEEP \u201ctrf1_1i\u201d, even if you\nchange the root name for output files (fourth line) to \u201ctrf1_2o\u201d or \u201ctrf1_3o\u201d,\nas well as the first, second and fifth lines of this file.\n\n\n\n\n**2. Frozen-phonon calculation of a second derivative of the total\n\u00b6\n\n\nenergy.**\n\n\n\u00b6\n\n\nWe will now aim at computing the second derivative of the total energy with\nrespect to an atomic displacement by different means. For that purpose, you\nmust first read \nsections 0 and the first paragraph of section\n1\n of the respfn_help file\n(the auxiliary help file, that deals specifically with the response function\nfeatures).\n\n\nWe will explain later, in more detail, the signification of the different\ninput parameters introduced in section 1 of the respfn_help file.\n\n\nFor now, in order to be able to perform a direct comparison with the result of\na response-function calculation, we choose as a perturbation the displacement\nof the Al atom along the first axis of the reduced coordinates.\n\n\nYou can copy the file ~abinit/tests/tutorespfn/Input/trf1_2.in in Work_rf1.\nThis is your input file. You should edit it and briefly look at the two\nchanges with respect to the file ~abinit/tests/tutorespfn/Input/trf1_1.in :\nthe change of \nxred\n, and the reading of the wavefunction file, using the\n\nirdwfk\n input variable. Then, you can make the run. The symmetry is lowered\nwith respect to the ground-state geometry, so that the number of k-points\nincreases a lot, and of course, the CPU time.\n\n\nFrom this run, it is possible to get the values of the total energy, and the\nvalue of the gradient of the total energy (dE) with respect to change of\nreduced coordinate (dt):\n\n\n rms dE/dt=  3.5517E-03; max dE/dt=  5.0079E-03; dE/dt below (all hartree)\n    1       0.005007937776      0.002526310510      0.002526310510\n    2      -0.005007879256     -0.002526283046     -0.002526283046\n ...\n    >>>>>>>>> Etotal= -9.76268124105767E+00\n\n\n\n\n\nThe change of reduced coordinate of the Al atom along the first axis was\nrather small (1/1000), and we can make an estimate of the second derivative of\nthe total energy with respect to the reduced coordinate thanks to finite-\ndifference formulas.\n\n\nWe start first from the total-energy difference. The total energy is symmetric\nwith respect to that perturbation, so that it has no linear term. The\ndifference between the ground-state value (-9.76268374500280E+00 hartree) of\nthe previous run, and the perturbed value (-9.76268124105767E+00 hartree) of\nthe present one, is thus one half of the square of the coordinate change\n(1/1000) times the second derivative of total energy (2DTE). From these\nnumber, the 2DTE is 5.0078902589 hartree.\n\n\nAlternatively, we can start from the reduced gradients. The value of the\nreduced gradient with respect to a displacement of the Al atom along the first\nreduced axis is 0.005007937776 (hartree). At first order, this quantity is the\nproduct of the 2DTE by the reduced coordinate difference. The estimate of the\n2DTE is thus 5.007937776 hartree. The agreement with the other estimate is\nrather good (4.10^-5 Hartree).\n\n\nHowever, it is possible to do much better, thanks to the use of a higher-order\nfinite-difference formula. For this purpose, one can perform another\ncalculation, in which the change of reduced coordinate along the first axis is\n0.002, instead of 0.001. The doubling of the perturbation allows for a rather\nsimple higher-order estimation, as we will see later. The results of this\ncalculation are as follows :\n\n\n rms dE/dt=  7.1249E-03; max dE/dt=  1.0016E-02; dE/dt below (all hartree)\n    1       0.010016307568      0.005097516146      0.005097516146\n    2      -0.010016187598     -0.005097463261     -0.005097463261\n ...\n\n\n\n\n\nFrom these data, taking into account that the perturbation was twice stronger,\nthe same procedure as above leads to the values 5.00800219 hartree (from\nfinite difference of energy) and 5.008153784 hartree (from finite difference\nof forces, the value 0.010016307568 has to be multiplied by 1000/2). The\ncombination of these data with the previous estimate can be done thanks to an\nhigher-order finite-difference formula, in which the difference of estimations\n(the largest perturbation minus the smallest one) is divided by three, and\nthen subtracted from the smallest estimation. As far as the total-energy\nestimation is concerned, the difference is 0.00011194 Ha, which divided by\nthree, and subtracted from 5.00789025 hartree, gives 5.00785294 hartree. The\nsame higher-order procedure for force estimates gives 5.0078657 hartree. So,\nthe agreement between total-energy estimate and force estimate of the 2DTE can\nbe observed up to the 6th digit, inclusive.\n\n\nBefore comparing this result with the 2DTE directly computed from the\nresponse-function capabilities of ABINIT, a last comment is in order. One can\nobserve that the action-reaction law is fulfilled only approximately by the\nsystem. Indeed, the force created on the second atom, should be exactly equal\nin magnitude to the force on the first atom. The values of dE/dt, mentioned\nabove show a small, but non-negligible difference between the two atoms. As an\nexample, for the doubled perturbation, there is a difference in the absolute\nvalues of the first component of the reduced force, 0.010016307568 and\n-0.010016187598. Actually, the forces should cancel each other exactly if the\ntranslation symmetry were perfect. This is not the case, but the breaking of\nthis symmetry can be shown to arise \nonly\n from the presence of the\nexchange-correlation grid of points. This grid does not move when atoms are\ndisplaced, and so there is a very small variation of the total energy when the\nsystem is moved as a whole. It is easy to restore the action-reaction law, by\nsubtracting from every force component the mean of the forces on all atoms.\nThis is actually done when the gradient with respect to reduced coordinates\nare transformed into forces, and specified in cartesian coordinates, as can be\nseen in the output file for the small displacement :\n\n\n cartesian forces (hartree/bohr) at end:\n    1     -0.00001684560079    -0.00094403841497    -0.00094403841497\n    2      0.00001684560079     0.00094403841497     0.00094403841497\n\n\n\n\n\nThis effect will be seen also at the level of 2DTE. The so-called \u201cacoustic\nsum rule\u201d, imposing that the frequency of three modes (called acoustic modes)\ntend to zero with vanishing wavevector, will also be slightly broken. In this\ncase also, it will be rather easy to reimpose the acoustic sum rule. In any\ncase, taking a finer XC grid will allow one to reduce this effect.\n\n\n\n\n**3. Response-function calculation of a second derivative of the total\n\u00b6\n\n\nenergy.**\n\n\n\u00b6\n\n\nWe now compute the second derivative of the total energy with respect to the\nsame atomic displacement, using the response-function capabilities of ABINIT.\n\n\nYou can copy the file ~abinit/tests/tutorespfn/Input/trf1_3.in in Work_rf1.\nThis is your input file. You should examine it. The changes with respect to\nthe file ~abinit/tests/tutorespfn/Input/trf1_1.in are all gathered in the\nfirst part of this file, before\n\n\n#######################################################################\n#Common input variables\n\n\n\n\n\nAccordingly, you should get familiarized with the new input variables :\n\nrfphon\n, \nrfatpol\n, \nrfdir\n. Then, pay attention to the special use of\nthe \nkptopt\n input variable. It will be explained in more detail later.\n\n\nWhen you have understood the purpose of the input variable values specified\nbefore the \u201cCommon input variables\u201d section, you can make the code run.\n\n\nThen, we need to analyze the different output files. For that purpose, you\nshould read the content of the \n section\n6\n of the respfn_help file.\nRead it quickly, as we will come back to the most important points hereafter.\n\n\nABINIT has created four different files :\n\n\n\n\ntrf1_3.log (the log file) \n\n\ntrf1_3.out (the output file) \n\n\ntrf1_3o_1WF1 (the 1st-order wavefunction file) \n\n\ntrf1_3o_DDB (the derivative database) \n\n\n\n\nLet us have a look at the output file. You can follow the description provided\nin the \n section 6.2\n of the\nrespfn_help file. You should be able to find the place where the iterations\nfor the minimisation (with respect to the unique perturbation) take place :\n\n\n      iter   2DEtotal(Ha)       deltaE(Ha) residm    vres2\n-ETOT  1   6.5156050845578     -1.464E+01 1.146E-02 1.947E+02\n ETOT  2   5.0216332567384     -1.494E+00 9.267E-04 2.027E+00\n ETOT  3   5.0081675390166     -1.347E-02 5.325E-06 5.660E-02\n ETOT  4   5.0078655420156     -3.020E-04 1.601E-07 2.087E-03\n ETOT  5   5.0078558671678     -9.675E-06 5.588E-09 3.089E-05\n ETOT  6   5.0078557436628     -1.235E-07 9.879E-11 2.297E-07\n ETOT  7   5.0078557427888     -8.741E-10 8.545E-13 2.728E-09\n\n\n\n\n\nFrom these data, you can see that the 2DTE determined by the response-function\ntechnique is in excellent agreement with the higher-order finite-difference\nvalues for the 2DTE, determined in the previous section : 5.007855 hartree\nfrom the energy differences, and 5.007852 hartree from the force differences.\n\n\nNow, you can read the remaining of the \n section\n6.2\n of the respfn_help\nfile. Then, you should also edit the trf1_3o_DDB file, and read the\ncorresponding \n section 6.5\n\nof the respfn_help file.\n\n\nFinally, the excellent agreement between the finite-difference formula and the\nresponse-function approach calls for some accuracy considerations. These can\nbe found in \n section 7\n of\nthe respfn_help file.\n\n\n\n\n4. Response-function calculation of the dynamical matrix at Gamma.\n\u00b6\n\n\n\u00b6\n\n\nWe are now in the position to compute the full dynamical matrix at Gamma\n(q=0). You can copy the file ~abinit/tests/tutorespfn/Input/trf1_4.in in\nWork_rf1. This is your input file. You should edit it. As for test rf1_3, the\nchanges with respect to the file ~abinit/tests/tutorespfn/Input/trf1_1.in are\nall gathered in the first part of this file. Moreover, the changes with\nrespect to trf1_3.in concern only the input variables \nrfatpol\n, and\n\nrfdir\n. Namely, all the atoms will be displaced, in all the directions.\n\n\nThere are six perturbations to consider. So, one might think that the CPU time\nwill raise accordingly. This is not true, as ABINIT is able to determine which\nperturbations are the symmetric of another perturbation, see \n section\n3\n of the respfn_help file.\n\n\nNow, you can make the run. You edit the file trf1_4.out, and notice that the\nresponse to two perturbations were computed explicitly, while the response to\nthe other four could be deduced by using the symmetries.\n\n\n The list of irreducible perturbations for this q vector is:\n    1)    idir= 1    ipert=   1\n    2)    idir= 1    ipert=   2\n\n\n\n\n\nNothing mysterious : one of the two irreducible perturbations is for the Al\natom, placed in a rather symmetric local site, and the other perturbation is\nfor the As atom.\n\n\nThe phonon frequencies, obtained by diagonalizing the dynamical matrix (where\nthe atomic masses have been taken into account, see \namu\n), are given as\nfollows :\n\n\n  Phonon wavevector (reduced coordinates) :  0.00000  0.00000  0.00000\n Phonon energies in Hartree :\n   2.558878E-06  2.558879E-06  2.558880E-06  1.568559E-03  1.568559E-03\n   1.568559E-03\n Phonon frequencies in cm-1    :\n-  5.616089E-01  5.616089E-01  5.616092E-01  3.442590E+02  3.442590E+02\n-  3.442590E+02\n\n\n\n\n\nYou might wonder about the dash sign present in the first column of the two\nlines giving the frequencies in cm-1. The first column of the main ABINIT\noutput files is always dedicated to signs needed to automatically treat the\ncomparison with respect to reference files. Except if you become a ABINIT\ndeveloper, you should ignore these signs. In the present case, they should not\nbe interpreted as a minus sign for the floating numbers that follow them.\n\n\nThere is a good news about this result, and a bad news. The good news is that\nthere are indeed three acoustic modes, with frequency rather close to zero\n(less than 1 cm^-1, which is rather good !). The bad news comes when the three\nother frequencies are compared with experimental results, or other theoretical\nresults. Indeed, in the present run, one obtains three degenerate modes, while\nthere should be a (2+1) splitting. This can be seen in the paper  Ab initio\ncalculation of phonon dispersions in semiconductors, by P. Giannozzi, S. de\nGironcoli, P. Pavone and S. Baroni, Phys. Rev. B 43, 7231 (1991) , especially\nFig. 2.\n\n\nActually, we have forgotten to take into account the coupling between atomic\ndisplacements and the homogeneous electric field, that exists in the case of\npolar insulators, for so-called \u201cLongitudinal Optic (LO) modes\u201d. A splitting\nappears between these modes and the \u201cTransverse Optic (TO) modes\u201d. This\nsplitting (Lyddane-Sachs-Teller LO-TO splitting) is presented in simple terms\nin standard textbooks, and should not be forgotten in doing Ab initio\ncalculations of phonon frequencies.\n\n\nThus we have now to treat correctly the homogeneous electric field type\nperturbation.\n\n\n\n\n**5. Response-function calculation of the effect of an homogeneous\n\u00b6\n\n\nelectric field.**\n\n\n\u00b6\n\n\nThe treatment of the homogeneous electric field perturbation is formally much\nmore complex than the treatment of atomic displacements. This is primarily\nbecause the change of potential associated with an homogeneous electric field\nis not periodic, and thus does not satisfy the Born-von Karman periodic\nboundary conditions.\n\n\nFor the purpose of the present tutorial, one should read the section II.C of\nthe above-mentioned paper  P. Giannozzi, S. de Gironcoli, P. Pavone and S.\nBaroni, Phys. Rev. B 43, 7231 (1991) . The reader will find in  X. Gonze,\nPhys. Rev. B 55, 10337 (1997) and  X. Gonze and C. Lee, Phys. Rev. B 55, 10355\n(1997) more detailed information of this perturbation, closely related to the\nABINIT implementation. There is also an extensive discussion of the Born\neffective charges by  Ph. Ghosez, J.-P. Michenaud and X. Gonze, Phys. Rev. B\n58, 6224 (1998).\n\n\nIn order to compute the response of solids to an homogeneous electric field,\nas implemented in ABINIT, the remaining sections of the respfn_help file\nshould be read. These sections also present the information needed to compute\nphonons with non-zero q wavevector, which will be the subject of the next\nsection of the present tutorial. The sections to be read are :\n\n\n\n\nthe part of \nsection 1\n that had not yet been read \n\n\nsection 2\n\n\nsection 4\n\n\nand, for completeness,\nsection 5\n \n\n\n\n\nYou are now in the position to compute the full dynamical matrix at Gamma\n(q=0), including the coupling with an homogeneous electric field. You can copy\nthe file ~abinit/tests/tutorespfn/Input/trf1_5.in in Work_rf1. This is your\ninput file. You should edit it. As for the other RF tests, the changes with\nrespect to the file ~abinit/tests/tutorespfn/Input/trf1_1.in are all gathered\nin the first part of this file. Unlike the other tests, however, the multi-\ndataset mode was used, computing from scratch the ground-state properties,\nthen computing the effect of the ddk perturbation, then the effect of all\nother perturbations (electric field as well as atomic displacements).\n\n\nThe analysis of the output file is even more cumbersome than the previous\nones. Let us skip the first dataset. In the dataset 2 section, one\nperturbation is correctly selected :\n\n\n ==>  initialize data related to q vector <==\n\n The list of irreducible perturbations for this q vector is:\n    1)    idir= 1    ipert=   3\n\n================================================================================\n\n--------------------------------------------------------------------------------\n Perturbation wavevector (in red.coord.)   0.000000  0.000000  0.000000\n Perturbation : derivative vs k along direction   1\n\n\n\n\n\nThe analysis of the output for this particular perturbation is not\nparticularly interesting, except for the f-sum rule ratio\n\n\n loper3 : ek2=    1.6833336546E+01\n          f-sum rule ratio=    1.0028582975E+00\n\n\n\n\n\nthat should be close to 1, and becomes closer to it when \necut\n is\nincreased, and the sampling of k points is improved. (In the present status of\nABINIT, the f-rule ratio is not computed correctly when \necutsm\n/=0)\n\n\nIn the third dataset section, three irreducible perturbations are considered :\n\n\n ==>  initialize data related to q vector <==\n\n The list of irreducible perturbations for this q vector is:\n    1)    idir= 1    ipert=   1\n    2)    idir= 1    ipert=   2\n    3)    idir= 1    ipert=   4\n\n\n\n\n\nMuch later, the dielectric tensor is given :\n\n\n  Dielectric tensor, in cartesian coordinates,\n     j1       j2             matrix element\n  dir pert dir pert     real part    imaginary part\n\n   1    4   1    4    9.7606052146    -0.0000000000\n   1    4   2    4    0.0000000000    -0.0000000000\n   1    4   3    4    0.0000000000    -0.0000000000\n\n   2    4   1    4    0.0000000000    -0.0000000000\n   2    4   2    4    9.7606052146    -0.0000000000\n   2    4   3    4    0.0000000000    -0.0000000000\n\n   3    4   1    4    0.0000000000    -0.0000000000\n   3    4   2    4    0.0000000000    -0.0000000000\n   3    4   3    4    9.7606052146    -0.0000000000\n\n\n\n\n\nIt is diagonal and isotropic, and corresponds to a dielectric constant of\n9.7606052146.\n\n\nThen, the Born effective charges are given, either computed from the\nderivative of the wavefunctions with respect to the electric field, or\ncomputed from the derivative of the wavefunctions with respect to an atomic\ndisplacement, as explained in section II of X. Gonze, Phys. Rev. B55, 10355\n(1997) :\n\n\n  Effective charges, in cartesian coordinates,\n  (from electric field response)\n  ...\n\n\n\n\n\nand\n\n\n  Effective charges, in cartesian coordinates,\n  (from phonon response)\n  ...\n\n\n\n\n\nNamely, the Born effective charge of the Al atom is 2.104, and the one of the\nAs atom is -2.127 . The charge neutrality sum rule is not fulfilled exactly.\nWhen \necut\n is increased, and the sampling of k points is improved, the sum\nof the two charges goes closer to zero.\n\n\nFinally, the phonon frequencies are computed:\n\n\n  Phonon wavevector (reduced coordinates) :  0.00000  0.00000  0.00000\n Phonon energies in Hartree :\n   2.558878E-06  2.558879E-06  2.558880E-06  1.568559E-03  1.568559E-03\n   1.568559E-03\n Phonon frequencies in cm-1    :\n-  5.616089E-01  5.616089E-01  5.616092E-01  3.442590E+02  3.442590E+02\n-  3.442590E+02\n\n  Phonon at Gamma, with non-analyticity in the\n  direction (cartesian coordinates)  1.00000  0.00000  0.00000\n Phonon energies in Hartree :\n   2.558878E-06  2.558879E-06  4.068910E-06  1.568559E-03  1.568559E-03\n   1.729575E-03\n Phonon frequencies in cm-1    :\n-  5.616089E-01  5.616089E-01  8.930225E-01  3.442590E+02  3.442590E+02\n-  3.795979E+02\n\n  Phonon at Gamma, with non-analyticity in the\n  direction (cartesian coordinates)  0.00000  1.00000  0.00000\n Phonon energies in Hartree :\n   2.558878E-06  2.558880E-06  4.068909E-06  1.568559E-03  1.568559E-03\n   1.729575E-03\n Phonon frequencies in cm-1    :\n-  5.616089E-01  5.616092E-01  8.930223E-01  3.442590E+02  3.442590E+02\n-  3.795979E+02\n\n  Phonon at Gamma, with non-analyticity in the\n  direction (cartesian coordinates)  0.00000  0.00000  1.00000\n Phonon energies in Hartree :\n   2.558879E-06  2.558880E-06  4.068909E-06  1.568559E-03  1.568559E-03\n   1.729575E-03\n Phonon frequencies in cm-1    :\n-  5.616089E-01  5.616092E-01  8.930223E-01  3.442590E+02  3.442590E+02\n-  3.795979E+02\n\n\n\n\n\nThe first few lines discard any effect of the homogeneous electric field,\nwhile the next sections consider it along the three cartesian coordinates.\n\n\nIn the present material, the directionality of the electric field has no\ninfluence. We note that there are still three acoustic mode, below 1cm^-1,\nwhile the optic modes have the correct degeneracies : two TO modes at 344.3\ncm^-1, and one LO mode at 379.6 cm^-1 .\n\n\nThese values can be compared to experimental (361 cm^-1 , 402 cm^-1) as well\nas theoretical (363 cm^-1 , 400 cm^-1) values (again the Gianozzi et al paper\nmentioned above). Most of the discrepancy comes from the too low value of\n\necut\n. Using ABINIT with \necut\n=6 hartree gives (358.8 cm^-1 , 389.8\ncm^-1). The remaining of the discrepancy may come partly from the\npseudopotentials, that are particularly soft.\n\n\nThe comparison of Born effective charges is also interesting. After imposition\nof the neutrality sum rule, the Al Born effective charge is 2.116 . The value\nfrom Gianozzi et al is 2.17, the experimental value is 2.18. Increasing\n\necut\n to 6 hartree in ABINIT gives 2.168.\n\n\nFor the dielectric tensor, it is more delicate. The value from Gianozzi et al\nis 9.2, while the experimental value is 8.2 . The agreement is not very good,\na fact that can be attributed to the LDA lack of polarization-dependence ( X.\nGonze, Ph. Ghosez and R. Godby, Phys. Rev. Lett. (1995)). Still, the agreement\nof our calculation with the theoretical result is not very good. With\n\necut\n=3 hartree, we have 9.76. Changing it to 6 hartree gives 10.40 . A\nbetter k point sampling (8x8x8), with \necut\n=6 hartree, reduces the value to\n9.89 . Changing pseudopotentials finally improves the agreement : with the\nmuch harder 13al.pspgth and 33as.psphgh pseudopotentials with adequate\n\necut\n=16 hartree and 8x8x8 Monkhorst-Pack sampling, we reach a value of\n9.37 . This illustrates that the dielectric tensor is a much more sensitive\nquantity than the others.\n\n\n\n\n6. Response-function calculation of phonon frequencies at non-zero q.\n\u00b6\n\n\n\u00b6\n\n\nThe computation of phonon frequencies at non-zero q is actually simpler than\nthe one at Gamma. One must distinguish two cases. Either the q wavevector\nconnects k points that belong to the same grid, or the wavevector q is\ngeneral. In any case, the computation within the response-function formalism\nis more efficient than using the frozen-phonon technique: the use of supercell\nis completely avoided. For an explanation of this fact, see for example\nsection IV of X. Gonze, Phys. Rev. B55, 10337 (1997).\n\n\nYou can copy the file ~abinit/tests/tutorespfn/Input/trf1_6.in in Work_rf1.\nThis is your input file. You should edit it. As for the other RF tests, the\nchanges with respect to the file ~abinit/tests/tutorespfn/Input/trf1_1.in are\nall gathered in the first part of this file. The multi-dataset mode is used,\ncomputing from scratch the ground-state properties, then computing different\ndynamical matrices. The run is about 2 minutes on a 2.8 GHz machine. So, you\nwould better leave your computer running, and either read more of the ABINIT\ndocumentation (why not the\n\nmrgddb_help\n and the\n\nanaddb_help\n), or make a walk.\n\n\nThe results of this simulation can be compared to those provided in the\nGianozzi et al paper. The agreement is rather good, despite the low cut-off\nenergy, and different pseudopotentials.\n\n\nAt X, they get 95cm^-1, 216cm^-1, 337cm^-1 and 393cm^-1, while we get\n92.5cm^-1, 204.6cm^-1, 313.9cm^-1 and 375.9cm^-1. With \necut\n=6 hartree, we\nget 89.7cm^-1, 212.3cm^-1, 328.5cm^-1 and 385.8cm^-1.\n\n\nAt L, they get 71cm^-1, 212cm^-1, 352cm^-1 and 372cm^-1, while we get\n69.0cm^-1, 202.5cm^-1, 332.6cm^-1 and 352.3cm^-1. With \necut\n=6 hartree, we\nget 68.1cm^-1, 208.5cm^-1, 346.7cm^-1 and 362.6cm^-1.\n\n\nAt q=(0.1 0 0), we get 31.6cm^-1, 63.6cm^-1, 342.0cm^-1 and 379.7cm^-1. The\nacoustic modes tends (nearly-)linearly to zero, while the optic modes are\nclose to their values at Gamma : 344.3 cm^-1 and 379.6 cm^-1.\n\n\n\n\nThis ABINIT tutorial is now finished. You are advised to read now the \n second\ntutorial on response functions",
            "title": "RF1"
        },
        {
            "location": "/tutorials/rf1/#146-the-ground-state-geometry-of-alas",
            "text": "",
            "title": "1. The ground-state geometry of AlAs."
        },
        {
            "location": "/tutorials/rf1/#246-frozen-phonon-calculation-of-a-second-derivative-of-the-total",
            "text": "energy.**",
            "title": "**2. Frozen-phonon calculation of a second derivative of the total"
        },
        {
            "location": "/tutorials/rf1/#346-response-function-calculation-of-a-second-derivative-of-the-total",
            "text": "energy.**",
            "title": "**3. Response-function calculation of a second derivative of the total"
        },
        {
            "location": "/tutorials/rf1/#446-response-function-calculation-of-the-dynamical-matrix-at-gamma",
            "text": "",
            "title": "4. Response-function calculation of the dynamical matrix at Gamma."
        },
        {
            "location": "/tutorials/rf1/#546-response-function-calculation-of-the-effect-of-an-homogeneous",
            "text": "electric field.**",
            "title": "**5. Response-function calculation of the effect of an homogeneous"
        },
        {
            "location": "/tutorials/rf1/#646-response-function-calculation-of-phonon-frequencies-at-non-zero-q",
            "text": "",
            "title": "6. Response-function calculation of phonon frequencies at non-zero q."
        },
        {
            "location": "/tutorials/rf2/",
            "text": "This lesson aims at showing how to get the following physical properties, for\nperiodic solids :\n\n\n\n\nInteratomic forces constants \n\n\nPhonon band structures \n\n\nThermodynamical properties \n\n\n\n\nThis lesson should take about 1 hour.\n\n\n\n\n\n\n\n\nGeneration of a derivative database \n\n\n\n\n\n\n\n\n\n\nManipulation of the derivative databases (the MRGDDB utility) \n\n\n\n\n\n\n\n\n\n\nAnalysis of the derivative databases (the ANADDB utility) \n\n\n\n\n\n\n\n\n\n\nThe computation of interatomic force constants \n\n\n\n\n\n\n\n\n\n\nThe efficient computation of phonon band structures \n\n\n\n\n\n\n\n\n\n\nThermodynamical properties. \n\n\n\n\n\n\n\n\n\n\n 1. Generation of the derivative databases \n\u00b6\n\n\n_Before beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not create \u201cWork_rf2\u201d in\n~abinit/tests/tutorespfn/Input ? _\n\n\nThis tutorial starts by the generation of a database, that is quite time-\nconsuming. We suggest you to start immediately this computation\u2026\n\nCopy the files ~abinit/tests/tutorespfn/Input/trf2_1.files and\n~abinit/tests/tutorespfn/Input/trf2_1.in in \u201cWork_rf2\u201d .\n\n\nIssue now :\n\n\n\n\n_ abinit < trf2_1.files >& log &_\n\n\n\n\nIt takes about 15 minutes to be completed on a PC 2.8 GHz \u2026\n\n\nIn order to do interatomic force constant calculations, and to compute\nassociated phonon band structure and thermodynamical properties, you should\nfirst have some theoretical background.\n\nLet us assume that you have read the litterature relative to the \nfirst lesson\non response functions\n. You might find additional material,\nrelated to the present section, in the following references:  \n\n\nX. Gonze and C. Lee, Phys. Rev. B55, 10355 (1997), especially section IX\n\nC. Lee, X. Gonze, Phys. Rev. B 51, 8610 (1995)\n\nS. Baroni, S. de Gironcoli, A. Dal Corso, P. Giannozzi, Rev. Mod. Phys. 73,\n515 (2001).\n\n\nIf you haven\u2019t read parts of these references, you should take the time to get\nand read them now.\n\n\nIn short, the idea is that, in order to compute properties for which the\nphonon frequencies are needed in all the Brillouin zone, one can use an\nelaborate Fourier interpolation, so that only few dynamical matrices need to\nbe computed directly. Others will be computed by interpolation.\n\n\nLet us have a look at the input file trf2_1.in . The calculation is done for\nAlAs, the same crystalline material as for the previous lesson on response\nfunctions. Many input parameters are also quite similar, both at the level of\nthe description of the unit cell, as for the choice of cut-off energy and k\npoint grid.\n\n\nStill, this input file is rather complex : in one single run, one produces the\n(Derivative Databases) DDBs needed for the rest of this tutorial. So, it\nstarts with a ground-state calculation (dataset 1), followed by the\ncomputation of the response to the d/dk perturbation (dataset 2), and the\nresponse to electric fields, and phonons at Gamma (dataset 3). Datasets 4 to\n10 generate the dynamical matrices at 7 q wavevectors, other than Gamma. At\npresent (v4.6), one can only compute one q point per dataset, that is why so\nmany datasets are needed.\n\n\nAlso, the values of these q wavevectors are not determined automatically. They\nmust correspond to the q wavevectors needed by the ANADDB utility (see later),\nthat is, they should form a reduced set of symmetry-inequivalent wavevectors,\ncorresponding to a regularly spaced grid. In principle, they ought not include\nthe Gamma point, but it is recommended to have it in the set, in order for the\nFourier interpolation not to introduce errors at that important point. In\norder to minimize the number of preliminary non-self-consistent calculations,\nit is advised to take a q point mesh that is adjusted to the k point mesh used\nfor the electronic structure : all q wavevectors should connect two k point\nwavevectors from this grid.\n\n\nSuch a set of q wavevectors can be generated straightforwardly by running a GS\ncalculation with \nkptopt\n=1, \nnshiftk\n=1, \nshiftk\n=0 0 0 (to include\ngamma) and taking the output kpt set file as this qpt set. One might set\n\nnstep\n=1 and \nnline\n=1, so only one iteration runs.\n\nThe input file ~abinit/tests/tutorespfn/Input/trf2_2.in is precisely an input\nfile that can be used to generate such a set of k points. Copy it in the\npresent Work_rf2 directly, as well as the accompanying\n~abinit/tests/tutorespfn/Input/trf2_2.files. Examine these files, then run\nthis calculation (it is very rapid - it won\u2019t hurt the trf2_1 job). The\nfollowing k point set is obtained :\n\n\n       kpt    0.00000000E+00  0.00000000E+00  0.00000000E+00\n              2.50000000E-01  0.00000000E+00  0.00000000E+00\n              5.00000000E-01  0.00000000E+00  0.00000000E+00\n              2.50000000E-01  2.50000000E-01  0.00000000E+00\n              5.00000000E-01  2.50000000E-01  0.00000000E+00\n             -2.50000000E-01  2.50000000E-01  0.00000000E+00\n              5.00000000E-01  5.00000000E-01  0.00000000E+00\n             -2.50000000E-01  5.00000000E-01  2.50000000E-01\n\n\n\n\n\nIt is, as promised, the same as the q point set in the trf2_1.in file.\n\n\nNow, it might be worth to examine in some detail one of the Derivative\nDatabase that has been created by the trf2_1 run. We suppose that the file\ntrf2_1o_DS3_DDB has already been created. It corresponds to the third dataset,\nnamely the response to q=0 and electric field.\n\nEdit this file, and read the\n\n6.5\n section of the\nrespfn_help.html file. Examine the trf2_1o_DS3_DDB file carefully.\n\n\nSeven other similar files will be generated by the trf2_1 run, containing the\nsame header, but a different 2DTE block. It will be the duty of the MRGDDB\nutility, next section, to gather all these information.\n\n\nNow, there might be two possibilities : either the trf2_1 run is finished, and\nyou can continue the tutorial with the section 2 about the MRGDDB utility, or\nthe run is not finished.\n\nIn the latter case, instead of waiting for trf2_1 to be finished, we suggest\nyou to pursue with section 3. You will use as DDB file the one that can be\nfound in ~abinit/tests/tutorespfn/Refs, with the name trf2_3.ddb.out,\n[[tests/tutorespfn/Refs/trf2_3.ddb.out]], instead of the one that would result\nfrom the section 2. Copy this file to the present directory, then go to\nsection section 3 of this tutorial. You might come back to section 2\nafterwards.\n\n\n\n\n 2. Manipulation of the derivative databases (the MRGDDB utility) \n\u00b6\n\n\nThe use of the MRGDDB utility is described in its \nhelp\nfile\n. Please, read it carefully\nnow.\n\n\nUse MRGDDB to create the merge DDB from the eight DDB\u2019s corresponding to\ndatasets 3 to 10 of the trf2_1 job, containing the dynamical matrices for the\n8 q points, as well as the response to the electric field (dielectric tensor\nand Born effective charges). Including also the one from dataset 1 won\u2019t hurt\n(it contains the forces and stresses), but is not needed for the computation\nof phonon band structure, interatomic force constants, and thermodynamical\nproperties. Name the new DDB trf2_3.ddb.out .\n\n\nFile ~abinit/tests/tutorespfn/Input/trf2_3.in is an example of input file for\nMRGDDB. You can copy it in the Work_rf2 directory, and run the merge as\nfollows :\n\n\nmrgddb < trf2_3.in\n\n\n\n\n\nIt takes less than one second on a typical PC.\n\n\n\n\n 3. Analysis of the derivative databases (the ANADDB utility) \n\u00b6\n\n\nAn introduction to the use of the ANADDB utility is described in its \nhelp\nfile\n. Please, read it carefully\nnow.\n\n\nThis ANADDB utility is able to perform many different tasks, each governed by\na selected set of input variables, with also some input variables common to\nmany of the different tasks. The list of tasks to be done in one run is\ngoverned by different flags. Here is the list of flags :\n\n\n\n\ndieflag\n\n\nelaflag\n\n\nelphflag\n\n\nifcflag\n\n\ninstrflag\n\n\nnlflag\n\n\npiezoflag\n\n\npolflag\n\n\nthmflag\n\n\n\n\nPlease, take some time to read the description of each of these flags. Note\nthat some of these flags might be required to allow to run another task.\n\n\nIn this tutorial, we will focus on the flags\n\nifcflag\n and\n\nthmflag\n\n\n\n\n 4. The computation of interatomic force constants \n\u00b6\n\n\nYou can copy the files ~abinit/tests/tutorespfn/Input/trf2_4.in and\n~abinit/tests/tutorespfn/Input/trf2_4.files to the Work_rf2 directory.\n\nEdit the file trf2_4.in . Note that\n\nifcflag\n is activated.\nRelated input variables can be split in three groups.\n\n\nThe first group of variables define the grid of q wavevectors :\n\n\n\n\nbrav\n\n\nnqgpt\n\n\nnqshft\n\n\nq1shft\n\n\n\n\nUnfortunately, the names of input variables and their meaning is not exactly\nthe same as the names used to generate the k points in ABINIT. This is a\nshame, a remnant of history \u2026 Please read carefully the documentation that\ndescribes these input variables.\n\n\nThe second group of variables allows to impose some known constraint on the\ndynamical matrices and Born effective charges before proceeding with the\nanalysis :\n\n\n\n\nasr\n\n\nchneut\n\n\n\n\nPlease, read carefully the explanation for these input variables.\n\n\nFinally, a third group of variables is related specifically to the analysis of\nthe Interatomic Force Constants :\n\n\n\n\ndipdip\n\n\nifcana\n\n\nifcout\n\n\nnatifc\n\n\natifc\n\n\n\n\nHere also, spend some time to read the associated documentation.\n\n\nNow, you should issue :\n\n\nanaddb < trf2_4.files > trf2_4.log\n\n\n\n\n\nIt will last only a few seconds.\n\n\nThe file trf2_4.out contains the list of interatomic force constants, as well\nas some analysis. Edit this file.\n\nTry to find the following paragraph :\n\n\n Analysis of interatomic force constants\n\n Are given : column(1-3), the total force constant\n       then  column(4-6), the Ewald part\n       then  column(7-9), the short-range part\n Column 1, 4 and 7 are related to the displacement\n       of the generic atom along x,\n column 2, 5 and 8 are related to the displacement\n       of the generic atom along y,\n column 3, 6 and 9 are related to the displacement\n       of the generic atom along z.\n\n\n\n\n\nThe interatomic force constants are output for the nuclei specified by the\ninput variable \natifc\n.\nHere, only atom 1 is considered. The IFCs with respect to the other nuclei is\ngiven, by order of increasing distance. For each pair of nuclei involving atom\n1, there is first the output of the IFCs in cartesian coordinates, as well as\ntheir decomposition into an Ewald and a short-range part, then, the analysis\nwith respect to a local system of coordinate. The latter is chosen such as to\ndiagonalize the IFC tensor, in case of the self-force constant, and in the\nother cases, the first vector is the vector joining the two nuclei, in order\nto decompose the IFC into a longitudinal and a transverse component.\n\n\n\n\n 5. The efficient computation of phonon band structures \n\u00b6\n\n\nYou can copy the files ~abinit/tests/tutorespfn/Input/trf2_5.in and\n~abinit/tests/tutorespfn/Input/trf2_5.files to the Work_rf2 directory.\n\nEdit the file trf2_5.in . Note that\n\nifcflag\n is again\nactivated. Indeed, in order to compute a phonon band structure using the\nFourier interpolation, the IFCs are required. This is why the two first groups\nof variables, needed to generate the IFCs are still defined. The third group\nof variables is now restricted to\n\ndipdip\n only.\n\n\nThen, come the input variables needed to define the list of q wavevectors in\nthe band structure :\n\n\n\n\neivec\n: flag to turn on the analysis of phonon eigenvectors\n\n\nnph1l\n number of q-points for phonon interpolation\n\n\nqph1l\n list of q-points for phonon interpolation\n\n\nnph2l\n number of q-directions for LO-TO correction\n\n\nqph2l\n list of q-directions for LO-TO correction\n\n\n\n\nNow, you should issue :\n\n\nanaddb < trf2_5.files > trf2_5.log\n\n\n\n\n\nIt will last only a few seconds.\n\n\nThe file trf2_5.out contains the list of eigenvalues, for all the needed\nq-wavevectors. You can edit it, and have a look at the different sections of\nthe file. Note that the interatomic force constants are computed (they are\nneeded for the Fourier interpolation), but not printed.\n\n\nPlease, edit also the other output file, named trf2_5_B2EPS.freq . It contains\nthe frequencies, in a format suitable for graphical output, using the program\nband2eps (the latter should be more documented, and will not be described in\nthe present tutorial).\n\n\nYou can copy the files [[tests/tutorespfn/Input/trf2_6.in]] and\n[[tests/tutorespfn/Input/trf2_6.files]] to the Work_rf2 directory, then issue\n\n\nband2eps < trf2_6.files > trf2_6.log\n\n\n\n\n\nThe file trf2_6.out.eps has been produced. It is an .eps file (eps stand for\nEncapsulated PostScript). You can use the program ghostview to vizualize it.\nThe command to issue will depend on the way you have configured your machine,\nbut the following might perhaps do the work:\n\n\ngv trf2_6.out.eps\n\n\n\n\n\nYou should see a nice phonon band structure for AlAs. Well, not so nice, after\nall, because there are two strange dips for the highest phonon band, at the\nGamma point.\n\nThis is due to the lack of LO-TO splitting for the ANADDB treatment of the\nfirst list of vector. The correct phonon band structure is presented\n\nhere\n. You can correct the LO-TO\nsplitting by the following little hack.\n\n\nEdit the file trf2_5_B2EPS.freq, and note that the value of the frequency, in\nthe sixth column, has a discontinuity exactly for the Gamma point (the three\nfirst columns give the k point coordinates), that is, at lines 1 and 31 :\n\n\n 0.000000D+00  0.000000D+00  0.000000D+00  0.156855D-02  0.156855D-02  0.156855D-02\n\n\n\n\n\nReplace these values (sixth column, line 1 and 31) by the correct value,\nincluding the LO-TO splitting, that you can find in the file trf2_5.out, at\nthe end, second list of vector. That is, the lines 1 and 31 should now read :\n\n\n 0.000000D+00  0.000000D+00  0.000000D+00  0.156855D-02  0.156855D-02  1.730353E-03\n\n\n\n\n\nNow, run again band2eps. Your phonon band structure should be perfect !\n\n\nIt can be compared with the AlAs phonon band structure published by\n\nP. Giannozzi, S. de Gironcoli, P. Pavone, and S. Baroni, Phys. Rev. B 43, 7231\n(1991).\n\n\nOf course, one should make a convergence study, on the k and q point grids\n(separately !), as well as on the energy cut-off, and also test LDA and GGA\n\u2026 But this is left to the user !\n\n\n\n\n 6. Thermodynamical properties. \n\u00b6\n\n\nWe will give only a very short example of the use of ANADDB to compute\nthermodynamical properties. This is because this part of ANADDB is likely the\nfarthest from a clean, stable, usage. By exploring the input variables, the\nuser should be able to produce figures and data like the ones for SiO2 quartz\nand stishovite, published in\n\nC. Lee, X. Gonze, Phys. Rev. B 51, 8610 (1995)\n\n\nYou can copy the files ~abinit/tests/tutorespfn/Input/trf2_7.in and\n~abinit/tests/tutorespfn/Input/trf2_7.files to the Work_rf2 directory, and\nhave a look at them.\n\nThe same DDB as for trf2_4 and trf2_5 is used, namely trf2_3.ddb.out. The\nfollowing additional input variables are present :\n\n\n\n\nthmflag\n\n\nng2qpt\n\n\nngrids\n\n\nq2shft\n\n\nnchan\n\n\nnwchan\n\n\nthmtol\n\n\nntemper\n\n\ntemperinc\n\n\ntempermin\n\n\n\n\nExamine the input file, the input variables, then run anaddb (as usual \u2026).\nThen, edit the output file. You should be able to find the crucial section :\n\n\n# At  T     F(J/mol-c)     E(J/mol-c)     S(J/(mol-c.K)) C(J/(mol-c.K))\n# (A mol-c is the abbreviation of a mole-cell, that is, the\n#  number of Avogadro times the atoms in a unit cell)\n 2.000E+01  8.1384755E+03  8.1463588E+03  3.9416455E-01  1.4169104E+00\n 4.000E+01  8.1061318E+03  8.2368069E+03  3.2668770E+00  7.8985031E+00\n 6.000E+01  7.9980215E+03  8.4575659E+03  7.6590742E+00  1.3992228E+01\n 8.000E+01  7.7974375E+03  8.7915524E+03  1.2426436E+01  1.9325166E+01\n 1.000E+02  7.5004822E+03  9.2274431E+03  1.7269609E+01  2.4175006E+01\n 1.200E+02  7.1069991E+03  9.7544364E+03  2.2061978E+01  2.8411189E+01\n 1.400E+02  6.6189291E+03  1.0359248E+04  2.6716565E+01  3.1955267E+01\n 1.600E+02  6.0396227E+03  1.1028289E+04  3.1179167E+01  3.4847423E+01\n 1.800E+02  5.3732223E+03  1.1749439E+04  3.5423427E+01  3.7183864E+01\n 2.000E+02  4.6241910E+03  1.2512641E+04  3.9442251E+01  3.9069448E+01\n\n\n\n\n\nThere, one finds, the phonon free energy, the phonon internal energy, the\nphonon entropy and the phonon heat capacity.\n\n\nDo not forget that we are working in the harmonic approximation ; beyond some\ntemperature, anharmonic effects will have a sizeable contributions.\n\n\nThe atomic temperature factors can also be computed. An example is presented\nin tests/v5 , test 22 .",
            "title": "RF2"
        },
        {
            "location": "/tutorials/rf2/#146-generation-of-the-derivative-databases",
            "text": "_Before beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not create \u201cWork_rf2\u201d in\n~abinit/tests/tutorespfn/Input ? _  This tutorial starts by the generation of a database, that is quite time-\nconsuming. We suggest you to start immediately this computation\u2026 \nCopy the files ~abinit/tests/tutorespfn/Input/trf2_1.files and\n~abinit/tests/tutorespfn/Input/trf2_1.in in \u201cWork_rf2\u201d .  Issue now :   _ abinit < trf2_1.files >& log &_   It takes about 15 minutes to be completed on a PC 2.8 GHz \u2026  In order to do interatomic force constant calculations, and to compute\nassociated phonon band structure and thermodynamical properties, you should\nfirst have some theoretical background. \nLet us assume that you have read the litterature relative to the  first lesson\non response functions . You might find additional material,\nrelated to the present section, in the following references:    X. Gonze and C. Lee, Phys. Rev. B55, 10355 (1997), especially section IX \nC. Lee, X. Gonze, Phys. Rev. B 51, 8610 (1995) \nS. Baroni, S. de Gironcoli, A. Dal Corso, P. Giannozzi, Rev. Mod. Phys. 73,\n515 (2001).  If you haven\u2019t read parts of these references, you should take the time to get\nand read them now.  In short, the idea is that, in order to compute properties for which the\nphonon frequencies are needed in all the Brillouin zone, one can use an\nelaborate Fourier interpolation, so that only few dynamical matrices need to\nbe computed directly. Others will be computed by interpolation.  Let us have a look at the input file trf2_1.in . The calculation is done for\nAlAs, the same crystalline material as for the previous lesson on response\nfunctions. Many input parameters are also quite similar, both at the level of\nthe description of the unit cell, as for the choice of cut-off energy and k\npoint grid.  Still, this input file is rather complex : in one single run, one produces the\n(Derivative Databases) DDBs needed for the rest of this tutorial. So, it\nstarts with a ground-state calculation (dataset 1), followed by the\ncomputation of the response to the d/dk perturbation (dataset 2), and the\nresponse to electric fields, and phonons at Gamma (dataset 3). Datasets 4 to\n10 generate the dynamical matrices at 7 q wavevectors, other than Gamma. At\npresent (v4.6), one can only compute one q point per dataset, that is why so\nmany datasets are needed.  Also, the values of these q wavevectors are not determined automatically. They\nmust correspond to the q wavevectors needed by the ANADDB utility (see later),\nthat is, they should form a reduced set of symmetry-inequivalent wavevectors,\ncorresponding to a regularly spaced grid. In principle, they ought not include\nthe Gamma point, but it is recommended to have it in the set, in order for the\nFourier interpolation not to introduce errors at that important point. In\norder to minimize the number of preliminary non-self-consistent calculations,\nit is advised to take a q point mesh that is adjusted to the k point mesh used\nfor the electronic structure : all q wavevectors should connect two k point\nwavevectors from this grid.  Such a set of q wavevectors can be generated straightforwardly by running a GS\ncalculation with  kptopt =1,  nshiftk =1,  shiftk =0 0 0 (to include\ngamma) and taking the output kpt set file as this qpt set. One might set nstep =1 and  nline =1, so only one iteration runs. \nThe input file ~abinit/tests/tutorespfn/Input/trf2_2.in is precisely an input\nfile that can be used to generate such a set of k points. Copy it in the\npresent Work_rf2 directly, as well as the accompanying\n~abinit/tests/tutorespfn/Input/trf2_2.files. Examine these files, then run\nthis calculation (it is very rapid - it won\u2019t hurt the trf2_1 job). The\nfollowing k point set is obtained :         kpt    0.00000000E+00  0.00000000E+00  0.00000000E+00\n              2.50000000E-01  0.00000000E+00  0.00000000E+00\n              5.00000000E-01  0.00000000E+00  0.00000000E+00\n              2.50000000E-01  2.50000000E-01  0.00000000E+00\n              5.00000000E-01  2.50000000E-01  0.00000000E+00\n             -2.50000000E-01  2.50000000E-01  0.00000000E+00\n              5.00000000E-01  5.00000000E-01  0.00000000E+00\n             -2.50000000E-01  5.00000000E-01  2.50000000E-01  It is, as promised, the same as the q point set in the trf2_1.in file.  Now, it might be worth to examine in some detail one of the Derivative\nDatabase that has been created by the trf2_1 run. We suppose that the file\ntrf2_1o_DS3_DDB has already been created. It corresponds to the third dataset,\nnamely the response to q=0 and electric field. \nEdit this file, and read the 6.5  section of the\nrespfn_help.html file. Examine the trf2_1o_DS3_DDB file carefully.  Seven other similar files will be generated by the trf2_1 run, containing the\nsame header, but a different 2DTE block. It will be the duty of the MRGDDB\nutility, next section, to gather all these information.  Now, there might be two possibilities : either the trf2_1 run is finished, and\nyou can continue the tutorial with the section 2 about the MRGDDB utility, or\nthe run is not finished. \nIn the latter case, instead of waiting for trf2_1 to be finished, we suggest\nyou to pursue with section 3. You will use as DDB file the one that can be\nfound in ~abinit/tests/tutorespfn/Refs, with the name trf2_3.ddb.out,\n[[tests/tutorespfn/Refs/trf2_3.ddb.out]], instead of the one that would result\nfrom the section 2. Copy this file to the present directory, then go to\nsection section 3 of this tutorial. You might come back to section 2\nafterwards.",
            "title": "1. Generation of the derivative databases"
        },
        {
            "location": "/tutorials/rf2/#246-manipulation-of-the-derivative-databases-the-mrgddb-utility",
            "text": "The use of the MRGDDB utility is described in its  help\nfile . Please, read it carefully\nnow.  Use MRGDDB to create the merge DDB from the eight DDB\u2019s corresponding to\ndatasets 3 to 10 of the trf2_1 job, containing the dynamical matrices for the\n8 q points, as well as the response to the electric field (dielectric tensor\nand Born effective charges). Including also the one from dataset 1 won\u2019t hurt\n(it contains the forces and stresses), but is not needed for the computation\nof phonon band structure, interatomic force constants, and thermodynamical\nproperties. Name the new DDB trf2_3.ddb.out .  File ~abinit/tests/tutorespfn/Input/trf2_3.in is an example of input file for\nMRGDDB. You can copy it in the Work_rf2 directory, and run the merge as\nfollows :  mrgddb < trf2_3.in  It takes less than one second on a typical PC.",
            "title": "2. Manipulation of the derivative databases (the MRGDDB utility)"
        },
        {
            "location": "/tutorials/rf2/#346-analysis-of-the-derivative-databases-the-anaddb-utility",
            "text": "An introduction to the use of the ANADDB utility is described in its  help\nfile . Please, read it carefully\nnow.  This ANADDB utility is able to perform many different tasks, each governed by\na selected set of input variables, with also some input variables common to\nmany of the different tasks. The list of tasks to be done in one run is\ngoverned by different flags. Here is the list of flags :   dieflag  elaflag  elphflag  ifcflag  instrflag  nlflag  piezoflag  polflag  thmflag   Please, take some time to read the description of each of these flags. Note\nthat some of these flags might be required to allow to run another task.  In this tutorial, we will focus on the flags ifcflag  and thmflag",
            "title": "3. Analysis of the derivative databases (the ANADDB utility)"
        },
        {
            "location": "/tutorials/rf2/#446-the-computation-of-interatomic-force-constants",
            "text": "You can copy the files ~abinit/tests/tutorespfn/Input/trf2_4.in and\n~abinit/tests/tutorespfn/Input/trf2_4.files to the Work_rf2 directory. \nEdit the file trf2_4.in . Note that ifcflag  is activated.\nRelated input variables can be split in three groups.  The first group of variables define the grid of q wavevectors :   brav  nqgpt  nqshft  q1shft   Unfortunately, the names of input variables and their meaning is not exactly\nthe same as the names used to generate the k points in ABINIT. This is a\nshame, a remnant of history \u2026 Please read carefully the documentation that\ndescribes these input variables.  The second group of variables allows to impose some known constraint on the\ndynamical matrices and Born effective charges before proceeding with the\nanalysis :   asr  chneut   Please, read carefully the explanation for these input variables.  Finally, a third group of variables is related specifically to the analysis of\nthe Interatomic Force Constants :   dipdip  ifcana  ifcout  natifc  atifc   Here also, spend some time to read the associated documentation.  Now, you should issue :  anaddb < trf2_4.files > trf2_4.log  It will last only a few seconds.  The file trf2_4.out contains the list of interatomic force constants, as well\nas some analysis. Edit this file. \nTry to find the following paragraph :   Analysis of interatomic force constants\n\n Are given : column(1-3), the total force constant\n       then  column(4-6), the Ewald part\n       then  column(7-9), the short-range part\n Column 1, 4 and 7 are related to the displacement\n       of the generic atom along x,\n column 2, 5 and 8 are related to the displacement\n       of the generic atom along y,\n column 3, 6 and 9 are related to the displacement\n       of the generic atom along z.  The interatomic force constants are output for the nuclei specified by the\ninput variable  atifc .\nHere, only atom 1 is considered. The IFCs with respect to the other nuclei is\ngiven, by order of increasing distance. For each pair of nuclei involving atom\n1, there is first the output of the IFCs in cartesian coordinates, as well as\ntheir decomposition into an Ewald and a short-range part, then, the analysis\nwith respect to a local system of coordinate. The latter is chosen such as to\ndiagonalize the IFC tensor, in case of the self-force constant, and in the\nother cases, the first vector is the vector joining the two nuclei, in order\nto decompose the IFC into a longitudinal and a transverse component.",
            "title": "4. The computation of interatomic force constants"
        },
        {
            "location": "/tutorials/rf2/#546-the-efficient-computation-of-phonon-band-structures",
            "text": "You can copy the files ~abinit/tests/tutorespfn/Input/trf2_5.in and\n~abinit/tests/tutorespfn/Input/trf2_5.files to the Work_rf2 directory. \nEdit the file trf2_5.in . Note that ifcflag  is again\nactivated. Indeed, in order to compute a phonon band structure using the\nFourier interpolation, the IFCs are required. This is why the two first groups\nof variables, needed to generate the IFCs are still defined. The third group\nof variables is now restricted to dipdip  only.  Then, come the input variables needed to define the list of q wavevectors in\nthe band structure :   eivec : flag to turn on the analysis of phonon eigenvectors  nph1l  number of q-points for phonon interpolation  qph1l  list of q-points for phonon interpolation  nph2l  number of q-directions for LO-TO correction  qph2l  list of q-directions for LO-TO correction   Now, you should issue :  anaddb < trf2_5.files > trf2_5.log  It will last only a few seconds.  The file trf2_5.out contains the list of eigenvalues, for all the needed\nq-wavevectors. You can edit it, and have a look at the different sections of\nthe file. Note that the interatomic force constants are computed (they are\nneeded for the Fourier interpolation), but not printed.  Please, edit also the other output file, named trf2_5_B2EPS.freq . It contains\nthe frequencies, in a format suitable for graphical output, using the program\nband2eps (the latter should be more documented, and will not be described in\nthe present tutorial).  You can copy the files [[tests/tutorespfn/Input/trf2_6.in]] and\n[[tests/tutorespfn/Input/trf2_6.files]] to the Work_rf2 directory, then issue  band2eps < trf2_6.files > trf2_6.log  The file trf2_6.out.eps has been produced. It is an .eps file (eps stand for\nEncapsulated PostScript). You can use the program ghostview to vizualize it.\nThe command to issue will depend on the way you have configured your machine,\nbut the following might perhaps do the work:  gv trf2_6.out.eps  You should see a nice phonon band structure for AlAs. Well, not so nice, after\nall, because there are two strange dips for the highest phonon band, at the\nGamma point. \nThis is due to the lack of LO-TO splitting for the ANADDB treatment of the\nfirst list of vector. The correct phonon band structure is presented here . You can correct the LO-TO\nsplitting by the following little hack.  Edit the file trf2_5_B2EPS.freq, and note that the value of the frequency, in\nthe sixth column, has a discontinuity exactly for the Gamma point (the three\nfirst columns give the k point coordinates), that is, at lines 1 and 31 :   0.000000D+00  0.000000D+00  0.000000D+00  0.156855D-02  0.156855D-02  0.156855D-02  Replace these values (sixth column, line 1 and 31) by the correct value,\nincluding the LO-TO splitting, that you can find in the file trf2_5.out, at\nthe end, second list of vector. That is, the lines 1 and 31 should now read :   0.000000D+00  0.000000D+00  0.000000D+00  0.156855D-02  0.156855D-02  1.730353E-03  Now, run again band2eps. Your phonon band structure should be perfect !  It can be compared with the AlAs phonon band structure published by \nP. Giannozzi, S. de Gironcoli, P. Pavone, and S. Baroni, Phys. Rev. B 43, 7231\n(1991).  Of course, one should make a convergence study, on the k and q point grids\n(separately !), as well as on the energy cut-off, and also test LDA and GGA\n\u2026 But this is left to the user !",
            "title": "5. The efficient computation of phonon band structures"
        },
        {
            "location": "/tutorials/rf2/#646-thermodynamical-properties",
            "text": "We will give only a very short example of the use of ANADDB to compute\nthermodynamical properties. This is because this part of ANADDB is likely the\nfarthest from a clean, stable, usage. By exploring the input variables, the\nuser should be able to produce figures and data like the ones for SiO2 quartz\nand stishovite, published in \nC. Lee, X. Gonze, Phys. Rev. B 51, 8610 (1995)  You can copy the files ~abinit/tests/tutorespfn/Input/trf2_7.in and\n~abinit/tests/tutorespfn/Input/trf2_7.files to the Work_rf2 directory, and\nhave a look at them. \nThe same DDB as for trf2_4 and trf2_5 is used, namely trf2_3.ddb.out. The\nfollowing additional input variables are present :   thmflag  ng2qpt  ngrids  q2shft  nchan  nwchan  thmtol  ntemper  temperinc  tempermin   Examine the input file, the input variables, then run anaddb (as usual \u2026).\nThen, edit the output file. You should be able to find the crucial section :  # At  T     F(J/mol-c)     E(J/mol-c)     S(J/(mol-c.K)) C(J/(mol-c.K))\n# (A mol-c is the abbreviation of a mole-cell, that is, the\n#  number of Avogadro times the atoms in a unit cell)\n 2.000E+01  8.1384755E+03  8.1463588E+03  3.9416455E-01  1.4169104E+00\n 4.000E+01  8.1061318E+03  8.2368069E+03  3.2668770E+00  7.8985031E+00\n 6.000E+01  7.9980215E+03  8.4575659E+03  7.6590742E+00  1.3992228E+01\n 8.000E+01  7.7974375E+03  8.7915524E+03  1.2426436E+01  1.9325166E+01\n 1.000E+02  7.5004822E+03  9.2274431E+03  1.7269609E+01  2.4175006E+01\n 1.200E+02  7.1069991E+03  9.7544364E+03  2.2061978E+01  2.8411189E+01\n 1.400E+02  6.6189291E+03  1.0359248E+04  2.6716565E+01  3.1955267E+01\n 1.600E+02  6.0396227E+03  1.1028289E+04  3.1179167E+01  3.4847423E+01\n 1.800E+02  5.3732223E+03  1.1749439E+04  3.5423427E+01  3.7183864E+01\n 2.000E+02  4.6241910E+03  1.2512641E+04  3.9442251E+01  3.9069448E+01  There, one finds, the phonon free energy, the phonon internal energy, the\nphonon entropy and the phonon heat capacity.  Do not forget that we are working in the harmonic approximation ; beyond some\ntemperature, anharmonic effects will have a sizeable contributions.  The atomic temperature factors can also be computed. An example is presented\nin tests/v5 , test 22 .",
            "title": "6. Thermodynamical properties."
        },
        {
            "location": "/tutorials/elastic/",
            "text": "This lesson shows how to calculate physical properties related to strain, for\nan insulator and a metal :\n\n\n\n\nthe rigid-atom elastic tensor \n\n\nthe rigid-atom piezoelectric tensor (insulators only) \n\n\nthe internal strain tensor \n\n\nthe atomic relaxation corrections to the elastic and piezoelectric tensor \n\n\n\n\nYou should complete lessons \nRF1\n and \nRF2\n\nto introduce the response-function features of ABINIT before starting this\nlesson. You will learn to use additional response-function features of ABINIT,\nand to use relevant parts of the associated codes Mrgddb and Anaddb.\n\n\nThis lesson should take about two hours.\n\n\n\n\n1 The ground-state geometry of (hypothetical) wurtzite AlAs.\n\n\n2 Response-function calculation of several second derivatives of the total energy.\n\n\n3 anaddb calculation to incorporate atom-relaxation effects.\n\n\n4 Finite-difference calculation of elastic and piezoelectric constants.\n\n\n5 Alternative response-function calculation of some piezoelectric constants.\n\n\n6 Response-function calculation of the elastic constants for Al metal.\n\n\n\n\n\n\n1. The ground-state geometry of (hypothetical) wurtzite AlAs.\n\u00b6\n\n\n_Before beginning, you might consider working in a different subdirectory as\nfor the other lessons. Why not create \u201cWork_elast\u201d in\n~abinit/tests/tutorespfn/Input ? _  \n\n\nYou should copy the files ~abinit/tests/tutorespfn/Input/telast_1.files and\ntelast_1.in into Work_elast. You may wish to start the calculation (less than\none minute on a standard 3GHz machine) before you read the following. You\nshould open your input file telast_1.in with an editor and examine it as you\nread this discussion.\n\n\nThe hypothetical wurtzite structure for AlAs retains the tetrahedral\ncoordination of the atoms of the actual zincblende structure of AlAs, but has\na hexagonal lattice. It was chosen for this lesson because the atomic\npositions are not completely determined by symmetry. Both the atomic positions\nand the lattice constants should be optimized before beginning response-\nfunction calculations, especially those related to strain properties. While GS\nstructural optimization was treated in lessons 1-3, we are introducing a few\nnew features here, and you should look at the following new input variables\nwhich will be discussed below:  \n\n\n\n\n getxred\n\n\niatfix\n \n\n\n natfix\n\n\n strfact\n   \n\n\n\n\nThere are two datasets specified in telast_1.in. First, let us examine the\ncommon input data. We specify a starting guess for \n\nacell\n , and give an\naccurate decimal specification for \n\nrprim\n . The\ndefinition of the atom types and atoms follows \nlesson RF1\n .\nThe reduced atomic positions \n\nxred\n are a starting\napproximation, and will be replaced by our converged results in the remaining\ninput files, as will \n\nacell\n .\n\n\nWe will work with a fixed plane wave cutoff \n\necut\n (=6 Ha), but\nintroduce \n ecutsm\n\n(=0.5 Ha)as in \n lesson 3\n to smear the cutoff, which\nproduces smoothly varying stresses as the lattice parameters are optimized. We\nwill keep the same value of \n\necutsm\n for the\nresponse-function calculations as well, since changing it from the\noptimization run value could reintroduce non-zero forces and stresses. For the\nk-point grid, we must explicitly specify \n\nshiftk\n since the\ndefault value results in a grid shifted so as to break hexagonal symmetry. The\nRF strain calculations check this, and will exit with an error message if the\ngrid does not have the proper symmetry. The self-consistency procedures follow\n\nlesson RF1\n .\n\n\nDataset 1 optimizes the atomic positions keeping the lattice parameters fixed,\nsetting \n ionmov\n =2\nas in \nlesson 1\n . The optimization steps proceed until the\nmaximum force component on any atom is less than \n\ntolmxf\n . It is\nalways advised to relax the forces before beginning the lattice parameter\noptimization. Dataset 2 optimizes the lattice parameters with \n\noptcell\n =2 as in\n\nlesson 3\n . However, lesson 3 treated cubic Si, and the\natom positions in reduced coordinates remained fixed. In the present, more\ngeneral case, the reduced atomic coordinates must be reoptimized as the\nlattice parameters are optimized. Note that it is necessary to include \n\ngetxred\n = -1 so\nthat the second dataset is initialized with the relaxed coordinates .\nCoordinate and lattice parameter optimizations actually take place\nsimultaneously, with the computed stresses at each step acting as forces on\nthe lattice parameters. We have introduced \n\nstrfact\n which\nscales the stresses so that they may be compared with the same \n\ntolmxf\n convergence\ntest that is applied to the forces. The default value of 100 is probably a\ngood choice for many systems, but you should be aware of what is happening.\n\n\nFrom the hexagonal symmetry, we know that the positions of the atoms in the\na-b basal plane are fixed. However, a uniform translation along the c axis of\nall the atoms leaves the structure invariant. Only the relative displacement\nof the Al and As planes along the c axis is physically relevant. We will fix\nthe Al positions to be at reduced c-axis coordinates 0 and 1/2 (these are\nrelated by symmetry) by introducing \n\nnatfix\n and \n\niatfix\n to constrain\nthe structural optimization. This is really just for cosmetic purposes, since\nletting them all slide an arbitrary amount (as they otherwise would) won\u2019t\nchange any results. However, you probably wouldn\u2019t want to publish the results\nthat way, so we may as well develop good habits.  \n\n\nNow we shall examine the results of the structural optimization run. As\nalways, we should first examine the log file to make sure the run has\nterminated cleanly. There are a number of warnings, but none of them are\napparently serious. Next, let us edit the output file, telast_1.out. The first\nthing to look for is to see whether Abinit recognized the symmetry of the\nsystem. In setting up a new data file, it\u2019s easy to make mistakes, so this is\na valuable check. We see\n\n\nDATASET    1 : space group P6_3 m c (#186); Bravais hP (primitive hexag.)\n\n\n\n\n\nwhich is correct. Next, we confirm that the structural optimization converged.\nThe following lines from dataset 1 and dataset2 tell us that things are OK:\n\n\nAt Broyd/MD step   4, gradients are converged :\n max grad (force/stress) = 1.0670E-08 < tolmxf= 1.0000E-06 ha/bohr (free atoms)\n\nAt Broyd/MD step  11, gradients are converged :\n max grad (force/stress) = 7.8147E-08 < tolmxf= 1.0000E-06 ha/bohr (free atoms)\n\n\n\n\n\nWe can also confirm that the stresses are relaxed:\n\n\nCartesian components of stress tensor (hartree/bohr^3)\n sigma(1 1)= -3.76811543E-10  sigma(3 2)=  0.00000000E+00\n sigma(2 2)= -3.76811542E-10  sigma(3 1)=  0.00000000E+00\n sigma(3 3)=  7.81471561E-10  sigma(2 1)=  0.00000000E+00\n\n\n\n\n\nNow would be a good time to copy telast_2.in and telast_2.files into your\nworking directory, since we will use the present output to start the next run.\nLocate the optimized lattice parameters and reduced atomic coordinates near\nthe end of telast_1.out:\n\n\n     acell2   7.5389647789E+00  7.5389647789E+00  1.2277795511E+01 Bohr\n\n      xred2   3.3333333333E-01  6.6666666667E-01  0.0000000000E+00\n              6.6666666667E-01  3.3333333333E-01  5.0000000000E-01\n              3.3333333333E-01  6.6666666667E-01  3.7608587611E-01\n              6.6666666667E-01  3.3333333333E-01  8.7608587611E-01\n\n\n\n\n\nWith your editor, copy and paste these into telast_2.in at the indicated\nplaces in the \u201cCommon input data\u201d area. Be sure to change acell2 and xred2 to\nacell and xred since these common values will apply to all datasets in the\nnext set of calculations.  \n\n\n\n\n**2. Response-function calculations of several second derivatives of the\n\u00b6\n\n\ntotal energy.**\n\n\nWe will now compute second derivatives of the total energy (2DTE\u2019s) with\nrespect to all the perturbations we need to compute elastic and piezoelectric\nproperties. You may want to review \n sections 0 and the first paragraph of\nsection 1\n of the respfn_help\nfile which you studied in lesson RF1. We will introduce only one new input\nvariable for the strain perturbation,\n\n\n\n\nrfstrs\n   \n\n\n\n\nThe treatment of strain as a perturbation has some subtle aspects. It would be\na good idea to read  Metric tensor formulation of strain in density-functional\nperturbation theory, by D. R. Hamann, Xifan Wu, Karin M. Rabe, and David\nVanderbilt, \nPhys. Rev. B 71, 035117\n(2005)\n , especially Sec. II and\nSec. IV. We will do all the RF calculations you learned in lesson RF1 together\nwith strain, so you should review the variables\n\n\n\n\n rfphon\n\n\n rfatpol\n\n\n rfdir\n\n\nrfelfd\n   \n\n\n\n\nIt would be a good idea to copy telast_2.files into Work_elast and start the\ncalculation while you read (less than 2 minutes on a standard 3GHz machine).\nLook at telast_2.in in your editor to follow the discussion, and double check\nthat you have copied acell and xred as discussed in the last section.\n\n\nThis has been set up as a self-contained calculation with three datasets. The\nfirst is simply a GS run to obtain the GS wave functions we will need for the\nresponse function (RF) calculations. We have removed the convergence test from\nthe common input data to remind ourselves that different tests are needed for\ndifferent datasets. We set a tight limit on the convergence of the self-\nconsistent potential with \n\ntolvrs\n . Since we\nhave specified \n\nnband\n =8, all the\nbands are occupied and the potential test also assures us that all the wave\nfunctions are well converged. This issue will come up again in section 6 . We\ncould have used the output wave functions telast_1o_DS2_WFK as input for our\nRF calculations and skipped dataset 1, but redoing the GS calculation takes\nrelatively little time for this simple system .\n\n\nDataset 2 involves the calculation of the derivatives of the wave functions\nwith respect to the Brillouin-zone wave vector, the so-called ddk wave\nfunctions. Recall that these are auxiliary quantities needed to compute the\nresponse to the\n electric field perturbation\n and\nintroduced in lesson RF1 . It would be a good idea to review the relevant\nparts of \n section 1\n of the\nrespfn_help file. Examining this section of telast_2.in, note that electric\nfield as well as strain are uniform perturbations, only are defined for \n\nqpt\n = 0 0 0. \n\nrfelfd\n = 2 specifies\nthat we want the ddk calculation to be performed, which requires \n\niscf\n = -3. The ddk\nwave functions will be used to calculate both the piezoelectric tensor and the\nBorn effective charges, and in general we need them for \n k\n derivatives in\nall three (reduced) directions, \n\nrfdir\n = 1 1 1. Since\nthere is no potential self-consistency in the ddk calculations, we must\nspecify convergence in terms of the wave function residuals using \n\ntolwfr\n .  \n\n\nFinally, dataset 3 performs the actual calculations of the needed 2DTE\u2019s for\nthe elastic and piezoelectric tensors. Setting \n\nrfphon\n = 1 turns on\nthe atomic displacement perturbation, which we need for all atoms (\n\nrfatpol\n = 1 4) and\nall directions (\n\nrfdir\n = 1 1 1).\nAbinit will calculate first-order wave functions for each atom and direction\nin turn, and use those to calculate 2DTE\u2019s with respect to all pairs of atomic\ndisplacements and with respect to one atomic displacement and one component of\nelectric field. These quantities, the interatomic force constants (at gamma)\nand the Born effective charges will be used later to compute the atomic\nrelaxation contribution to the elastic and piezoelectric tensor.\n\n\nFirst-order wave functions for the strain perturbation are computed next.\nSetting \nrfstrs\n = 3 specifies that we want both uniaxial and shear strains\nto be treated, and \n\nrfdir\n = 1 1 1 cycles\nthrough strains xx, yy, and zz for uniaxial and yz, xz, and xy for shear. We\nnote that while other perturbations in Abinit are treated in reduced\ncoordinates, strain is better dealt with in Cartesian coordinates for reasons\ndiscussed in the reference cited above. These wave functions are used to\ncompute three types of 2DTE\u2019s. Derivatives with respect to two strain\ncomponents give us the so-called rigid-ion elastic tensor. Derivatives with\nrespect to one strain and one electric field component give us the rigid-ion\npiezoelectric tensor. Finally, derivatives with respect to one strain and one\natomic displacement yield the internal-strain force-response tensor, an\nintermediate quantity that will be necessary to compute the atomic relaxation\ncorrections to the rigid-ion quantities. As in lesson RF1, we specify\nconvergence in terms of the residual of the potential (here the first-order\npotential) using \n\ntolvrs\n .\n\n\nYour run should have completed by now. Abinit should have created quite a few\nfiles.\n\n\n\n\ntelast_2.log (log file)\n\n\ntelast_2.out (main output file)\n\n\ntelast_2o_DS1_DDB (first derivatives of the energy from GS calculation)\n\n\ntelast_2o_DS3_DDB (second derivatives from the RF calculation)\n\n\ntelast_2o_DS1_WFK (GS wave functions)\n\n\ntelast_2o_DS2_1WF* (ddk wave functions)\n\n\ntelast_2o_DS3_1WF* (RF first-order wave functions from various perturbations)\n\n\n\n\nThe log and out files are diagnostics and readable output information for a\nwide variety of properties. The derivative database DDB files are ascii and\nreadable, but primarily for subsequent analysis by anaddb which we will\nundertake in the next section. Finally, the various wave function binary files\nare primarily of use for subsequent calculations, where they could cut the\nnumber of needed iterations in, for example, convergence testing. We take note\nof a few conventions in the file names. The root output file name telast_2o is\nfrom the 4th line of the \u201cfiles\u201d file. The dataset producing the file is next.\nFinally, the first-order wave function 1WF files have a final \u201cpertcase\u201d\nnumber described in \n section\n1\n of the respfn_help file.\nWhile telast_2.in specifies all atomic displacements, only the symmetry-\ninequivalent perturbations are treated, so the \u201cpertcase\u201d list is incomplete.\nAll cases specified in the input data are treated for the strain perturbation.  \n\n\nFirst, take a look at the end of the telast_2.log file to make sure the run\nhas completed without error. You might wish to take a look at the WARNING\u2019s,\nbut they all appear to be harmless. Next, edit your telast_2.out file.\nSearching backwards for ETOT you will find\n\n\n     iter   2DEtotal(Ha)       deltaE(Ha) residm    vres2\n-ETOT  1   2.3955208361366     -6.519E+00 6.313E-01 4.126E+02\n ETOT  2   1.3040286462220     -1.091E+00 4.926E-04 4.735E+00\n ETOT  3   1.2898966738702     -1.413E-02 1.857E-05 3.504E-01\n ETOT  4   1.2891923712805     -7.043E-04 2.937E-07 8.931E-03\n ETOT  5   1.2891781500347     -1.422E-05 7.582E-09 5.989E-05\n ETOT  6   1.2891780804502     -6.958E-08 4.440E-11 7.674E-07\n ETOT  7   1.2891780792714     -1.179E-09 1.236E-12 2.972E-08\n ETOT  8   1.2891780791847     -8.667E-11 2.674E-14 7.671E-10\n ETOT  9   1.2891780791827     -2.006E-12 9.086E-16 4.128E-12\n\n At SCF step    9       vres2   =  4.13E-12 < tolvrs=  1.00E-10 =>converged.\n\n\n\n\n\nAbinit is solving a set of Schroedinger-like equations for the first-order\nwave functions, and these functions minimize a variational expression for the\n2DTE.  (Technically, they are called self-consistent Sternheimer equations.)\nThe  energy  convergence looks similar to that of GS calculations.  The fact\nthat vres2, the residual of the self-consistent first-order potential, has\nreached \n tolvrs\n\nwell within \nnstep\n (40) iterations indicates that the 2DTE calculation for\nthis perturbation (xy strain) has converged . It would pay to examine a few\nmore cases for different perturbations (unless you have looked through all the\nwarnings in the log).\n\n\nAnother convergence item to examine in your .out file is\n\n\n Seventeen components of 2nd-order total energy (hartree) are\n 1,2,3: 0th-order hamiltonian combined with 1st-order wavefunctions\n     kin0=   9.10477366E+00 eigvalue=   3.11026184E-01  local=  -3.66858410E+00\n 4,5,6,7: 1st-order hamiltonian combined with 1st and 0th-order wfs\n loc psp =  -8.91644855E+00  Hartree=   4.33575581E+00     xc=  -6.58530138E-01\n     kin1=  -8.62111363E+00\n 8,9,10: eventually, occupation + non-local contributions\n    edocc=   0.00000000E+00     enl0=   6.43290228E-01   enl1=  -1.55388963E-01\n 1-10 gives the relaxation energy (to be shifted if some occ is /=2.0)\n   erelax=  -7.62521951E+00\n 11,12,13 Non-relaxation  contributions : frozen-wavefunctions and Ewald\n  fr.hart=  -1.18530360E-01   fr.kin=   5.20015318E+00 fr.loc=   4.18792202E-01\n 14,15,16 Non-relaxation  contributions : frozen-wavefunctions and Ewald\n  fr.nonl=   2.94970622E-01    fr.xc=   9.41457939E-02  Ewald=   3.02486615E+00\n 17 Non-relaxation  contributions : pseudopotential core energy\n  pspcore=   0.00000000E+00\n Resulting in :\n 2DEtotal=    0.1289178079E+01 Ha. Also 2DEtotal=    0.350803195765E+02 eV\n    (2DErelax=   -7.6252195073E+00 Ha. 2DEnonrelax=    8.9143975865E+00 Ha)\n    (  non-var. 2DEtotal :    1.2891781360E+00 Ha)\n\n\n\n\n\nThis detailed breakdown of the contributions to 2DTE is probably of limited\ninterest, but you should compare \u201c2DEtotal\u201d and \u201cnon-var. 2DEtotal\u201d from the\nlast three lines. While the first-order wave function for the present\nperturbation minimizes a variational  expression for the second derivative\nwith respect to this perturbation as we just saw, the various 2DTE given as\nelastic tensors, etc. in the output and in the DDB file are all computed using\nnon-variational expressions.  Using the non-variational expressions, mixed\nsecond derivatives with respect to the present perturbation and all other\nperturbations of interest can be computed directly from the present first-\norder wave functions.   The disadvantage is that the non-variational result\nhas errors which are linearly proportional to convergence errors in the GS and\nfirst-order wave functions.  Since errors in the variational 2DEtotal are\nsecond-order in wave-function convergence errors, comparing this to the non-\nvariational result for the diagonal second derivative will give an idea of the\naccuracy of the latter and perhaps indicate the need for tighter convergence\ntolerances for both the GS and RF wave functions.  This is discussed in  X.\nGonze and C. Lee, Phys. Rev. B 55, 10355 (1997) , Sec. II.  For an atomic-\ndisplacement perturbation, the corresponding breakdown of the 2DTE is headed\n\u201cThirteen components.\u201d\n\n\nNow let us take a look at the results we want, the various 2DTE\u2019s. They begin\n\n\n ==> Compute Derivative Database <==\n\n  2nd-order matrix (non-cartesian coordinates, masses not included,\n   asr not included )\n  cartesian coordinates for strain terms (1/ucvol factor\n   for elastic tensor components not included)\n     j1       j2             matrix element\n  dir pert dir pert     real part     imaginary part\n\n   1    1   1    1         5.4508668454         0.0000000000\n   1    1   2    1        -2.7254334227         0.0000000000\n   1    1   3    1         0.0000000000         0.0000000000\n            .....\n\n\n\n\n\nThese are the \u201craw\u201d 2DTE\u2019s, in reduced coordinates for atom-displacement and\nelectric-field perturbations, but Cartesian coordinates for strain\nperturbations. This same results with the same organization appear in the file\ntelast_2_DS3_DDB which will be used later as input for automated analysis and\nconverted to more useful notation and units by anaddb. A breakout of various\ntypes of 2DTE\u2019s follows (all converted to Cartesian coordinates and in atomic\nunits):  \n\n\n  Dynamical matrix, in cartesian coordinates,\n    if specified in the inputs, asr has been imposed\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    1   1    1         0.0959051967         0.0000000000\n   1    1   2    1         0.0000000000         0.0000000000\n   1    1   3    1         0.0000000000         0.0000000000\n            .....\n\n\n\n\n\nThis contains the interatomic force constant data that will be used later to\ninclude atomic relaxation effects.  \u201casr\u201d refers to the acoustic sum rule,\nwhich basically is a way of making sure that forces sum to zero when an atom\nis displaced.\n\n\n  Effective charges, in cartesian coordinates,\n    (from phonon response)\n    if specified in the inputs, asr has been imposed\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    6   1    1         1.8290469443         0.0000000000\n   2    6   1    1         0.0000000000         0.0000000000\n   3    6   1    1         0.0000000000         0.0000000000\n            .....\n\n\n\n\n\nThe Born effective charges will be used to find the atomic relaxation\ncontributions of the piezoelectric tensor.\n\n\n  Rigid-atom elastic tensor , in cartesian coordinates,\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    7   1    7         0.0056418385         0.0000000000\n   1    7   2    7         0.0013753710         0.0000000000\n   1    7   3    7         0.0007168444         0.0000000000\n            .....\n\n\n\n\n\nThe rigid-atom elastic tensor is the 2DTE with respect to a pair of strains.\nWe recall that \u201cpert\u201d = natom+3 and natom+4 for unaxial and shear strains,\nrespectively.\n\n\n  Internal strain coupling parameters, in cartesian coordinates,\n    zero average net force deriv. has been imposed\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    1   1    7         0.1249319229         0.0000000000\n   1    1   2    7        -0.1249319273         0.0000000000\n   1    1   3    7         0.0000000000         0.0000000000\n            .....\n\n\n\n\n\nThese 2DTE\u2019s with respect to one strain and one atomic displacement are needed\nfor atomic relaxation corrections to both the elastic tensor and piezoelectric\ntensor. While this set of parameters is of limited direct interest, it should\nbe examined in cases when you think that high symmetry may eliminate the need\nfor these corrections. You are probably wrong, and any non-zero term indicates\na correction.\n\n\n  Rigid-atom proper piezoelectric tensor, in cartesian coordinates,\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    1   1    7         0.1249319273         0.0000000000\n\n   1    1   2    7        -0.1249319211         0.0000000000\n\n   1    1   3    7         0.0000000000         0.0000000000\n\n\n\n\n\nFinally, we have the piezoelectric tensor, the 2DTE with respect to one strain\nand one uniform electric field component.  (Yes, there are non-zero elements.)  \n\n\n\n\n3. anaddb calculation of atom-relaxation effects.\n\u00b6\n\n\nIn this section, we will run the program anaddb, which analyzes DDB files\ngenerated in prior RF calculations. You should copy telast_3.in and\ntelast_3.files in your Work_elast directory. You should now go to the \n anaddb\nhelp file\n , and read the short\nintroduction. The bulk of the material in this help file is contained in the\ndescription of the variables. You should read the descriptions of  \n\n\n\n\nelaflag\n\n\npiezoflag\n\n\n\n\ninstrflag\n   \n\n\n\n\n\n\nchneut\n\n\n\n\n\n\nFor the theory underlying the incorporation of atom-relaxation corrections, it\nis recommended you see  X. Wu, D. Vanderbilt, and D. R. Hamann, \nPhys. Rev, B\n72, 035105\n(2005)\n .  \n\n\nAnaddb can do lots of other things, such as calculate the frequency-dependent\ndielectric tensor, interpolate the phonon spectrum to make nice phonon\ndispersion plots, calculate Raman spectra, etc., but we are focusing on the\nminimum needed for the elastic and piezoelectric constants at zero electric\nfield.  \n\n\nWe also mention that \n mrgddb\n\nis another utility program that can be used to combine DDB files generated in\nseveral different datasets or in different runs into a single DDB file that\ncan be analyzed by anaddb. One particular usage would be to combine the DDB\nfile produced by the GS run, which contains first-derivative information such\nas stresses and forces with the RF DDB. It is anticipated that anaddb in a\nfuture release will implement the finite-stress corrections to the elastic\ntensor discussed in \n notes by A. R.\nOganov\n .  \n\n\nNow would be a good time to edit telast_3.in and observe that it is very\nsimple, consisting of nothing more than the four variables listed above set to\nappropriate values. The telast_3.files file is used with anaddb in the same\nmanner as the abinit .files you are by now used to. The first two lines\nspecify the .in and .out files, the third line specifies the DDB file, and the\nlast two lines are dummy names which would be used in connection with other\ncapabilities of anaddb. Now you should run the calculation, which is done in\nthe same way as you are now used to for abinit:  \n\n\n../../anaddb <telast_3.files >&telast_3.log  \n\n\nThis calculation should only take a few seconds. You should edit the log file,\ngo to the end, and make sure the calculation terminated without error. Next,\nexamine telast_3.out. After some header information, we come to tables giving\nthe \u201cforce-response\u201d and \u201cdisplacement-response\u201d internal strain tensors.\nThese represent, respectively, the force on each atom and the displacement of\neach atom in response to a unit strain of the specified type. These numbers\nare of limited interest to us, but represent important intermediate quantities\nin the treatment of atomic relaxation (see the X. Wu paper cited above).  \n\n\nNext, we come to the elastic tensor output:  \n\n\n Elastic Tensor(clamped ion)(unit:10^2GP):\n\n   1.6598859   0.4046480   0.2109029   0.0000000   0.0000000   0.0000000\n   0.4046480   1.6598859   0.2109029   0.0000000  -0.0000000   0.0000000\n   0.2109030   0.2109030   1.8258575   0.0000000  -0.0000000   0.0000000\n  -0.0000000  -0.0000000  -0.0000000   0.4081820  -0.0000000   0.0000000\n   0.0000000   0.0000000   0.0000000  -0.0000000   0.4081820  -0.0000000\n  -0.0000000  -0.0000000  -0.0000000   0.0000000  -0.0000000   0.6276190\n\n Elastic Tensor(relaxed ion)(unit:10^2GP):\n   (at fixed electric field boundary condition)\n\n   1.3526217   0.5445039   0.3805291  -0.0000000   0.0000000   0.0000000\n   0.5445039   1.3526217   0.3805292   0.0000000  -0.0000000   0.0000000\n   0.3805292   0.3805293   1.4821104   0.0000000  -0.0000000   0.0000000\n  -0.0000000   0.0000000   0.0000000   0.3055071  -0.0000000   0.0000000\n   0.0000000  -0.0000000  -0.0000000  -0.0000000   0.3055071   0.0000000\n  -0.0000000   0.0000000  -0.0000000   0.0000000   0.0000000   0.4040588\n\n\n\n\n\nWhile not labeled, the rows and columns 1-6 here represent xx, yy, zz, yz, xz,\nxy strains and stresses in the conventional Voigt notation.\n\nThe clamped-ion results were calculated in the telast_2 RF run, and are simply\nconverted to standard GPa units by anaddb (the terms \u201cclamped ion,\u201d \u201cclamped\natom,\u201d and \u201crigid atom\u201d used in various places are interchangeable, similarly\nfor \u201crelaxed.\u201d)\n\nThe relaxed-ion result was calculated by anaddb by combining 2DTE\u2019s for\ninternal strain and interatomic force constants which are stored in the input\nDDB file. Comparing the clamped and relaxed results, we see that all the\ndiagonal elastic constants have decreased in value.\n\nThis is plausible, since allowing the internal degrees of freedom to relax\nshould make a material less stiff. These tensors should be symmetric, and\ncertain tensor elements should be zero or identical by symmetry.\n\nIt\u2019s a good idea to check these properties against a standard text such as  J.\nF. Nye, Physical Properties of Crystals (Oxford U. P., Oxford 1985).\nDepartures from expected symmetries (there are a few in the last decimal place\nhere) are due to either convergence errors or, if large, incorrectly specified\ngeometry (however, see the final comments on symmetry  below).  \n\n\nNext in telast_3.out we find the piezoelectric tensor results:  \n\n\n Proper piezoelectric constants(clamped ion)(unit:c/m^2)\n\n      0.00000000      0.00000000      0.38490079\n      0.00000000      0.00000000      0.38490075\n      0.00000000      0.00000000     -0.73943025\n      0.00000000      0.43548797      0.00000000\n      0.43548796      0.00000000     -0.00000000<\n      0.00000000      0.00000000      0.00000001\n\n Proper piezoelectric constants(relaxed ion)(unit:c/m^2)\n\n      0.00000000     -0.00000000     -0.01187149\n     -0.00000000      0.00000000     -0.01187169\n     -0.00000000      0.00000000      0.06462779\n     -0.00000000     -0.04828847     -0.00000000\n     -0.04828832     -0.00000000      0.00000000\n\n\n\n\n\nThe 3 columns here represent x, y, and z electric polarization, and the 6 rows\nthe Voigt strains. The clamped-ion result was calculated in the telast_2 RF\nrun, and is simply scaled to conventional units by anaddb. The ion relaxation\ncontributions are based on 2DTE\u2019s for internal strain, interatomic force\nconstants, and Born effective charges, and typically constitute much larger\ncorrections to the piezoelectric tensor than to the elastic tensor. Once\nagain, symmetries should be checked. (The slight discrepancies seen here can\nbe removed by setting tolvrs3=1.0d-18 in telast_2.in.) One should be aware\nthat the piezoelectric tensor is identically zero in any material which has a\ncenter of symmetry.  \n\n\nSince we are dealing with a hypothetical material, there is no experimental\ndata with which to compare our results. In the next section, we will calculate\na few of these numbers by a finite-difference method to gain confidence in the\nRF approach.  \n\n\n\n\n**4. Finite-difference calculation of elastic and piezoelectric\n\u00b6\n\n\nconstants.**\n\n\nYou should copy telast_4.in and telast_4.files into your Work_elast directory.\nEditing telast_4.in, you will see that it has four datasets, the first two\nwith the c-axis contracted 0.01% and the second two with it expanded 0.01%,\nwhich we specified by changing the third row of \n\nrprim\n . The common\ndata is essentially the same as telast_2.in, and the relaxed \n\nacell\n values and \n\nxred\n from\ntelast_1.out have already been included. Datasets 1 and 3 do the self-\nconsistent convergence of the GS wave functions for the strained lattices and\ncompute the stress. Datasets 2 and 4 introduce a new variable.  \n\n\n\n\nberryopt\n \n\n\n\n\nElectric polarization in solids is a subtle topic which has only recently been\nrigorously resolved. It is now understood to be a bulk property, and to be\nquantitatively described by a Berry phase formulation introduced by R. D.\nKing-Smith and D. Vanderbilt, Phys. Ref. B 47, 1651(1993) . It can be\ncalculated in a GS calculation by integrating the gradient with respect to\n\nk\n of the GS wave functions over the Brillouin zone. In GS calculations,\nthe gradients are approximated by finite-difference expressions constructed\nfrom neighboring points in the \nk\n mesh. These are closely related to the\nddk wave functions used in RF calculations in  2 and introduced in \n lesson\nRF1, section 5\n . We will use \n\nberryopt\n = -1,\nwhich utilizes an improved coding of the calculation, and must specify\n\nrfdir\n = 1 1 1 so that the Cartesian components of the polarization are\ncomputed.  \n\n\nNow, run the telast_4 calculation, which should only take a minute or two, and\nedit telast_4.out. To calculate the elastic constants, we need to find the\nstresses  sigma(1 1) and sigma(3 3) . We see that each of the four datasets\nhave stress results, but that there are slight differences between those from,\nfor example dataset 1 and dataset 2, which should be identical. Despite our\ntight limit, this is still a convergence issue. Look at the following\nconvergence results,  \n\n\nDataset 1:\n At SCF step   13       vres2   =  6.24E-21 < tolvrs=  1.00E-18 =>converged.\n\nDataset 2:\n At SCF step    1       vres2   =  5.08E-21 < tolvrs=  1.00E-18 =>converged.\n\n\n\n\n\nSince dataset 2 has better convergence, we will use this and the dataset 4\nresults, choosing those in GPa units,\n\n\n- sigma(1 1)= -2.11918835E-03  sigma(3 2)=  0.00000000E+00\n- sigma(3 3)= -1.82392050E-02  sigma(2 1)=  0.00000000E+00\n\n- sigma(1 1)=  2.09886408E-03  sigma(3 2)=  0.00000000E+00\n- sigma(3 3)=  1.82778679E-02  sigma(2 1)=  0.00000000E+00\n\n\n\n\n\nLet us now compute the numerical derivative of  sigma(3 3)and compare to our\nRF result. Recalling that our dimensionless strains were \u00b10.0001, we find\n182.5853 GPa. This compares very well with the value  182.58575 GPa, the 3,3\nelement of the Rigid-ion elastic tensor we found from our anaddb calculation\nin  3 . (Recall that our strain and stress were both 3 3 or z z or Voigt 3.)\nSimilarly, the numerical derivative of  sigma(1 1)is 21.09026 GPa, compared to\n21.09029 GPa, the 3,1 elastic-tensor element.\n\n\nThe good agreement we found from this simple numerical differentiation\nrequired that we had accurately relaxed the lattice so that the stress of the\nunstrained structure was very small. Similar numerical-derivative comparisons\nfor systems with finite stress are more complicated, as discussed in \n notes\nby A. R. Oganov\n . Numerical-\nderivative comparisons for the relaxed-ion results are extremely challenging\nsince they require relaxing atomic forces to exceedingly small limits.\n\n\nNow let us examine the electric polarizations found in datasets 2 and 4,\nfocusing on the C/m^2 results,\n\n\n           Polarization    -1.578272218E-11 C/m^2\n           Polarization     1.578207434E-11 C/m^2\n           Polarization    -2.979936062E-01 C/m^2\n\n           Polarization    -1.577757536E-11 C/m^2\n           Polarization     1.577753205E-11 C/m^2\n           Polarization    -2.981427239E-01 C/m^2\n\n\n\n\n\nWhile not labeled as such, these are the Cartesian x, y, and z components,\nrespectively, and the x and y components are zero within numerical accuracy as\nthey must be from symmetry. Numerical differentiation of the z component\nyields -0.745589 C/m^2. This is to be compared with the z,3 element of our\nrigid-ion piezoelectric tensor from 3, -0.73943025 C/m^2, and the two results\ndo not compare as well as we might wish.\n\n\nWhat is wrong? There are two possibilities. The first is that the RF\ncalculation produces the proper piezoelectric tensor, while numerical\ndifferentiation of the polarization produces the improper piezoelectric\ntensor. This is a subtle point, for which you are referred to  D. Vanderbilt,\nJ. Phys. Chem. Solids 61, 147 (2000) . The improper-to-proper transformation\nonly effects certain tensor elements, however, and for our particular\ncombination of crystal symmetry and choice of strain there is no correction.\nThe second possibility is the subject of the next section.\n\n\n\n\n**5. Alternative response-function calculation of some piezoelectric\n\u00b6\n\n\nconstants.**\n\n\nOur GS calculation of the polarization in 4 used, in effect, a finite-\ndifference approximation to ddk wave functions, while our RF calculations in\n2 used analytic results based on the RF approach. Since the \n k\n grid\ndetermined by \n\nngkpt\n = 4 4 4 and \n\nnshiftk\n = 1 is\nrather coarse, this is a probable source of discrepancy. Since this issue was\nnoted previously in connection with the calculation of Born effective charges\nby Na Sai, K. M. Rabe, and D. Vanderbilt, Phys. Rev. B 66, 104108 (2002) ,\nAbinit has incorporated the ability to use finite-difference ddk wave\nfunctions from GS calculations in RF calculations of electric-field-related\n2DTE\u2019s. Copy telast_5.in and telast_5.files into Work_elast, and edit\ntelast_5.in.\n\n\nYou should compare this with our previous RF data, telast_2.in, and note that\ndataset1 and the Common data (after entering relaxed structural results) are\nessentially identical. Dataset 2 has been replaced by a non-self-consistent GS\ncalculation with \n\nberryopt\n = -2\nspecified to perform the finite-difference ddk wave function calculation. (The\nfinite-difference first-order wave functions are implicit but not actually\ncalculated in the GS polarization calculation.) We have restricted \n\nrfdir\n to 0 0 1 since\nwe are only interested in the 3,3 piezoelectric constant. Now compare dataset\n3 with that in telast_2.in. Can you figure out what we have dropped and why?\nRun the telast_5 calculation, which will only take about a minute with our\nsimplifications.\n\n\nNow edit telast_5.out, looking for the piezoelectric tensor,\n\n\n  Rigid-atom proper piezoelectric tensor, in cartesian coordinates,\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   3    6   3    7        -0.0130314050         0.0000000000\n\n\n\n\n\nWe immediately see a problem \u2013 this output, like most of the .out file, is in\natomic units, while we computed our numerical derivative in conventional C/m^2\nunits. While you might think to simply run anaddb to do the conversion as\nbefore, its present version is not happy with such an incomplete DDB file as\ntelast_5 has generated and will not produce the desired result. While it\nshould be left as an exercise to the student to dig the conversion factor out\nof the literature, or better yet out of the source code, we will cheat and\ntell you that 1a.u.=57.2147606 C/m^2 Thus the new RF result for the 3,3 rigid-\nion piezoelectric constant is -0.7455887 C/m^2 compared to the result found in\n4 by a completely-GS finite difference calculation, -0.745589 C/m^2. The\nagreement is now excellent!\n\n\nThe fully RF calculation in 2 in fact will converge much more rapidly with \n\nk\n sample than the partial-finite-difference method introduced here.  Is it\nworthwhile to have learned how to do this? We believe that is always pays to\nhave alternative ways to test results, and besides, this didn\u2019t take much\ntime. (Have you found the conversion factor on your own yet?)  \n\n\n\n\n**6. Response-function calculation of the elastic constants of Al\n\u00b6\n\n\nmetal.**\n\n\nFor metals, the existence of partially occupied bands is a complicating\nfeature for RF as well as GS calculations.  Now would be a good time to review\n\nlesson 4\n which dealt in detail with the interplay between\n\n k\n-sample convergence and Fermi-surface broadening, especially section \n\n4.3\n .  You should copy telast_6.in and telast_6.files\ninto Work_elast, and begin your run while you read on, since it involves a\nconvergence study with multiple datasets and may take about two minutes.  \n\n\nWhile the run is in progress, edit telast_6.in.  As in t43.in, we will set \n\nudtset\n to specify a\ndouble loop.  In the present case, however, the outer loop will be over 3\nsuccessively larger meshes of \nk\n points, while the inner loop will be\nsuccessively  \n\n\n\n\nGS self-consistent runs with optimization of acell.\n\n\nGS density-generating run for the next step.\n\n\nNon-self-consistent GS run to converge unoccupied or slightly-occupied bands.\n\n\nRF run for symmetry-inequivalent elastic constants.\n\n\n\n\nIn Section 1 , we did a separate GS structural optimization run and\ntransferred the results by hand to RF  run 2 .  Because we are doing a\nconvergence test here, we have combined these steps, and use \n\ngetcell\n to\ntransfer the optimized coordinates from the first dataset of the inner loop\nforward to the rest.  If we were doing a more complicated structure with\ninternal coordinates that were also optimized, we would need to use both this\nand \n getxred\n to\ntransfer these, as in telast_1.in.  \n\n\nThe specific data for inner-loop dataset 1 is very similar to that for\ntelast_1.in.  Inner-loop dataset 2 is a bit of a hack.  We need the density\nfor inner-loop dataset 3, and while we could set \n\nprtden\n = 1 in\ndataset 1, this would produce a separate density file for every step in the\nstructural optimization, and it isn\u2019t clear how to automatically pick out the\nlast one.  So, dataset 2 picks up the wave functions from dataset 1 (only one\nfile of these is produced, for the optimized structure), does one more\niteration with fixed geometry, and writes a density file.  \n\n\nInner-loop dataset 3 is a non-self-consistent run whose purpose is to ensure\nthat all the wave functions specified by \n\nnband\n are well\nconverged. For metals, we have to specify enough bands to make sure that the\nFermi surface is properly calculated.  Bands above the  Fermi level which have\nsmall occupancy or near-zero occupancy if their energies exceed the Fermi\nenergy by more than a few times\n\ntsmear\n , will have\nvery little effect on the self-consistent potential, so the \n\ntolvrs\n test in\ndataset 1 doesn\u2019t ensure their convergence.  Using \n\ntolwfr\n in inner-\nloop dataset 3 does.  Partially-occupied or unoccupied bands up to \n\nnband\n   play a\ndifferent role in constructing the first-order wave functions than do the many\nunoccupied bands beyond \n\nnband\n which aren\u2019t\nexplicitly treated in Abinit, as discussed in  S. de Gironcoli, Phys. Rev. B\n51, 6773 (1995).  By setting \n\nnband\n exactly equal\nto the number of occupied bands for RF calculations for semiconductors and\ninsulators, we avoid having to deal with the issue of converging unoccupied\nbands.  Could we avoid the extra steps by simply using \n\ntolwfr\n instead of \n\ntolvrs\n in dataset\n1?  Perhaps, but experience has shown that this does not necessarily lead to\nas well-converged a potential, and it is not recommended.  These same\nconsiderations apply to phonon calculations for metals, or in particular to \n\nqpt\n = 0 0 0 phonon\ncalculations for the interatomic force constants needed to find atom-\nrelaxation contributions to the elastic constants for non-trivial structures\nas in 2 and 3 .  \n\n\nThe data specific to the elastic-tensor RF calculation in inner-loop dataset 4\nshould by now be familiar.  We take advantage of the fact that for cubic\nsymmetry the only symmetry-inequivalent elastic constants are C 11, C 12 , and\nC 44 .  Abinit, unfortunately, does not do this analysis automatically, so we\nspecify \n rfdir\n =1 0\n0 to avoid duplicate calculations.  (Note that if atom relaxation is to be\ntaken into account  for a more complex structure, the full set of directions\nmust be used.)  \n\n\nWhen the telast_6 calculations finish, first look at telast_6.log as usual to\nmake sure they have run to completion without error.  Next, it would be a good\nidea to look at the band occupancies occ?? (where ?? is a dual-loop dataset\nindex) reported at the end (following  ==END DATASET(S)==).  The highest band,\nthe fourth in this case, should have zero or very small occupation, or you\nneed to increase \n\nnband\n or decrease \n\ntsmear\n .  Now, use\nyour newly perfected knowledge of the Abinit perturbation indexing conventions\nto scan through telast_6.out and find C 11 , C12 , and C 44 for each of the\nthree \nk\n-sample choices, which will be  under the \u201d Rigid-atom elastic\ntensor\u201d heading.  Also find the lattice constants for each case, whose\nconvergence you studied in lesson 4.  You should be able to cut-and-paste\nthese into a table like the following,  \n\n\n            C_11           C_12           C_44           acell\nngkpt=3*6   0.0037773556   0.0022583541   0.0013453692   7.5710952266\nngkpt=3*8   0.0042004431   0.0020423388   0.0013076763   7.5693986665\nngkpt=3*10  0.0042034396   0.0020343437   0.0012956768   7.5694820855\n\n\n\n\n\nWe can immediately see that the lattice constant converges considerably more\nrapidly with \nk\n sample than the elastic constants.  For \n\nngkpt\n =3\n6, acell is\nconverged to 0.02%, while the C\u2019s have 5-10% errors.  For \nngkpt\n =3\n8, the\nC\u2019s are converged to better than 1%, much better for the largest, C11, which\nshould be acceptable.\n\n\nAs in lesson 4, the \nngkpt\n convergence is controlled by \n\ntsmear\n .  The\nsmaller the broadening, the denser the \nk\n sample that is needed to get a\nsmooth variation of occupancy, and presumably stress, with strain.  While we\nwill not explore \n\ntsmear\n convergence\nin this lesson, you may wish to do so on your own.  We believe that the value\n\n tsmear\n = 0.02  in\ntelast_6.in gives results within 1% of the fully-converged small-broadening\nlimit.\n\n\nWe find that\n \n occopt\n \n*=3, standard Fermi-Dirac broadening\n*, gives _ much better_ convergence of the C\u2019s than \u201ccold smearing.\u201d\n  Changing \n occopt\n to 4 in telast_6.in, the option used in lesson 4, the C\u2019s show no sign of convergence.  At ngkpt=3*16, errors are still ~5%.  The reasons that this supposedly superior smoothing function performs so poorly in this context is a future research topic.  The main thing to be learned is that checking convergence with respect to all relevant parameters is \n always\n the user\u2019s responsibility.  Simple systems that include the main physical features of a complex system of interest will usually suffice for this testing.  Don\u2019t get caught publishing a result that another researcher refutes on convergence grounds, and don\u2019t blame such a mistake on Abinit!\n\n\nNow we make a comparison with experiment.  Converting the C\u2019s to standard\nunits (Ha/Bohr^3 = 2.94210119E+04 GPa) and using zero-temperature extrapolated\nexperimental results from P. M. Sutton, Phys. Rev. 91, 816 (1953), we find  \n\n\n                     C_11(GPa)  C_12(GPa)  C_44(GPa)\n     Calculated        123.7      59.9       38.1\n     Experiment (T=0)  123.0      70.8       30.9\n\n\n\n\n\nIs this good agreement?  There isn\u2019t much literature on DFT calculations of\nfull sets of elastic constants.  Many calculations of the bulk modulus\n(K=(C11+2C 12 )/3 in the cubic case) typically are within 10% of experiment\nfor the LDA.  Running telast_6 with ixc=11, the Perdew-Burke-Enzerhof GGA,\nincreases the calculated C\u2019s by 1-2%, and wouldn\u2019t be expected to make a large\ndifference for a nearly-free-electron metal.  \n\n\nComment on symmetry\n\u00b6\n\n\nIt is important to bear in mind that the way a tensor like the elastic tensor\nappears is a function of the frame used. Thus for the aluminum fcc case\nconsidered above, the nonzero elements are \nC11\n, \nC12\n, and \nC44\n, _ provided\nthat the crystal axes are aligned with the laboratory frame. _ For an\narbitrary alignment of the crystal axes, many more \nCij\n elements will be non-\nzero, and this can be confusing. It\u2019s easy to see why this happens if you\nimagine actually measuring the elastic tensor elements. If you start with the\nconventional cubic cell, and apply pressure to one face, you can measure\n\nC11\n. But if you turn the cell to some random angle, you\u2019ll measure a\nresponse that is a mixture of \nC11\n and \nC12\n. Within ABINIT, if the aluminum\nfcc cell is described using \nangdeg\n and\n\nacell\n, then an\naxis of the primitive cell will be aligned along the laboratory \nz\n axis but\nthis will not lead to a (conventional) cell alignment with the laboratory\nframe. The resulting elastic tensor will be correct but will appear to be more\ncomplicated than in the illustration above. It can be rotated back to a simple\nframe by hand (bearing in mind that all four indices of the fourth-rank\nelastic tensor have to be rotated!) but it\u2019s easier to start with a more\nconventional alignment of the unit cell. If you use a standard text like\nBradley and Cracknell, The Mathematical Theory of Symmetry in Solids, Oxford\nyou can find the standard primitive cell descriptions for the Bravais lattice\ntypes and these are aligned as much as possible with a standard laboratory\nframe.\n\n\n\n\nThis ABINIT lesson is now finished\u2026",
            "title": "Elastic"
        },
        {
            "location": "/tutorials/elastic/#146-the-ground-state-geometry-of-hypothetical-wurtzite-alas",
            "text": "_Before beginning, you might consider working in a different subdirectory as\nfor the other lessons. Why not create \u201cWork_elast\u201d in\n~abinit/tests/tutorespfn/Input ? _    You should copy the files ~abinit/tests/tutorespfn/Input/telast_1.files and\ntelast_1.in into Work_elast. You may wish to start the calculation (less than\none minute on a standard 3GHz machine) before you read the following. You\nshould open your input file telast_1.in with an editor and examine it as you\nread this discussion.  The hypothetical wurtzite structure for AlAs retains the tetrahedral\ncoordination of the atoms of the actual zincblende structure of AlAs, but has\na hexagonal lattice. It was chosen for this lesson because the atomic\npositions are not completely determined by symmetry. Both the atomic positions\nand the lattice constants should be optimized before beginning response-\nfunction calculations, especially those related to strain properties. While GS\nstructural optimization was treated in lessons 1-3, we are introducing a few\nnew features here, and you should look at the following new input variables\nwhich will be discussed below:      getxred  iatfix     natfix   strfact       There are two datasets specified in telast_1.in. First, let us examine the\ncommon input data. We specify a starting guess for  \nacell  , and give an\naccurate decimal specification for  \nrprim  . The\ndefinition of the atom types and atoms follows  lesson RF1  .\nThe reduced atomic positions  \nxred  are a starting\napproximation, and will be replaced by our converged results in the remaining\ninput files, as will  \nacell  .  We will work with a fixed plane wave cutoff  \necut  (=6 Ha), but\nintroduce   ecutsm \n(=0.5 Ha)as in   lesson 3  to smear the cutoff, which\nproduces smoothly varying stresses as the lattice parameters are optimized. We\nwill keep the same value of  \necutsm  for the\nresponse-function calculations as well, since changing it from the\noptimization run value could reintroduce non-zero forces and stresses. For the\nk-point grid, we must explicitly specify  \nshiftk  since the\ndefault value results in a grid shifted so as to break hexagonal symmetry. The\nRF strain calculations check this, and will exit with an error message if the\ngrid does not have the proper symmetry. The self-consistency procedures follow lesson RF1  .  Dataset 1 optimizes the atomic positions keeping the lattice parameters fixed,\nsetting   ionmov  =2\nas in  lesson 1  . The optimization steps proceed until the\nmaximum force component on any atom is less than  \ntolmxf  . It is\nalways advised to relax the forces before beginning the lattice parameter\noptimization. Dataset 2 optimizes the lattice parameters with  \noptcell  =2 as in lesson 3  . However, lesson 3 treated cubic Si, and the\natom positions in reduced coordinates remained fixed. In the present, more\ngeneral case, the reduced atomic coordinates must be reoptimized as the\nlattice parameters are optimized. Note that it is necessary to include  \ngetxred  = -1 so\nthat the second dataset is initialized with the relaxed coordinates .\nCoordinate and lattice parameter optimizations actually take place\nsimultaneously, with the computed stresses at each step acting as forces on\nthe lattice parameters. We have introduced  \nstrfact  which\nscales the stresses so that they may be compared with the same  \ntolmxf  convergence\ntest that is applied to the forces. The default value of 100 is probably a\ngood choice for many systems, but you should be aware of what is happening.  From the hexagonal symmetry, we know that the positions of the atoms in the\na-b basal plane are fixed. However, a uniform translation along the c axis of\nall the atoms leaves the structure invariant. Only the relative displacement\nof the Al and As planes along the c axis is physically relevant. We will fix\nthe Al positions to be at reduced c-axis coordinates 0 and 1/2 (these are\nrelated by symmetry) by introducing  \nnatfix  and  \niatfix  to constrain\nthe structural optimization. This is really just for cosmetic purposes, since\nletting them all slide an arbitrary amount (as they otherwise would) won\u2019t\nchange any results. However, you probably wouldn\u2019t want to publish the results\nthat way, so we may as well develop good habits.    Now we shall examine the results of the structural optimization run. As\nalways, we should first examine the log file to make sure the run has\nterminated cleanly. There are a number of warnings, but none of them are\napparently serious. Next, let us edit the output file, telast_1.out. The first\nthing to look for is to see whether Abinit recognized the symmetry of the\nsystem. In setting up a new data file, it\u2019s easy to make mistakes, so this is\na valuable check. We see  DATASET    1 : space group P6_3 m c (#186); Bravais hP (primitive hexag.)  which is correct. Next, we confirm that the structural optimization converged.\nThe following lines from dataset 1 and dataset2 tell us that things are OK:  At Broyd/MD step   4, gradients are converged :\n max grad (force/stress) = 1.0670E-08 < tolmxf= 1.0000E-06 ha/bohr (free atoms)\n\nAt Broyd/MD step  11, gradients are converged :\n max grad (force/stress) = 7.8147E-08 < tolmxf= 1.0000E-06 ha/bohr (free atoms)  We can also confirm that the stresses are relaxed:  Cartesian components of stress tensor (hartree/bohr^3)\n sigma(1 1)= -3.76811543E-10  sigma(3 2)=  0.00000000E+00\n sigma(2 2)= -3.76811542E-10  sigma(3 1)=  0.00000000E+00\n sigma(3 3)=  7.81471561E-10  sigma(2 1)=  0.00000000E+00  Now would be a good time to copy telast_2.in and telast_2.files into your\nworking directory, since we will use the present output to start the next run.\nLocate the optimized lattice parameters and reduced atomic coordinates near\nthe end of telast_1.out:       acell2   7.5389647789E+00  7.5389647789E+00  1.2277795511E+01 Bohr\n\n      xred2   3.3333333333E-01  6.6666666667E-01  0.0000000000E+00\n              6.6666666667E-01  3.3333333333E-01  5.0000000000E-01\n              3.3333333333E-01  6.6666666667E-01  3.7608587611E-01\n              6.6666666667E-01  3.3333333333E-01  8.7608587611E-01  With your editor, copy and paste these into telast_2.in at the indicated\nplaces in the \u201cCommon input data\u201d area. Be sure to change acell2 and xred2 to\nacell and xred since these common values will apply to all datasets in the\nnext set of calculations.",
            "title": "1. The ground-state geometry of (hypothetical) wurtzite AlAs."
        },
        {
            "location": "/tutorials/elastic/#246-response-function-calculations-of-several-second-derivatives-of-the",
            "text": "total energy.**  We will now compute second derivatives of the total energy (2DTE\u2019s) with\nrespect to all the perturbations we need to compute elastic and piezoelectric\nproperties. You may want to review   sections 0 and the first paragraph of\nsection 1  of the respfn_help\nfile which you studied in lesson RF1. We will introduce only one new input\nvariable for the strain perturbation,   rfstrs       The treatment of strain as a perturbation has some subtle aspects. It would be\na good idea to read  Metric tensor formulation of strain in density-functional\nperturbation theory, by D. R. Hamann, Xifan Wu, Karin M. Rabe, and David\nVanderbilt,  Phys. Rev. B 71, 035117\n(2005)  , especially Sec. II and\nSec. IV. We will do all the RF calculations you learned in lesson RF1 together\nwith strain, so you should review the variables    rfphon   rfatpol   rfdir  rfelfd       It would be a good idea to copy telast_2.files into Work_elast and start the\ncalculation while you read (less than 2 minutes on a standard 3GHz machine).\nLook at telast_2.in in your editor to follow the discussion, and double check\nthat you have copied acell and xred as discussed in the last section.  This has been set up as a self-contained calculation with three datasets. The\nfirst is simply a GS run to obtain the GS wave functions we will need for the\nresponse function (RF) calculations. We have removed the convergence test from\nthe common input data to remind ourselves that different tests are needed for\ndifferent datasets. We set a tight limit on the convergence of the self-\nconsistent potential with  \ntolvrs  . Since we\nhave specified  \nnband  =8, all the\nbands are occupied and the potential test also assures us that all the wave\nfunctions are well converged. This issue will come up again in section 6 . We\ncould have used the output wave functions telast_1o_DS2_WFK as input for our\nRF calculations and skipped dataset 1, but redoing the GS calculation takes\nrelatively little time for this simple system .  Dataset 2 involves the calculation of the derivatives of the wave functions\nwith respect to the Brillouin-zone wave vector, the so-called ddk wave\nfunctions. Recall that these are auxiliary quantities needed to compute the\nresponse to the  electric field perturbation  and\nintroduced in lesson RF1 . It would be a good idea to review the relevant\nparts of   section 1  of the\nrespfn_help file. Examining this section of telast_2.in, note that electric\nfield as well as strain are uniform perturbations, only are defined for  \nqpt  = 0 0 0.  \nrfelfd  = 2 specifies\nthat we want the ddk calculation to be performed, which requires  \niscf  = -3. The ddk\nwave functions will be used to calculate both the piezoelectric tensor and the\nBorn effective charges, and in general we need them for   k  derivatives in\nall three (reduced) directions,  \nrfdir  = 1 1 1. Since\nthere is no potential self-consistency in the ddk calculations, we must\nspecify convergence in terms of the wave function residuals using  \ntolwfr  .    Finally, dataset 3 performs the actual calculations of the needed 2DTE\u2019s for\nthe elastic and piezoelectric tensors. Setting  \nrfphon  = 1 turns on\nthe atomic displacement perturbation, which we need for all atoms ( \nrfatpol  = 1 4) and\nall directions ( \nrfdir  = 1 1 1).\nAbinit will calculate first-order wave functions for each atom and direction\nin turn, and use those to calculate 2DTE\u2019s with respect to all pairs of atomic\ndisplacements and with respect to one atomic displacement and one component of\nelectric field. These quantities, the interatomic force constants (at gamma)\nand the Born effective charges will be used later to compute the atomic\nrelaxation contribution to the elastic and piezoelectric tensor.  First-order wave functions for the strain perturbation are computed next.\nSetting  rfstrs  = 3 specifies that we want both uniaxial and shear strains\nto be treated, and  \nrfdir  = 1 1 1 cycles\nthrough strains xx, yy, and zz for uniaxial and yz, xz, and xy for shear. We\nnote that while other perturbations in Abinit are treated in reduced\ncoordinates, strain is better dealt with in Cartesian coordinates for reasons\ndiscussed in the reference cited above. These wave functions are used to\ncompute three types of 2DTE\u2019s. Derivatives with respect to two strain\ncomponents give us the so-called rigid-ion elastic tensor. Derivatives with\nrespect to one strain and one electric field component give us the rigid-ion\npiezoelectric tensor. Finally, derivatives with respect to one strain and one\natomic displacement yield the internal-strain force-response tensor, an\nintermediate quantity that will be necessary to compute the atomic relaxation\ncorrections to the rigid-ion quantities. As in lesson RF1, we specify\nconvergence in terms of the residual of the potential (here the first-order\npotential) using  \ntolvrs  .  Your run should have completed by now. Abinit should have created quite a few\nfiles.   telast_2.log (log file)  telast_2.out (main output file)  telast_2o_DS1_DDB (first derivatives of the energy from GS calculation)  telast_2o_DS3_DDB (second derivatives from the RF calculation)  telast_2o_DS1_WFK (GS wave functions)  telast_2o_DS2_1WF* (ddk wave functions)  telast_2o_DS3_1WF* (RF first-order wave functions from various perturbations)   The log and out files are diagnostics and readable output information for a\nwide variety of properties. The derivative database DDB files are ascii and\nreadable, but primarily for subsequent analysis by anaddb which we will\nundertake in the next section. Finally, the various wave function binary files\nare primarily of use for subsequent calculations, where they could cut the\nnumber of needed iterations in, for example, convergence testing. We take note\nof a few conventions in the file names. The root output file name telast_2o is\nfrom the 4th line of the \u201cfiles\u201d file. The dataset producing the file is next.\nFinally, the first-order wave function 1WF files have a final \u201cpertcase\u201d\nnumber described in   section\n1  of the respfn_help file.\nWhile telast_2.in specifies all atomic displacements, only the symmetry-\ninequivalent perturbations are treated, so the \u201cpertcase\u201d list is incomplete.\nAll cases specified in the input data are treated for the strain perturbation.    First, take a look at the end of the telast_2.log file to make sure the run\nhas completed without error. You might wish to take a look at the WARNING\u2019s,\nbut they all appear to be harmless. Next, edit your telast_2.out file.\nSearching backwards for ETOT you will find       iter   2DEtotal(Ha)       deltaE(Ha) residm    vres2\n-ETOT  1   2.3955208361366     -6.519E+00 6.313E-01 4.126E+02\n ETOT  2   1.3040286462220     -1.091E+00 4.926E-04 4.735E+00\n ETOT  3   1.2898966738702     -1.413E-02 1.857E-05 3.504E-01\n ETOT  4   1.2891923712805     -7.043E-04 2.937E-07 8.931E-03\n ETOT  5   1.2891781500347     -1.422E-05 7.582E-09 5.989E-05\n ETOT  6   1.2891780804502     -6.958E-08 4.440E-11 7.674E-07\n ETOT  7   1.2891780792714     -1.179E-09 1.236E-12 2.972E-08\n ETOT  8   1.2891780791847     -8.667E-11 2.674E-14 7.671E-10\n ETOT  9   1.2891780791827     -2.006E-12 9.086E-16 4.128E-12\n\n At SCF step    9       vres2   =  4.13E-12 < tolvrs=  1.00E-10 =>converged.  Abinit is solving a set of Schroedinger-like equations for the first-order\nwave functions, and these functions minimize a variational expression for the\n2DTE.  (Technically, they are called self-consistent Sternheimer equations.)\nThe  energy  convergence looks similar to that of GS calculations.  The fact\nthat vres2, the residual of the self-consistent first-order potential, has\nreached   tolvrs \nwell within  nstep  (40) iterations indicates that the 2DTE calculation for\nthis perturbation (xy strain) has converged . It would pay to examine a few\nmore cases for different perturbations (unless you have looked through all the\nwarnings in the log).  Another convergence item to examine in your .out file is   Seventeen components of 2nd-order total energy (hartree) are\n 1,2,3: 0th-order hamiltonian combined with 1st-order wavefunctions\n     kin0=   9.10477366E+00 eigvalue=   3.11026184E-01  local=  -3.66858410E+00\n 4,5,6,7: 1st-order hamiltonian combined with 1st and 0th-order wfs\n loc psp =  -8.91644855E+00  Hartree=   4.33575581E+00     xc=  -6.58530138E-01\n     kin1=  -8.62111363E+00\n 8,9,10: eventually, occupation + non-local contributions\n    edocc=   0.00000000E+00     enl0=   6.43290228E-01   enl1=  -1.55388963E-01\n 1-10 gives the relaxation energy (to be shifted if some occ is /=2.0)\n   erelax=  -7.62521951E+00\n 11,12,13 Non-relaxation  contributions : frozen-wavefunctions and Ewald\n  fr.hart=  -1.18530360E-01   fr.kin=   5.20015318E+00 fr.loc=   4.18792202E-01\n 14,15,16 Non-relaxation  contributions : frozen-wavefunctions and Ewald\n  fr.nonl=   2.94970622E-01    fr.xc=   9.41457939E-02  Ewald=   3.02486615E+00\n 17 Non-relaxation  contributions : pseudopotential core energy\n  pspcore=   0.00000000E+00\n Resulting in :\n 2DEtotal=    0.1289178079E+01 Ha. Also 2DEtotal=    0.350803195765E+02 eV\n    (2DErelax=   -7.6252195073E+00 Ha. 2DEnonrelax=    8.9143975865E+00 Ha)\n    (  non-var. 2DEtotal :    1.2891781360E+00 Ha)  This detailed breakdown of the contributions to 2DTE is probably of limited\ninterest, but you should compare \u201c2DEtotal\u201d and \u201cnon-var. 2DEtotal\u201d from the\nlast three lines. While the first-order wave function for the present\nperturbation minimizes a variational  expression for the second derivative\nwith respect to this perturbation as we just saw, the various 2DTE given as\nelastic tensors, etc. in the output and in the DDB file are all computed using\nnon-variational expressions.  Using the non-variational expressions, mixed\nsecond derivatives with respect to the present perturbation and all other\nperturbations of interest can be computed directly from the present first-\norder wave functions.   The disadvantage is that the non-variational result\nhas errors which are linearly proportional to convergence errors in the GS and\nfirst-order wave functions.  Since errors in the variational 2DEtotal are\nsecond-order in wave-function convergence errors, comparing this to the non-\nvariational result for the diagonal second derivative will give an idea of the\naccuracy of the latter and perhaps indicate the need for tighter convergence\ntolerances for both the GS and RF wave functions.  This is discussed in  X.\nGonze and C. Lee, Phys. Rev. B 55, 10355 (1997) , Sec. II.  For an atomic-\ndisplacement perturbation, the corresponding breakdown of the 2DTE is headed\n\u201cThirteen components.\u201d  Now let us take a look at the results we want, the various 2DTE\u2019s. They begin   ==> Compute Derivative Database <==\n\n  2nd-order matrix (non-cartesian coordinates, masses not included,\n   asr not included )\n  cartesian coordinates for strain terms (1/ucvol factor\n   for elastic tensor components not included)\n     j1       j2             matrix element\n  dir pert dir pert     real part     imaginary part\n\n   1    1   1    1         5.4508668454         0.0000000000\n   1    1   2    1        -2.7254334227         0.0000000000\n   1    1   3    1         0.0000000000         0.0000000000\n            .....  These are the \u201craw\u201d 2DTE\u2019s, in reduced coordinates for atom-displacement and\nelectric-field perturbations, but Cartesian coordinates for strain\nperturbations. This same results with the same organization appear in the file\ntelast_2_DS3_DDB which will be used later as input for automated analysis and\nconverted to more useful notation and units by anaddb. A breakout of various\ntypes of 2DTE\u2019s follows (all converted to Cartesian coordinates and in atomic\nunits):      Dynamical matrix, in cartesian coordinates,\n    if specified in the inputs, asr has been imposed\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    1   1    1         0.0959051967         0.0000000000\n   1    1   2    1         0.0000000000         0.0000000000\n   1    1   3    1         0.0000000000         0.0000000000\n            .....  This contains the interatomic force constant data that will be used later to\ninclude atomic relaxation effects.  \u201casr\u201d refers to the acoustic sum rule,\nwhich basically is a way of making sure that forces sum to zero when an atom\nis displaced.    Effective charges, in cartesian coordinates,\n    (from phonon response)\n    if specified in the inputs, asr has been imposed\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    6   1    1         1.8290469443         0.0000000000\n   2    6   1    1         0.0000000000         0.0000000000\n   3    6   1    1         0.0000000000         0.0000000000\n            .....  The Born effective charges will be used to find the atomic relaxation\ncontributions of the piezoelectric tensor.    Rigid-atom elastic tensor , in cartesian coordinates,\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    7   1    7         0.0056418385         0.0000000000\n   1    7   2    7         0.0013753710         0.0000000000\n   1    7   3    7         0.0007168444         0.0000000000\n            .....  The rigid-atom elastic tensor is the 2DTE with respect to a pair of strains.\nWe recall that \u201cpert\u201d = natom+3 and natom+4 for unaxial and shear strains,\nrespectively.    Internal strain coupling parameters, in cartesian coordinates,\n    zero average net force deriv. has been imposed\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    1   1    7         0.1249319229         0.0000000000\n   1    1   2    7        -0.1249319273         0.0000000000\n   1    1   3    7         0.0000000000         0.0000000000\n            .....  These 2DTE\u2019s with respect to one strain and one atomic displacement are needed\nfor atomic relaxation corrections to both the elastic tensor and piezoelectric\ntensor. While this set of parameters is of limited direct interest, it should\nbe examined in cases when you think that high symmetry may eliminate the need\nfor these corrections. You are probably wrong, and any non-zero term indicates\na correction.    Rigid-atom proper piezoelectric tensor, in cartesian coordinates,\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   1    1   1    7         0.1249319273         0.0000000000\n\n   1    1   2    7        -0.1249319211         0.0000000000\n\n   1    1   3    7         0.0000000000         0.0000000000  Finally, we have the piezoelectric tensor, the 2DTE with respect to one strain\nand one uniform electric field component.  (Yes, there are non-zero elements.)",
            "title": "**2. Response-function calculations of several second derivatives of the"
        },
        {
            "location": "/tutorials/elastic/#346-anaddb-calculation-of-atom-relaxation-effects",
            "text": "In this section, we will run the program anaddb, which analyzes DDB files\ngenerated in prior RF calculations. You should copy telast_3.in and\ntelast_3.files in your Work_elast directory. You should now go to the   anaddb\nhelp file  , and read the short\nintroduction. The bulk of the material in this help file is contained in the\ndescription of the variables. You should read the descriptions of     elaflag  piezoflag   instrflag        chneut    For the theory underlying the incorporation of atom-relaxation corrections, it\nis recommended you see  X. Wu, D. Vanderbilt, and D. R. Hamann,  Phys. Rev, B\n72, 035105\n(2005)  .    Anaddb can do lots of other things, such as calculate the frequency-dependent\ndielectric tensor, interpolate the phonon spectrum to make nice phonon\ndispersion plots, calculate Raman spectra, etc., but we are focusing on the\nminimum needed for the elastic and piezoelectric constants at zero electric\nfield.    We also mention that   mrgddb \nis another utility program that can be used to combine DDB files generated in\nseveral different datasets or in different runs into a single DDB file that\ncan be analyzed by anaddb. One particular usage would be to combine the DDB\nfile produced by the GS run, which contains first-derivative information such\nas stresses and forces with the RF DDB. It is anticipated that anaddb in a\nfuture release will implement the finite-stress corrections to the elastic\ntensor discussed in   notes by A. R.\nOganov  .    Now would be a good time to edit telast_3.in and observe that it is very\nsimple, consisting of nothing more than the four variables listed above set to\nappropriate values. The telast_3.files file is used with anaddb in the same\nmanner as the abinit .files you are by now used to. The first two lines\nspecify the .in and .out files, the third line specifies the DDB file, and the\nlast two lines are dummy names which would be used in connection with other\ncapabilities of anaddb. Now you should run the calculation, which is done in\nthe same way as you are now used to for abinit:    ../../anaddb <telast_3.files >&telast_3.log    This calculation should only take a few seconds. You should edit the log file,\ngo to the end, and make sure the calculation terminated without error. Next,\nexamine telast_3.out. After some header information, we come to tables giving\nthe \u201cforce-response\u201d and \u201cdisplacement-response\u201d internal strain tensors.\nThese represent, respectively, the force on each atom and the displacement of\neach atom in response to a unit strain of the specified type. These numbers\nare of limited interest to us, but represent important intermediate quantities\nin the treatment of atomic relaxation (see the X. Wu paper cited above).    Next, we come to the elastic tensor output:     Elastic Tensor(clamped ion)(unit:10^2GP):\n\n   1.6598859   0.4046480   0.2109029   0.0000000   0.0000000   0.0000000\n   0.4046480   1.6598859   0.2109029   0.0000000  -0.0000000   0.0000000\n   0.2109030   0.2109030   1.8258575   0.0000000  -0.0000000   0.0000000\n  -0.0000000  -0.0000000  -0.0000000   0.4081820  -0.0000000   0.0000000\n   0.0000000   0.0000000   0.0000000  -0.0000000   0.4081820  -0.0000000\n  -0.0000000  -0.0000000  -0.0000000   0.0000000  -0.0000000   0.6276190\n\n Elastic Tensor(relaxed ion)(unit:10^2GP):\n   (at fixed electric field boundary condition)\n\n   1.3526217   0.5445039   0.3805291  -0.0000000   0.0000000   0.0000000\n   0.5445039   1.3526217   0.3805292   0.0000000  -0.0000000   0.0000000\n   0.3805292   0.3805293   1.4821104   0.0000000  -0.0000000   0.0000000\n  -0.0000000   0.0000000   0.0000000   0.3055071  -0.0000000   0.0000000\n   0.0000000  -0.0000000  -0.0000000  -0.0000000   0.3055071   0.0000000\n  -0.0000000   0.0000000  -0.0000000   0.0000000   0.0000000   0.4040588  While not labeled, the rows and columns 1-6 here represent xx, yy, zz, yz, xz,\nxy strains and stresses in the conventional Voigt notation. \nThe clamped-ion results were calculated in the telast_2 RF run, and are simply\nconverted to standard GPa units by anaddb (the terms \u201cclamped ion,\u201d \u201cclamped\natom,\u201d and \u201crigid atom\u201d used in various places are interchangeable, similarly\nfor \u201crelaxed.\u201d) \nThe relaxed-ion result was calculated by anaddb by combining 2DTE\u2019s for\ninternal strain and interatomic force constants which are stored in the input\nDDB file. Comparing the clamped and relaxed results, we see that all the\ndiagonal elastic constants have decreased in value. \nThis is plausible, since allowing the internal degrees of freedom to relax\nshould make a material less stiff. These tensors should be symmetric, and\ncertain tensor elements should be zero or identical by symmetry. \nIt\u2019s a good idea to check these properties against a standard text such as  J.\nF. Nye, Physical Properties of Crystals (Oxford U. P., Oxford 1985).\nDepartures from expected symmetries (there are a few in the last decimal place\nhere) are due to either convergence errors or, if large, incorrectly specified\ngeometry (however, see the final comments on symmetry  below).    Next in telast_3.out we find the piezoelectric tensor results:     Proper piezoelectric constants(clamped ion)(unit:c/m^2)\n\n      0.00000000      0.00000000      0.38490079\n      0.00000000      0.00000000      0.38490075\n      0.00000000      0.00000000     -0.73943025\n      0.00000000      0.43548797      0.00000000\n      0.43548796      0.00000000     -0.00000000<\n      0.00000000      0.00000000      0.00000001\n\n Proper piezoelectric constants(relaxed ion)(unit:c/m^2)\n\n      0.00000000     -0.00000000     -0.01187149\n     -0.00000000      0.00000000     -0.01187169\n     -0.00000000      0.00000000      0.06462779\n     -0.00000000     -0.04828847     -0.00000000\n     -0.04828832     -0.00000000      0.00000000  The 3 columns here represent x, y, and z electric polarization, and the 6 rows\nthe Voigt strains. The clamped-ion result was calculated in the telast_2 RF\nrun, and is simply scaled to conventional units by anaddb. The ion relaxation\ncontributions are based on 2DTE\u2019s for internal strain, interatomic force\nconstants, and Born effective charges, and typically constitute much larger\ncorrections to the piezoelectric tensor than to the elastic tensor. Once\nagain, symmetries should be checked. (The slight discrepancies seen here can\nbe removed by setting tolvrs3=1.0d-18 in telast_2.in.) One should be aware\nthat the piezoelectric tensor is identically zero in any material which has a\ncenter of symmetry.    Since we are dealing with a hypothetical material, there is no experimental\ndata with which to compare our results. In the next section, we will calculate\na few of these numbers by a finite-difference method to gain confidence in the\nRF approach.",
            "title": "3. anaddb calculation of atom-relaxation effects."
        },
        {
            "location": "/tutorials/elastic/#446-finite-difference-calculation-of-elastic-and-piezoelectric",
            "text": "constants.**  You should copy telast_4.in and telast_4.files into your Work_elast directory.\nEditing telast_4.in, you will see that it has four datasets, the first two\nwith the c-axis contracted 0.01% and the second two with it expanded 0.01%,\nwhich we specified by changing the third row of  \nrprim  . The common\ndata is essentially the same as telast_2.in, and the relaxed  \nacell  values and  \nxred  from\ntelast_1.out have already been included. Datasets 1 and 3 do the self-\nconsistent convergence of the GS wave functions for the strained lattices and\ncompute the stress. Datasets 2 and 4 introduce a new variable.     berryopt     Electric polarization in solids is a subtle topic which has only recently been\nrigorously resolved. It is now understood to be a bulk property, and to be\nquantitatively described by a Berry phase formulation introduced by R. D.\nKing-Smith and D. Vanderbilt, Phys. Ref. B 47, 1651(1993) . It can be\ncalculated in a GS calculation by integrating the gradient with respect to k  of the GS wave functions over the Brillouin zone. In GS calculations,\nthe gradients are approximated by finite-difference expressions constructed\nfrom neighboring points in the  k  mesh. These are closely related to the\nddk wave functions used in RF calculations in  2 and introduced in   lesson\nRF1, section 5  . We will use  \nberryopt  = -1,\nwhich utilizes an improved coding of the calculation, and must specify rfdir  = 1 1 1 so that the Cartesian components of the polarization are\ncomputed.    Now, run the telast_4 calculation, which should only take a minute or two, and\nedit telast_4.out. To calculate the elastic constants, we need to find the\nstresses  sigma(1 1) and sigma(3 3) . We see that each of the four datasets\nhave stress results, but that there are slight differences between those from,\nfor example dataset 1 and dataset 2, which should be identical. Despite our\ntight limit, this is still a convergence issue. Look at the following\nconvergence results,    Dataset 1:\n At SCF step   13       vres2   =  6.24E-21 < tolvrs=  1.00E-18 =>converged.\n\nDataset 2:\n At SCF step    1       vres2   =  5.08E-21 < tolvrs=  1.00E-18 =>converged.  Since dataset 2 has better convergence, we will use this and the dataset 4\nresults, choosing those in GPa units,  - sigma(1 1)= -2.11918835E-03  sigma(3 2)=  0.00000000E+00\n- sigma(3 3)= -1.82392050E-02  sigma(2 1)=  0.00000000E+00\n\n- sigma(1 1)=  2.09886408E-03  sigma(3 2)=  0.00000000E+00\n- sigma(3 3)=  1.82778679E-02  sigma(2 1)=  0.00000000E+00  Let us now compute the numerical derivative of  sigma(3 3)and compare to our\nRF result. Recalling that our dimensionless strains were \u00b10.0001, we find\n182.5853 GPa. This compares very well with the value  182.58575 GPa, the 3,3\nelement of the Rigid-ion elastic tensor we found from our anaddb calculation\nin  3 . (Recall that our strain and stress were both 3 3 or z z or Voigt 3.)\nSimilarly, the numerical derivative of  sigma(1 1)is 21.09026 GPa, compared to\n21.09029 GPa, the 3,1 elastic-tensor element.  The good agreement we found from this simple numerical differentiation\nrequired that we had accurately relaxed the lattice so that the stress of the\nunstrained structure was very small. Similar numerical-derivative comparisons\nfor systems with finite stress are more complicated, as discussed in   notes\nby A. R. Oganov  . Numerical-\nderivative comparisons for the relaxed-ion results are extremely challenging\nsince they require relaxing atomic forces to exceedingly small limits.  Now let us examine the electric polarizations found in datasets 2 and 4,\nfocusing on the C/m^2 results,             Polarization    -1.578272218E-11 C/m^2\n           Polarization     1.578207434E-11 C/m^2\n           Polarization    -2.979936062E-01 C/m^2\n\n           Polarization    -1.577757536E-11 C/m^2\n           Polarization     1.577753205E-11 C/m^2\n           Polarization    -2.981427239E-01 C/m^2  While not labeled as such, these are the Cartesian x, y, and z components,\nrespectively, and the x and y components are zero within numerical accuracy as\nthey must be from symmetry. Numerical differentiation of the z component\nyields -0.745589 C/m^2. This is to be compared with the z,3 element of our\nrigid-ion piezoelectric tensor from 3, -0.73943025 C/m^2, and the two results\ndo not compare as well as we might wish.  What is wrong? There are two possibilities. The first is that the RF\ncalculation produces the proper piezoelectric tensor, while numerical\ndifferentiation of the polarization produces the improper piezoelectric\ntensor. This is a subtle point, for which you are referred to  D. Vanderbilt,\nJ. Phys. Chem. Solids 61, 147 (2000) . The improper-to-proper transformation\nonly effects certain tensor elements, however, and for our particular\ncombination of crystal symmetry and choice of strain there is no correction.\nThe second possibility is the subject of the next section.",
            "title": "**4. Finite-difference calculation of elastic and piezoelectric"
        },
        {
            "location": "/tutorials/elastic/#546-alternative-response-function-calculation-of-some-piezoelectric",
            "text": "constants.**  Our GS calculation of the polarization in 4 used, in effect, a finite-\ndifference approximation to ddk wave functions, while our RF calculations in\n2 used analytic results based on the RF approach. Since the   k  grid\ndetermined by  \nngkpt  = 4 4 4 and  \nnshiftk  = 1 is\nrather coarse, this is a probable source of discrepancy. Since this issue was\nnoted previously in connection with the calculation of Born effective charges\nby Na Sai, K. M. Rabe, and D. Vanderbilt, Phys. Rev. B 66, 104108 (2002) ,\nAbinit has incorporated the ability to use finite-difference ddk wave\nfunctions from GS calculations in RF calculations of electric-field-related\n2DTE\u2019s. Copy telast_5.in and telast_5.files into Work_elast, and edit\ntelast_5.in.  You should compare this with our previous RF data, telast_2.in, and note that\ndataset1 and the Common data (after entering relaxed structural results) are\nessentially identical. Dataset 2 has been replaced by a non-self-consistent GS\ncalculation with  \nberryopt  = -2\nspecified to perform the finite-difference ddk wave function calculation. (The\nfinite-difference first-order wave functions are implicit but not actually\ncalculated in the GS polarization calculation.) We have restricted  \nrfdir  to 0 0 1 since\nwe are only interested in the 3,3 piezoelectric constant. Now compare dataset\n3 with that in telast_2.in. Can you figure out what we have dropped and why?\nRun the telast_5 calculation, which will only take about a minute with our\nsimplifications.  Now edit telast_5.out, looking for the piezoelectric tensor,    Rigid-atom proper piezoelectric tensor, in cartesian coordinates,\n     j1       j2                   matrix element\n  dir pert dir pert          real part        imaginary part\n\n   3    6   3    7        -0.0130314050         0.0000000000  We immediately see a problem \u2013 this output, like most of the .out file, is in\natomic units, while we computed our numerical derivative in conventional C/m^2\nunits. While you might think to simply run anaddb to do the conversion as\nbefore, its present version is not happy with such an incomplete DDB file as\ntelast_5 has generated and will not produce the desired result. While it\nshould be left as an exercise to the student to dig the conversion factor out\nof the literature, or better yet out of the source code, we will cheat and\ntell you that 1a.u.=57.2147606 C/m^2 Thus the new RF result for the 3,3 rigid-\nion piezoelectric constant is -0.7455887 C/m^2 compared to the result found in\n4 by a completely-GS finite difference calculation, -0.745589 C/m^2. The\nagreement is now excellent!  The fully RF calculation in 2 in fact will converge much more rapidly with  \nk  sample than the partial-finite-difference method introduced here.  Is it\nworthwhile to have learned how to do this? We believe that is always pays to\nhave alternative ways to test results, and besides, this didn\u2019t take much\ntime. (Have you found the conversion factor on your own yet?)",
            "title": "**5. Alternative response-function calculation of some piezoelectric"
        },
        {
            "location": "/tutorials/elastic/#646-response-function-calculation-of-the-elastic-constants-of-al",
            "text": "metal.**  For metals, the existence of partially occupied bands is a complicating\nfeature for RF as well as GS calculations.  Now would be a good time to review lesson 4  which dealt in detail with the interplay between  k -sample convergence and Fermi-surface broadening, especially section  \n4.3  .  You should copy telast_6.in and telast_6.files\ninto Work_elast, and begin your run while you read on, since it involves a\nconvergence study with multiple datasets and may take about two minutes.    While the run is in progress, edit telast_6.in.  As in t43.in, we will set  \nudtset  to specify a\ndouble loop.  In the present case, however, the outer loop will be over 3\nsuccessively larger meshes of  k  points, while the inner loop will be\nsuccessively     GS self-consistent runs with optimization of acell.  GS density-generating run for the next step.  Non-self-consistent GS run to converge unoccupied or slightly-occupied bands.  RF run for symmetry-inequivalent elastic constants.   In Section 1 , we did a separate GS structural optimization run and\ntransferred the results by hand to RF  run 2 .  Because we are doing a\nconvergence test here, we have combined these steps, and use  \ngetcell  to\ntransfer the optimized coordinates from the first dataset of the inner loop\nforward to the rest.  If we were doing a more complicated structure with\ninternal coordinates that were also optimized, we would need to use both this\nand   getxred  to\ntransfer these, as in telast_1.in.    The specific data for inner-loop dataset 1 is very similar to that for\ntelast_1.in.  Inner-loop dataset 2 is a bit of a hack.  We need the density\nfor inner-loop dataset 3, and while we could set  \nprtden  = 1 in\ndataset 1, this would produce a separate density file for every step in the\nstructural optimization, and it isn\u2019t clear how to automatically pick out the\nlast one.  So, dataset 2 picks up the wave functions from dataset 1 (only one\nfile of these is produced, for the optimized structure), does one more\niteration with fixed geometry, and writes a density file.    Inner-loop dataset 3 is a non-self-consistent run whose purpose is to ensure\nthat all the wave functions specified by  \nnband  are well\nconverged. For metals, we have to specify enough bands to make sure that the\nFermi surface is properly calculated.  Bands above the  Fermi level which have\nsmall occupancy or near-zero occupancy if their energies exceed the Fermi\nenergy by more than a few times \ntsmear  , will have\nvery little effect on the self-consistent potential, so the  \ntolvrs  test in\ndataset 1 doesn\u2019t ensure their convergence.  Using  \ntolwfr  in inner-\nloop dataset 3 does.  Partially-occupied or unoccupied bands up to  \nnband    play a\ndifferent role in constructing the first-order wave functions than do the many\nunoccupied bands beyond  \nnband  which aren\u2019t\nexplicitly treated in Abinit, as discussed in  S. de Gironcoli, Phys. Rev. B\n51, 6773 (1995).  By setting  \nnband  exactly equal\nto the number of occupied bands for RF calculations for semiconductors and\ninsulators, we avoid having to deal with the issue of converging unoccupied\nbands.  Could we avoid the extra steps by simply using  \ntolwfr  instead of  \ntolvrs  in dataset\n1?  Perhaps, but experience has shown that this does not necessarily lead to\nas well-converged a potential, and it is not recommended.  These same\nconsiderations apply to phonon calculations for metals, or in particular to  \nqpt  = 0 0 0 phonon\ncalculations for the interatomic force constants needed to find atom-\nrelaxation contributions to the elastic constants for non-trivial structures\nas in 2 and 3 .    The data specific to the elastic-tensor RF calculation in inner-loop dataset 4\nshould by now be familiar.  We take advantage of the fact that for cubic\nsymmetry the only symmetry-inequivalent elastic constants are C 11, C 12 , and\nC 44 .  Abinit, unfortunately, does not do this analysis automatically, so we\nspecify   rfdir  =1 0\n0 to avoid duplicate calculations.  (Note that if atom relaxation is to be\ntaken into account  for a more complex structure, the full set of directions\nmust be used.)    When the telast_6 calculations finish, first look at telast_6.log as usual to\nmake sure they have run to completion without error.  Next, it would be a good\nidea to look at the band occupancies occ?? (where ?? is a dual-loop dataset\nindex) reported at the end (following  ==END DATASET(S)==).  The highest band,\nthe fourth in this case, should have zero or very small occupation, or you\nneed to increase  \nnband  or decrease  \ntsmear  .  Now, use\nyour newly perfected knowledge of the Abinit perturbation indexing conventions\nto scan through telast_6.out and find C 11 , C12 , and C 44 for each of the\nthree  k -sample choices, which will be  under the \u201d Rigid-atom elastic\ntensor\u201d heading.  Also find the lattice constants for each case, whose\nconvergence you studied in lesson 4.  You should be able to cut-and-paste\nthese into a table like the following,                C_11           C_12           C_44           acell\nngkpt=3*6   0.0037773556   0.0022583541   0.0013453692   7.5710952266\nngkpt=3*8   0.0042004431   0.0020423388   0.0013076763   7.5693986665\nngkpt=3*10  0.0042034396   0.0020343437   0.0012956768   7.5694820855  We can immediately see that the lattice constant converges considerably more\nrapidly with  k  sample than the elastic constants.  For  \nngkpt  =3 6, acell is\nconverged to 0.02%, while the C\u2019s have 5-10% errors.  For  ngkpt  =3 8, the\nC\u2019s are converged to better than 1%, much better for the largest, C11, which\nshould be acceptable.  As in lesson 4, the  ngkpt  convergence is controlled by  \ntsmear  .  The\nsmaller the broadening, the denser the  k  sample that is needed to get a\nsmooth variation of occupancy, and presumably stress, with strain.  While we\nwill not explore  \ntsmear  convergence\nin this lesson, you may wish to do so on your own.  We believe that the value  tsmear  = 0.02  in\ntelast_6.in gives results within 1% of the fully-converged small-broadening\nlimit.  We find that    occopt   *=3, standard Fermi-Dirac broadening *, gives _ much better_ convergence of the C\u2019s than \u201ccold smearing.\u201d   Changing   occopt  to 4 in telast_6.in, the option used in lesson 4, the C\u2019s show no sign of convergence.  At ngkpt=3*16, errors are still ~5%.  The reasons that this supposedly superior smoothing function performs so poorly in this context is a future research topic.  The main thing to be learned is that checking convergence with respect to all relevant parameters is   always  the user\u2019s responsibility.  Simple systems that include the main physical features of a complex system of interest will usually suffice for this testing.  Don\u2019t get caught publishing a result that another researcher refutes on convergence grounds, and don\u2019t blame such a mistake on Abinit!  Now we make a comparison with experiment.  Converting the C\u2019s to standard\nunits (Ha/Bohr^3 = 2.94210119E+04 GPa) and using zero-temperature extrapolated\nexperimental results from P. M. Sutton, Phys. Rev. 91, 816 (1953), we find                         C_11(GPa)  C_12(GPa)  C_44(GPa)\n     Calculated        123.7      59.9       38.1\n     Experiment (T=0)  123.0      70.8       30.9  Is this good agreement?  There isn\u2019t much literature on DFT calculations of\nfull sets of elastic constants.  Many calculations of the bulk modulus\n(K=(C11+2C 12 )/3 in the cubic case) typically are within 10% of experiment\nfor the LDA.  Running telast_6 with ixc=11, the Perdew-Burke-Enzerhof GGA,\nincreases the calculated C\u2019s by 1-2%, and wouldn\u2019t be expected to make a large\ndifference for a nearly-free-electron metal.",
            "title": "**6. Response-function calculation of the elastic constants of Al"
        },
        {
            "location": "/tutorials/elastic/#comment-on-symmetry",
            "text": "It is important to bear in mind that the way a tensor like the elastic tensor\nappears is a function of the frame used. Thus for the aluminum fcc case\nconsidered above, the nonzero elements are  C11 ,  C12 , and  C44 , _ provided\nthat the crystal axes are aligned with the laboratory frame. _ For an\narbitrary alignment of the crystal axes, many more  Cij  elements will be non-\nzero, and this can be confusing. It\u2019s easy to see why this happens if you\nimagine actually measuring the elastic tensor elements. If you start with the\nconventional cubic cell, and apply pressure to one face, you can measure C11 . But if you turn the cell to some random angle, you\u2019ll measure a\nresponse that is a mixture of  C11  and  C12 . Within ABINIT, if the aluminum\nfcc cell is described using  angdeg  and acell , then an\naxis of the primitive cell will be aligned along the laboratory  z  axis but\nthis will not lead to a (conventional) cell alignment with the laboratory\nframe. The resulting elastic tensor will be correct but will appear to be more\ncomplicated than in the illustration above. It can be rotated back to a simple\nframe by hand (bearing in mind that all four indices of the fourth-rank\nelastic tensor have to be rotated!) but it\u2019s easier to start with a more\nconventional alignment of the unit cell. If you use a standard text like\nBradley and Cracknell, The Mathematical Theory of Symmetry in Solids, Oxford\nyou can find the standard primitive cell descriptions for the Bravais lattice\ntypes and these are aligned as much as possible with a standard laboratory\nframe.   This ABINIT lesson is now finished\u2026",
            "title": "Comment on symmetry"
        },
        {
            "location": "/tutorials/eph/",
            "text": "This lesson demonstrates how to obtain the following physical properties, for\na metal :\n\n\n\n\nthe phonon linewidths (inverse lifetimes) due to the electron-phonon interaction\n\n\nthe Eliashberg spectral function\n\n\nthe electron-phonon coupling strength\n\n\nthe McMillan critical temperature\n\n\nthe resistivity and electronic part of the thermal conductivity\n\n\n\n\nHere you will learn to use the electron-phonon coupling part of the anaddb\nutility. This implies a preliminary calculation of the electron-phonon matrix\nelements and phonon frequencies and eigenvectors, from a standard ABINIT\nphonon calculation, which will be reviewed succinctly.\n\n\nThis lesson should take about 1 hour.\n\n\n\n\n1 Calculation of the ground state and phonon structure of fcc Al.\n\n\n2 Merging of the 2DTE DDB files using MRGDDB.\n\n\n3 Merging of the electron-phonon matrix elements using MRGGKK.\n\n\n4 Basic ANADDB calculation of electron-phonon quantities.\n\n\n5 Convergence tests of the integration techniques.\n\n\n6 Transport quantities within Boltzmann theory.\n\n\n\n\n\n\n1. Calculation of the ground state and phonon structure of fcc Al.\n\u00b6\n\n\n\u00b6\n\n\n_Before beginning, you might consider making a different subdirectory to work\nin. Why not create \u201cWork_eph\u201d in ~abinit/tests/tutorespfn/Input ? _  \n\n\nIt is presumed that the user has already followed the Tutorials\n\nRF1\n and \nRF2\n, and understands the\ncalculation of ground state and response function (phonon) properties with\nABINIT.\n\n\nThe file ~abinit/tests/tutorespfn/Input/teph_1.files lists the file names and\nroot names for the first run (GS+perturbations). You can copy it to the\nworking directory. You can also copy the file\n~abinit/tests/tutorespfn/Input/teph_1.in to your working directory. This is\nyour input file.\n\n\n\n\n_cp ../teph_1.files . _\n\n\n_cp ../teph_1.in . _\n\n\n\n\nYou can immediately start this run - the input files will be examined later\n\u2026\n\n\n../../abinit < teph_1.files > tmp-log &\n\n\n\n\n\n\nDataset Structure and Flow\n\u00b6\n\n\nThe teph_1.in file contains a number of datasets (DS). These will perform the\nground state (DS 1), then the phonon perturbations (DS 2-4), for a cell of FCC\naluminium. The DDK perturbation (DS 5) is also calculated, and will be used to\nobtain the Fermi velocities for the transport calculations in Section 6.\n\n\nOnce these are done, abinit calculates the wave functions on the full grid of\nk-points (using \nkptopt\n3\n) in DS 6: these\nwill be used to calculate the electron-phonon matrix elements. In a full\ncalculation the density of k-points should be increased significantly here and\nfor the following datasets. For DS 1-5 only the normal convergence of the\nphonon frequencies should be ensured. In DS 7-10 only the matrix elements are\ncalculated, for the electron-phonon coupling and for the DDK\n(position/momentum matrix elements), on the dense and complete grid of\nk-points from DS 6. Note that the separation of the matrix element calculation\nis new from version 7.6.\n\n\nThe important variable for electron-phonon coupling calculations is \nprtgkk\n\nThis prints out files suffixed GKK, which contain the electron-phonon matrix\nelements. The matrix elements only depend on the self-consistent perturbed\ndensity (files suffixed 1DENx), which we get from DS 2-4 (linked by variable\n\nget1den\n). These can therefore be calculated on arbitrarily dense k-point\nmeshes. Even better, only a single step is needed, since no self-consistency\nis required. To enforce the calculation of all the matrix elements on all\nk-points, symmetries are disabled when \nprtgkk\n is set to 1, so be sure not\nto use it during the normal self-consistent phonon runs DS 2-4. Again this is\nvery different from versions before 7.6.\n\n\nConvergence\n\u00b6\n\n\nThe calculation is done using minimal values of a number of parameters, in\norder to make it tractable in a time appropriate for a tutorial. The results\nwill be completely unconverged, but by the end of the lesson you should know\nhow to run a full electron phonon calculation, and be able to improve the\nconvergence on your own.\n\n\nEdit the file teph_1.in. We now examine several variables. The kinetic energy\ncutoff \necut\n is a bit low, and the number of k-points (determined by\n\nngkpt\n) is much too\nlow. Electron-phonon calculations require a very precise determination of the\nFermi surface of the metal. This implies a very dense k-point mesh, and the\nconvergence of the grid must be checked. In our case, for Al, we will use a\n(non-shifted) 4x4x4 k-point grid, but a converged calculation needs more than\n16x16x16 points. This will be re-considered in section 5. The q-point grid\nwill be 2x2x2. It must be a sub-grid of the full k-point grid, and must\ncontain the \u0393 point.\n\n\nThe value of \nacell\n is fixed to a rounded value from experiment. It, too,\nshould be converged to get physical results (see \n Tutorial\n3\n).\n\n\nNote that the value of 1.0E-14 for \ntolwfr\n is tight, and should be even\nlower (down to 1.0E-20 or even 1.0E-22). This is because the wavefunctions\nwill be used later explicitly in the matrix elements for ANADDB, as opposed to\nonly energy values or densities, which are averages of the wavefunctions and\neigenenergies over k-points and bands. Electron-phonon quantities are delicate\nsums of a few of these small matrix elements (those near the Fermi surface),\nso each matrix element must be accurate. You can however set \nprtwf\n to 0 in\nthe phonon calculations, and avoid saving huge perturbed wavefunction files to\ndisk (you only need to keep the ground state wave functions, with prtwf1 1).\n\n\nExecution\n\u00b6\n\n\nRun the first input (a few seconds on a recent PC), and you should obtain a\nvalue of\n\n\n etotal -2.0828579336121 Ha\n\n\n\n\n\nfor the energy at the end of DATASET 1. The following datasets calculate the\nsecond order energy variations under atomic displacement in the three reduced\ndirections of the fcc unit cell. This is done for three different phonons,\nGamma, (1/2,0,0), and X=(1/2,1/2,0), which generate the 2x2x2 q-point grid\n(take care with the reduced coordinates of the reciprocal space points! They\nare not along cartesian directions, but along the reciprocal space lattice\nvectors.). The whole calculation follows the same lines as \n Tutorial\nRF1\n. As an example, DATASET 3 calculates the perturbed\nwavefunctions at k+q, for k in the ground state k-point mesh, and q=(1/2,0,0).\nThen, DATASET 3 calculates\n\n\n 2DTE 0.80951882353353\n\n\n\n\n\nfor the second-order energy variation for movement of the (unique) atom along\nthe first reduced direction for q=(1/2,0,0). The main differences with \n\nTutorial RF1\n are that Given we are dealing with a metal, no\nperturbation wrt electric fields is considered ; However, if you want to do\ntransport calculations, you need the ddk calculation anyway, to get the\nelectron band velocities. This is added in dataset 5. In the standard case,\nABINIT uses symmetry operations and non-stationary expressions to calculate a\nminimal number of 2DTE for different mixed second derivatives of the total\nenergy. In our case we use the first derivatives, and they must all be\ncalculated explicitly.\n\n\nYou are now the proud owner of 9 first-order matrix element files (suffixed\n_GKKx), corresponding to the three directional perturbations of the atom at\neach of the three q-points. The _GKK files contain the matrix elements of the\nelectron-phonon interaction, which we will extract and use in the following.\nBesides the _GKK files there are the _DDB files for each perturbation which\ncontain the 2DTE for the different phonons wavevectors q.\n\n\n\n\n2. Merging of the 2DTE _DDB files using MRGDDB.\n\u00b6\n\n\n\u00b6\n\n\nYou can copy the following content to a file teph_2.in within your working\ndirectory:\n\n\nteph_2.ddb.out\nTotal ddb for Al FCC system\n3\nteph_1o_DS2_DDB\nteph_1o_DS3_DDB\nteph_1o_DS4_DDB\n\n\n\n\n\nThis is your input file for the\n\nMRGDDB\n utility, which will\ntake the different _DDB files and merge them into a single one which ANADDB\nwill use to determine the phonon frequencies and eigenvectors. teph_2.in\ncontains the name of the final file, a comment line, then the number of _DDB\nfiles to be merged and their names.\n\n\nMRGDDB\n is run with the command\n\n\n mrgddb < teph_2.in\n\n\n\n\n\nIt runs in a few seconds.\n\n\n\n\n**3. Extraction and merging of the electron-phonon matrix elements using\n\u00b6\n\n\nMRGGKK.**\n\n\n\u00b6\n\n\nA merge similar to that in the last section must be carried out for the\nelectron-phonon matrix elements. This is done using the MRGGKK utility, and\nits input file is ~abinit/tests/tutorespfn/Input/teph_3.in, shown below\n\n\nteph_3o_GKK.bin   # Name of output file\n0                    # binary (0) or ascii (1) output\nteph_1o_DS1_WFK   # GS wavefunction file\n0  9 9               # number of 1WF files, of GKK files, and of perturbations in the GKK files\nteph_1o_DS2_GKK1  # names of the 1WF then the (eventual) GKK files\nteph_1o_DS2_GKK2\n...\n\n\n\n\n\nThe matrix element sections of all the _GKK files will be extracted and\nconcatenated into one (binary) file, here named teph_3o_GKK.bin. The following\nlines in teph_3.in give the output format (0 for binary or 1 for ascii), then\nthe name of the ground state wavefunction file. The fourth line contains 3\nintegers, which give the number of _1WF files (which can also be used to\nsalvage the GKK), the number of _GKK files, and the number of perturbations in\nthe _GKK files. Thus, MRGGKK functions very much like\n\nMRGDDB\n, and can merge _GKK\nfiles which already contain several perturbations (q-points or atomic\ndisplacements). Finally, the names of the different _1WF and _GKK files are\nlisted.\n\n\nMRGGKK will run on this example in a few seconds. In more general cases, the\nruntime will depend on the size of the system, and for a large number of bands\nor k-points can extend up to 20 minutes or more.\n\n\n\n\n4. Basic ANADDB calculation of electron-phonon quantities.\n\u00b6\n\n\n\u00b6\n\n\nThe general theory of electron-phonon coupling and Eliashberg\nsuperconductivity is reviewed in \nTheory of Superconducting Tc, P.B. Allen and\nB. Mitrovic in Sol. State Phys. \n37\n (1982) ed. Ehrenreich, Seitz, and\nTurnbull\n. The first implementations similar to that in ABINIT are those in\n\nS.Y. Savrasov and D.Y. Savrasov, Phys. Rev. B \n54\n 16487 (1996)\n and \nA.Y.\nLiu and A.A. Quong, Phys. Rev. B \n53\n R7575-R7579 (1996)\n.\n\n\nFile ~abinit/tests/tutorespfn/Input/teph_4.in contains the input needed by\nANADDB to carry out the calculation of the electron-phonon quantities. ANADDB\ntakes a files file, just like ABINIT, which tells it where to find the input,\nddb, and gkk files, and what to name the output, thermodynamical output, and\nelectron phonon output files. ~abinit/tests/tutorespfn/Input/teph_4.files is\nyour files file for ANADDB. You can edit it now.\n\n\nThe new variables are at the head of the file:\n\n\n# turn on calculation of the electron-phonon quantities\nelphflag 1\n\n# Path in reciprocal space along which the phonon linewidths\n#  and band structure will be calculated\nnqpath 7\nqpath\n 0.0 0.0 0.0\n 1/2 1/2 0.0\n 1   1   1\n 1/2 1/2 1/2\n 1/2 1/2 0.0\n 1/2 3/4 1/4\n 1/2 1/2 1/2\n\n# Coulomb pseudopotential parameter\nmustar 0.136\n\n\n\n\n\n elphflag\n is a flag\nto turn on the calculation of the electron-phonon quantities. The first\nquantities which will be calculated are the phonon linewidths along a path in\nreciprocal space (exactly like the band structure in \nLesson\n3.5\n). The path is specified by the variable\n\nqpath\n giving the apexes\nof the path in reciprocal space, which are usually special points of high\nsymmetry. The number of points is given by\n\nnqpath\n. Note that qpath\ncan be used in normal phonon band structure calculations as well, provided\nthat \nq1phl\n is omitted\nfrom the input file (the latter overrides qpath). The phonon linewidths are\nprinted to a file suffixed _LWD.\n\n\nThe phonon linewidths are proportional to the electron phonon coupling, and\nstill depend on the phonon wavevector q. The other electron-phonon\ncalculations which are presently implemented in ANADDB, in particular for\nsuperconductivity, determine isotropic quantities, which are averaged over the\nFermi surface and summed over q-points. Integrating the coupling over\nreciprocal space, but keeping the resolution in the phonon mode\u2019s energy, one\ncalculates the Eliashberg spectral function \u03b1\u00b2F. The \u03b1\u00b2F function is similar\nto the density of states of the phonons, but is weighted according to the\ncoupling of the phonons to the electrons. It is output to a file with suffix\n\nA2F, which is ready to be represented using any graphical software (Xmgr,\nmatlab, OpenDX\u2026). The first inverse moment of \u03b1\u00b2F gives the global coupling\nstrength, or mass renormalization factor, \u03bb. From \u03bb, using the McMillan\nformula (_Phys. Rev. \n167\n 331-344 (1968)\n) as modified by Allen and Dynes\n(\nPhys. Rev. B \n12\n 905 (1975)\n), ANADDB calculates the critical temperature\nfor superconductivity. The formula contains an adjustable parameter \u03bc* which\napproximates the effect of Coulomb interactions, and is given by the input\nvariable \nmustar\n. For Al\nwith the k-point grid given and a value of \u03bc=0.136 the ANADDB output file\nshows the following values\n\n\n mka2f: lambda <omega^2> =     8.891284E-07\n mka2f: lambda <omega^3> =     7.757272E-10\n mka2f: lambda <omega^4> =     8.715049E-13\n mka2f: lambda <omega^5> =     1.108658E-15\n mka2f: isotropic lambda =     8.337444E+00\n mka2f: omegalog  =     1.769558E-04 (Ha)     5.587816E+01 (Kelvin)\n mka2f: input mustar =     1.360000E-01\n-mka2f: MacMillan Tc =     4.038730E-05 (Ha)     1.275329E+01 (Kelvin)\n\n\n\n\n\nAs expected, this is a fairly bad estimation of the experimental value of 1.2\nK. The coupling strength is severely overestimated (experiment gives 0.44),\nand the logarithmic average frequency is too low, but not nearly enough to\ncompensate \u03bb. Aluminum is a good case in which things can be improved, easily\nbecause its Fermi surface is isotropic and the coupling is weak.\n\n\n\n\n5. Convergence tests of the integration techniques.\n\u00b6\n\n\n\u00b6\n\n\nIn section 4, we used the default method for integration on the Fermi surface,\nwhich employs a smearing of the DOS and attributes Gaussian weights to each\nk-point as a function of its distance from the Fermi surface. Another\nefficient method of integration in k-space is the tetrahedron method, which is\nalso implemented in ANADDB, and can be used by setting\n\ntelphint\n = 0. In this\ncase the k-point grid must be specified explicitly in the input, repeating the\nvariable \nkptrlatt\n\nfrom the ABINIT output, so that ANADDB can re-construct the different\ntetrahedra which fill the reciprocal unit cell. In the Gaussian case, the\nwidth of the smearing can be controlled using the input variable\n\nelphsmear\n.\n\n\nTo test our calculations, they should be re-done with a denser k-point grid\nand a denser q-point grid, until the results (\u03b1\u00b2F or \u03bb) are converged. The\nvalue of \nelphsmear\n\nshould also be checked, to make sure that it does not affect results.\nNormally, the limit for a very small\n\nelphsmear\n and a very\ndense k-point grid is the same as the value obtained with the tetrahedron\nmethod (which usually converges with a sparser k-point grid).\n\n\nEdit input file ~abinit/tests/tutorespfn/Input/teph_5.in and you will see the\nmain difference with teph_4.in is the choice of the tetrahedron integration\nmethod. If you are patient, save the output _LWD and _A2F files and run the\nfull lesson again with a denser k-point grid (say, 6x6x6) and you will be able\nto observe the differences in convergence.\n\n\n\n\n6. Transport quantities within Boltzmann theory.\n\u00b6\n\n\n\u00b6\n\n\nThe electron-phonon interaction is also responsible for the resistivity of\nnormal metals and related phenomena. Even in a perfect crystal, interaction\nwith phonons will limit electron life times (and vice versa). This can be\ncalculated fairly simply using the Boltzmann theory of transport with first\norder scattering by phonons (see, e.g., \u201cElectrons and Phonons\u201d by Ziman).\n\n\nThe additional ingredient needed to calculate transport quantities (electrical\nresistivity, heat conductivity limited by electron-phonon coupling) is the\nFermi velocity, i.e. the group velocity of a wavepacket of electrons placed at\nthe Fermi surface. This is the \u201ctrue\u201d velocity the charge will move at, once\nyou have displaced the Fermi sphere a little bit in k space (see, e.g.\nAshcroft and Mermin as well). The velocity can be related simply to a\ncommutator of the position, which is also used for dielectric response, using\na DDK calculation (see \nthe Gamma point phonon\ntutorial\n). The phonon calculation at Gamma need not\ninclude the electric field (this is a metal after all, so the effect on the\nphonons should be negligible), but we need an additional dataset to calculate\nthe 3 DDK files along the 3 primitive directions of the unit cell. To be more\nprecise, just as for the el-ph matrix elements, we do not need the perturbed\nwavefunctions, only the perturbed eigenvalues. Calculating the DDK derivatives\nwith \nprtgkk\n set to 1 will output files named _GKKxx (xx=3\nnatom+1 to\n3\nnatom+3) containing the matrix elements of the ddk perturbation (these are\nbasically the first part of the normal DDK files for E field perturbation,\nwithout the wave function coefficients).\n\n\nThe anaddb \u201cfiles\u201d file must specify where the ddk files are, so anaddb can\ncalculate the Fermi velocities. It actually reads:\n\n\nteph_6.in\nteph_6.out\nteph_2.ddb.out\nmoldyn\nteph_3o_GKK.bin\nteph.ep\nteph_6.ddk\n\n\n\n\n\nwhere the last line is the name of a small file listing the 3 DDK files to be\nused:\n\n\nteph_1_DS5_GKK4\nteph_1_DS5_GKK5\nteph_1_DS5_GKK6\n\n\n\n\n\nThe abinit input file teph_1.in already obtained the DDK files from the\nadditional dataset, DS5, with the following lines of teph_1.in:\n\n\ntolwfr5 1.0d-14\nqpt5 0 0 0\nrfphon5 0\nrfelfd5 2\n\n\n\n\n\nCopy the additional .ddk file from the tests/tutorespfn/Inputs directory, and\nrun anaddb with the new \u201cfiles\u201d file. The input for teph_6 has added to\nteph_5.in the following 2 lines:\n\n\nifltransport 1\nep_keepbands 1\n\n\n\n\n\nand has produced a number of additional files:\n\n\n\n\n_A2F_TR\n contain the equivalent Eliashberg spectral functions with Fermi speed factors (how many phonons do we have at a given energy, how much do they couple with the electrons, and how fast are these electrons going). Integrating with appropriate functions of the phonon energy, one gets:\n\n\nthe resistivity as a function of temperature (teph_6.out_ep_RHO and figure) and\n\n\nthe thermal conductivity as a function of temperature (teph_6.out_ep_WTH) but ONLY the electronic contribution. You are still missing the phonon-phonon interactions, which are the limiting factor in the thermal conductivity beyond a few 100 K. For metals at even higher temperature the electrons will often dominate again as they contain more degrees of freedom.\n\n\n\n\n\n\nThe high T behavior is necessarily linear if you include only first order e-p\ncoupling and neglect the variation of the GKK off of the Fermi surface. The\ninset shows the low T behavior, which is not a simple polynomial (with simple\nmodels it should be T^3 or T^5 - see Ashcroft and Mermin). See the Savrasov\npaper above for reference values in simple metals using well converged k- and\nq- point grids.\n\n\nFinally, note that the _RHO and _WTH files contain a series of tensor\ncomponents, for the resistivity tensor (2 1 = y x or the current response\nalong y when you apply an electric field along x). In most systems the tensor\nshould be diagonal by symmetry, and the value of off-diagonal terms gives an\nestimate of the numerical error.",
            "title": "EPH"
        },
        {
            "location": "/tutorials/eph/#146-calculation-of-the-ground-state-and-phonon-structure-of-fcc-al",
            "text": "",
            "title": "1. Calculation of the ground state and phonon structure of fcc Al."
        },
        {
            "location": "/tutorials/eph/#dataset-structure-and-flow",
            "text": "The teph_1.in file contains a number of datasets (DS). These will perform the\nground state (DS 1), then the phonon perturbations (DS 2-4), for a cell of FCC\naluminium. The DDK perturbation (DS 5) is also calculated, and will be used to\nobtain the Fermi velocities for the transport calculations in Section 6.  Once these are done, abinit calculates the wave functions on the full grid of\nk-points (using  kptopt\n3 ) in DS 6: these\nwill be used to calculate the electron-phonon matrix elements. In a full\ncalculation the density of k-points should be increased significantly here and\nfor the following datasets. For DS 1-5 only the normal convergence of the\nphonon frequencies should be ensured. In DS 7-10 only the matrix elements are\ncalculated, for the electron-phonon coupling and for the DDK\n(position/momentum matrix elements), on the dense and complete grid of\nk-points from DS 6. Note that the separation of the matrix element calculation\nis new from version 7.6.  The important variable for electron-phonon coupling calculations is  prtgkk \nThis prints out files suffixed GKK, which contain the electron-phonon matrix\nelements. The matrix elements only depend on the self-consistent perturbed\ndensity (files suffixed 1DENx), which we get from DS 2-4 (linked by variable get1den ). These can therefore be calculated on arbitrarily dense k-point\nmeshes. Even better, only a single step is needed, since no self-consistency\nis required. To enforce the calculation of all the matrix elements on all\nk-points, symmetries are disabled when  prtgkk  is set to 1, so be sure not\nto use it during the normal self-consistent phonon runs DS 2-4. Again this is\nvery different from versions before 7.6.",
            "title": "Dataset Structure and Flow"
        },
        {
            "location": "/tutorials/eph/#convergence",
            "text": "The calculation is done using minimal values of a number of parameters, in\norder to make it tractable in a time appropriate for a tutorial. The results\nwill be completely unconverged, but by the end of the lesson you should know\nhow to run a full electron phonon calculation, and be able to improve the\nconvergence on your own.  Edit the file teph_1.in. We now examine several variables. The kinetic energy\ncutoff  ecut  is a bit low, and the number of k-points (determined by ngkpt ) is much too\nlow. Electron-phonon calculations require a very precise determination of the\nFermi surface of the metal. This implies a very dense k-point mesh, and the\nconvergence of the grid must be checked. In our case, for Al, we will use a\n(non-shifted) 4x4x4 k-point grid, but a converged calculation needs more than\n16x16x16 points. This will be re-considered in section 5. The q-point grid\nwill be 2x2x2. It must be a sub-grid of the full k-point grid, and must\ncontain the \u0393 point.  The value of  acell  is fixed to a rounded value from experiment. It, too,\nshould be converged to get physical results (see   Tutorial\n3 ).  Note that the value of 1.0E-14 for  tolwfr  is tight, and should be even\nlower (down to 1.0E-20 or even 1.0E-22). This is because the wavefunctions\nwill be used later explicitly in the matrix elements for ANADDB, as opposed to\nonly energy values or densities, which are averages of the wavefunctions and\neigenenergies over k-points and bands. Electron-phonon quantities are delicate\nsums of a few of these small matrix elements (those near the Fermi surface),\nso each matrix element must be accurate. You can however set  prtwf  to 0 in\nthe phonon calculations, and avoid saving huge perturbed wavefunction files to\ndisk (you only need to keep the ground state wave functions, with prtwf1 1).",
            "title": "Convergence"
        },
        {
            "location": "/tutorials/eph/#execution",
            "text": "Run the first input (a few seconds on a recent PC), and you should obtain a\nvalue of   etotal -2.0828579336121 Ha  for the energy at the end of DATASET 1. The following datasets calculate the\nsecond order energy variations under atomic displacement in the three reduced\ndirections of the fcc unit cell. This is done for three different phonons,\nGamma, (1/2,0,0), and X=(1/2,1/2,0), which generate the 2x2x2 q-point grid\n(take care with the reduced coordinates of the reciprocal space points! They\nare not along cartesian directions, but along the reciprocal space lattice\nvectors.). The whole calculation follows the same lines as   Tutorial\nRF1 . As an example, DATASET 3 calculates the perturbed\nwavefunctions at k+q, for k in the ground state k-point mesh, and q=(1/2,0,0).\nThen, DATASET 3 calculates   2DTE 0.80951882353353  for the second-order energy variation for movement of the (unique) atom along\nthe first reduced direction for q=(1/2,0,0). The main differences with  \nTutorial RF1  are that Given we are dealing with a metal, no\nperturbation wrt electric fields is considered ; However, if you want to do\ntransport calculations, you need the ddk calculation anyway, to get the\nelectron band velocities. This is added in dataset 5. In the standard case,\nABINIT uses symmetry operations and non-stationary expressions to calculate a\nminimal number of 2DTE for different mixed second derivatives of the total\nenergy. In our case we use the first derivatives, and they must all be\ncalculated explicitly.  You are now the proud owner of 9 first-order matrix element files (suffixed\n_GKKx), corresponding to the three directional perturbations of the atom at\neach of the three q-points. The _GKK files contain the matrix elements of the\nelectron-phonon interaction, which we will extract and use in the following.\nBesides the _GKK files there are the _DDB files for each perturbation which\ncontain the 2DTE for the different phonons wavevectors q.",
            "title": "Execution"
        },
        {
            "location": "/tutorials/eph/#246-merging-of-the-2dte-_ddb-files-using-mrgddb",
            "text": "",
            "title": "2. Merging of the 2DTE _DDB files using MRGDDB."
        },
        {
            "location": "/tutorials/eph/#346-extraction-and-merging-of-the-electron-phonon-matrix-elements-using",
            "text": "MRGGKK.**",
            "title": "**3. Extraction and merging of the electron-phonon matrix elements using"
        },
        {
            "location": "/tutorials/eph/#446-basic-anaddb-calculation-of-electron-phonon-quantities",
            "text": "",
            "title": "4. Basic ANADDB calculation of electron-phonon quantities."
        },
        {
            "location": "/tutorials/eph/#546-convergence-tests-of-the-integration-techniques",
            "text": "",
            "title": "5. Convergence tests of the integration techniques."
        },
        {
            "location": "/tutorials/eph/#646-transport-quantities-within-boltzmann-theory",
            "text": "",
            "title": "6. Transport quantities within Boltzmann theory."
        },
        {
            "location": "/tutorials/dmft/",
            "text": "This lesson aims at showing how to perform a DFT+DMFT calculation using\nAbinit.\n\n\nYou will not learn here what is DFT+DMFT. But you will learn how to do a\nDFT+DMFT calculation and what are the main input variables controlling this\ntype of calculation.\n\n\nIt might be useful that you already know how to do PAW calculations using\nABINIT but it is not mandatory (you can follow the two lessons on PAW in\nABINIT (\nPAW1\n, \nPAW2\n)). Also the DFT+U\ntutorial in ABINIT (\nDFT+U\n) might be useful to know some\nbasic variables common to DFT+U and DFT+DMFT.\n\n\nThis lesson should take one hour to complete (especially if you have access to\nseveral processors).\n\n\n\n\n\n\n\n\nThe DFT+DMFT method: summary and key parameters. \n\n\n\n\n\n\n\n\n\n\nElectronic structure calculation of SrVO3 in LDA. \n\n\n\n\n\n\n\n\n\n\nElectronic Structure of SrVO3: DFT+DMFT calculation. \n\n\n\n\n\n\n\n\n\n\nElectronic Structure of SrVO3: Choice of correlated orbitals \n\n\n\n\n\n\n\n\n\n\nElectronic Structure of SrVO3: the Internal energy \n\n\n\n\n\n\n\n\n\n\nElectronic Structure of SrVO3 in DFT+DMFT: Equilibrium volume \n\n\n\n\n\n\n\n\n\n\nElectronic Structure of SrVO3: Conclusion \n\n\n\n\n\n\n\n\n\n\n1. The DFT+DMFT method: summary and key parameters\n\u00b6\n\n\nThe DFT+DMFT method aims at improving the description of strongly correlated\nsystems. Generally, these highly correlated materials contain rare-earth\nmetals or transition metals, which have partially filled \nd\n or \nf\n bands and\nthus localized electrons. For further information on this method, please refer\nto \nGeorges1996\n and \nKotliar2006\n. For an introduction to Many Body\nPhysics (Green\u2019s function, Self-energy, imaginary time, and Matsubara\nfrequencies), see e.g. \nColeman2015\n and \nTremblay2017\n.\n\n\nSeveral parameters (both physical and technical) needs to be discussed for a\nDFT+DMFT calculation.\n\n\n\n\nThe definition of correlated orbitals. In the ABINIT DMFT implementation, it is done with the help of Projected Wannier orbitals (see \nAmadon2008\n). The first part of the tutorial explains the importance of this choice. Wannier functions are unitarily related to a selected set of Kohn Sham (KS) wavefunctions, specified in ABINIT by band index \ndmftbandi\n, and \ndmftbandi\n. Thus, as empty bands are necessary to build Wannier functions, it is required in DMFT calculations that the KS Hamiltonian is correctly diagonalized: use high values for \nnnsclo\n, and \nnline\n for DMFT calculations and preceding DFT calculations. Roughly speaking, the larger dmftbandf-dmftbandi is, the more localized is the radial part of the orbital. Note that this definition is different from the definition of correlated orbitals in the DFT+U implementation in ABINIT (see \nAmadon2008a\n). The relation between the two expressions is briefly discussed in \nAmadon2012\n. \n\n\nThe definition of the Coulomb and exchange interaction U and J are done as in DFT+U through the variables \nupawu\n and \njpawu\n. They could be computed with the cRPA method, also available in ABINIT. The value of U and J should in principle depend on the definition of correlated orbitals. In this tutorial, U and J will be seen as parameters, as in the DFT+U approach. As in DFT+U, two double counting methods are available (see the \ndmft_dc\n input variable). Note that in version 7.10.5 (but not in later versions) \njpawu\n=0 is required if the density matrix in the correlated subspace is not diagonal. \n\n\nThe choice of the double counting correction. The current default choice in ABINIT is (\ndmft_dc\n=1) which corresponds to the full localized limit. \n\n\nThe method of resolution of the Anderson model. In ABINIT, it can be the Hubbard I method (\ndmft_solv\n=2) the Continuous time Quantum Monte Carlo (CTQMC) method (\ndmft_solv\n=5) or the static mean field method (\ndmft_solv\n=1) equivalent to usual DFT+U. \n\n\nThe solution of the Anderson Hamiltonian and the DMFT solution are strongly dependent over temperature. So the temperature \ntsmear\n is a very important physical parameter of the calculation. \n\n\nThe practical solution of the DFT+DMFT scheme is usually presented as a double loop over first the local Green\u2019s function, and second the electronic local density. (cf Fig. 1 in \nAmadon2012\n). The number of iterations of both loops are respectively given in ABINIT by keywords \ndmft_iter\n and \nnstep\n. Other useful variables are \ndmft_rslf\n=1 and \nprtden\n=-1 (to be able to restart the calculation from the density file). Lastly, one linear and one logarithmic grid are used for Matsubara Frequencies indicated by \ndmft_nwli\n and \ndmft_nwlo\n (Typical values are 100000 and 100, but convergence should be studied). A large number of informations are given in the log file using \npawprtvol\n=3. \n\n\n\n\n\n\n2. Electronic Structure of SrVO3 in LDA \n\u00b6\n\n\nYou might create a subdirectory of the ~abinit/tests/tutoparal directory, and\nuse it for the tutorial. In what follows, the names of files will be mentioned\nas if you were in this subdirectory\n\n\nCopy the files ../Input/tdmft_1.in and ../Input/tdmft_x.files in your Work\ndirectory and run ABINIT (as usual, the actual \u201cabinit\u201d command is something\nlike ../../../../src/98_main/abinit):\n\n\nabinit < tdmft_x.files > log_1\n\n\n\n\n\nThis run should take some time. It is recommended that you use at least 10\nprocessors (and 32 should be fast). It calculates the LDA ground state of\nSrVO3 and compute the band structure in a second step. The variable\n\npawfatbnd\n\nallows to create files with \u201cfatbands\u201d (see description of the variable in the\nlist of variables): the width of the line along each k-point path and for each\nband is proportional to the contribution of a given atomic orbital on this\nparticular Kohn Sham Wavefunction. A low cutoff and a small number of k-points\nare used in order to speed up the calculation. During this time you can take a\nlook at the input file. There are two datasets. The first one is a ground\nstate calculations with\n\nnnsclo\n=3 and\n\nnline\n=3 in order to\nhave well diagonalized eigenfunctions even for empty states. In practice, you\nhave however to check that the residue of wavefunctions is small at the end of\nthe calculation. In this calculation, we find 1.E-06, which is large (1.E-10\nwould be better, so nnsclo and nline should be increased, but it would take\nmore time). When the calculation is finished, you can plot the fatbands for\nVanadium and l=2. Several possibilities are available for that purpose. We\nwill work with the simple XMGRACE package (you need to install it, if not\nalready avaialble on your machine).\n\n\nxmgrace tdmft_1o_DS2_FATBANDS_at0001_V_is1_l0002\n\n\n\n\n\nThe band structure is given in eV.\n\n\n  \n\n\nand the fatbands for Oxygen and l=1 with\n\n\nxmgrace tdmft_1o_DS2_FATBANDS_at0003_O_is1_l0001.\n\n\n\n\n\n\nIn these plots, you recover the band structure of SrVO3 (see for comparison\nthe band structure of Fig.3 of \nAmadon2008\n). , and the main character of\nthe bands. Bands 21 to 25 are mainly \nd\n and bands 12 to 20 are mainly oxygen\n\np\n. However, we clearly see an important hybridization. The Fermi level (at 0\neV) is in the middle of bands 21-23.\n\n\nOne can easily check thats bands 21-23 are mainly \nd-t2g\n and bands 24-25 are\nmainly \neg\n: just use pawfatbnd=2 in tdmft_1.in and relaunch the calculations.\nThen the file tdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m-2,\ntdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m-1 and\ntdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m1 give you respectively the xy,yz and\nxz fatbands (ie \nd-t2g\n) and tdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m+0 and\ntdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m+2 give the z2 and z2-y2 fatbands (ie\n\neg\n).\n\n\nSo in conclusion of this study, the Kohn Sham bands which are mainly \nt2g\n are\nthe bands 21,22 and 23.\n\n\nOf course, it could have been anticipated from classical crystal field theory:\nthe vanadium is in the center of an octahedron of oxygen atoms, so \nd\n\norbitals are splitted in \nt2g\n and \neg\n. As \nt2g\n orbitals are not directed\ntoward oxygen atoms, \nt2g\n-like bands are lower in energy and filled with one\nelectron, whereas \neg\n-like bands are higher and empty.\n\n\nIn the next section, we will thus use the \nt2g\n-like bands to built Wannier\nfunctions and do the DFT+DMFT calculation.\n\n\n\n\n3. Electronic Structure of SrVO3: DFT+DMFT calculation \n\u00b6\n\n\n2.1. The input file for DMFT calculation: correlated orbitals, screened\n\u00b6\n\n\nCoulomb interaction and frequency mesh\n\n\nIn ABINIT, correlated orbitals are defined using the projected local orbitals\nWannier functions as outlined above. The definition requires to define a given\nenergy window from which projected Wannier functions are constructed. We would\nlike in this tutorial, to apply the DMFT method on \nd\n orbitals and for\nsimplicity on a subset of d orbitals, namely \nt2g\n orbitals (\neg\n orbitals\nplay a minor role because they are empty). But we need to define \nt2g\n\norbitals. For this, we will use Wannier functions.\n\n\nAs we have seen in the orbitally resolved fatbands, the Kohn Sham wave\nfunction contains a important weight of \nt2g\n atomic orbitals mainly in \nt2g\n-\nlike bands but also in oxygen bands.\n\n\nSo, we can use only the \nt2g\n-like bands to define Wannier functions or also\nboth the \nt2g\n-like and \nO-p\n-like bands.\n\n\nThe first case corresponds to the input file tdmft_2.in. In this case\n\ndmftbandi\n=21\nand\n\ndmftbandi\n=23.\nAs we only put the electron interaction on \nt2g\n orbitals, we have to use\nfirst lpawu=2, but also the keyword\n\ndmft_t2g\n=1 in\norder to restrict the application of interaction on \nt2g\n orbitals.\n\n\nNotice also that before launching a DMFT calculation, the LDA should be\nperfectly converged, including the empty states (check nline and nnsclo in the\ninput file). The input file tdmft_2.in thus contains two datasets: the first\none is a well converged LDA calculation, and the second is the DFT+DMFT\ncalculation.\n\n\nNotice the other dmft variables used in the input file and check their meaning\nin the input variable glossary. In particular, we are using dmft_solv=5 for\nthe dmft dataset in order to use the density-density continuous time quantum\nmonte carlo (CTQMC) solver. (See \nGull2011\n, as well as the ABINIT 2016\npaper \nGonze2016\n for details about the CTQMC implementation in ABINIT.)\n\nNote that the number of imaginary frequencies\n\ndmft_nwlo\n has\nto be set to at least twice the value of\n\ndmftqmc_l\n (the\ndiscretization in imaginary time). Here, we choose a temperature of 1200 K.\nFor lower temperature, the number of Matsubara frequencies should be higher.\n\n\nHere we use a fast calculation, with a small value of the parameters,\nespecially\n\ndmft_nwlo\n,\n\ndmftqmc_l\n and\n\ndmftqmc_n\n.\n\n\nLet\u2019s now discuss the value of the effective Coulomb interaction U\n(\nupawu\n) and J\n(\njpawu\n). The values\nof U and J used in ABINIT in DMFT use the same convention as in DFT+U\ncalculations in ABINIT (cf \nAmadon2008a\n). However, calculations in Ref.\n\nAmadon2008\n use for U and J the usual convention for _ t2g _ systems as\nfound in \nLechermann2006\n, Eq. 26 (see also the appendix in\n\nFresard1997\n). It corresponds to the Slater integral F4=0 and we can show\nthat U_abinit=U-4/3 J and J_abinit=7/6 J . So in order to use U=4 eV and\nJ=0.65 eV with these latter conventions (as in \nAmadon2008\n), we have to use\nin ABINIT:\n\nupawu\n=3.13333 eV;\n\njpawu\n=0.75833 eV\nand\n\nf4of2_sla\n=0.\n\n\nNow, you can launch the calculation:\n\n\nCopy the files ../Input/tdmft_2.in and modify tdmft_x.files in your Work\ndirectory and run ABINIT:\n\n\nmpirun -n 32 ../../../tmp/src/98_main/abinit < tdmft_x.files > log_2\n\n\n\n\n\n2.2. The DFT+DMFT calculation: the log file\n\u00b6\n\n\nWe are now going to browse quickly the log file (log_2) for this calculation.\n\n\nStarting from\n\n\n     =====  Start of DMFT calculation\n\n\n\n\n\nwe have first the definition of logarithmic grid for frequency, then, after:\n\n\n  == Prepare data for DMFT calculation\n\n\n\n\n\nThe projection of Kohn Sham wavefunctions and (truncated) atomic orbitals are\ncomputed (Eq.(2.1) in \nAmadon2012\n) and unnormalized orbitals are built\n(Eq.(2.2) in \nAmadon2012\n) The occupation matrix in this orbital basis is\n\n\n  ------ Symetrised Occupation\n\n\n\n        0.11142  -0.00000  -0.00000\n       -0.00000   0.11142  -0.00000\n       -0.00000  -0.00000   0.11142\n\n\n\n\n\nand the Normalization of this orbital basis is\n\n\n  ------ Symetrised Norm\n\n\n\n        0.65790   0.00000   0.00000\n        0.00000   0.65790   0.00000\n        0.00000   0.00000   0.65790\n\n\n\n\n\nNow, let\u2019s compare these numbers to other quantities. If the preceding LDA\ncalculation is converged, dmatpuopt=1 is used, and\n\ndmftbandi\n=1\nand\n\ndmftbandf\n=nband,\nthen the above Symetrised Occupation should be exactly equal to the occupation\nmatrix given in the usual DFT+U occupation matrix written in the log file\n(with dmatpuopt=1) (see discussion in \nAmadon2012\n). In our case, we are not\nin this case because\n\ndmftbandi\n=21\nso this condition is not fulfilled. Concerning the norm if these orbitals, two\nfactors play a role:\n\n\n\n\nFirstly, the number of Kohn Sham function used should be infinite (cf Eq. B.4 of \nAmadon2012\n), which is not the case here, because we take into account only bands 21-23. We emphasize that it is not a limitation of our approach, but just a physical choice concerning Wannier functions. This physical choice induces that these intermediate wave functions have a very low norm. \n\n\n\n\nSecondly, the atomic orbitals used to do the projection are cut at the PAW radius. As a consequence, even if we would use a complete set of KS wavefunctions and thus the closure relation, the norm could not be one. In our case, it could be at most 0.86852, which is the norm of the truncated atomic function of \nd\n orbitals of Vanadium used in this calculation. This number can be found in the log file by searching for ph0phiint (grep \u201cph0phiint(icount)= 1\u201d log_2). (See also the discussion in Section B.3 of \nAmadon2012\n). \nNext the LDA Green\u2019s function is computed.\n\n\n=====  LDA Green Function Calculation\n\n\n\n\n\n\nThen the Green\u2019s function is integrated to compute the occupation matrix.\nInterestingly, the density matrix here must be equal to the density matrix\ncomputed with the unnormalized correlated orbitals. If this is not the case,\nit means that the frequency grid is not sufficiently large. In our case, we\nfind:\n\n\n        0.11143   0.00000   0.00000\n        0.00000   0.11143   0.00000\n        0.00000   0.00000   0.11143\n\n\n\n\n\nSo the error is very small (1.10E-5). As an exercise, you can decrease the\nnumber of frequencies and see that the error becomes larger.\n\n\nThen the true orthonormal Wannier functions are built and the Green\u2019s function\nis computed in this basis just after:\n\n\n =====  LDA Green Function Calculation with renormalized psichi\n\n\n\n\n\nThe occupation matrix is now:\n\n\n        0.16937   0.00000  -0.00000\n        0.00000   0.16937   0.00000\n       -0.00000   0.00000   0.16937\n\n\n\n\n\nWe see that because of the orthonormalization of the orbitals necessary to\nbuilt Wannier functions, the occupation matrix logically increases.\n\n\nThen, after:\n\n\n =====  Define Interaction and self-energy\n\n\n\n\n\nThe Interaction kernel is computed from U and J, and the self energy is read\nfrom the disk file (if it exists). Then, the Green\u2019s function is computed with\nthe self energy and the Fermi level is computed. Then the DMFT Loop starts.\n\n\n =====  DMFT Loop starts here\n\n\n\n\n\nThe log contains a lot of details about the calculation (especially if\n\npawprtvol\n=3).\nIn order to have a more synthetic overview of the calculation (this is\nespecially useful to detect possible divergence of the calculation), the\nfollowing command extracts the evolution of the number of electrons (LDA, LDA\nwith Wannier functions, and DMFT number of electrons) as a function of\niterations (be careful, all numbers of electron are computed differently as\nexplained in the log file):\n\n\ngrep -e Nb -e ITER log_2\n\n\n\n\n\nBesides, during each DMFT calculation, there are one or more CTQMC\ncalculations:\n\n\nStarting QMC  (Thermalization)\n\n\n\n\n\nFor the sake of efficiency, the DMFT Loop is in this calculation done only\nonce before doing again the DFT Loop (cf Fig. 1 of \nAmadon2012\n). At the end\nof the calculation, the occupation matrix is written and is:\n\n\n          -- polarization spin component  1\n        0.16843   0.00000  -0.00000\n       -0.00000   0.16843  -0.00000\n       -0.00000   0.00000   0.16843\n\n\n\n\n\nWe can see that the total number of electron is very close to one and it does\nnot change much as a function of iterations. As an output of the calculation,\nyou can find the self energy in file tdmft_2o_DS2Self-omega_iatom0001_isppol1\nand the Green\u2019s function is file Gtau.dat.\n\n\n2.3. The self energy\n\u00b6\n\n\nYou can use the self-energy to compute the quasiparticle renormalization\nweight. We first extract the first six Matsubara frequencies:\n\n\nhead -n 8 tdmft_2o_DS2Self-omega_iatom0001_isppol1 > self.dat\n\n\n\n\n\nThen we plot the imaginary part of the self-energy (in imaginary frequency):\n\n\nxmgrace -block self.dat -bxy 1:3\n\n\n\n\n\nThen using xmgrace, you click on \nData\n, then on _ Transformations _ and then\non _ Regression _ and you can do a 4th order fit as:\n\n\n\nThe slope at zero frequency obtained is 0.82. From this number, the\nquasiparticle renormalisation weight can be obtained using Z=1/(1+0.82)=0.55.\n\n\n2.4. The Green\u2019s function for correlated orbitals\n\u00b6\n\n\nThe impurity (or local) Green\u2019s function for correlated orbitals is written in\nthe file Gtau.dat. It is plotted as a function of the imaginary time in the\ninterval [0,\u03b2] where \u03b2 is the inverse temperature (in Hartree). You can plot\nthis Green\u2019s function for the six \nt2g\n orbitals using e.g xmgrace\n\n\nxmgrace -nxy Gtau.dat\n\n\n\n\n\n\nAs the six _ t2g _ orbitals are degenerated, the six Green\u2019s function must be\nsimilar, within the stochastic noise. Moreover, this imaginary time Green\u2019s\nfunction must be negative and the value of G(\u03b2) for the orbital i is equal to\nthe opposite of the number of electrons in the orbital i (-ni). Optionnally,\nyou can check how the Green\u2019s function can be a rough way to check for the\nimportance of stochastic noise. For example, change for simplicity the number\nof steps for the DMFT calculation to 1:\n\n\nnstep2 1\n\n\n\n\n\nand then use a much smaller number of steps for the Monte Carlo Solver such as\n\n\ndmftqmc_n 1.d3\n\n\n\n\n\nsave the previous Gtau.dat file:\n\n\ncp Gtau.dat Gtau.dat_save\n\n\n\n\n\nThen relaunch the calculation. After it is completed, compare the new Green\u2019s\nfunction and the old one with the previous value of\n\ndmftqmc_n\n.\nUsing xmgrace,\n\n\nxmgrace -nxy Gtau.dat_save -nxy Gtau.dat\n\n\n\n\n\none obtains:\n\n\n\nOne naturally sees that the stochastic noise is much larger in this case. This\nstochastic noise can induces that the variation of physical quantities (number\nof electrons, electronic density, energy) as a function of the number of\niteration is noisy. Once you have finished this comparison, copy the saved\nGreen\u2019s function into Gtau.dat in order to continue the tutorial with a\nprecise Green\u2019s function in Gtau.dat:\n\n\ncp Gtau.dat_save Gtau.dat\n\n\n\n\n\n2.5. The local spectral function\n\u00b6\n\n\nYou can now use the imaginary time Green\u2019s function (contained in file\nGtau.dat) to compute the spectral function in real frequency. Such analytical\ncontinuation can be done on quantum Monte Carlo data using the Maximum Entropy\nmethod.\n\n\nA maximum entropy code has been published recently by D. Bergeron. It can be\ndownloaded\n\nhere\n. Please\ncite the related paper \nBergeron2016\n if you use this code in a publication.\n\n\nThe code has a lot of options, and definitely, the method should be understood\nand the user guide should be read before any real use. It is not the goal of\nthis DFT+DMFT tutorial to introduce to the Maximum Entropy Method (see\n\nBergeron2016\n and references therein). We give here a very quick way to\nobtain a spectral function. First, you have to install this code and the\narmadillo library by following the\n\nguidelines\n,\nand then launch it on the current directory in order to generate the default\ninput file OmegaMaxEnt_input_params.dat.\n\n\nOmegaMaxEnt\n\n\n\n\n\nThen edit the file OmegaMaxEnt_input_params.dat, and modify the first seven\nlines with:\n\n\ndata file: Gtau.dat\n\nOPTIONAL PREPROCESSING TIME PARAMETERS\n\nDATA PARAMETERS\nbosonic data (yes/[no]): no\nimaginary time data (yes/[no]): yes\n\n\n\n\n\nThen relaunch the code\n\n\nOmegaMaxEnt\n\n\n\n\n\nand plot the spectral function:\n\n\nxmgrace OmegaMaxEnt_final_result/optimal_spectral_function_*.dat\n\n\n\n\n\nChange the unit from Hartree to eV, and then, you have the spectral function:\n\n\n\nEven if the calculation is not well converged, you recognize in the spectral\nfunctions the quasiparticle peak as well as Hubbard bands at -2 eV and +2.5 eV\nas in Fig.4 of \nAmadon2008\n.\n\n\n\n\n4. Electronic Structure of SrVO3: Choice of correlated orbitals \n\u00b6\n\n\nPreviously, only the \nt2g\n-like bands were used in the definition of Wannier\nfunctions. If there were no hybridization between \nt2g\n orbitals and oxygen\n\np\n orbitals, the Wannier functions would be pure atomic orbitals and they\nwould not change if the energy window was increased. But there is an important\nhybridization, as a consequence, we will now built Wannier functions with a\nlarge window, by including oxygen \np\n-like bands in the definition of Wannier\nfunctions. Create a new input file:\n\n\ncp tdmft_2.in tdmft_3.in\n\n\n\n\n\nand use\n\ndmftbandi\n= 12\nin tdmft_3.in. Now the code will built Wannier functions with a larger window,\nincluding \nO-p\n-like bands, and thus much more localized. Launch the\ncalculation after having updated tdmft_x.files (if the calculation is too\nlong, you can decide to restart the second dataset directly from a converged\nLDA calculation instead of redoing the LDA calculation for each new DMFT\ncalculation).\n\n\nabinit < tdmft_x.files > log_3\n\n\n\n\n\nIn this case, both the occupation and the norm are larger because more states\nare taken into account: you have the occupation matrix which is\n\n\n  ------ Symetrised Occupation\n\n\n\n        0.23573  -0.00000  -0.00000\n       -0.00000   0.23573  -0.00000\n       -0.00000  -0.00000   0.23573\n\n\n\n\n\nand the norm is:\n\n\n  ------ Symetrised Norm\n\n\n\n        0.78223   0.00000  -0.00000\n        0.00000   0.78223  -0.00000\n       -0.00000  -0.00000   0.78223\n\n\n\n\n\nLet us now compare the total number of electron and the norm with the two\nenergy window:\n\n\n Energy window:                              _t2g_-like bands         _t2g_-like+_O-p_-like bands\n dmftbandi/dmftbandf:                           21/23                      12/23\n Norm:                                           0.66                       0.78\n LDA Number of electrons (before \u22a5):            0.66(=0.11*6)              1.42(=0.235*6)\n LDA Number of electrons (after  \u22a5):            1.02                       1.81\n\n\n\n\n\nFor the large window, as we use more Kohn Sham states, both the occupation and\nthe norm are larger, mainly because of the important weight of \nd\n orbitals in\nthe oxygen bands (because of the hybridization). Concerning the norm, remind\nthat in any case, it cannot be larger that 0.86. So as the Norm is 0.78, it\nmeans that by selecting bands 12-23 in the calculation, we took into account\n0.78/0.86*100=90\\% of the weight of the truncated atomic orbital among Kohn\nSham bands. Moreover, after orthonormalization, you can check that the\ndifference between LDA numbers of electrons is still large (1.02 versus 1.81),\neven if the orthonormalization effect is larger on the small windows case.\nNote that in this particular case, with diagonal matrix, the number of\nelectrons before and after orthonormalization are simply linked by\nn_before/Norm=n_after, i.e. 1.81\u22481.42/0.78 and 1.02\u22480.66/0.66\n\n\nAt the end of the DFT+DMFT calculation, the occupation matrix is written and\nis\n\n\n          -- polarization spin component  1\n        0.29450   0.00000   0.00000\n        0.00000   0.29450   0.00000\n        0.00000   0.00000   0.29450\n\n\n\n\n\nSimilarly to the previous calculation, the spectral function can be plotted\nusing the Maximum Entropy code: we find a spectral function with an\nhybridation peak at -5 eV, as described in Fig.5 of \nAmadon2008\n.\n\n\n\nResolving the lower Hubbard bands would require a more converged calculation.\n\n\nAs above, one can compute the renormalization weight and it gives 0.68. It\nshows that with the same value of U and J, interactions have a weaker effect\nfor the large window Wannier functions. Indeed, the value of the screened\ninteraction U should be larger because the Wannier functions are more\nlocalized (see discussion in \nAmadon2008\n).\n\n\n\n\n5. Electronic Structure of SrVO3: the internal energy \n\u00b6\n\n\nThe internal energy can be obtained with\n\n\ngrep -e ITER -e Internal log_3\n\n\n\n\n\nand select the second occurrence for each iteration (the double counting\nexpression) which should be accurate with iscf=17 (at convergence both\nexpressions are equals also in DFT+DMFT). So after gathering the data:\n\n\n  1      -1.51483736718814E+02\n  2      -1.51480860837124E+02\n  3      -1.51479980721122E+02\n  4      -1.51479456233951E+02\n  5      -1.51479511038784E+02\n  6      -1.51479570943715E+02\n  7      -1.51479487485907E+02\n  8      -1.51479539558451E+02\n  9      -1.51479457525225E+02\n 10      -1.51479582334490E+02\n\n\n\n\n\nYou can plot the evolution of the internal energy as a function of the\niteration.\n\n\n\nYou notice that the internal energy (in a DFT+DMFT calculations) does not\nconverge as a function of iterations, because there is a finite statistical\nnoise. So, as a function of iterations, first, the internal energy starts to\nconverge, because the modification of the energy induced by the self-\nconsistency cycle is larger than the statistical noise, but then the internal\nenergy fluctuates around a mean value. So if the statistical noise is larger\nthan the tolerance, the calculation will never converge. So if a given\nprecision on the total energy is expected, a practical solution is to increase\nthe number of Quantum Monte Carlo steps\n(\ndmftqmc_n\n) in\norder to lower the statistical noise. Also another solution is to do an\naverage over the last values of the internal energy. Note that in version\n7.10.5, only the Internal energy has a physical meaning in DFT+DMFT and not\nEtotal or ETOT.\n\n\n\n\n6. Electronic Structure of SrVO3 in DFT+DMFT: Equilibrium volume \n\u00b6\n\n\nWe focus now on the total energy. Create a new input file, tdmft_4.in:\n\n\ncp tdmft_3.in tdmft_4.in\n\n\n\n\n\nAnd use acell=7.1605 instead of 7.2605. Relaunch the calculation and note the\nInternal energy (grep Internal tdmft_4.out).\n\n\nRedo another calculation with acell=7.00. Then extract the LDA Internal energy\nand the DMFT Internal energy (grep Internal tdmft_5.out).\n\n\nacell   Internal energy LDA    Internal energy DMFT\n7.0000   -151.51517               -151.4797\n7.1605   -151.52399               -151.4877\n7.2605   -151.51515               -151.4795\n\n\n\n\n\nand then plot DMFT and LDA energies as a function of acell. You will notice\nthat the equilibrium volume is very weakly modified by the strong correlations\nis this case.\n\n\n\n\n7. Electronic Structure of SrVO3: Conclusion \n\u00b6\n\n\nTo sum up, the important physical parameters for DFT+DMFT are the definition\nof correlated orbitals, the choice of U and J (and double counting). The\nimportant technical parameters are the frequency and time grids as well as the\nnumber of steps for Monte Carlo, the DMFT loop and the DFT loop.\n\n\nWe showed in this tutorial how to compute spectral functions, quasiparticle\nrenormalization weights and total internal energy.",
            "title": "DMFT"
        },
        {
            "location": "/tutorials/dmft/#1-the-dftdmft-method-summary-and-key-parameters",
            "text": "The DFT+DMFT method aims at improving the description of strongly correlated\nsystems. Generally, these highly correlated materials contain rare-earth\nmetals or transition metals, which have partially filled  d  or  f  bands and\nthus localized electrons. For further information on this method, please refer\nto  Georges1996  and  Kotliar2006 . For an introduction to Many Body\nPhysics (Green\u2019s function, Self-energy, imaginary time, and Matsubara\nfrequencies), see e.g.  Coleman2015  and  Tremblay2017 .  Several parameters (both physical and technical) needs to be discussed for a\nDFT+DMFT calculation.   The definition of correlated orbitals. In the ABINIT DMFT implementation, it is done with the help of Projected Wannier orbitals (see  Amadon2008 ). The first part of the tutorial explains the importance of this choice. Wannier functions are unitarily related to a selected set of Kohn Sham (KS) wavefunctions, specified in ABINIT by band index  dmftbandi , and  dmftbandi . Thus, as empty bands are necessary to build Wannier functions, it is required in DMFT calculations that the KS Hamiltonian is correctly diagonalized: use high values for  nnsclo , and  nline  for DMFT calculations and preceding DFT calculations. Roughly speaking, the larger dmftbandf-dmftbandi is, the more localized is the radial part of the orbital. Note that this definition is different from the definition of correlated orbitals in the DFT+U implementation in ABINIT (see  Amadon2008a ). The relation between the two expressions is briefly discussed in  Amadon2012 .   The definition of the Coulomb and exchange interaction U and J are done as in DFT+U through the variables  upawu  and  jpawu . They could be computed with the cRPA method, also available in ABINIT. The value of U and J should in principle depend on the definition of correlated orbitals. In this tutorial, U and J will be seen as parameters, as in the DFT+U approach. As in DFT+U, two double counting methods are available (see the  dmft_dc  input variable). Note that in version 7.10.5 (but not in later versions)  jpawu =0 is required if the density matrix in the correlated subspace is not diagonal.   The choice of the double counting correction. The current default choice in ABINIT is ( dmft_dc =1) which corresponds to the full localized limit.   The method of resolution of the Anderson model. In ABINIT, it can be the Hubbard I method ( dmft_solv =2) the Continuous time Quantum Monte Carlo (CTQMC) method ( dmft_solv =5) or the static mean field method ( dmft_solv =1) equivalent to usual DFT+U.   The solution of the Anderson Hamiltonian and the DMFT solution are strongly dependent over temperature. So the temperature  tsmear  is a very important physical parameter of the calculation.   The practical solution of the DFT+DMFT scheme is usually presented as a double loop over first the local Green\u2019s function, and second the electronic local density. (cf Fig. 1 in  Amadon2012 ). The number of iterations of both loops are respectively given in ABINIT by keywords  dmft_iter  and  nstep . Other useful variables are  dmft_rslf =1 and  prtden =-1 (to be able to restart the calculation from the density file). Lastly, one linear and one logarithmic grid are used for Matsubara Frequencies indicated by  dmft_nwli  and  dmft_nwlo  (Typical values are 100000 and 100, but convergence should be studied). A large number of informations are given in the log file using  pawprtvol =3.",
            "title": "1. The DFT+DMFT method: summary and key parameters"
        },
        {
            "location": "/tutorials/dmft/#2-electronic-structure-of-srvo3-in-lda",
            "text": "You might create a subdirectory of the ~abinit/tests/tutoparal directory, and\nuse it for the tutorial. In what follows, the names of files will be mentioned\nas if you were in this subdirectory  Copy the files ../Input/tdmft_1.in and ../Input/tdmft_x.files in your Work\ndirectory and run ABINIT (as usual, the actual \u201cabinit\u201d command is something\nlike ../../../../src/98_main/abinit):  abinit < tdmft_x.files > log_1  This run should take some time. It is recommended that you use at least 10\nprocessors (and 32 should be fast). It calculates the LDA ground state of\nSrVO3 and compute the band structure in a second step. The variable pawfatbnd \nallows to create files with \u201cfatbands\u201d (see description of the variable in the\nlist of variables): the width of the line along each k-point path and for each\nband is proportional to the contribution of a given atomic orbital on this\nparticular Kohn Sham Wavefunction. A low cutoff and a small number of k-points\nare used in order to speed up the calculation. During this time you can take a\nlook at the input file. There are two datasets. The first one is a ground\nstate calculations with nnsclo =3 and nline =3 in order to\nhave well diagonalized eigenfunctions even for empty states. In practice, you\nhave however to check that the residue of wavefunctions is small at the end of\nthe calculation. In this calculation, we find 1.E-06, which is large (1.E-10\nwould be better, so nnsclo and nline should be increased, but it would take\nmore time). When the calculation is finished, you can plot the fatbands for\nVanadium and l=2. Several possibilities are available for that purpose. We\nwill work with the simple XMGRACE package (you need to install it, if not\nalready avaialble on your machine).  xmgrace tdmft_1o_DS2_FATBANDS_at0001_V_is1_l0002  The band structure is given in eV.      and the fatbands for Oxygen and l=1 with  xmgrace tdmft_1o_DS2_FATBANDS_at0003_O_is1_l0001.  \nIn these plots, you recover the band structure of SrVO3 (see for comparison\nthe band structure of Fig.3 of  Amadon2008 ). , and the main character of\nthe bands. Bands 21 to 25 are mainly  d  and bands 12 to 20 are mainly oxygen p . However, we clearly see an important hybridization. The Fermi level (at 0\neV) is in the middle of bands 21-23.  One can easily check thats bands 21-23 are mainly  d-t2g  and bands 24-25 are\nmainly  eg : just use pawfatbnd=2 in tdmft_1.in and relaunch the calculations.\nThen the file tdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m-2,\ntdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m-1 and\ntdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m1 give you respectively the xy,yz and\nxz fatbands (ie  d-t2g ) and tdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m+0 and\ntdmft_1o_DS2_FATBANDS_at0001_V_is1_l2_m+2 give the z2 and z2-y2 fatbands (ie eg ).  So in conclusion of this study, the Kohn Sham bands which are mainly  t2g  are\nthe bands 21,22 and 23.  Of course, it could have been anticipated from classical crystal field theory:\nthe vanadium is in the center of an octahedron of oxygen atoms, so  d \norbitals are splitted in  t2g  and  eg . As  t2g  orbitals are not directed\ntoward oxygen atoms,  t2g -like bands are lower in energy and filled with one\nelectron, whereas  eg -like bands are higher and empty.  In the next section, we will thus use the  t2g -like bands to built Wannier\nfunctions and do the DFT+DMFT calculation.",
            "title": "2. Electronic Structure of SrVO3 in LDA"
        },
        {
            "location": "/tutorials/dmft/#3-electronic-structure-of-srvo3-dftdmft-calculation",
            "text": "",
            "title": "3. Electronic Structure of SrVO3: DFT+DMFT calculation"
        },
        {
            "location": "/tutorials/dmft/#21-the-input-file-for-dmft-calculation-correlated-orbitals-screened",
            "text": "Coulomb interaction and frequency mesh  In ABINIT, correlated orbitals are defined using the projected local orbitals\nWannier functions as outlined above. The definition requires to define a given\nenergy window from which projected Wannier functions are constructed. We would\nlike in this tutorial, to apply the DMFT method on  d  orbitals and for\nsimplicity on a subset of d orbitals, namely  t2g  orbitals ( eg  orbitals\nplay a minor role because they are empty). But we need to define  t2g \norbitals. For this, we will use Wannier functions.  As we have seen in the orbitally resolved fatbands, the Kohn Sham wave\nfunction contains a important weight of  t2g  atomic orbitals mainly in  t2g -\nlike bands but also in oxygen bands.  So, we can use only the  t2g -like bands to define Wannier functions or also\nboth the  t2g -like and  O-p -like bands.  The first case corresponds to the input file tdmft_2.in. In this case dmftbandi =21\nand dmftbandi =23.\nAs we only put the electron interaction on  t2g  orbitals, we have to use\nfirst lpawu=2, but also the keyword dmft_t2g =1 in\norder to restrict the application of interaction on  t2g  orbitals.  Notice also that before launching a DMFT calculation, the LDA should be\nperfectly converged, including the empty states (check nline and nnsclo in the\ninput file). The input file tdmft_2.in thus contains two datasets: the first\none is a well converged LDA calculation, and the second is the DFT+DMFT\ncalculation.  Notice the other dmft variables used in the input file and check their meaning\nin the input variable glossary. In particular, we are using dmft_solv=5 for\nthe dmft dataset in order to use the density-density continuous time quantum\nmonte carlo (CTQMC) solver. (See  Gull2011 , as well as the ABINIT 2016\npaper  Gonze2016  for details about the CTQMC implementation in ABINIT.) \nNote that the number of imaginary frequencies dmft_nwlo  has\nto be set to at least twice the value of dmftqmc_l  (the\ndiscretization in imaginary time). Here, we choose a temperature of 1200 K.\nFor lower temperature, the number of Matsubara frequencies should be higher.  Here we use a fast calculation, with a small value of the parameters,\nespecially dmft_nwlo , dmftqmc_l  and dmftqmc_n .  Let\u2019s now discuss the value of the effective Coulomb interaction U\n( upawu ) and J\n( jpawu ). The values\nof U and J used in ABINIT in DMFT use the same convention as in DFT+U\ncalculations in ABINIT (cf  Amadon2008a ). However, calculations in Ref. Amadon2008  use for U and J the usual convention for _ t2g _ systems as\nfound in  Lechermann2006 , Eq. 26 (see also the appendix in Fresard1997 ). It corresponds to the Slater integral F4=0 and we can show\nthat U_abinit=U-4/3 J and J_abinit=7/6 J . So in order to use U=4 eV and\nJ=0.65 eV with these latter conventions (as in  Amadon2008 ), we have to use\nin ABINIT: upawu =3.13333 eV; jpawu =0.75833 eV\nand f4of2_sla =0.  Now, you can launch the calculation:  Copy the files ../Input/tdmft_2.in and modify tdmft_x.files in your Work\ndirectory and run ABINIT:  mpirun -n 32 ../../../tmp/src/98_main/abinit < tdmft_x.files > log_2",
            "title": "2.1. The input file for DMFT calculation: correlated orbitals, screened"
        },
        {
            "location": "/tutorials/dmft/#22-the-dftdmft-calculation-the-log-file",
            "text": "We are now going to browse quickly the log file (log_2) for this calculation.  Starting from       =====  Start of DMFT calculation  we have first the definition of logarithmic grid for frequency, then, after:    == Prepare data for DMFT calculation  The projection of Kohn Sham wavefunctions and (truncated) atomic orbitals are\ncomputed (Eq.(2.1) in  Amadon2012 ) and unnormalized orbitals are built\n(Eq.(2.2) in  Amadon2012 ) The occupation matrix in this orbital basis is    ------ Symetrised Occupation\n\n\n\n        0.11142  -0.00000  -0.00000\n       -0.00000   0.11142  -0.00000\n       -0.00000  -0.00000   0.11142  and the Normalization of this orbital basis is    ------ Symetrised Norm\n\n\n\n        0.65790   0.00000   0.00000\n        0.00000   0.65790   0.00000\n        0.00000   0.00000   0.65790  Now, let\u2019s compare these numbers to other quantities. If the preceding LDA\ncalculation is converged, dmatpuopt=1 is used, and dmftbandi =1\nand dmftbandf =nband,\nthen the above Symetrised Occupation should be exactly equal to the occupation\nmatrix given in the usual DFT+U occupation matrix written in the log file\n(with dmatpuopt=1) (see discussion in  Amadon2012 ). In our case, we are not\nin this case because dmftbandi =21\nso this condition is not fulfilled. Concerning the norm if these orbitals, two\nfactors play a role:   Firstly, the number of Kohn Sham function used should be infinite (cf Eq. B.4 of  Amadon2012 ), which is not the case here, because we take into account only bands 21-23. We emphasize that it is not a limitation of our approach, but just a physical choice concerning Wannier functions. This physical choice induces that these intermediate wave functions have a very low norm.    Secondly, the atomic orbitals used to do the projection are cut at the PAW radius. As a consequence, even if we would use a complete set of KS wavefunctions and thus the closure relation, the norm could not be one. In our case, it could be at most 0.86852, which is the norm of the truncated atomic function of  d  orbitals of Vanadium used in this calculation. This number can be found in the log file by searching for ph0phiint (grep \u201cph0phiint(icount)= 1\u201d log_2). (See also the discussion in Section B.3 of  Amadon2012 ). \nNext the LDA Green\u2019s function is computed.  =====  LDA Green Function Calculation    Then the Green\u2019s function is integrated to compute the occupation matrix.\nInterestingly, the density matrix here must be equal to the density matrix\ncomputed with the unnormalized correlated orbitals. If this is not the case,\nit means that the frequency grid is not sufficiently large. In our case, we\nfind:          0.11143   0.00000   0.00000\n        0.00000   0.11143   0.00000\n        0.00000   0.00000   0.11143  So the error is very small (1.10E-5). As an exercise, you can decrease the\nnumber of frequencies and see that the error becomes larger.  Then the true orthonormal Wannier functions are built and the Green\u2019s function\nis computed in this basis just after:   =====  LDA Green Function Calculation with renormalized psichi  The occupation matrix is now:          0.16937   0.00000  -0.00000\n        0.00000   0.16937   0.00000\n       -0.00000   0.00000   0.16937  We see that because of the orthonormalization of the orbitals necessary to\nbuilt Wannier functions, the occupation matrix logically increases.  Then, after:   =====  Define Interaction and self-energy  The Interaction kernel is computed from U and J, and the self energy is read\nfrom the disk file (if it exists). Then, the Green\u2019s function is computed with\nthe self energy and the Fermi level is computed. Then the DMFT Loop starts.   =====  DMFT Loop starts here  The log contains a lot of details about the calculation (especially if pawprtvol =3).\nIn order to have a more synthetic overview of the calculation (this is\nespecially useful to detect possible divergence of the calculation), the\nfollowing command extracts the evolution of the number of electrons (LDA, LDA\nwith Wannier functions, and DMFT number of electrons) as a function of\niterations (be careful, all numbers of electron are computed differently as\nexplained in the log file):  grep -e Nb -e ITER log_2  Besides, during each DMFT calculation, there are one or more CTQMC\ncalculations:  Starting QMC  (Thermalization)  For the sake of efficiency, the DMFT Loop is in this calculation done only\nonce before doing again the DFT Loop (cf Fig. 1 of  Amadon2012 ). At the end\nof the calculation, the occupation matrix is written and is:            -- polarization spin component  1\n        0.16843   0.00000  -0.00000\n       -0.00000   0.16843  -0.00000\n       -0.00000   0.00000   0.16843  We can see that the total number of electron is very close to one and it does\nnot change much as a function of iterations. As an output of the calculation,\nyou can find the self energy in file tdmft_2o_DS2Self-omega_iatom0001_isppol1\nand the Green\u2019s function is file Gtau.dat.",
            "title": "2.2. The DFT+DMFT calculation: the log file"
        },
        {
            "location": "/tutorials/dmft/#23-the-self-energy",
            "text": "You can use the self-energy to compute the quasiparticle renormalization\nweight. We first extract the first six Matsubara frequencies:  head -n 8 tdmft_2o_DS2Self-omega_iatom0001_isppol1 > self.dat  Then we plot the imaginary part of the self-energy (in imaginary frequency):  xmgrace -block self.dat -bxy 1:3  Then using xmgrace, you click on  Data , then on _ Transformations _ and then\non _ Regression _ and you can do a 4th order fit as:  \nThe slope at zero frequency obtained is 0.82. From this number, the\nquasiparticle renormalisation weight can be obtained using Z=1/(1+0.82)=0.55.",
            "title": "2.3. The self energy"
        },
        {
            "location": "/tutorials/dmft/#24-the-greens-function-for-correlated-orbitals",
            "text": "The impurity (or local) Green\u2019s function for correlated orbitals is written in\nthe file Gtau.dat. It is plotted as a function of the imaginary time in the\ninterval [0,\u03b2] where \u03b2 is the inverse temperature (in Hartree). You can plot\nthis Green\u2019s function for the six  t2g  orbitals using e.g xmgrace  xmgrace -nxy Gtau.dat  \nAs the six _ t2g _ orbitals are degenerated, the six Green\u2019s function must be\nsimilar, within the stochastic noise. Moreover, this imaginary time Green\u2019s\nfunction must be negative and the value of G(\u03b2) for the orbital i is equal to\nthe opposite of the number of electrons in the orbital i (-ni). Optionnally,\nyou can check how the Green\u2019s function can be a rough way to check for the\nimportance of stochastic noise. For example, change for simplicity the number\nof steps for the DMFT calculation to 1:  nstep2 1  and then use a much smaller number of steps for the Monte Carlo Solver such as  dmftqmc_n 1.d3  save the previous Gtau.dat file:  cp Gtau.dat Gtau.dat_save  Then relaunch the calculation. After it is completed, compare the new Green\u2019s\nfunction and the old one with the previous value of dmftqmc_n .\nUsing xmgrace,  xmgrace -nxy Gtau.dat_save -nxy Gtau.dat  one obtains:  \nOne naturally sees that the stochastic noise is much larger in this case. This\nstochastic noise can induces that the variation of physical quantities (number\nof electrons, electronic density, energy) as a function of the number of\niteration is noisy. Once you have finished this comparison, copy the saved\nGreen\u2019s function into Gtau.dat in order to continue the tutorial with a\nprecise Green\u2019s function in Gtau.dat:  cp Gtau.dat_save Gtau.dat",
            "title": "2.4. The Green's function for correlated orbitals"
        },
        {
            "location": "/tutorials/dmft/#25-the-local-spectral-function",
            "text": "You can now use the imaginary time Green\u2019s function (contained in file\nGtau.dat) to compute the spectral function in real frequency. Such analytical\ncontinuation can be done on quantum Monte Carlo data using the Maximum Entropy\nmethod.  A maximum entropy code has been published recently by D. Bergeron. It can be\ndownloaded here . Please\ncite the related paper  Bergeron2016  if you use this code in a publication.  The code has a lot of options, and definitely, the method should be understood\nand the user guide should be read before any real use. It is not the goal of\nthis DFT+DMFT tutorial to introduce to the Maximum Entropy Method (see Bergeron2016  and references therein). We give here a very quick way to\nobtain a spectral function. First, you have to install this code and the\narmadillo library by following the guidelines ,\nand then launch it on the current directory in order to generate the default\ninput file OmegaMaxEnt_input_params.dat.  OmegaMaxEnt  Then edit the file OmegaMaxEnt_input_params.dat, and modify the first seven\nlines with:  data file: Gtau.dat\n\nOPTIONAL PREPROCESSING TIME PARAMETERS\n\nDATA PARAMETERS\nbosonic data (yes/[no]): no\nimaginary time data (yes/[no]): yes  Then relaunch the code  OmegaMaxEnt  and plot the spectral function:  xmgrace OmegaMaxEnt_final_result/optimal_spectral_function_*.dat  Change the unit from Hartree to eV, and then, you have the spectral function:  \nEven if the calculation is not well converged, you recognize in the spectral\nfunctions the quasiparticle peak as well as Hubbard bands at -2 eV and +2.5 eV\nas in Fig.4 of  Amadon2008 .",
            "title": "2.5. The local spectral function"
        },
        {
            "location": "/tutorials/dmft/#4-electronic-structure-of-srvo3-choice-of-correlated-orbitals",
            "text": "Previously, only the  t2g -like bands were used in the definition of Wannier\nfunctions. If there were no hybridization between  t2g  orbitals and oxygen p  orbitals, the Wannier functions would be pure atomic orbitals and they\nwould not change if the energy window was increased. But there is an important\nhybridization, as a consequence, we will now built Wannier functions with a\nlarge window, by including oxygen  p -like bands in the definition of Wannier\nfunctions. Create a new input file:  cp tdmft_2.in tdmft_3.in  and use dmftbandi = 12\nin tdmft_3.in. Now the code will built Wannier functions with a larger window,\nincluding  O-p -like bands, and thus much more localized. Launch the\ncalculation after having updated tdmft_x.files (if the calculation is too\nlong, you can decide to restart the second dataset directly from a converged\nLDA calculation instead of redoing the LDA calculation for each new DMFT\ncalculation).  abinit < tdmft_x.files > log_3  In this case, both the occupation and the norm are larger because more states\nare taken into account: you have the occupation matrix which is    ------ Symetrised Occupation\n\n\n\n        0.23573  -0.00000  -0.00000\n       -0.00000   0.23573  -0.00000\n       -0.00000  -0.00000   0.23573  and the norm is:    ------ Symetrised Norm\n\n\n\n        0.78223   0.00000  -0.00000\n        0.00000   0.78223  -0.00000\n       -0.00000  -0.00000   0.78223  Let us now compare the total number of electron and the norm with the two\nenergy window:   Energy window:                              _t2g_-like bands         _t2g_-like+_O-p_-like bands\n dmftbandi/dmftbandf:                           21/23                      12/23\n Norm:                                           0.66                       0.78\n LDA Number of electrons (before \u22a5):            0.66(=0.11*6)              1.42(=0.235*6)\n LDA Number of electrons (after  \u22a5):            1.02                       1.81  For the large window, as we use more Kohn Sham states, both the occupation and\nthe norm are larger, mainly because of the important weight of  d  orbitals in\nthe oxygen bands (because of the hybridization). Concerning the norm, remind\nthat in any case, it cannot be larger that 0.86. So as the Norm is 0.78, it\nmeans that by selecting bands 12-23 in the calculation, we took into account\n0.78/0.86*100=90\\% of the weight of the truncated atomic orbital among Kohn\nSham bands. Moreover, after orthonormalization, you can check that the\ndifference between LDA numbers of electrons is still large (1.02 versus 1.81),\neven if the orthonormalization effect is larger on the small windows case.\nNote that in this particular case, with diagonal matrix, the number of\nelectrons before and after orthonormalization are simply linked by\nn_before/Norm=n_after, i.e. 1.81\u22481.42/0.78 and 1.02\u22480.66/0.66  At the end of the DFT+DMFT calculation, the occupation matrix is written and\nis            -- polarization spin component  1\n        0.29450   0.00000   0.00000\n        0.00000   0.29450   0.00000\n        0.00000   0.00000   0.29450  Similarly to the previous calculation, the spectral function can be plotted\nusing the Maximum Entropy code: we find a spectral function with an\nhybridation peak at -5 eV, as described in Fig.5 of  Amadon2008 .  \nResolving the lower Hubbard bands would require a more converged calculation.  As above, one can compute the renormalization weight and it gives 0.68. It\nshows that with the same value of U and J, interactions have a weaker effect\nfor the large window Wannier functions. Indeed, the value of the screened\ninteraction U should be larger because the Wannier functions are more\nlocalized (see discussion in  Amadon2008 ).",
            "title": "4. Electronic Structure of SrVO3: Choice of correlated orbitals"
        },
        {
            "location": "/tutorials/dmft/#5-electronic-structure-of-srvo3-the-internal-energy",
            "text": "The internal energy can be obtained with  grep -e ITER -e Internal log_3  and select the second occurrence for each iteration (the double counting\nexpression) which should be accurate with iscf=17 (at convergence both\nexpressions are equals also in DFT+DMFT). So after gathering the data:    1      -1.51483736718814E+02\n  2      -1.51480860837124E+02\n  3      -1.51479980721122E+02\n  4      -1.51479456233951E+02\n  5      -1.51479511038784E+02\n  6      -1.51479570943715E+02\n  7      -1.51479487485907E+02\n  8      -1.51479539558451E+02\n  9      -1.51479457525225E+02\n 10      -1.51479582334490E+02  You can plot the evolution of the internal energy as a function of the\niteration.  \nYou notice that the internal energy (in a DFT+DMFT calculations) does not\nconverge as a function of iterations, because there is a finite statistical\nnoise. So, as a function of iterations, first, the internal energy starts to\nconverge, because the modification of the energy induced by the self-\nconsistency cycle is larger than the statistical noise, but then the internal\nenergy fluctuates around a mean value. So if the statistical noise is larger\nthan the tolerance, the calculation will never converge. So if a given\nprecision on the total energy is expected, a practical solution is to increase\nthe number of Quantum Monte Carlo steps\n( dmftqmc_n ) in\norder to lower the statistical noise. Also another solution is to do an\naverage over the last values of the internal energy. Note that in version\n7.10.5, only the Internal energy has a physical meaning in DFT+DMFT and not\nEtotal or ETOT.",
            "title": "5. Electronic Structure of SrVO3: the internal energy"
        },
        {
            "location": "/tutorials/dmft/#6-electronic-structure-of-srvo3-in-dftdmft-equilibrium-volume",
            "text": "We focus now on the total energy. Create a new input file, tdmft_4.in:  cp tdmft_3.in tdmft_4.in  And use acell=7.1605 instead of 7.2605. Relaunch the calculation and note the\nInternal energy (grep Internal tdmft_4.out).  Redo another calculation with acell=7.00. Then extract the LDA Internal energy\nand the DMFT Internal energy (grep Internal tdmft_5.out).  acell   Internal energy LDA    Internal energy DMFT\n7.0000   -151.51517               -151.4797\n7.1605   -151.52399               -151.4877\n7.2605   -151.51515               -151.4795  and then plot DMFT and LDA energies as a function of acell. You will notice\nthat the equilibrium volume is very weakly modified by the strong correlations\nis this case.",
            "title": "6. Electronic Structure of SrVO3 in DFT+DMFT: Equilibrium volume"
        },
        {
            "location": "/tutorials/dmft/#7-electronic-structure-of-srvo3-conclusion",
            "text": "To sum up, the important physical parameters for DFT+DMFT are the definition\nof correlated orbitals, the choice of U and J (and double counting). The\nimportant technical parameters are the frequency and time grids as well as the\nnumber of steps for Monte Carlo, the DMFT loop and the DFT loop.  We showed in this tutorial how to compute spectral functions, quasiparticle\nrenormalization weights and total internal energy.",
            "title": "7. Electronic Structure of SrVO3: Conclusion"
        },
        {
            "location": "/tutorials/gw1/",
            "text": "This lesson aims at showing how to calculate self-energy corrections to the\nDFT Kohn-Sham eigenvalues in the GW approximation.\n\n\nA brief description of the formalism and of the equations implemented in the\ncode can be found in the\n\nGW_notes\n.\n\n\nThe different formulas of the GW formalism have been written in a pdf document\nby Valerio Olevano (who also wrote the first version of this tutorial), see\n~abinit/doc/theory/gwa.pdf .\n\n\nFor a much more consistent discussion of the theoretical aspects of the GW\nmethod we refer the reader to the review\n\n\n\n\n\u201cQuasiparticle calculations in solids\u201d, by Aulbur WG, Jonsson L, Wilkins JW, \n\nin Solid State Physics 54, 1-218 (2000),\n\nalso available at \n\nhttp://ftp.abinit.org/docs/quasiparticle_calculations_in_solids.pdf.bz2\n\n\n\n\nIt is suggested to\n\nacknowledge\n the\nefforts of developers of the GW part of ABINIT, by citing\n\nX. Gonze, G.-M. Rignanese, M. Verstraete, J.-M. Beuken, Y. Pouillon, R.\nCaracas, F. Jollet, M. Torrent, G. Zerah, M. Mikami, Ph. Ghosez, M. Veithen,\nJ.-Y. Raty, V. Olevano, F. Bruneval, L. Reining, R. Godby, G. Onida, D.R.\nHamann, and D.C. Allan. Zeit. Kristallogr. 220, 558-562 (2005).  \n\n\nThe user should be familiarized with the four basic lessons of ABINIT, see the\n\ntutorial home page\n.\n\n\nAfter this first tutorial on GW, you should read the \nsecond lesson on\nGW\n.\n\n\nThis lesson should take about 2 hours.\n\n\n\n\n\n\n\n\nGeneral example of well converged GW calculation. \n\n\n\n\n\n\n\n\n\n\nCalculation of the WFK and of the screening (SCR file). \n\n\n\n\n\n\n\n\n\n\nConvergence on the number of planewaves in the wavefunctions to calculate the Self-Energy. \n\n\n\n\n\n\n\n\n\n\nConvergence on the number of planewaves to calculate \u03a3x. \n\n\n\n\n\n\n\n\n\n\nConvergence on the number of bands to calculate \u03a3c. \n\n\n\n\n\n\n\n\n\n\nConvergence on the number of planewaves in the wavefunctions to calculate \u03b5-1. \n\n\n\n\n\n\n\n\n\n\nConvergence on the number of bands to calculate \u03b5-1. \n\n\n\n\n\n\n\n\n\n\nConvergence on the dimension of the \u03b5-1 matrix. \n\n\n\n\n\n\n\n\n\n\nCalculation of the GW corrections for the band gap in \u0393. \n\n\n\n\n\n\n\n\n\n\nAdvanced features: calculations without plasmon-pole models, and self-consistency. \n\n\n\n\n\n\n\n\n\n\n\u00b6\n\n\n** 1. Computation of the Silicon band gap at \u0393, using a GW calculation.\n\u00b6\n\n\n**\n\n\nBefore beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not \u201cWork_gw1\u201d ?\n\n\nAt the end of \nlesson 3\n, we computed the Kohn-Sham band\nstructure of silicon. In this approximation, the band dispersion as well as\nthe band widths are reasonable, but the band gaps are qualitatively wrong.\nNow, we will compute the band gaps much more accurately, using the so-called\nGW approximation.\n\n\nWe start by an example, in which we show how to perform in a single input file\nthe calculation of the ground state density, the Kohn Sham band structure, the\nscreening, and the GW corrections. We use reasonable values for the parameters\nof the calculation. The discussion on the convergence tests is postponed to\nthe next paragraphs. We will see that GW calculations are MUCH MORE time-\nconsuming than the computation of the Kohn-Sham eigenvalues.\n\n\nSo, let us run immediately this calculation, and while it is running, we will\nexplain what has been done.\n\n\nIn the directory ~abinit/tests/tutorial/Input/Work_gw1, copy the files\n~abinit/tests/tutorial/Input/tgw1_x.files and tgw1_1.in, and modify the\ntgw1_x.files file as usual (see lesson 1).\n\n\nThen, issue:\n\n\nabinit < tgw1_x.files >& tgw1_1.log &\n\n\n\n\n\nIt is very important to run this job in background because it takes about 1\nminute. In the meantime, you should read the following.\n\n\n\u00b6\n\n\n 1.a The four steps of a GW calculation.\n\u00b6\n\n\nIn order to perform a standard one-shot GW calculation one has to:\n\n\n\n\n\n\nRun a converged Ground State calculation to obtain the self-consistent density. \n\n\n\n\n\n\nPerform a non self-consistent run to compute the Kohn-Sham eigenvalues and the eigenfunctions including several empty states. Note that, unlike standard band structure calculations, here the KS states must be computed on a regular grid of k-points. \n\n\n\n\n\n\nUse \noptdriver\n=3 to compute the independent-particle susceptibility (\u03c70) on a regular grid of \nq\n-points, for at least two frequencies (usually, \u03c9=0 and a large purely imaginary frequency - of the order of the plasmon frequency, a dozen of eV). The inverse dielectric matrix (\u03b5-1) is then obtained via matrix inversion and stored in an external file (SCR). The list of \nq\n-points is automatically defined by the k-mesh used to generate the KS states in the previous step. \n\n\n\n\n\n\nUse \noptdriver\n=4 to compute the self-energy (\u03a3) matrix element for a given set of k-points in order to obtain the GW quasiparticle energies Note that the k-point must belong to the k-mesh used to generate the WFK file in step 2. \n\n\n\n\n\n\nThe flowchart diagram of a standard one-shot run is depicted in the figure\nbelow.\n\n\n\n\nThe input file tgw1_1.in has precisely that structure: there are four\ndatasets.\n\n\nThe first dataset performs the SCF calculation to get the density. The second\ndataset reads the previous density file and performs a NSCF run including\nseveral empty states. The third dataset reads the WFK file produced in the\nprevious step and drives the computation of susceptibility and dielectric\nmatrices, producing another specialized file, tgw1_xo_DS2_SCR (_SCR for\n\u201cScreening\u201d, actually the inverse dielectric matrix \u03b5-1). Then, in the fourth\ndataset, the code calculates the quasiparticle energies for the 4th and 5th\nbands at the \u0393 point.\n\n\nSo, you can edit this tgw1_1.in file.\n\n\nThe dataset-independent part of this file (the last half of the file),\ncontains the usual set of input variables describing the cell, atom types,\nnumber, position, planewave cut-off energy, SCF convergence parameters driving\nthe Kohn-Sham band structure calculation. Then, for the fourth datasets, you\nwill find specialized additional input variables.\n\n\n\u00b6\n\n\n 1.b Generating the Kohn-Sham band structure: the WFK file.\n\u00b6\n\n\nDataset 1 is a rather standard SCF calculation. It\u2019s worth noticing that we\nuse tolvrs to stop the SCF cycle because we want a well-converged KS potential\nto be used in the subsequent NSCF calculation. Dataset 2 computes 40 bands and\nwe set nbdbuf to 5 so that only the first 35 states must be converged within\ntolwfr. This tricks allows us to save several minimization steps because the\nlast bands usually require more iterations to converge\n\n\n############\n# Dataset 1\n############\n# SCF-GS run \nnband1  6\ntolvrs1 1.0e-10\n\n############\n# Dataset 2\n############\n# Definition of parameters for the calculation of the WFK file\nnband2      40       # Number of (occ and empty) bands to be computed\nnbdbuf2      5\niscf2       -2\ngetden2     -1\ntolwfr2  1.0d-18     # Will stop when this tolerance is achieved\n\n\n\n\n\n\u00b6\n\n\n 1.c Generating the screening: the SCR file.\n\u00b6\n\n\nIn dataset 3, the calculation of the screening (susceptibility, dielectric\nmatrix) is performed. We need to set \noptdriver\n=3 to do that:\n\n\noptdriver3  3        # Screening calculation\n\n\n\n\n\nThe \ngetwfk\n input variable is similar to other \u201cget\u201d input variables of\nABINIT:\n\n\ngetwfk3     -1       # Obtain WFK file from previous dataset\n\n\n\n\n\nIn this case, it tells the code to use the WFK file calculated in the previous\ndataset.\n\n\nThen, three input variables describe the computation:\n\n\nnband3      17       # Bands used in the screening calculation\necut        8.0      # Cut-off energy of the planewave set to represent the wavefunctions\necuteps3    3.6      # Cut-off energy of the planewave set to represent the dielectric matrix\n\n\n\n\n\nIn this case, we use 17 bands to calculate the Kohn-Sham response function\n\n\\chi^{(0)}_{KS}\n. A cut-off of 8 Hartree is used to represent the\nwavefunctions in the calculation of \n\\chi^{(0)}_{KS}\n. The dimension of\n\n\\chi^{(0)}_{KS}\n, as well as all the other matrices (\n\\chi\n, \n\\epsilon\n) is\ndetermined by \necuteps\n=3.6 Hartree, giving 169 planewaves.\n\n\nFinally, we define the frequencies at which the screening must be evaluated:\n\u03c9=0.0 eV and the imaginary frequency \u03c9= i 16.7 eV. The latter is determined by\nthe input variable \nppmfrq\n\n\nppmfrq3    16.7 eV  # Imaginary frequency where to calculate the screening\n\n\n\n\n\nThe two frequencies are used to calculate the plasmon-pole model parameters.\nFor the non-zero frequency it is recommended to use a value close to the\nplasmon frequency for the plasmon-pole model to work well. Plasmons\nfrequencies are usually close to 0.5 Hartree. The parameters for the screening\ncalculation are not far from the ones that give converged Energy Loss Function\n(-Im \\epsilon^-1_00) spectra, So that one can start up by using indications\nfrom EELS calculations existing in literature.\n\n\n\u00b6\n\n\n 1.d Computing the GW energies.\n\u00b6\n\n\nIn dataset 4 the calculation of the Self-Energy matrix elements is performed.\nOne needs to define the driver option, as well as the _WFK and _SCR files.\n\n\noptdriver4  4       # Self-Energy calculation\ngetwfk4    -2       # Obtain WFK file from dataset 1\ngetscr4    -1       # Obtain SCR file from previous dataset\n\n\n\n\n\nThe \ngetscr\n input variable is similar to other \u201cget\u201d input variables of\nABINIT.\n\n\nThen, comes the definition of parameters needed to compute the self-energy. As\nfor the computation of the susceptibility and dielectric matrices, one must\ndefine the set of bands, and two sets of planewaves:\n\n\nnband4       30      # Bands to be used in the Self-Energy calculation\necutsigx4   6.0      # Dimension of the G sum in Sigma_x\n                     # (the dimension in Sigma_c is controlled by npweps)\n\n\n\n\n\nIn this case, \nnband\n controls the number of bands used to calculate the\ncorrelation part of the Self-Energy. \necutsigx\n gives the number of\nplanewaves used to calculate \u03c3x (the exchange part of the self-energy). The\nsize of the planewave set used to compute \u03a3c (the correlation part of the\nself-energy) is controlled by \necuteps\n (cannot be larger than the value\nused to generate the SCR file). However, it is taken equal to the number of\nplanewave of \u03a3x if the latter is smaller than the one for \u03a3c.\n\n\nThen, come the parameters defining the k-points and the band indices for which\nthe quasiparticle energies will be computed:\n\n\nnkptgw4      1               # number of k-point where to calculate the GW correction\nkptgw4                       # k-points\n  -0.125    0.000    0.000\nbdgw4       4  5             # calculate GW corrections for bands from 4 to 5\n\n\n\n\n\nnkptgw\n defines the number of k-points for which the GW corrections will be\ncomputed. The k-point reduced coordinates are specified in \nkptgw\n. At\npresent, they MUST belong to the k-mesh used to generate the WFK file. Hence\nif you wish the GW correction in a particular k-point, you should choose a\ngrid containing it. Usually this is done by taking the k-point grid where the\nconvergence is achieved and shifting it such as at least one k-point is placed\non the wished position in the Brillouin zone. \nbdgw\n gives the\nminimum/maximum band whose energies are calculated for the given k-point.\n\n\nThere is an additional parameter, called \nzcut\n, related to the self-energy\ncomputation. It is meant to avoid some divergences that might occur in the\ncalculation due to integrable poles along the integration path.\n\n\n\u00b6\n\n\n 1.e Examination of the output file.\n\u00b6\n\n\nLet us hope that your calculation has been completed, and that we can examine\nthe output file. Open tgw1_1.out in your preferred editor and find the section\ncorresponding to DATASET 3.\n\n\nAfter the description of the unit cell and of the pseudopotentials, you will\nfind the list of k-points used for the electrons and the grid of q-point (in\nthe Irreducible part of the Brillouin Zone) on which the susceptibility and\ndielectric matrices will be computed. It is a set of BZ points defined as all\nthe possible differences among the k-points (\nq=k-k\u2019\n) of the grid chosen to\ngenerate the WFK file. From the last statement it is clear the interest to\nchoose homogeneous k-point grids, in order not to minimize the number of\nq-points.\n\n\nAfter this section, the code prints the parameters of the FFT grid needed to\nrepresent the wavefunctions and to compute their convolution (required for the\nscreening matrices). Then we have some information about the MPI distribution\nof the bands and the total number of valence electrons computed by integrating\nthe density in the unit cell.\n\n\nOn the basis of the density, one can obtain the classical Drude plasmon\nfrequency. The next lines calculate the average density of the system, and\nevaluate the r_s parameter, then compute the Drude plasmon frequency. This is\nthe value used by default for \nppmfrq\n. It is in fact the second frequency\nwhere the code calculates the dielectric matrix to adjust the plasmon-pole\nmodel parameters. It has been found that Drude plasma frequency is a\nreasonable value where to adjust the model. The control over this parameter is\nhowever left to the user in order to check that the result does not change\nwhen changing \nppmfrq\n. If it is the case, then the plasmon-pole model is\nnot appropriated and one should go beyond by taking into account a full\ndynamical dependence in the screening (see later, the contour-deformation\nmethod). However, the plasmon-pole model has been found to work well for a\nvery large range of systems when focusing only on the real part of the GW\ncorrections.\n\n\nAt the end of the screening calculation, the macroscopic dielectric constant\nis printed:\n\n\n  dielectric constant =  13.5073\n  dielectric constant without local fields =  15.0536\n\n\n\n\n\nNote that the convergence in the dielectric constant DOES NOT guarantee the\nconvergence in the GW corrections. In fact, the dielectric constant is\nrepresentative of only one element i.e. the head of the full dielectric\nmatrix. Even if the convergence on the dielectric constant with local fields\ntakes somehow into account also other non-diagonal elements. In a GW\ncalculation all the \u03b5-1 matrix is used to build the Self-Energy operator.\n\nThe dielectric constant here reported is the so-called RPA dielectric constant\ndue to the electrons. Although evaluated at zero frequency, it is understood\nthat the ionic response is not included (this term can be computed with DFPT\nand ANADDB). The RPA dielectric constant restricted to electronic effects is\nalso not the same as the one computed in the RESPFN part of ABINIT, that\nincludes exchange-correlation effects.\n\n\nWe now enter the fourth dataset. As for dataset 3, after some general\ninformation (origin of WFK file, header, description of unit cell, k-points,\nq-points), the description of the FFT grid and jellium parameters, there is\nthe echo of parameters for the plasmon-pole model, and the inverse dielectric\nfunction (the screening). The self-energy operator has been constructed, and\none can evaluate the GW energies, for each of the states.\n\n\nThe final results are:\n\n\nk =   -0.125   0.000   0.000\n Band     E0  <VxcLDA>   SigX SigC(E0)    Z dSigC/dE  Sig(E)    E-E0     E\n    4   5.616 -11.115 -12.334   1.257   0.775  -0.290 -11.085   0.030   5.646\n    5   8.357 -10.140  -5.951  -3.336   0.779  -0.284  -9.476   0.664   9.021\n\n E^0_gap          2.741\n E^GW_gap         3.375\n DeltaE^GW_gap    0.634\n\n\n\n\n\nFor the desired k-point, state 4, then state 5, one finds different\ninformation:\n\n\n\n\n\n\nE0 is the Kohn-Sham eigenenergy \n\n\n\n\n\n\nVxcLDA gives the average Kohn-Sham exchange-correlation potential \n\n\n\n\n\n\nSigX gives the exchange contribution to the self-energy \n\n\n\n\n\n\nSigC(E0) gives the correlation contribution to the self-energy, evaluated at the Kohn-Sham eigenenergy\n\n\n\n\n\n\nZ is the renormalisation factor \n\n\n\n\n\n\ndSigC/dE is the energy derivative of SigC with respect to the energy\n\n\n\n\n\n\nSigC(E) gives the correlation contribution to the self-energy, evaluated at the GW energy\n\n\n\n\n\n\nE-E0 is the difference between GW energy and Kohn-Sham eigenenergy \n\n\n\n\n\n\nE is the GW energy \n\n\n\n\n\n\nIn this case, the gap is also analyzed: E^0_gap is the direct Kohn-Sham gap at\nthat k point (and spin, in the case of spin-polarized calculations), E^GW_gap\nis the GW one, and DeltaE^GW_gap is the difference. This direct gap is always\ncomputed between the band whose number is equal to the number of electrons in\nthe cell divided by two (integer part, in case of spin-polarized calculation),\nand the next one. (Warning: for a metal, these two bands do not systematically\nlie below and above the Fermi energy - but the concept of a direct gap is not\nrelevant in that case).\n\n\nIt is seen that the average Kohn-Sham exchange-correlation potential for the\nstate 4 (a valence state) is very close to the exchange self-energy\ncorrection. For that state, the correlation correction is small, and the\ndifference between Kohn-Sham and GW energies is also small (43 meV). By\ncontrast, the exchange self-energy is much smaller than the average Kohn-Sham\npotential for the state 5 (a conduction state), but the correlation correction\nis much larger than for state 4. On the whole, the difference between Kohn-\nSham and GW energies is not very large, but nevertheless, it is quite\nimportant when compared with the size of the gap.\n\n\n\n\n\u00b6\n\n\n2 Preparing convergence studies: Kohn-Sham structure (WFK file) and screening (SCR file). \n\n\nIn the following sections, we will perform different convergence studies. In\norder to keep the CPU time at a reasonable level, we will use fake WFK and SCR\ndata. Moreover we will only consider the correction at the \u0393 point only. In\nthis way, we will be able to verify convergence aspects that could be very\ncumbersome (at least in the framework of a tutorial) if more k-points were\nused. Testing the convergence with a \u0393 point only grid of k point represents a\nconvenient approach although some caution should always be used.\n\n\nIn directory ~abinit/tests/tutorial/Input/Work_gw1, copy the file\n../tgw1_2.in, and modify the tgw1_x.files file as usual. Edit the tgw1_2.in\nfile, and take the time to examine it.\n\n\nThen, issue:\n\n\nabinit < tgw1_x.files >& tgw1_2.log &\n\n\n\n\n\nAfter this step you will need the WFK and SCR files produced in this run for\nthe next runs (up to 6.8). Move tgw1o_DS2_WFK to tgw1o_DS1_WFK and\ntgw1o_DS3_SCR to tgw1o_DS1_SCR.\n\n\nThe next sections are intended to show you how to find the converged\nparameters for a GW calculation. In principle, the following parameters might\nbe used to decrease the CPU time and/or the memory requirements:\n\noptdriver\n=3\n\necutwfn\n, \necuteps\n, \nnband\n. and for\n\noptdriver\n=4,\n\necutwfn\n, \necutsigx\n, \nnband\n.\n\n\nBefore 2008, the advice was indeed to check independently what was the best\nvalue for each of these. However, with the evolution of memory/disk space, as\nwell as the advent of new techniques to diminish the number of bands that is\nneeded (see e.g. F. Bruneval, X. Gonze, Phys. Rev. B 78, 085125 (2008), and\nthe input variable \ngwcomp\n), standard calculations nowadays only need the\ntuning of \nnband\n \necuteps\n, simultaneously for\n\noptdriver\n=3 and\n=4. Indeed, \necutwfn\n and can have the default value of \necut\n, while\n\necutsigx\n can have the default value of 4*\necut\n for norm-conserving\npseudopotentials, or \npawecutdg\n for PAW calculations. Actually, the present\ntutorial needs to be updated to account for the current practice.\n\n\nWe begin by the convergence study on the three parameters needed in the self-\nenergy calculation\n(\noptdriver\n=4):\n\necutwfn\n, \necutsigx\n, \nnband\n. This is because for these, we will not\nneed a double dataset loop to check this convergence, and we will rely on the\npreviously determined SCR file.\n\n\n\n\n\u00b6\n\n\n3 Convergence on the number of planewaves in the wavefunctions to calculate the Self-Energy (optional). \n\n\nThe convergence study is done in the input file tgw1_3.in. First, we check the\nconvergence on the number of planewaves used to describe the wavefunctions, in\nthe calculation of the Self-Energy. This will be done by defining five\ndatasets, with increasing \necutwfn\n:\n\n\nndtset     5\necutwfn:  3.0\necutwfn+  1.0\n\n\n\n\n\nIn directory ~abinit/tests/tutorial/Input/Work_gw1, copy the file\n../tgw1_3.in, and modify the tgw1_x.files file as usual. Edit the tgw1_3.in\nfile, and take the time to examine it.\n\n\nThen, issue:\n\n\nabinit < tgw1_x.files >& tgw1_3.log &\n\n\n\n\n\nEdit the output file. The number of plane waves used for the wavefunctions in\nthe computation of the self-energy is mentioned in the fragments of output:\n\n\n SIGMA fundamental parameters:\n PLASMON POLE MODEL\n number of plane-waves for SigmaX                  169\n number of plane-waves for SigmaC and W            169\n number of plane-waves for wavefunctions            59\n\n\n\n\n\nGathering the GW energies for each planewave set, one gets:\n\n\n number of plane-waves for wavefunctions            59\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.490 -15.198   4.050   0.812  -0.232 -11.212   0.277   6.192\n    5   8.445  -9.431  -3.101  -5.381   0.822  -0.216  -8.651   0.781   9.226\n\n number of plane-waves for wavefunctions           113\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.648 -15.253   3.853   0.807  -0.239 -11.448   0.200   6.115\n    5   8.445  -9.685  -3.234  -5.511   0.818  -0.222  -8.916   0.769   9.214\n\n number of plane-waves for wavefunctions           137\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.244   3.810   0.806  -0.241 -11.474   0.165   6.080\n    5   8.445  -9.675  -3.213  -5.557   0.818  -0.223  -8.935   0.740   9.185\n\n number of plane-waves for wavefunctions           169\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.244   3.801   0.806  -0.241 -11.481   0.157   6.072\n    5   8.445  -9.686  -3.216  -5.571   0.818  -0.223  -8.950   0.736   9.181\n\n number of plane-waves for wavefunctions           259\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.650 -15.250   3.790   0.806  -0.241 -11.497   0.152   6.068\n    5   8.445  -9.697  -3.218  -5.583   0.818  -0.223  -8.965   0.733   9.178\n\n\n\n\n\nSo that \necutwfn\n=5.0 (\nnpwwfn\n=137) can be considered to lead to\neigenenergies converged within 0.01 eV.\n\n\n\n\n\u00b6\n\n\n4 Convergence on the number of planewaves to calculate \u03a3x (optional). \n\n\nSecond, we check the convergence on the number of planewaves in the\ncalculation of \u03a3x. This study in done in tgw1_4.in As mentioned in the\ndocumentation \necutsigx\n, safe values exist for \necutsigx\n, so that if you\ndo not want to squeeze the CPU time for your calculation (you might gain only\na few percent in some cases \u2026), you can impose these values, and skip the\ncorresponding convergence study.\n\n\nIn this lesson, this convergence study will be done by defining five datasets,\nwith increasing \necutsigx\n:\n\n\nndtset     7\necutsigx:  3.0\necutsigx+  1.0\n\n\n\n\n\nIn directory ~abinit/tests/tutorial/Input/Work_gw1, copy the file\n../tgw1_4.in, and modify the tgw1_x.files file as usual. Edit the tgw1_4.in\nfile, and take the time to examine it.\n\n\nThen, issue:\n\n\nabinit < tgw1_x.files >& tgw1_4.log &\n\n\n\n\n\nEdit the output file. The number of plane waves used for \u03a3x is mentioned in\nthe fragments of output:\n\n\n SIGMA fundamental parameters:\n PLASMON POLE MODEL\n number of plane-waves for SigmaX                   59\n number of plane-waves for SigmaC and W             59\n\n\n\n\n\nGathering the GW energies for each planewave set, one gets:\n\n\n number of plane-waves for SigmaX                   59\n number of plane-waves for SigmaC and W             59\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.194   3.886   0.808  -0.238 -11.372   0.268   6.183\n    5   8.445  -9.675  -3.174  -5.573   0.818  -0.222  -8.916   0.759   9.204\n\n number of plane-waves for SigmaX                  113\n number of plane-waves for SigmaC and W            113\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.236   3.825   0.806  -0.240 -11.455   0.184   6.099\n    5   8.445  -9.675  -3.208  -5.561   0.818  -0.222  -8.934   0.741   9.186\n\n number of plane-waves for SigmaX                  137\n number of plane-waves for SigmaC and W            137\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.241   3.815   0.806  -0.240 -11.468   0.172   6.087\n    5   8.445  -9.675  -3.211  -5.558   0.818  -0.223  -8.933   0.741   9.187\n\n number of plane-waves for SigmaX                  169\n number of plane-waves for SigmaC and W            169\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.244   3.810   0.806  -0.241 -11.474   0.165   6.080\n    5   8.445  -9.675  -3.213  -5.557   0.818  -0.223  -8.935   0.740   9.185\n\n number of plane-waves for SigmaX                  259\n number of plane-waves for SigmaC and W            169\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.246   3.810   0.806  -0.241 -11.475   0.164   6.079\n    5   8.445  -9.675  -3.215  -5.557   0.818  -0.223  -8.937   0.738   9.183\n\n number of plane-waves for SigmaX                  283\n number of plane-waves for SigmaC and W            169\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.246   3.810   0.806  -0.241 -11.475   0.164   6.079\n    5   8.445  -9.675  -3.215  -5.557   0.818  -0.223  -8.937   0.738   9.183\n\n number of plane-waves for SigmaX                  283\n number of plane-waves for SigmaC and W            169\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.915 -11.639 -15.246   3.810   0.806  -0.241 -11.475   0.164   6.079\n    5   8.445  -9.675  -3.215  -5.557   0.818  -0.223  -8.937   0.738   9.183\n\n\n\n\n\nSo that ecutsigx=6.0 (npwsigx=169) can be considered converged within 0.01 eV.\n\n\n\n\n\u00b6\n\n\n5 Convergence on the number of bands to calculate \u03a3c (important). \n\n\nAt last, as concerns the computation of the self-energy, we check the\nconvergence on the number of bands in the calculation of \u03a3c. This convergence\nstudy is rather important, usually, BUT it can be done at the same time as the\nconvergence study for the number of bands for the dielectric matrix.\n\n\nThe convergence on the number of bands to calculate the Self-Energy will be\ndone by defining five datasets, with increasing \nnband\n:\n\n\nndtset  5\nnband:  50\nnband+  50\n\n\n\n\n\nIn directory ~abinit/tests/tutorial/Input/Work_gw1, copy the file\n../tgw1_5.in, and modify the tgw1_x.files file as usual. Edit the tgw1_5.in\nfile, and take the time to examine it.\n\nThen, issue:\n\n\nabinit < tgw1_x.files >& tgw1_5.log &\n\n\n\n\n\nEdit the output file. The number of bands used for the self-energy is\nmentioned in the fragments of output:\n\n\n SIGMA fundamental parameters:\n PLASMON POLE MODEL\n number of plane-waves for SigmaX                  169\n number of plane-waves for SigmaC and W            169\n number of plane-waves for wavefunctions           137\n number of bands                                    50\n\n\n\n\n\nGathering the GW energies for each number of bands, one gets:\n\n\n number of bands                                   50\n    4   5.915 -11.639 -15.244   3.878   0.807  -0.240 -11.419   0.220   6.135\n    5   8.445  -9.675  -3.213  -5.492   0.819  -0.222  -8.881   0.794   9.239\n\n number of bands                                  100\n    4   5.915 -11.639 -15.244   3.810   0.806  -0.241 -11.474   0.165   6.080\n    5   8.445  -9.675  -3.213  -5.557   0.818  -0.223  -8.935   0.740   9.185\n\n number of bands                                  150\n    4   5.915 -11.639 -15.244   3.805   0.806  -0.241 -11.478   0.161   6.076\n    5   8.445  -9.675  -3.213  -5.563   0.818  -0.223  -8.940   0.735   9.180\n\n number of bands                                  200\n    4   5.915 -11.639 -15.244   3.804   0.806  -0.241 -11.479   0.160   6.075\n    5   8.445  -9.675  -3.213  -5.564   0.818  -0.223  -8.940   0.734   9.180\n\n number of bands                                  250\n    4   5.915 -11.639 -15.244   3.804   0.806  -0.241 -11.479   0.160   6.075\n    5   8.445  -9.675  -3.213  -5.564   0.818  -0.223  -8.941   0.734   9.179\n\n\n\n\n\nSo that nband=100 can be considered converged within 0.01 eV.\n\n\nAt this stage, we know that for the self-energy computation, we need\n\necutwfn\n=5.0 \necutsigx\n=6.0, \nnband\n=100 .\n\n\n\n\n\u00b6\n\n\n6 Convergence on the number of planewaves in the wavefunctions to calculate the screening (\u03b5-1) (optional). \n\n\nNow, we come back to the calculation of the screening. Adequate convergence\nstudies will couple the change of parameters for \noptdriver\n=3 with a\ncomputation of the GW energy changes. One cannot rely on the convergence of\nthe macroscopic dielectric constant to assess the convergence of the GW\nenergies.\n\n\nAs a consequence, we will define a double loop over the datasets:\n\n\nndtset      10\nudtset      5  2\n\n\n\n\n\nThe datasets 12,22,32,42 and 52, drive the computation of the GW energies:\n\n\n# Calculation of the Self-Energy matrix elements (GW corrections)\noptdriver?2   4\ngetscr?2     -1\necutwfn?2     5.0\necutsigx      6.0\nnband?2       100\n\n\n\n\n\nThe datasets 11,21,31,41 and 51, drive the corresponding computation of the\nscreening:\n\n\n# Calculation of the screening (epsilon^-1 matrix)\noptdriver?1  3\n\n\n\n\n\nIn this latter series, we will have to vary the three different parameters\n\necutwfn\n, \necuteps\n and \nnband\n.\n\n\nFirst, we check the convergence on the number of planewaves to describe the\nwavefunctions, in the calculation of the screening. This will be done by\ndefining five datasets, with increasing \necutwfn\n:\n\n\necutwfn:?   3.0\necutwfn+?   1.0\n\n\n\n\n\nIn directory ~abinit/tests/tutorial/Input/Work_gw1, copy the file\n../tgw1_6.in, and modify the tgw1_x.files file as usual. Edit the tgw1_6.in\nfile, and take the time to examine it.\n\nThen, issue:\n\n\nabinit < tgw1_x.files >& tgw1_6.log &\n\n\n\n\n\nEdit the output file. The number of plane waves used for the wavefunctions in\nthe computation of the screening is mentioned in the fragments of output:\n\n\n EPSILON^-1 parameters (SCR file):\n dimension of the eps^-1 matrix                    169\n number of plane-waves for wavefunctions            59\n\n\n\n\n\nGathering the macroscopic dielectric constant and GW energies for each\nplanewave set, one gets:\n\n\n dielectric constant =  99.4320\n dielectric constant without local fields = 147.6068\n number of plane-waves for wavefunctions            59\n    4   5.915 -11.639 -15.244   3.843   0.811  -0.233 -11.446   0.193   6.108\n    5   8.445  -9.675  -3.213  -5.527   0.819  -0.221  -8.909   0.766   9.211\n\n dielectric constant =  99.8529\n dielectric constant without local fields = 144.5675\n number of plane-waves for wavefunctions           113\n    4   5.915 -11.639 -15.244   3.789   0.804  -0.244 -11.492   0.147   6.063\n    5   8.445  -9.675  -3.213  -5.564   0.817  -0.224  -8.941   0.734   9.179\n\n dielectric constant =  99.5260\n dielectric constant without local fields = 143.7201\n number of plane-waves for wavefunctions           137\n    4   5.915 -11.639 -15.244   3.779   0.804  -0.243 -11.500   0.140   6.055\n    5   8.445  -9.675  -3.213  -5.568   0.816  -0.226  -8.945   0.729   9.175\n\n dielectric constant =  98.2593\n dielectric constant without local fields = 142.5976\n number of plane-waves for wavefunctions           169\n    4   5.915 -11.639 -15.244   3.772   0.802  -0.248 -11.505   0.134   6.049\n    5   8.445  -9.675  -3.213  -5.573   0.815  -0.227  -8.951   0.724   9.169\n\n dielectric constant =  96.8379\n dielectric constant without local fields = 141.0644\n number of plane-waves for wavefunctions           259\n    4   5.915 -11.639 -15.244   3.769   0.804  -0.244 -11.508   0.131   6.047\n    5   8.445  -9.675  -3.213  -5.578   0.815  -0.227  -8.954   0.721   9.166\n\n\n\n\n\nSo that \necutwfn\n=4.0 (\nnpwwfn\n=113) can be considered to lead to\neigenenergies converged within 0.01 eV.\n\n\n\n\n\u00b6\n\n\n7 Convergence on the number of bands to calculate the screening (important). \n\n\nThis convergence study is rather important. It can be done at the same time as\nthe convergence study for the number of bands for the self-energy. Note that\nthe number of bands used to calculate both the screening and the self-energy\ncan be lowered by a large amount by resorting to the extrapolar technique (see\nthe input variable \ngwcomp\n).\n\n\nSecond, we check the convergence on the number of bands in the calculation of\nthe screening. This will be done by defining five datasets, with increasing\n\nnband\n:\n\n\nnband11  25\nnband21  50\nnband31  100\nnband41  150\nnband51  200\n\n\n\n\n\nIn directory ~abinit/tests/tutorial/Input/Work_gw1, copy the file\n../tgw1_7.in, and modify the tgw1_x.files file as usual. Edit the tgw1_7.in\nfile, and take the time to examine it.\n\n\nThen, issue:\n\n\nabinit < tgw1_x.files >& tgw1_7.log &\n\n\n\n\n\nEdit the output file. The number of bands used for the wavefunctions in the\ncomputation of the screening is mentioned in the fragments of output:\n\n\n EPSILON^-1 parameters (SCR file):\n dimension of the eps^-1 matrix                    169\n number of plane-waves for wavefunctions           113\n number of bands                                    25\n\n\n\n\n\nGathering the macroscopic dielectric constant and GW energies for each number\nof bands, one gets:\n\n\n dielectric constant =  99.8529\n dielectric constant without local fields = 144.5675\n number of bands                                    25\n    4   5.915 -11.639 -15.244   3.789   0.804  -0.244 -11.492   0.147   6.063\n    5   8.445  -9.675  -3.213  -5.564   0.817  -0.224  -8.941   0.734   9.179\n\n dielectric constant = 100.9503\n dielectric constant without local fields = 144.5701\n number of bands                                    50\n    4   5.915 -11.639 -15.244   3.624   0.806  -0.241 -11.624   0.015   5.930\n    5   8.445  -9.675  -3.213  -5.738   0.814  -0.228  -9.085   0.590   9.035\n\n dielectric constant = 101.2722\n dielectric constant without local fields = 144.5703\n number of bands                                   100\n    4   5.915 -11.639 -15.244   3.577   0.807  -0.239 -11.662  -0.023   5.892\n    5   8.445  -9.675  -3.213  -5.792   0.813  -0.230  -9.131   0.544   8.989\n\n dielectric constant = 101.3772\n dielectric constant without local fields = 144.5703\n number of bands                                   150\n    4   5.915 -11.639 -15.244   3.568   0.807  -0.240 -11.669  -0.030   5.885\n    5   8.445  -9.675  -3.213  -5.800   0.813  -0.230  -9.137   0.538   8.983\n\n dielectric constant = 101.3814\n dielectric constant without local fields = 144.5703\n number of bands                                   200\n    4   5.915 -11.639 -15.244   3.568   0.807  -0.240 -11.669  -0.030   5.885\n    5   8.445  -9.675  -3.213  -5.801   0.813  -0.230  -9.137   0.537   8.983\n\n\n\n\n\nSo that the computation using 100 bands can be considered converged within\n0.01 eV.\n\n\n\n\n\u00b6\n\n\n8 Convergence on the dimension of the \u03b5-1 matrix (important). \n\n\nThird, we check the convergence on the number of plane waves in the\ncalculation of the screening. This will be done by defining six datasets, with\nincreasing \necuteps\n:\n\n\necuteps:?     3.0\necuteps+?     1.0\n\n\n\n\n\nIn directory ~abinit/tests/tutorial/Input/Work_gw1, copy the file\n../tgw1_8.in, and modify the tgw1_x.files file as usual. Edit the tgw1_8.in\nfile, and take the time to examine it.\n\n\nThen, issue:\n\n\nabinit < tgw1_x.files >& tgw1_8.log &\n\n\n\n\n\nEdit the output file. The number of bands used for the wavefunctions in the\ncomputation of the screening is mentioned in the fragments of output:\n\n\n EPSILON^-1 parameters (SCR file):\n dimension of the eps^-1 matrix                     59\n\n\n\n\n\nGathering the macroscopic dielectric constant and GW energies for each number\nof bands, one gets:\n\n\n dielectric constant = 102.1696\n dielectric constant without local fields = 144.5703\n dimension of the eps^-1 matrix                     59\n    4   5.915 -11.639 -15.244   3.721   0.808  -0.237 -11.545   0.094   6.009\n    5   8.445  -9.675  -3.213  -5.805   0.813  -0.230  -9.141   0.534   8.979\n\n dielectric constant = 101.3721\n dielectric constant without local fields = 144.5703\n dimension of the eps^-1 matrix                    113\n    4   5.915 -11.639 -15.244   3.613   0.807  -0.239 -11.633   0.007   5.922\n    5   8.445  -9.675  -3.213  -5.799   0.813  -0.230  -9.136   0.539   8.984\n\n dielectric constant = 101.3560\n dielectric constant without local fields = 144.5703\n dimension of the eps^-1 matrix                    137\n    4   5.915 -11.639 -15.244   3.591   0.807  -0.239 -11.651  -0.012   5.904\n    5   8.445  -9.675  -3.213  -5.793   0.813  -0.230  -9.131   0.543   8.989\n\n dielectric constant = 101.2722\n dielectric constant without local fields = 144.5703\n dimension of the eps^-1 matrix                    169\n    4   5.915 -11.639 -15.244   3.577   0.807  -0.239 -11.662  -0.023   5.892\n    5   8.445  -9.675  -3.213  -5.792   0.813  -0.230  -9.131   0.544   8.989\n\n dielectric constant = 101.2405\n dielectric constant without local fields = 144.5703\n dimension of the eps^-1 matrix                    259\n    4   5.915 -11.639 -15.244   3.577   0.807  -0.239 -11.662  -0.023   5.892\n    5   8.445  -9.675  -3.213  -5.792   0.813  -0.230  -9.130   0.544   8.990\n dielectric constant = 101.2404\n dielectric constant without local fields = 144.5703\n dimension of the eps^-1 matrix                    283\n    4   5.915 -11.639 -15.244   3.577   0.807  -0.239 -11.662  -0.023   5.892\n    5   8.445  -9.675  -3.213  -5.792   0.813  -0.230  -9.130   0.544   8.990\n\n\n\n\n\nSo that ecuteps=6.0 (npweps=169) can be considered converged within 0.01 eV.\n\n\nAt this stage, we know that for the screening computation, we need\n\necutwfn\n=4.0 \necuteps\n=6.0, \nnband\n=100.\n\n\nOf course, until now, we have skipped the most difficult part of the\nconvergence tests: the convergence in the number of k-points. It is as\nimportant to check the convergence on this parameter, than on the other ones.\nHowever, this might be very time consuming, since the CPU time scales as the\nsquare of the number of k points (roughly), and the number of k-points can\nincrease very rapidly from one possible grid to the next denser one. This is\nwhy we will leave this out of the present tutorial, and consider that we\nalready know a sufficient k-point grid, for the last calculation.\n\n\n\n\n\u00b6\n\n\n9 Calculation of the GW corrections for the band gap in \u0393. \n\n\nNow we try to perform a GW calculation for a real problem: the calculation of\nthe GW corrections for the direct band gap of bulk Silicon in \u0393.\n\n\nIn directory ~abinit/tests/tutorial/Input/Work_gw1, copy the file\n../tgw1_9.in, and modify the tgw1_x.files file as usual. Then, edit the\ntgw1_9.in file, and, without examining it, comment the line\n\n\n ngkpt    2 2 2         # Density of k points used for the automatic tests of the tutorial\n\n\n\n\n\nand uncomment the line\n\n\n#ngkpt    4 4 4        # Density of k points needed for a converged calculation\n\n\n\n\n\nThen,\n\nIssue:\n\n\nabinit < tgw1_x.files >& tgw1_9.log &\n\n\n\n\n\nThis job lasts about 1 minute so it is worth to run it before the examination\nof the input file.\n\n\nNow, you can examine it.\n\nWe need the usual part of the input file to perform a ground state\ncalculation. This is done in dataset 1 and at the end we print out the\ndensity. We use a 4x4x4 FCC grid (so, 256 k points in the full Brillouin\nZone), shifted, because it is the most economical. It gives 10 k-points in the\nIrreducible part of the Brillouin Zone. However, this k-point grid does not\ncontains the \u0393 point, and, at present, one cannot perform calculations of the\nself-energy corrections for other k points than those present in the grid of\nk-points in the WFK file.\n\n\nThen in dataset 2 we perform a non self-consistent calculation to calculate\nthe Kohn-Sham structure in a set of 19 k-points in the Irreducible Brillouin\nZone. This set of k-points is also derived from a 4x4x4 FCC grid, but a NON-\nSHIFTED one. It has the same density of points as the 10 k-point set, but the\nsymmetries are not used in a very efficient way. However, this set contains\nthe \u0393 point, which allows us to tackle the computation of the band gap at this\npoint.\n\n\nIn dataset 3 we calculate the screening. The screening calculation is very\ntime-consuming. So, we have decided to decrease a bit the parameters found in\nthe previous convergence studies. Indeed, \necutwfn\n has been decreased from\n4.0 to 3.6. This is rather innocuous. Also, \nnband\n has been decreased from\n100 to 25. This is a drastic change. The CPU time of this part is linear with\nrespect to this parameter (or more exactly, with the number of conduction\nbands). Thus, the CPU time has been decreased by a factor of 4. Referring to\nour previous convergence study, we see that the absolute accuracy on the GW\nenergies is now on the order of 0.2 eV only. However, the gap energy\n(difference between valence and conduction states), that is the relative\naccuracy, is likely correct within 0.02 eV. It is very important to clarify\nthis point: in bulk systems what matters is only the relative accuracy. There\nis no zero of the energy defined for a bulk system. Hence in these systems one\nCAN WELL check the convergence only on the relative accuracy on the energies\nrather than the absolute, by checking the convergence on the band gap for\nexample. This will reduce a lot the values to be found for the convergence\nparameters. The same holds for 2-, 1-, and 0-dimensional systems if one is\ninterested only on relative energies and is not interested in calculating\nquantities like the work function.\n\n\nFinally in dataset 4 we calculate the self-energy matrix element in \u0393, using\nthe previously determined parameters.\n\n\nYou should obtain the following results:\n\n\n k =    0.000   0.000   0.000\n Band     E0  VxcLDA    SigX SigC(E0)      Z dSigC/dE  Sig(E)    E-E0       E\n    4   5.951 -11.253 -12.628   1.187   0.777  -0.287 -11.398  -0.146   5.806\n    5   8.464 -10.042  -5.563  -3.878   0.777  -0.287  -9.575   0.467   8.931\n\n E^0_gap          2.513\n E^GW_gap         3.126\n DeltaE^GW_gap    0.613\n\n\n\n\n\nSo that the LDA energy gap in \u0393 is about 2.53 eV, while the GW correction is\nabout 0.64 eV, so that the GW band gap found is 3.17 eV.\n\n\nOne can compare now what have been obtained to what one can get from the\nliterature.\n\n\n EXP         3.40 eV   Landolt-Boernstein\n\n LDA         2.57 eV   L. Hedin, Phys. Rev. 139, A796 (1965)\n LDA         2.57 eV   M.S. Hybertsen and S. Louie, PRL 55, 1418 (1985)\n LDA (FLAPW) 2.55 eV   N. Hamada, M. Hwang and A.J. Freeman, PRB 41, 3620 (1990)\n LDA (PAW)   2.53 eV   B. Arnaud and M. Alouani, PRB 62, 4464 (2000)\n LDA         2.53 eV   present work\n\n GW          3.27 eV   M.S. Hybertsen and S. Louie, PRL 55, 1418 (1985)\n GW          3.35 eV   M.S. Hybertsen and S. Louie, PRB 34, 5390 (1986)\n GW          3.30 eV   R.W. Godby, M. Schlueter, L.J. Sham, PRB 37, 10159 (1988)\n GW  (FLAPW) 3.30 eV   N. Hamada, M. Hwang and A.J. Freeman, PRB 41, 3620 (1990)\n GW  (PAW)   3.15 eV   B. Arnaud and M. Alouani, PRB 62, 4464 (2000)\n GW  (FLAPW) 3.12 eV   W. Ku and A.G. Eguiluz, PRL 89, 126401 (2002)\n GW          3.17 eV   present work\n\n\n\n\n\nThe values are spread over an interval of 0.2 eV. They depend on the details\nof the calculation. In the case of pseudopotential calculations, they depend\nof course on the pseudopotential used. However, a GW result is hardly\nmeaningful beyond 0.1 eV, in the present state of the art. But this goes also\nwith the other source of inaccuracy, the choice of the pseudopotential, that\ncan arrive up to even 0.2 eV. This can also be taken into account when\nchoosing the level of accuracy for the convergence parameters in the GW\ncalculation.\n\n\nFinally, it is possible to calculate a full band plot of a system. There are\ntwo possible techniques. The first one is based on the use of Wannier\nfunctions, to interpolate a few selected points obtained using the direct GW\napproach. You need to have the Wannier90 plug-in installed. See the directory\ntests/wannier90, test case 03, for an example of a file where a GW calculation\nis followed by the use of Wannier90. Another practical way follows from the\nfact that the GW corrections are quite linear with the energy, for each group\nof bands. This is evident when reporting on a plot the GW correction with\nrespect to the 0-order LDA energy for each state. One can then simply correct\nthe Kohn-Sham band structure at any point, by using a GW correction for the\nk-points where it has not been calculated explicitly, using a fit of the GW\ncorrection at a sparse set of points.\n\n\n\n\n10 Advanced features in the GW code \n\u00b6\n\n\nThe user might switch to the \nsecond GW tutorial\n before\ncoming back to the present section.\n\n\n Calculations without using the Plasmon-Pole model \n\u00b6\n\n\nIn order to circumvent the plasmon-pole model, the GW frequency convolution\nhas to be calculated explicitly along the real axis. This is a tough job,\nsince G and W have poles along the real axis. Therefore it is more convenient\nto use another path of integration along the imaginary axis plus the residues\nenclosed in the path.\n\n\nConsequently, it is better to evaluate the screening for imaginary frequencies\n(to perform the integration) and also for real frequencies (to evaluate the\ncontributions of the residues that may enter into the path of integration).\nThe number of imaginary frequencies is set by the input variable \nnfreqim\n.\nThe regular grid of real frequencies is determined by the input variables\n\nnfreqre\n, which sets the number of real frequencies, and \nfreqremax\n,\nwhich indicates the maximum real frequency used.\n\n\nThe method is particularly suited to output the spectral function (contained\nin file out.sig). The grid of real frequencies used to calculate the spectral\nfunction is set by the number of frequencies (input variable \nnfreqsp\n) and\nby the maximum frequency calculated (input variable \nfreqspmax\n).\n\n\n Self-consistent calculations \n\u00b6\n\n\nThe details in the implementation and the justification for the approximations\nretained can be found in F. Bruneval, N. Vast, and L. Reining, Phys. Rev. B\n\n74\n, 045102 (2006).\n\nThe only added input variables are \ngetqps\n and \nirdqps\n. These variables\nconcerns the reading of the _QPS file, that contains the eigenvalues and the\nunitary transform matrices of a previous quasiparticle calculation. QPS stands\nfor \u201cQuasiParticle Structure\u201d.\n\nThe only modified input variables for self-consistent calculations are\n\ngwcalctyp\n and \nbdgw\n.\n\nWhen the variable \ngwcalctyp\n is in between 0 and 9, The code calculates the\nquasiparticle energies only and does not output any QPS file (as in a standard\nGW run).\n\nWhen the variable \ngwcalctyp\n is in between 10 and 19, the code calculates\nthe quasiparticle energies only and outputs them in a QPS file.\n\nWhen the variable \ngwcalctyp\n is in between 20 and 29, the code calculates\nthe quasiparticle energies and wavefunctions and outputs them in a QPS file.\n\nFor a full self-consistency calculation, the quasiparticle wavefunctions are\nexpanded in the basis set of the Kohn-Sham wavefunctions. The variable\n\nbdgw\n now indicates the size of all matrices to be calculated and\ndiagonalized. The quasiparticle wavefunctions are consequently linear\ncombinations of the Kohn-Sham wavefunctions in between the min and max values\nof bdgw.\n\n\nA correct self-consistent calculation should consist of the following runs:\n\n\n\n\n1) Self-consistent Kohn-Sham calculation: outputs a WFK file \n\n\n2) Screening calculation (with Kohn-Sham inputs): outputs a SCR file \n\n\n3) Sigma calculation (with Kohn-Sham inputs): outputs a QPS file \n\n\n4) Screening calculation (with the WFK, and QPS file as an input): outputs a new SCR file \n\n\n5) Sigma calculation (with the WFK, QPS and the new SCR files): outputs a new QPS file \n\n\n6) Screening calculation (with the WFK, the new QPS file): outputs a newer SCR file \n\n\n7) Sigma calculation (with the WFK, the newer QPS and SCR files): outputs a newer QPS \n\n\n............ and so on, until the desired accuracy is reached \n\n\n\n\nNote that for Hartree-Fock calculations a dummy screening is required for\ninitialization reasons. Therefore, a correct HF calculations should look like\n\n\n\n\n1) Self-consistent Kohn-Sham calculation: outputs a WFK file \n\n\n2) Screening calculation using very low convergence parameters (with Kohn-Sham inputs): output a \ndummy\n SCR file \n\n\n3) Sigma calculation (with Kohn-Sham inputs): outputs a QPS file \n\n\n4) Sigma calculation (with the WFK and QPS files): outputs a new QPS file \n\n\n5) Sigma calculation (with the WFK and the new QPS file): outputs a newer QPS file \n\n\n............ and so on, until the desired accuracy is reached \n\n\n\n\nIn the case of a self-consistent calculation, the output is slightly more\ncomplex:\n\n\nFor instance, iteration 2\n\n\n k =    0.500   0.250   0.000\n Band     E_lda  <Vxclda>    E(N-1) <Hhartree>    SigX  SigC[E(N-1)]    Z     dSigC/dE  Sig[E(N)]  DeltaE  E(N)_pert E(N)_diago\n    1    -3.422   -10.273    -3.761     6.847   -15.232     4.034     1.000     0.000   -11.198    -0.590    -4.351    -4.351\n    2    -0.574   -10.245    -0.850     9.666   -13.806     2.998     1.000     0.000   -10.807    -0.291    -1.141    -1.141\n    3     2.242    -9.606     2.513    11.841   -11.452     1.931     1.000     0.000    -9.521    -0.193     2.320     2.320\n    4     3.595   -10.267     4.151    13.866   -11.775     1.842     1.000     0.000    -9.933    -0.217     3.934     3.934\n    5     7.279    -8.804     9.916    16.078    -4.452    -1.592     1.000     0.000    -6.044     0.119    10.034    10.035\n    6    10.247    -9.143    13.462    19.395    -4.063    -1.775     1.000     0.000    -5.838     0.095    13.557    13.557\n    7    11.488    -9.704    15.159    21.197    -4.061    -1.863     1.000     0.000    -5.924     0.113    15.273    15.273\n    8    11.780    -9.180    15.225    20.958    -3.705    -1.893     1.000     0.000    -5.598     0.135    15.360    15.360\n\n E^0_gap          3.684\n E^GW_gap         5.764\n DeltaE^GW_gap    2.080\n\n\n\n\n\nThe columns are\n\n\n\n\n\n\nBand\n: index of the band   \n\n\n\n\n\n\nE_lda\n: LDA eigenvalue   \n\n\n\n\n\n\n<Vxclda>\n: diagonal expectation value of the xc potential in between LDA bra and ket   \n\n\n\n\n\n\nE(N-1)\n: quasiparticle energy of the previous iteration (equal to LDA for the first iteration)   \n\n\n\n\n\n\n<Hhartree>\n: diagonal expectation value of the Hartree Hamiltonian (equal to E_lda - <Vxclda> for the first iteration only)   \n\n\n\n\n\n\nSigX\n: diagonal expectation value of the exchange self-energy   \n\n\n\n\n\n\nSigC[E(N-1)]\n: diagonal expectation value of the correlation self-energy (evaluated for the energy of the preceeding iteration)   \n\n\n\n\n\n\nZ\n: quasiparticle renormalization factor Z (taken equal to 1 in methods HF, SEX, COHSEX and model GW)   \n\n\n\n\n\n\ndSigC/dE\n: Derivative of the correlation self-energy with respect to the energy   \n\n\n\n\n\n\nSig[E(N)]\n: Total self-energy for the new quasiparticle energy   \n\n\n\n\n\n\nDeltaE\n: Energy difference with respect to the previous step   \n\n\n\n\n\n\nE(N)_pert\n: QP energy as obtained by the usual perturbative method   \n\n\n\n\n\n\nE(N)_diago\n: QP energy as obtained by the full diagonalization",
            "title": "GW1"
        },
        {
            "location": "/tutorials/gw1/#146-computation-of-the-silicon-band-gap-at-using-a-gw-calculation",
            "text": "**  Before beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not \u201cWork_gw1\u201d ?  At the end of  lesson 3 , we computed the Kohn-Sham band\nstructure of silicon. In this approximation, the band dispersion as well as\nthe band widths are reasonable, but the band gaps are qualitatively wrong.\nNow, we will compute the band gaps much more accurately, using the so-called\nGW approximation.  We start by an example, in which we show how to perform in a single input file\nthe calculation of the ground state density, the Kohn Sham band structure, the\nscreening, and the GW corrections. We use reasonable values for the parameters\nof the calculation. The discussion on the convergence tests is postponed to\nthe next paragraphs. We will see that GW calculations are MUCH MORE time-\nconsuming than the computation of the Kohn-Sham eigenvalues.  So, let us run immediately this calculation, and while it is running, we will\nexplain what has been done.  In the directory ~abinit/tests/tutorial/Input/Work_gw1, copy the files\n~abinit/tests/tutorial/Input/tgw1_x.files and tgw1_1.in, and modify the\ntgw1_x.files file as usual (see lesson 1).  Then, issue:  abinit < tgw1_x.files >& tgw1_1.log &  It is very important to run this job in background because it takes about 1\nminute. In the meantime, you should read the following.",
            "title": "** 1. Computation of the Silicon band gap at \u0393, using a GW calculation."
        },
        {
            "location": "/tutorials/gw1/#1a-the-four-steps-of-a-gw-calculation",
            "text": "In order to perform a standard one-shot GW calculation one has to:    Run a converged Ground State calculation to obtain the self-consistent density.     Perform a non self-consistent run to compute the Kohn-Sham eigenvalues and the eigenfunctions including several empty states. Note that, unlike standard band structure calculations, here the KS states must be computed on a regular grid of k-points.     Use  optdriver =3 to compute the independent-particle susceptibility (\u03c70) on a regular grid of  q -points, for at least two frequencies (usually, \u03c9=0 and a large purely imaginary frequency - of the order of the plasmon frequency, a dozen of eV). The inverse dielectric matrix (\u03b5-1) is then obtained via matrix inversion and stored in an external file (SCR). The list of  q -points is automatically defined by the k-mesh used to generate the KS states in the previous step.     Use  optdriver =4 to compute the self-energy (\u03a3) matrix element for a given set of k-points in order to obtain the GW quasiparticle energies Note that the k-point must belong to the k-mesh used to generate the WFK file in step 2.     The flowchart diagram of a standard one-shot run is depicted in the figure\nbelow.   The input file tgw1_1.in has precisely that structure: there are four\ndatasets.  The first dataset performs the SCF calculation to get the density. The second\ndataset reads the previous density file and performs a NSCF run including\nseveral empty states. The third dataset reads the WFK file produced in the\nprevious step and drives the computation of susceptibility and dielectric\nmatrices, producing another specialized file, tgw1_xo_DS2_SCR (_SCR for\n\u201cScreening\u201d, actually the inverse dielectric matrix \u03b5-1). Then, in the fourth\ndataset, the code calculates the quasiparticle energies for the 4th and 5th\nbands at the \u0393 point.  So, you can edit this tgw1_1.in file.  The dataset-independent part of this file (the last half of the file),\ncontains the usual set of input variables describing the cell, atom types,\nnumber, position, planewave cut-off energy, SCF convergence parameters driving\nthe Kohn-Sham band structure calculation. Then, for the fourth datasets, you\nwill find specialized additional input variables.",
            "title": "1.a The four steps of a GW calculation."
        },
        {
            "location": "/tutorials/gw1/#1b-generating-the-kohn-sham-band-structure-the-wfk-file",
            "text": "Dataset 1 is a rather standard SCF calculation. It\u2019s worth noticing that we\nuse tolvrs to stop the SCF cycle because we want a well-converged KS potential\nto be used in the subsequent NSCF calculation. Dataset 2 computes 40 bands and\nwe set nbdbuf to 5 so that only the first 35 states must be converged within\ntolwfr. This tricks allows us to save several minimization steps because the\nlast bands usually require more iterations to converge  ############\n# Dataset 1\n############\n# SCF-GS run \nnband1  6\ntolvrs1 1.0e-10\n\n############\n# Dataset 2\n############\n# Definition of parameters for the calculation of the WFK file\nnband2      40       # Number of (occ and empty) bands to be computed\nnbdbuf2      5\niscf2       -2\ngetden2     -1\ntolwfr2  1.0d-18     # Will stop when this tolerance is achieved",
            "title": "1.b Generating the Kohn-Sham band structure: the WFK file."
        },
        {
            "location": "/tutorials/gw1/#1c-generating-the-screening-the-scr-file",
            "text": "In dataset 3, the calculation of the screening (susceptibility, dielectric\nmatrix) is performed. We need to set  optdriver =3 to do that:  optdriver3  3        # Screening calculation  The  getwfk  input variable is similar to other \u201cget\u201d input variables of\nABINIT:  getwfk3     -1       # Obtain WFK file from previous dataset  In this case, it tells the code to use the WFK file calculated in the previous\ndataset.  Then, three input variables describe the computation:  nband3      17       # Bands used in the screening calculation\necut        8.0      # Cut-off energy of the planewave set to represent the wavefunctions\necuteps3    3.6      # Cut-off energy of the planewave set to represent the dielectric matrix  In this case, we use 17 bands to calculate the Kohn-Sham response function \\chi^{(0)}_{KS} . A cut-off of 8 Hartree is used to represent the\nwavefunctions in the calculation of  \\chi^{(0)}_{KS} . The dimension of \\chi^{(0)}_{KS} , as well as all the other matrices ( \\chi ,  \\epsilon ) is\ndetermined by  ecuteps =3.6 Hartree, giving 169 planewaves.  Finally, we define the frequencies at which the screening must be evaluated:\n\u03c9=0.0 eV and the imaginary frequency \u03c9= i 16.7 eV. The latter is determined by\nthe input variable  ppmfrq  ppmfrq3    16.7 eV  # Imaginary frequency where to calculate the screening  The two frequencies are used to calculate the plasmon-pole model parameters.\nFor the non-zero frequency it is recommended to use a value close to the\nplasmon frequency for the plasmon-pole model to work well. Plasmons\nfrequencies are usually close to 0.5 Hartree. The parameters for the screening\ncalculation are not far from the ones that give converged Energy Loss Function\n(-Im \\epsilon^-1_00) spectra, So that one can start up by using indications\nfrom EELS calculations existing in literature.",
            "title": "1.c Generating the screening: the SCR file."
        },
        {
            "location": "/tutorials/gw1/#1d-computing-the-gw-energies",
            "text": "In dataset 4 the calculation of the Self-Energy matrix elements is performed.\nOne needs to define the driver option, as well as the _WFK and _SCR files.  optdriver4  4       # Self-Energy calculation\ngetwfk4    -2       # Obtain WFK file from dataset 1\ngetscr4    -1       # Obtain SCR file from previous dataset  The  getscr  input variable is similar to other \u201cget\u201d input variables of\nABINIT.  Then, comes the definition of parameters needed to compute the self-energy. As\nfor the computation of the susceptibility and dielectric matrices, one must\ndefine the set of bands, and two sets of planewaves:  nband4       30      # Bands to be used in the Self-Energy calculation\necutsigx4   6.0      # Dimension of the G sum in Sigma_x\n                     # (the dimension in Sigma_c is controlled by npweps)  In this case,  nband  controls the number of bands used to calculate the\ncorrelation part of the Self-Energy.  ecutsigx  gives the number of\nplanewaves used to calculate \u03c3x (the exchange part of the self-energy). The\nsize of the planewave set used to compute \u03a3c (the correlation part of the\nself-energy) is controlled by  ecuteps  (cannot be larger than the value\nused to generate the SCR file). However, it is taken equal to the number of\nplanewave of \u03a3x if the latter is smaller than the one for \u03a3c.  Then, come the parameters defining the k-points and the band indices for which\nthe quasiparticle energies will be computed:  nkptgw4      1               # number of k-point where to calculate the GW correction\nkptgw4                       # k-points\n  -0.125    0.000    0.000\nbdgw4       4  5             # calculate GW corrections for bands from 4 to 5  nkptgw  defines the number of k-points for which the GW corrections will be\ncomputed. The k-point reduced coordinates are specified in  kptgw . At\npresent, they MUST belong to the k-mesh used to generate the WFK file. Hence\nif you wish the GW correction in a particular k-point, you should choose a\ngrid containing it. Usually this is done by taking the k-point grid where the\nconvergence is achieved and shifting it such as at least one k-point is placed\non the wished position in the Brillouin zone.  bdgw  gives the\nminimum/maximum band whose energies are calculated for the given k-point.  There is an additional parameter, called  zcut , related to the self-energy\ncomputation. It is meant to avoid some divergences that might occur in the\ncalculation due to integrable poles along the integration path.",
            "title": "1.d Computing the GW energies."
        },
        {
            "location": "/tutorials/gw1/#1e-examination-of-the-output-file",
            "text": "Let us hope that your calculation has been completed, and that we can examine\nthe output file. Open tgw1_1.out in your preferred editor and find the section\ncorresponding to DATASET 3.  After the description of the unit cell and of the pseudopotentials, you will\nfind the list of k-points used for the electrons and the grid of q-point (in\nthe Irreducible part of the Brillouin Zone) on which the susceptibility and\ndielectric matrices will be computed. It is a set of BZ points defined as all\nthe possible differences among the k-points ( q=k-k\u2019 ) of the grid chosen to\ngenerate the WFK file. From the last statement it is clear the interest to\nchoose homogeneous k-point grids, in order not to minimize the number of\nq-points.  After this section, the code prints the parameters of the FFT grid needed to\nrepresent the wavefunctions and to compute their convolution (required for the\nscreening matrices). Then we have some information about the MPI distribution\nof the bands and the total number of valence electrons computed by integrating\nthe density in the unit cell.  On the basis of the density, one can obtain the classical Drude plasmon\nfrequency. The next lines calculate the average density of the system, and\nevaluate the r_s parameter, then compute the Drude plasmon frequency. This is\nthe value used by default for  ppmfrq . It is in fact the second frequency\nwhere the code calculates the dielectric matrix to adjust the plasmon-pole\nmodel parameters. It has been found that Drude plasma frequency is a\nreasonable value where to adjust the model. The control over this parameter is\nhowever left to the user in order to check that the result does not change\nwhen changing  ppmfrq . If it is the case, then the plasmon-pole model is\nnot appropriated and one should go beyond by taking into account a full\ndynamical dependence in the screening (see later, the contour-deformation\nmethod). However, the plasmon-pole model has been found to work well for a\nvery large range of systems when focusing only on the real part of the GW\ncorrections.  At the end of the screening calculation, the macroscopic dielectric constant\nis printed:    dielectric constant =  13.5073\n  dielectric constant without local fields =  15.0536  Note that the convergence in the dielectric constant DOES NOT guarantee the\nconvergence in the GW corrections. In fact, the dielectric constant is\nrepresentative of only one element i.e. the head of the full dielectric\nmatrix. Even if the convergence on the dielectric constant with local fields\ntakes somehow into account also other non-diagonal elements. In a GW\ncalculation all the \u03b5-1 matrix is used to build the Self-Energy operator. \nThe dielectric constant here reported is the so-called RPA dielectric constant\ndue to the electrons. Although evaluated at zero frequency, it is understood\nthat the ionic response is not included (this term can be computed with DFPT\nand ANADDB). The RPA dielectric constant restricted to electronic effects is\nalso not the same as the one computed in the RESPFN part of ABINIT, that\nincludes exchange-correlation effects.  We now enter the fourth dataset. As for dataset 3, after some general\ninformation (origin of WFK file, header, description of unit cell, k-points,\nq-points), the description of the FFT grid and jellium parameters, there is\nthe echo of parameters for the plasmon-pole model, and the inverse dielectric\nfunction (the screening). The self-energy operator has been constructed, and\none can evaluate the GW energies, for each of the states.  The final results are:  k =   -0.125   0.000   0.000\n Band     E0  <VxcLDA>   SigX SigC(E0)    Z dSigC/dE  Sig(E)    E-E0     E\n    4   5.616 -11.115 -12.334   1.257   0.775  -0.290 -11.085   0.030   5.646\n    5   8.357 -10.140  -5.951  -3.336   0.779  -0.284  -9.476   0.664   9.021\n\n E^0_gap          2.741\n E^GW_gap         3.375\n DeltaE^GW_gap    0.634  For the desired k-point, state 4, then state 5, one finds different\ninformation:    E0 is the Kohn-Sham eigenenergy     VxcLDA gives the average Kohn-Sham exchange-correlation potential     SigX gives the exchange contribution to the self-energy     SigC(E0) gives the correlation contribution to the self-energy, evaluated at the Kohn-Sham eigenenergy    Z is the renormalisation factor     dSigC/dE is the energy derivative of SigC with respect to the energy    SigC(E) gives the correlation contribution to the self-energy, evaluated at the GW energy    E-E0 is the difference between GW energy and Kohn-Sham eigenenergy     E is the GW energy     In this case, the gap is also analyzed: E^0_gap is the direct Kohn-Sham gap at\nthat k point (and spin, in the case of spin-polarized calculations), E^GW_gap\nis the GW one, and DeltaE^GW_gap is the difference. This direct gap is always\ncomputed between the band whose number is equal to the number of electrons in\nthe cell divided by two (integer part, in case of spin-polarized calculation),\nand the next one. (Warning: for a metal, these two bands do not systematically\nlie below and above the Fermi energy - but the concept of a direct gap is not\nrelevant in that case).  It is seen that the average Kohn-Sham exchange-correlation potential for the\nstate 4 (a valence state) is very close to the exchange self-energy\ncorrection. For that state, the correlation correction is small, and the\ndifference between Kohn-Sham and GW energies is also small (43 meV). By\ncontrast, the exchange self-energy is much smaller than the average Kohn-Sham\npotential for the state 5 (a conduction state), but the correlation correction\nis much larger than for state 4. On the whole, the difference between Kohn-\nSham and GW energies is not very large, but nevertheless, it is quite\nimportant when compared with the size of the gap.",
            "title": "1.e Examination of the output file."
        },
        {
            "location": "/tutorials/gw1/#10-advanced-features-in-the-gw-code",
            "text": "The user might switch to the  second GW tutorial  before\ncoming back to the present section.",
            "title": "10 Advanced features in the GW code"
        },
        {
            "location": "/tutorials/gw1/#calculations-without-using-the-plasmon-pole-model",
            "text": "In order to circumvent the plasmon-pole model, the GW frequency convolution\nhas to be calculated explicitly along the real axis. This is a tough job,\nsince G and W have poles along the real axis. Therefore it is more convenient\nto use another path of integration along the imaginary axis plus the residues\nenclosed in the path.  Consequently, it is better to evaluate the screening for imaginary frequencies\n(to perform the integration) and also for real frequencies (to evaluate the\ncontributions of the residues that may enter into the path of integration).\nThe number of imaginary frequencies is set by the input variable  nfreqim .\nThe regular grid of real frequencies is determined by the input variables nfreqre , which sets the number of real frequencies, and  freqremax ,\nwhich indicates the maximum real frequency used.  The method is particularly suited to output the spectral function (contained\nin file out.sig). The grid of real frequencies used to calculate the spectral\nfunction is set by the number of frequencies (input variable  nfreqsp ) and\nby the maximum frequency calculated (input variable  freqspmax ).",
            "title": "Calculations without using the Plasmon-Pole model"
        },
        {
            "location": "/tutorials/gw1/#self-consistent-calculations",
            "text": "The details in the implementation and the justification for the approximations\nretained can be found in F. Bruneval, N. Vast, and L. Reining, Phys. Rev. B 74 , 045102 (2006). \nThe only added input variables are  getqps  and  irdqps . These variables\nconcerns the reading of the _QPS file, that contains the eigenvalues and the\nunitary transform matrices of a previous quasiparticle calculation. QPS stands\nfor \u201cQuasiParticle Structure\u201d. \nThe only modified input variables for self-consistent calculations are gwcalctyp  and  bdgw . \nWhen the variable  gwcalctyp  is in between 0 and 9, The code calculates the\nquasiparticle energies only and does not output any QPS file (as in a standard\nGW run). \nWhen the variable  gwcalctyp  is in between 10 and 19, the code calculates\nthe quasiparticle energies only and outputs them in a QPS file. \nWhen the variable  gwcalctyp  is in between 20 and 29, the code calculates\nthe quasiparticle energies and wavefunctions and outputs them in a QPS file. \nFor a full self-consistency calculation, the quasiparticle wavefunctions are\nexpanded in the basis set of the Kohn-Sham wavefunctions. The variable bdgw  now indicates the size of all matrices to be calculated and\ndiagonalized. The quasiparticle wavefunctions are consequently linear\ncombinations of the Kohn-Sham wavefunctions in between the min and max values\nof bdgw.  A correct self-consistent calculation should consist of the following runs:   1) Self-consistent Kohn-Sham calculation: outputs a WFK file   2) Screening calculation (with Kohn-Sham inputs): outputs a SCR file   3) Sigma calculation (with Kohn-Sham inputs): outputs a QPS file   4) Screening calculation (with the WFK, and QPS file as an input): outputs a new SCR file   5) Sigma calculation (with the WFK, QPS and the new SCR files): outputs a new QPS file   6) Screening calculation (with the WFK, the new QPS file): outputs a newer SCR file   7) Sigma calculation (with the WFK, the newer QPS and SCR files): outputs a newer QPS   ............ and so on, until the desired accuracy is reached    Note that for Hartree-Fock calculations a dummy screening is required for\ninitialization reasons. Therefore, a correct HF calculations should look like   1) Self-consistent Kohn-Sham calculation: outputs a WFK file   2) Screening calculation using very low convergence parameters (with Kohn-Sham inputs): output a  dummy  SCR file   3) Sigma calculation (with Kohn-Sham inputs): outputs a QPS file   4) Sigma calculation (with the WFK and QPS files): outputs a new QPS file   5) Sigma calculation (with the WFK and the new QPS file): outputs a newer QPS file   ............ and so on, until the desired accuracy is reached    In the case of a self-consistent calculation, the output is slightly more\ncomplex:  For instance, iteration 2   k =    0.500   0.250   0.000\n Band     E_lda  <Vxclda>    E(N-1) <Hhartree>    SigX  SigC[E(N-1)]    Z     dSigC/dE  Sig[E(N)]  DeltaE  E(N)_pert E(N)_diago\n    1    -3.422   -10.273    -3.761     6.847   -15.232     4.034     1.000     0.000   -11.198    -0.590    -4.351    -4.351\n    2    -0.574   -10.245    -0.850     9.666   -13.806     2.998     1.000     0.000   -10.807    -0.291    -1.141    -1.141\n    3     2.242    -9.606     2.513    11.841   -11.452     1.931     1.000     0.000    -9.521    -0.193     2.320     2.320\n    4     3.595   -10.267     4.151    13.866   -11.775     1.842     1.000     0.000    -9.933    -0.217     3.934     3.934\n    5     7.279    -8.804     9.916    16.078    -4.452    -1.592     1.000     0.000    -6.044     0.119    10.034    10.035\n    6    10.247    -9.143    13.462    19.395    -4.063    -1.775     1.000     0.000    -5.838     0.095    13.557    13.557\n    7    11.488    -9.704    15.159    21.197    -4.061    -1.863     1.000     0.000    -5.924     0.113    15.273    15.273\n    8    11.780    -9.180    15.225    20.958    -3.705    -1.893     1.000     0.000    -5.598     0.135    15.360    15.360\n\n E^0_gap          3.684\n E^GW_gap         5.764\n DeltaE^GW_gap    2.080  The columns are    Band : index of the band       E_lda : LDA eigenvalue       <Vxclda> : diagonal expectation value of the xc potential in between LDA bra and ket       E(N-1) : quasiparticle energy of the previous iteration (equal to LDA for the first iteration)       <Hhartree> : diagonal expectation value of the Hartree Hamiltonian (equal to E_lda - <Vxclda> for the first iteration only)       SigX : diagonal expectation value of the exchange self-energy       SigC[E(N-1)] : diagonal expectation value of the correlation self-energy (evaluated for the energy of the preceeding iteration)       Z : quasiparticle renormalization factor Z (taken equal to 1 in methods HF, SEX, COHSEX and model GW)       dSigC/dE : Derivative of the correlation self-energy with respect to the energy       Sig[E(N)] : Total self-energy for the new quasiparticle energy       DeltaE : Energy difference with respect to the previous step       E(N)_pert : QP energy as obtained by the usual perturbative method       E(N)_diago : QP energy as obtained by the full diagonalization",
            "title": "Self-consistent calculations"
        },
        {
            "location": "/tutorials/gw2/",
            "text": "This lesson aims at showing how to obtain self-energy corrections to the DFT\nKohn-Sham eigenvalues within the GW approximation, in the metallic case,\nwithout the use of a plasmon-pole model. The band width and Fermi energy of\nAluminum will be computed.  \n\n\nThe user may read the paper\n\n\n\n\n\n\nF. Bruneval, N. Vast, and L. Reining, Phys. Rev. B \n74\n, 045102 (2006), \nfor some information and results about the GW treatment of Aluminum. He will\nalso find there an analysis of the effect of self-consistency on\nquasiparticles in solids (not present in this tutorial, however available in\nAbinit). The description of the contour deformation technique that bypasses\nthe use of a plasmon-pole model to calculate the frequency convolution of G\nand W can be found in\n\n\n\n\n\n\nS. Lebegue, S. Arnaud, M. Alouani, P. Bloechl, Phys. Rev. B 67, 155208 (2003), \nwith the relevant formulas. We will refer to these papers as the\nBruneval[2006] and the Lebegue[2003] papers.\n\n\n\n\n\n\nA brief description of the equations implemented in the code can be found in\nthe \nGW_notes\n.\n\n\nAlso, it is suggested to [acknowledge the efforts of developers of the GW part\nof ABINIT, by citing\n\n\n\n\nX. Gonze, G.-M. Rignanese, M. Verstraete, J.-M. Beuken, Y. Pouillon, R. Caracas, F. Jollet, M. Torrent, G. Zerah, M. Mikami, Ph. Ghosez, M. Veithen, J.-Y. Raty, V. Olevano, F. Bruneval, L. Reining, R. Godby, G. Onida, D.R. Hamann, and D.C. Allan. Zeit. Kristallogr. 220, 558-562 (2005). \n\n\n\n\nThe user should be familiarized with the four basic lessons of ABINIT, see the\n\ntutorial home page\n, as well as the \nfirst lesson on\nGW\n.\n\n\nThis lesson should take about one hour to be completed (also including the\nreading of Bruneval[2006] and Lebegue[2003]).\n\n\n\n\n\n\n\n\nThe preliminary Kohn-Sham band structure calculation. \n\n\n\n\n\n\n\n\n\n\nCalculation of the screening file. \n\n\n\n\n\n\n\n\n\n\nFinding the Fermi energy and the bottom of the valence band. \n\n\n\n\n\n\n\n\n\n\nComputing a GW spectral function, and the plasmon satellite of Aluminum. \n\n\n\n\n\n\n\n\n\n\n\u00b6\n\n\n 1. The preliminary Kohn-Sham band structure calculation. \n\u00b6\n\n\nBefore beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not \u201cWork_gw2\u201d ?\n\n\nDuring \nlesson 4\n, you computed different properties of\nAluminum within the LDA. Unlike for silicon, in this approximation, there is\nno outstanding problem in the computed band structure. Nevertheless, as you\nwill see, the agreement of the band structure with experiment can be improved\nsignificantly if one relies on the GW approximation.\n\n\nIn the directory ~abinit/tests/tutorial/Input/Work_gw2, copy the files\n~abinit/tests/tutorial/Input/tgw2_x.files and tgw2_1.in, and modify the\ntgw2_x.files file as usual (see lesson 1).\n\nThen (supposing abinit is the proper alias), issue:\n\n\nabinit < tgw2_x.files >& tgw2_1.log &\n\n\n\n\n\nThis run generates the WFK file for the subsequent GW computation and also\nprovides the band width of Aluminum. Note that the simple Fermi-Dirac smearing\nfunctional is used (\noccopt\n=3), with a large smearing (\ntsmear\n=0.05 Ha).\nThe k point grid is quite rough, an unshifted 4x4x4 Monkhorst-Pack grid (64 k\npoints in the full Brillouin Zone, folding to 8 k points in the Irreducible\nwedge, \nngkpt\n=4 4 4). Converged results would need a 4x4x4 grid with 4\nshifts (256 k points in the full Brillouin zone). This grid contains the Gamma\npoint, at which the valence band structure reaches its minimum.\n\n\nThe output file presents the Fermi energy\n\n\n Fermi (or HOMO) energy (eV) =   7.14774   Average Vxc (eV)=  -9.35982\n\n\n\n\n\nas well as the lowest energy, at the Gamma point\n\n\n Eigenvalues (   eV  ) for nkpt=   8  k points:\n kpt#   1, nband=  6, wtk=  0.01563, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n  -3.76175  19.92114  19.92114  19.92114  21.00078  21.00078\n\n\n\n\n\nSo, the occupied band width is 10.90 eV. More converged calculations would\ngive 11.06 eV (see Bruneval[2006]).\n\nThis is to be compared to the experimental value of 10.6 eV (see references in\nBruneval[2006]).\n\n\n\n\n\u00b6\n\n\n2. Calculation of the screening file. \n\n\nIn order not to lose time, let us start the calculation of the screening file\nbefore the examination of the corresponding input file. So, copy the file\ntgw2_2.in, and modify the tgw2_x.files file as usual (replace occurrences of\ntwg2_x by tgw2_2). Also, copy the WFK file (tgw2_1o_WFK) to tgw2_2i_WFK. Then\nrun the calculation (it should take about 30 seconds on a 3 GHz PC).\n\n\nWe now have to consider starting a GW calculation. However, unlike in the case\nof Silicon in the previous GW tutorial, where we were focussing on quantities\nclose to the Fermi energy (spanning a range of a few eV), here we need to\nconsider a much wider range of energy: the bottom of the valence band lies\naround -11 eV below the Fermi level. Unfortunately, this energy is of the same\norder of magnitude as the plasmon excitations. With a rough evaluation, the\nclassical plasma frequency for a homogeneous electron gas with a density equal\nto the average valence density of Aluminum is 15.77 eV. Hence, using plasmon-\npole models may be not really appropriate.\n\n\nIn what follows, one will compute the GW band structure without a plasmon-pole\nmodel, by performing explicitly the numerical frequency convolution. In\npractice, it is convenient to extend all the functions of frequency to the\nfull complex plane. And then, making use of the residue theorem, the\nintegration path can be deformed: one transforms an integral along the real\naxis into an integral along the imaginary axis plus residues enclosed in the\nnew contour of integration. The method is extensively described in\nLebegue[2003].\n\n\nExamine the input file tgw2_2.in . The ten first lines contain the important\ninformation. There, you find some input variables that you are already\nfamiliarized with, like \noptdriver\n, \necuteps\n, \necutwfn\n, but also new\ninput variables: \ngwcalctyp\n, \nnfreqim\n, \nnfreqre\n, and \nfreqremax\n.\nThe purpose of this run is simply to generate the screening matrices. Unlike\nfor the plasmon-pole models, one needs to compute these at many different\nfrequencies. This is the purpose of the new input variables. The main variable\n\ngwcalctyp\n is set to 2 in order to specify a \nnon\n plasmon-pole model\ncalculation. Note that the number of frequencies along the imaginary axis\ngoverned by \nnfreqim\n can be chosen quite small, since all functions are\nsmooth in this direction. In contrast, the number of frequencies needed along\nthe real axis set with the variable \nnfreqre\n is usually larger.\n\n\n\n\n\u00b6\n\n\n3. Finding the Fermi energy and the bottom of the valence band. \n\n\nIn order not to lose time, let us start the calculation of the band width\nbefore the study of the input file. So, copy the file tgw2_3.in, and modify\nthe tgw3_x.files file as usual (replace occurrences of twg2_x by tgw2_3).\nAlso, copy the WFK file (tgw2_1o_WFK) to tgw2_3i_WFK, and the screening file\n(tgw2_2o_SCR) to tgw2_3i_SCR. Then run the calculation (it should take about 2\nminutes on a 3 GHz PC).\n\n\nThe computation of the GW quasi-particle energy at the Gamma point of Aluminum\ndoes not differ from the one of quasi-particle in Silicon. However, the\ndetermination of the Fermi energy raises a completely new problem: one should\nsample the Brillouin Zone, to get new energies (quasi-particle energies) and\nthen determine the Fermi energy. This is actually the first step towards a\nself-consistency!\n\n\nExamine the input file tgw2_3.in. The first thirty lines contain the important\ninformation. There, you find some input variables with values that you are\nalready familiarized with, like \noptdriver\n, \necutsigx\n, \necutwfn\n.\nThen, comes the input variable \ngwcalctyp\n=12. The value \nx2\n corresponds to\na contour integration. The value \n1x\n corresponds to a self-consistent\ncalculation with update of the energies only. Then, one finds the list of k\npoints and bands for which a quasi-particle correction will be computed:\n\nnkptgw\n, \nkptgw\n, and \nbdgw\n. The number and list of k points is simply\nthe same as \nnkpt\n and \nkpt\n. One might have specified less k points,\nthough (only those needing an update). The list of band ranges \nbdgw\n has\nbeen generated on the basis of the LDA eigenenergies. We considered only the\nbands in the vicinity of the Fermi level: bands much below or much above are\nlikely to remain much or much above the Fermi region. In the present run, we\nare just interested in the states that may cross the Fermi level, when going\nfrom LDA to GW. For commodity, one could have selected an homogeneous range\nfor the whole Brillouin zone, e.g. from 1 to 5, but this would have been more\ntime-consuming.\n\n\nIn the output file, one finds the quasi-particle energy at Gamma, for the\nlowest band:\n\n\nk =    0.000   0.000   0.000\n Band     E_lda   <Vxclda>   E(N-1)  <Hhartree>   SigX  SigC[E(N-1)]    Z     dSigC/dE  Sig[E(N)]  DeltaE  E(N)_pert E(N)_diago\n    1    -3.762    -9.451    -3.762     5.689   -15.049     5.676     0.777    -0.287    -9.390     0.060    -3.701    -3.684\n\n\n\n\n\n(the last column is the relevant quantity). The updated Fermi energy is also\nmentioned:\n\n\n New Fermi energy:     2.469501E-01 Ha ,    6.719854E+00 eV\n\n\n\n\n\nThe last information is not printed in case of \ngwcalctyp\n lower than 10.\n\n\nCombining the quasi-particle energy at Gamma and the Fermi energy, gives the\nband width, 10.404 eV. Using converged parameters, the band width will be\n10.54 eV (see Bruneval[2006]). This is in excellent agreement with the\nexperimental value of 10.6 eV.\n\n\n\n\n\u00b6\n\n\n4. Computing a GW spectral function, and the plasmon satellite of Aluminum. \n\n\nThe access to the non-plasmon-pole-model self-energy (real and imaginary part)\nhas additional benefit, e.g. an accurate spectral function can be computed,\nsee Lebegue[2003]. You may be interested to see the plasmon satellite of\nAluminum, which can be accounted for within the GW approximation. Remember the\nspectral function is almost (except some matrix elements) the spectrum which\nis measured in photoemission spectroscopy (PES). In PES, a photon impinges the\nsample and extracts an electron from the material. The difference of energy\nbetween the incoming photon and the obtained electron gives the binding energy\nof the electron in the solid, or in other words the quasiparticle energy or\nthe band structure. In simple metals, an additional process can take place\neasily: the impinging photon can \nextract an electron together with a global\ncharge oscillation in the sample\n. The extracted electron will have a kinetic\nenergy lower than in the direct process, because a part of the energy has gone\nto the plasmon. The electron will appear to have a larger binding energy\u2026\nYou will see that the spectral function of Aluminum consists of a main peak\nwhich corresponds to the quasiparticle excitation and some additional peaks\nwhich correspond to quasiparticle and plasmon excitations together.\n\n\nIn order not to lose time, this calculation can be started before the\nexamination of the input file. So, copy the file tgw2_4.in, and modify the\ntgw4_x.files file as usual (replace occurrences of twg2_x by tgw2_4). Also,\ncopy the WFK file (tgw2_1o_WFK) to tgw2_4i_WFK, and the screening file\n(tgw2_2o_SCR) to tgw2_4i_SCR. Then run the calculation (it should take about 2\nminutes on a 3 GHz PC).\n\n\nCompared to the previous file (tgw2_3.in), the input file contains two\nadditional keywords: \nnfreqsp\n, and \nfreqspmax\n. Also, the computation of\nthe GW self-energy is done only at the Gamma point.\n\n\nThe spectral function is written in the file tgw2_4o_SIG. It is a simple text\nfile. It contains, as a function of the frequency (eV), the real part of the\nself-energy, the imaginary part of the self-energy, and the spectral function.\nYou can visualize it using your preferred software. For instance, issue\n\n\n$ gnuplot\ngnuplot>  p\n'tgw2_4o_SIG'\n u \n1\n:4 w l\n\n\n\n\n\nYou should be able to distinguish the main quasiparticle peak located at the\nGW energy (-3.7 eV) and some additional features in the vicinity of the GW\neigenvalue minus a plasmon energy (-3.7 eV - 15.8 eV = -19.5 eV).\n\n\nAnother file, tgw2_4o_GW, is worth to mention: it contains information to be\nused for the subsequent calculation of excitonic effects by the EXC code\n(usually available at http://theory.polytechnique.fr/codes/exc ; if not, see\nthe \nETSF software page\n and\nfurther links).",
            "title": "GW2"
        },
        {
            "location": "/tutorials/gw2/#146-the-preliminary-kohn-sham-band-structure-calculation",
            "text": "Before beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not \u201cWork_gw2\u201d ?  During  lesson 4 , you computed different properties of\nAluminum within the LDA. Unlike for silicon, in this approximation, there is\nno outstanding problem in the computed band structure. Nevertheless, as you\nwill see, the agreement of the band structure with experiment can be improved\nsignificantly if one relies on the GW approximation.  In the directory ~abinit/tests/tutorial/Input/Work_gw2, copy the files\n~abinit/tests/tutorial/Input/tgw2_x.files and tgw2_1.in, and modify the\ntgw2_x.files file as usual (see lesson 1). \nThen (supposing abinit is the proper alias), issue:  abinit < tgw2_x.files >& tgw2_1.log &  This run generates the WFK file for the subsequent GW computation and also\nprovides the band width of Aluminum. Note that the simple Fermi-Dirac smearing\nfunctional is used ( occopt =3), with a large smearing ( tsmear =0.05 Ha).\nThe k point grid is quite rough, an unshifted 4x4x4 Monkhorst-Pack grid (64 k\npoints in the full Brillouin Zone, folding to 8 k points in the Irreducible\nwedge,  ngkpt =4 4 4). Converged results would need a 4x4x4 grid with 4\nshifts (256 k points in the full Brillouin zone). This grid contains the Gamma\npoint, at which the valence band structure reaches its minimum.  The output file presents the Fermi energy   Fermi (or HOMO) energy (eV) =   7.14774   Average Vxc (eV)=  -9.35982  as well as the lowest energy, at the Gamma point   Eigenvalues (   eV  ) for nkpt=   8  k points:\n kpt#   1, nband=  6, wtk=  0.01563, kpt=  0.0000  0.0000  0.0000 (reduced coord)\n  -3.76175  19.92114  19.92114  19.92114  21.00078  21.00078  So, the occupied band width is 10.90 eV. More converged calculations would\ngive 11.06 eV (see Bruneval[2006]). \nThis is to be compared to the experimental value of 10.6 eV (see references in\nBruneval[2006]).",
            "title": "1. The preliminary Kohn-Sham band structure calculation."
        },
        {
            "location": "/tutorials/bse/",
            "text": "authors : MG, MS\nhtmltitle: Lesson on Bethe-Salpeter calculations\n\n\n\n\nLesson on Bethe-Salpeter calculations\n\u00b6\n\n\nThis lesson discusses how to calculate the macroscopic dielectric function\nincluding excitonic effects within the Bethe-Salpeter (BS) approach.\nCrystalline silicon is used as test case. A brief description of the formalism\ncan be found in the Bether-Salpeter noted (\ntheorydoc_bse\n).\n\n\nThe user should be familiarized with the four basic lessons of ABINIT and the\nfirst lesson of the GW tutorial, see the \ntutorial home page\n.\n\n\nThis lesson should take about one hour to be completed.\n\n\n\n\n\n\n\n\nPreparatory steps (generating the WFK and the SCR file) \n\n\n\n\n\n\n\n\n\n\nComputing the absorption spectrum with different approximations \n\n\n\n\n\n\n\n\n\n\nConvergence with respect to the number of bands in the transition space \n\n\n\n\n\n\n\n\n\n\nConvergence with respect to the number of planewaves in the screening \n\n\n\n\n\n\n\n\n\n\nConvergence with respect to the number of k-points \n\n\n\n\n\n\n\n\n\n\nAdditional exercises (optional) \n\n\n\n\n\n\n\n\n\n\nNotes on the MPI implementation \n\n\n\n\n\n\n\n\n 1. Preparatory steps (generating the WFK and the SCR file).\n\u00b6\n\n\nBefore beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not \u201cWork_bs\u201d ?\n\n\nIn the directory ~abinit/tests/tutorial/Input/Work_bs, copy the files file\n~abinit/tests/tutorial/Input/tbs_1.files. Now run immediately the calculation\nwith the command:\n\n\n    $ abinit < tbs_1.files >\n&\n tbs_1.log \n&\n\n\n\n\n\n\nso that we can analyze the input file while the code is running.\n\n\nThe input file is located in ~abinit/tests/tutorial/Input/tbs_1.in. The header\nreports a brief description of the calculation so read it carefully. Don\u2019t\nworry if some parts are not clear to you as we are going to discuss the\ncalculation in step by step fashion.\n\n\nThis input file generates the two WFK files and the screening file needed for\nthe subsequent Bethe-Salpeter computations. The first dataset performs a\nrather standard ground-state calculation on an unshifted 4x4x4 grid (64 k\npoints in the full Brillouin Zone, folding to 8 k points in the irreducible\nwedge). Then the ground-state density is used in dataset 2 and 3 to generate\ntwo WFK files with a standard NSCF cycle, solved with the conjugate-gradient\nmethod.\n\n\nNote that the WFK file computed in dataset 2 contains 100 bands on the 4x4x4\ngamma-centered k-mesh whereas the WFK file produced in dataset 3 has only 10\nbands on a 4x4x4 k-mesh that has been shifted along the direction\n\n\n    shiftk3    0.11 0.21 0.31  # This shift breaks the symmetry of the k-mesh.\n\n\n\n\n\nThe gamma-centered \nk\n-mesh contains 8 points in the irreducible zone while the\nshifted k-mesh breaks the symmetry of the crystal leading to 64 points in the\nIBZ (actually the IBZ now coincides with the full Brillouin zone). The second\nmesh is clearly inefficient, so you might wonder why we are using such a\nbizarre sampling and, besides, why we need to generate two different WFK\nfiles!\n\n\nIndeed this approach strongly differs from the one we followed in the GW\ntutorials, but there is a good reason for doing so. It is anticipated that\noptical spectra converge slowly with the Brillouin zone sampling, and that\nsymmetry-breaking k-meshes lead to faster convergence in \nnkpt\n than the\nstandard symmetric k-meshes commonly used for ground-state or GW calculations.\n\n\nThis explains the bizarre shift but still why two WFK files? Why don\u2019t we\nsimply use the WFK file on the shifted k-mesh to compute the screening?\n\n\nThe reason is that a screening calculation done with many empty bands on the\nshifted k-mesh would be very memory demanding as the code should allocate a\nhuge portion of memory whose size scales with (\nnband\n * \nnkpt\n), and no\nsymmetry can be used to reduce the number of k-points.\n\n\nTo summarize: the WFK with the symmetric k-point sampling and 100 bands will\nbe used to compute the screening, while the WFK file with the shifted k-mesh\nand 10 bands will be used to construct the transition space employed for\nsolving the Bethe-Salpeter equation. The two k-meshes differ just for the\nshift thus they produce the same set of q-points (the list of q-points in the\nscreening is defined as all the possible differences between the k-points of\nthe WFK file). This means that, in the BS run, we can use the SCR file\ngenerated with the symmetric mesh even though the transition space is\nconstructed with the shifted k-mesh.\n\n\nAfter this lengthy discussion needed to clarify this rather technical point,\nwe can finally proceed to analyze the screening computation performed in the\nlast dataset of tbs_1.in.\n\n\nThe SCR file is calculated in dataset 4 using \nnband\n=100 and \necuteps\n\n6.0 Ha. In the \nfirst lesson\n of the GW tutorial, these\nvalues were found to give QP energies converged within 0.01 eV, so we are\nconfident that our SCR file is well converged and it can be safely used for\nperforming convergence tests in the Bethe-Salpeter part.\n\n\nNote that, for efficiency reasons, only the static limit of W is computed:\n\n\n    nfreqre4  1     # Only the static limit of W is needed for standard BSE calculations.\n    nfreqim4  0\n\n\n\n\n\nIndeed, in the standard formulation of the Bethe-Salpeter equation, only the\nstatic limit of the screened interaction is needed to construct the Coulomb\nterm of the BS Hamiltonian. Using a single frequency allows us to save some\nCPU time in the screening part, but keep in mind that this SCR file can only\nbe used either for Bethe-Salpeter computations or for GW calculations\nemploying the plasmon-pole models corresponding to \nppmodel\n=3,4.\n\n\nAt this point the calculation should have completed, but there\u2019s still one\nthing that we have to do before moving to the next paragraph.\n\n\nAs we said, we will need the WFK file on the shifted k-mesh and the SCR file\nfor our BS calculations so do not delete them! It is also a good idea to\nrename these precious files using more meaningful names e.g.:\n\n\n    $ mv tbs_1o_DS2_WFK 444_gamma_WFK\n    $ mv tbs_1o_DS3_WFK 444_shifted_WFK\n    $ mv tbs_1o_DS4_SCR 444_SCR\n\n\n\n\n\nKeep in mind that henceforth the k-point sampling cannot be changed anymore:\nthe list of k-points specified in the BS input files MUST equal the one used\nto generate the WFK file. Two new WFK files and a new SCR file must be\ngenerated from scratch if we want to change the k-point sampling used to\nconstruct the transition space.\n\n\n\n\n2. Computing the absorption spectrum within the Tamm-Dancoff approximation. \n\u00b6\n\n\nThis section is intended to show how to perform a standard excitonic\ncalculation within the Tamm-Dancoff approximation (TDA) using the Haydock\niterative technique. The input file is ~abinit/tests/tutorial/Input/tbs_2.in.\n\n\nBefore running the job, we have to connect this calculation with the output\nresults produced in tbs_1.in.\n\n\nUse the Unix commands:\n\n\n    ln -s 444_shifted_WFK tbs_2i_WFK\n    ln -s 444_SCR tbs_2i_SCR\n\n\n\n\n\nto create two symbolic links for the shifted WFK and the SCR file. The reason\nfor doing so will be clear afterwards once we discuss the input file.\n\n\nThis job lasts 1-2 minutes on a modern machine so it is worth running it\nbefore inspecting the input file.\n\n\nCopy the files file ~abinit/tests/tutorial/Input/tbs_2.files in the working\ndirectory and issue\n\n\n    $ abinit < tbs_2.files >& tbs_2.log &\n\n\n\n\n\nto put the job in background so that we can examine tbs_2.in.\n\n\nNow open ~abinit/tests/tutorial/Input/tbs_2.in in your preferred editor and go\nto the next section where we discuss the most important variables governing a\ntypical BS computation.\n\n\n 2.a The structure of the input file.\n\u00b6\n\n\nFirst we need to set \noptdriver\n=99 to call the BSE routines\n\n\n    optdriver  99        # BS calculation\n\n\n\n\n\nThe variables \nirdwfk\n and \nirdscr\n are similar to other \u201cird\u201d variables\nof ABINIT and are used to read the files produced in the previous paragraph\n\n\n    irdwfk  1     # Read the WFK file produced in tbs_1 \n    irdscr  1     # Read the SCR file produced in tbs_1 \n\n\n\n\n\nThe code expects to find an input WFK file and an input SCR file whose name is\nconstructed according to prefix specified in the files file tbs_2.files (see\n\nsection 1.1\n of the\nabinit_help file). This is the reason why we had to create the two symbolic\nlinks before running the code.\n\n\nThen we have a list of five variables specifying how to construct the\nexcitonic Hamiltonian.\n\n\n    bs_calctype       1       # L0 is constructed with KS orbitals and energies.\n    mbpt_sciss       0.8 eV   # Scissors operator used to correct the KS band structure.\n    bs_exchange_term  1       # Exchange term included.\n    bs_coulomb_term  11       # Coulomb term included using the full matrix W_GG'\n    bs_coupling       0       # Tamm-Dancoff approximation.\n\n\n\n\n\nThe value \nbs_calctype\n=1 specifies that the independent-particle\npolarizability should be costructed with the Kohn-Sham orbitals and energies\nread from the WFK file. To simulate the self-energy correction, the KS\nenergies are corrected with a scissors operator of energy \nmbpt_sciss\n= 0.8\neV. This permits us to avoid a cumbersome GW calculation for each state\nincluded in our transition space. The use of the scissors operator is a\nreasonable approximation for silicon but it might fail in more complicated\nsystems in which the GW corrections cannot be simulated in terms of a simple\nrigid shift of the initial KS bands structure.\n\n\nThe remaining three variables specify how to construct the excitonic\nHamiltonian. \nbs_exchange_term\n=1 tells the program to calculate the exchage\npart of the kernel, hence this calculation includes local-field effects. The\nvariable \nbs_coulomb_term\n is used to select among different options that\nare available for the Coulomb term (please take some time to read the\ndescription of the variable and the relevant equations in the Bethe-Salpeter\nnotes (\ntheorydoc_bse\n). Finally \nbs_coupling\n=0 specifies that the off-\ndiagonal coupling blocks should be neglected (Tamm-Dancoff approximation).\nThis particular combination of parameters thus corresponds to a Bethe-Salpeter\ncalculation within the Tamm-Dancoff approximation with local field effects\nincluded.\n\n\nThen we have the specification of the bands used to construct the transition\nspace:\n\n\n    bs_loband         2 \n    nband             8\n\n\n\n\n\nIn this case all the bands around the gap whose index is between 2 and 8 are\nincluded in the basis set.\n\n\nThe frequency mesh for the macroscopic dielectric function is specified\nthrough \nbs_freq_mesh\n\n\n    bs_freq_mesh 0 6 0.02 eV  # Frequency mesh.\n\n\n\n\n\nThis triplet of real values defines a linear mesh that covers the range [0,6]\neV with a step of 0.02 eV. The number of frequency points in the mesh does not\nhave any significant effect on the CPU time, but it is important to stress\nthat the number of bands included in the transition space defines, in\nconjunction with the number of k-points, the frequency range that can be\ndescribed. As a consequence \nbs_loband\n and \nnband\n should be subject to\nan accurate converge study.\n\n\nThen we have the parameters that define and control the algorithm employed to\ncalculate the macroscopic dielectric function\n\n\n    bs_algorithm        2      # Haydock method (this is the default value).\n    bs_haydock_niter   100     # Max number of iterations for the Haydock method.\n    bs_haydock_tol     0.05    # Tolerance for the iterative method.\n    zcut               0.15 eV # Complex shift to avoid divergences in the continued fraction.\n\n\n\n\n\nbs_algorithm\n specifies the algorithm used to calculate the macroscopic\ndielectric function. In this case we use the iterative Haydock technique whose\nmaximum number of iterations is given by \nbs_haydock_niter\n. The iterative\nalgorithm stops when the difference between two consecutive evaluations of the\noptical spectra is less than\n\nbs_haydock_tol\n.\nThe input variable \nzcut\n gives the complex shift to avoid divergences in\nthe continued fraction. From a physical point of view, this parameters mimics\nthe experimental broadening of the absorption peaks. In this test, due to the\ncoarseness of the k-mesh, we have to use a value slightly larger than the\ndefault one (0.1 eV) in order to facilitate the convergence of the Haydock\nalgorithm. Ideally, one should make a convergence study decreasing the value\nof \nzcut\n for increasing number of k-points.\n\n\nThe k-point sampling is specified by the set of variables.\n\n\n    # Definition of the k-point grid\n    kptopt 1                  # Option for the automatic generation of k points,\n    ngkpt  4 4 4              # This mesh is too coarse for optical properties.\n    nshiftk 1\n    shiftk    0.11 0.21 0.31  # This shift breaks the symmetry of the k-mesh.\n    chksymbreak 0             # Mandatory for using symmetry-breaking k-meshes in the BS code.\n\n\n\n\n\nThe values of \nkptopt\n, \nngkpt\n, \nnshiftk\n, and \nshiftk\n MUST equal\nthe ones used to specify the grid for the WFK file. \nchksymbreak\n=0 is used\nto bypass the check on symmetry breaking that, otherwise, would make the code\nstop.\n\n\nThe last section of the input file\n\n\n    ecutwfn 8.0               # Cutoff for the wavefunction.\n    ecuteps 2.0               # Cutoff for W and /bare v used to calculate the BS matrix elements.\n    inclvkb 2                 # The Commutator for the optical limit is correctly evaluated.\n\n\n\n\n\nspecifies the parameters used to calculate the kernel matrix elements and the\nmatrix elements of the dipole operator. We have already encountered these\nvariables in the \nfirst lesson\n of the GW tutorial so their\nmeaning is (hopefully) familiar to you. A more detailed discussion of the role\nplayed by these variables in the BS code can be found in the Bether-Salpeter\nnotes\ntheorydoc_bse\n.\n\n\n 2.c Output files.\n\u00b6\n\n\nThe output file, tbs_2.out, reports the basic parameters of the calculation\nand eventual WARNINGs that are issued if the iterative method does not\nconverge. Please take some time to understand its structure.\n\n\nCould you answer the following questions?\n\n\n\n\nHow many transitions are included in the basis set? \n\n\nHow many directions are used to evaluate the optical limit? \n\n\nWhat is the value of the Lorentzian broadening used in the continued fraction? \n\n\n\n\nAfter this digression on the main output file, we can finally proceed to\nanalyse the output data of the computation.\n\n\nThe most important results are stored in five different files:\n\n\n\n\ntbs_2o_BSR \n\n\ntbs_2o_HAYDR_SAVE \n\n\ntbs_2o_RPA_NLF_MDF \n\n\ntbs_2o_GW_NLF_MDF \n\n\ntbs_2o_EXC_MDF \n\n\n\n\nIn what follows, we provide a brief description of the format and of the\ncontent of each output file.\n\n\n\n\ntbs_2o_BSR: \n\n\n\n\nThis binary file stores the upper triangle of the resonant block (the matrix\nis Hermitian hence only the non-redundant part is computed and saved on file).\nThe BSR file can be used to restart the run from a previous computation using\nthe variables \ngetbsreso\n or \nirdbsreso\n. This restart capability is\nuseful for restarting the Haydock method if convergence was not achieved or to\nexecute Haydock computations with different values of \nzcut\n. \ngetbsreso\n\nand \nirdbsreso\n are also handy if one wants to include the coupling on top\nof a pre-existing TDA calculation since the code uses two different files to\nstore the resonant and the coupling block (BSC is the prefix used for the\nfiles storing the coupling term).\n\n\n\n\ntbs_2o_HAYDR_SAVE: \n\n\n\n\nIt is a binary file containing the results of the Haydock method: the\ncoefficient of the tridiagonal matrix and the three vectors employed in the\niterative algorithm. It is usually used to restart the algorithm if\nconvergence has not been achieved (see the related input variables\n\ngethaydock\n and\n\nirdhaydock\n).\n\n\n\n\ntbs_2o_RPA_NLF_MDF and tbs_2o_GW_NLF_MDF \n\n\n\n\nThe RPA spectrum without local field effects obtained with KS energies and the\nGW energies, respectively (mnemonics: NLF stands for No Local Field, while MDF\nstands for Macroscopic Dielectric Function).\n\n\n\n\ntbs_2o_EXC_MDF: \n\n\n\n\nFormatted file reporting the macroscopic dielectric function with excitonic\neffects. Since this file contains the most important results of our\ncalculation it is worth spending some time to discuss its format.\n\n\nFirst we have a header reporting the basic parameters of the calculation\n\n\n    # Macroscopic dielectric function obtained with the BS equation.\n    #  RPA L0 with KS energies and KS wavefunctions     LOCAL FIELD EFFECTS INCLUDED\n    # RESONANT-ONLY calculation\n    # Coulomb term constructed with full W(G1,G2)\n    # Scissor operator energy =  0.8000 [eV]\n    # Tolerance =  0.0500\n    # npweps  = 27\n    # npwwfn  = 283\n    # nbands  = 8\n    # loband  = 2\n    # nkibz   = 64\n    # nkbz    = 64\n    # Lorentzian broadening =  0.1500 [eV]\n\n\n\n\n\nthen the list of q-points giving the direction of the incident photon:\n\n\n    #  List of q-points for the optical limit:\n    # q =  0.938821, 0.000000, 0.000000, [Reduced coords] \n    # q =  0.000000, 0.938821, 0.000000, [Reduced coords] \n    # q =  0.000000, 0.000000, 0.938821, [Reduced coords] \n    # q =  0.000000, 0.813043, 0.813043, [Reduced coords] \n    # q =  0.813043, 0.000000, 0.813043, [Reduced coords] \n    # q =  0.813043, 0.813043, 0.000000, [Reduced coords] \n\n\n\n\n\nBy default the code calculates the macroscopic dielectric function considering\nsix different directions in q-space (the three basis vectors of the reciprocal\nlattice and the three Cartesian axis). It is possible to specify custom\ndirections using the input variables \ngw_nqlwl\n and \ngw_qlwl\n.\n\n\nThen comes the section with the real and the imaginary part of the macroscopic\ndielectric as a function of frequency for the different directions:\n\n\n    # omega [eV]    RE(eps(q=1)) IM(eps(q=1) RE(eps(q=2) ) ... \n    0.000  1.8026E+01  0.0000E+00  1.7992E+01  0.0000E+00  1.4292E+01  0.0000E+00  1.3993E+01 0.0000E+00  1.7117E+01  0.0000E+00  1.7080E+01  0.0000E+00\n      .... .... ...\n\n\n\n\n\nYou can visualize the data using your preferred software. For instance,\n\n\n    \n$\n \ngnu\nplot\n\n    \ngnu\nplot\n>\n  \np\n \n\"tbs_2o_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n\n\n\n\n\nwill plot the imaginary part of the macroscopic dielectric function (the\nabsorption spectrum) for the first q-point. You should obtain a graphic\nsimilar to the one reported below\n\n\n\n\nPlease note that these results are not converged, we postpone the discussion\nabout convergence tests to the next paragraphs of this tutorial.\n\n\nThe most important feature of the spectrum is the presence of two peaks\nlocated at around 3.4 and 4.3 eV. To understand the nature of these peaks and\nthe role played by the BS kernel, it is useful to compare the excitonic\nspectra with the RPA results obtained without local field effects.\n\n\nUse the sequence of gnuplot command\n\n\n    \n$\n \ngnu\nplot\n\n    \ngnu\nplot\n>\n  \np\n   \n\"tbs_2o_EXC_MDF\"\n     \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n  \nrep\n \n\"tbs_2o_RPA_NLF_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n  \nrep\n \n\"tbs_2o_GW_NLF_MDF\"\n  \nu\n \n1\n:\n3\n \nw\n \nl\n\n\n\n\n\n\nto plot the absorption spectrum obtained with the three different approaches.\nThe final result is reported in the figure below.\n\n\n\n\nThe RPA-KS spectrum underestimates the experimental optical threshold due to\nthe well know band gap problem of DFT. Most importantly, the amplitude of the\nfirst peak is underestimated, a problem than is not solved when local-field\neffects are correctly included in the calculation.\n\n\nThe RPA-GW results with QP corrections simulated with \nmbpt_sciss\n does not\nshow any significant improvement over RPA-KS: the RPA-GW spectrum is just\nshifted towards higher frequencies due to opening of the gap, but the shape of\nthe two spectra is very similar, in particular the amplitude of the first peak\nis still underestimated.\n\n\nOn the contrary, the inclusion of the BS kernel leads to important changes\nboth in the optical threshold as well as in the amplitude of the first peak.\nThis simple analysis tells us that the first peak in the absorption spectrum\nof silicon has a strong excitonic character that is not correctly described\nwithin the RPA. Our first BS spectrum is not converged at all and it barely\nresembles the experimental result, nevertheless this unconverged calculation\nis already able to capture the most important physics.\n\n\n 2.c Optional Exercises.\n\u00b6\n\n\n\n\nChange the value of the Lorentzian broadening \nzcut\n used to avoid divergences in the continued fraction. Then restart the Haydock algorithm from the _BSR and _HAYDR_SAVE files using the appropriate variables. What is the main effect of the broadening on the final spectrum. Does the number of iterations needed to converge depend on the broadening? \n\n\nUse the appropriate values for \nbs_exchange_term\n and \nbs_coulomb_term\n to calculate the BS spectrum without local field effects. Compare the results obtained with and without local field effects. \n\n\nModify the input file tbs_2.in so that the code reads in the resonant block produced in the previous run and calculates the spectrum employing the method based on the direct diagonalization (use \nirdbsreso\n to restart the run but remember to rename the file with the resonant block). Compare the CPU time needed by the two algorithms as a function of the number of transitions in the transition space. Which one has the best scaling? \n\n\n\n\n2.d Preliminary discussion about convergence studies \n\u00b6\n\n\nConverging the excitonic spectrum requires a careful analysis of many\ndifferent parameters:\n\n\n\n\nbs_loband\n \n\n\nnband\n \n\n\necutwfn\n \n\n\necuteps\n \n\n\nngkpt\n \n\n\nnshiftk\n \n\n\nshiftk\n \n\n\n\n\nSince the memory requirements scale quadratically with the number of k-points\nin the \nfull\n Brillouin zone \ntimes\n the number of valence bands\n\ntimes\n the number of conduction bands included in the transition space,\nit is very important to find a good compromise between accuracy and\ncomputational efficiency.\n\n\nFirst of all one should select the frequency range of interest since this\nchoice has an important effect on the number of valence and conduction states\nthat have to be included in the transition space. The optical spectrum is\nexpected to converge faster in the number of bands than the GW corrections\nsince only those transitions whose energy is \u201cclose\u201d to the frequency range\nunder investigation are expected to contribute.\n\n\necutwfn\n usually plays a secondary role since it only affects the accuracy\nof the oscillator matrix elements. We suggest avoiding any truncation of the\ninitial basis set by setting \necutwfn\n to a value slightly larger than the\nvalue of \necut\n used to generate the WFK file. One should truncate the\ninitial planewave basis set only when experiencing memory problems although\nthis kind of problems can be usually solved by just increasing the number of\nprocessors or, alternatively, with an appropriate choice of \ngwmem\n.\n\n\nThe value of \necuteps\n affects the accuracy of the matrix elements of the\nCoulomb term, the fundamental term that drives the creation of the excitons.\nAs a consequence \necuteps\n should be subject to an accurate convergence\ntest. As a rule of thumb, \necuteps\n can be chosen equal or, sometimes, even\nsmaller than the value needed to converge the GW corrections.\n\n\nAs already stated: optical spectra converge slowly with the Brillouin zone\nsampling. The convergence in the number of k-points thus represents the most\nimportant and tedious part of our convergence study. For this reason, this\nstudy should be done once converged values for the other parameters have been\nalready found.\n\n\n\n\n3. Convergence with respect to the number of bands in the transition space \n\u00b6\n\n\nIn this section we take advantage of the multi-dataset capabilities of ABINIT\nto perform calculations with different values for \nbs_loband\n and \nnband\n\n\nBefore running the test take some time to read the input file\n~abinit/tests/tutorial/Input/tbs_3.in.\n\n\nThe convergence in the number of transitions is performed by defining five\ndatasets with different values for \nnband\n and \nbs_loband\n\n\n    ndtset     5\n    bs_loband1  4 nband1  5\n    bs_loband2  3 nband2  6\n    bs_loband3  2 nband3  7\n    bs_loband4  2 nband4  8\n    bs_loband5  1 nband5  8\n\n\n\n\n\nThe parameters defining how to build the excitonic Hamiltonian are similar to\nthe ones used in tbs_2.in. The only difference is in the value used for\n\nbs_coulomb_term\n, i.e.\n\n\n    bs_coulomb_term      10 # Coulomb term evaluated within the diagonal approximation.\n\n\n\n\n\nthat allows us to save some CPU time during the computation of the Coulomb term.\n\n\nAlso in this case, before running the test, we have to connect tbs_3.in to the\nWFK and the SCR file produced in the first step. Note that tbs_3.in uses\n\nirdwfk\n and \nirdscr\n to read the external files, hence we have to create\nsymbolic links for each dataset:\n\n\n    ln -s 444_SCR tbs_3i_DS1_SCR\n    ln -s 444_SCR tbs_3i_DS2_SCR\n    ln -s 444_SCR tbs_3i_DS3_SCR\n    ln -s 444_SCR tbs_3i_DS4_SCR\n    ln -s 444_SCR tbs_3i_DS5_SCR\n    ln -s 444_shifted_WFK tbs_3i_DS1_WFK\n    ln -s 444_shifted_WFK tbs_3i_DS2_WFK\n    ln -s 444_shifted_WFK tbs_3i_DS3_WFK\n    ln -s 444_shifted_WFK tbs_3i_DS4_WFK\n    ln -s 444_shifted_WFK tbs_3i_DS5_WFK\n\n\n\n\n\nNow we can finally run the test with\n\n\n    abinit < tbs_3.files >\n&\n tbs3.log \n&\n\n\n\n\n\n\nThis job should last 3-4 minutes so be patient!\n\n\nLet us hope that your calculation has been completed, and that we can examine\nthe output results.\n\n\nUse the following sequence of gnuplot commands:\n\n\n    \n$\n \ngnu\nplot\n\n    \ngnu\nplot\n>\n \np\n   \n\"tbs_3o_DS1_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n \nrep\n \n\"tbs_3o_DS2_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n \nrep\n \n\"tbs_3o_DS3_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n \nrep\n \n\"tbs_3o_DS4_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n \nrep\n \n\"tbs_3o_DS5_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n\n\n\n\n\nto plot on the same graphic the absorption spectrum obtained with different\ntransition spaces. You should obtain a graphic similar to this one:\n\n\n\n\nThe results obtained with (\nbs_loband\n=4, \nnband\n=5) are clearly\nunconverged as the basis set contains too few transitions that are not able to\ndescribe the frequency-dependence of the polarizability in the energy range\nunder investigation. For a well converged spectrum, we have to include the\nthree higher occupied states and the first four conduction bands (the blue\ncurve corresponding to \nbs_loband\n=2, and \nnband\n=8).\n\n\nNote that adding the first occupied band, curve (1-8), gives results that are\nalmost on top of (2,8). This is due to the fact that, in silicon, the bottom\nof the first band is located at around 12 eV from the top of the conduction\nband therefore its inclusion does not lead to any significant improvement of\nthe transition space in the frequency range [0,8] eV. For completeness, we\nalso report the results obtained in a separate calculation done with\n\nbs_loband\n=2 \nnband\n=9 to show that four empty states are enough to\nconverge the spectrum.\n\n\nWe therefore fix the number of bands for the transition space using the\nconverged values \nbs_loband\n=2, \nnband\n=8, and we proceed to analyse the\nconvergence of the spectrum with respect to the number of planewaves in the\nscreening.\n\n\nFor expert users:\n\u00b6\n\n\nThe use of \nirdwfk\n and \nirdscr\n is not handy when we have several\ndatasets that are reading the SAME external file as we are forced to use\ndifferent names for the input of each dataset. To work around this annoyance,\none can introduce a fictitious dataset (say dataset 99), and let the code use\nthe output of this nonexistent dataset as the input of the real datasets. An\nexample will help clarify: Instead of using the lengthy list of links as done\nbefore, we might use the much simpler sequence of commands\n\n\n    ln -s 444_shifted_WFK tbs_3o_DS99_WFK\n    ln -s 444_SCR         tbs_3o_DS99_SCR\n\n\n\n\n\nprovided that, in the input file, we replace \nirdwfk\n and \nirdscr\n with\n\n\n    getwfk  99              # Trick to read the same file tbs_o3_DS99_WFK in each dataset\n    getscr  99              # Same trick for the SCR file\n\n\n\n\n\n\n\n5. Convergence with respect to the number of planewaves in the screening \n\u00b6\n\n\nFirst of all, before running the calculation, take some time to understand\nwhat is done in ~abinit/tests/tutorial/Input/tbs_4.in.\n\n\nThe structure of the input file is very similar to the one of tbs_3.in, the\nmain difference is in the first section:\n\n\n    ndtset 4\n    ecuteps: 1 ecuteps+ 2 \n    bs_coulomb_term 11\n\n\n\n\n\nthat instructs the code to execute four calculations where the direct term is\nconstructed using different value of \necuteps\n. We also relax the diagonal-\nonly approximation for the screening by setting \nbs_coulomb_term\n=11 so that\nthe non-locality of W(r,r\u2019) is correctly taken into account.\n\n\nIt is important to stress that it is not necessary to recalculate the SCR file\nfrom scratch just to modify the value of \necuteps\n used in the BS run. The\nSCR file calculated in the preparatory step contains G-vectors whose energy\nextends up to ecuteps=6.0 Ha. This is the MAXIMUM cutoff energy that can be\nused in our convergence tests. If the value of \necuteps\n specified in the\ninput file is smaller than the one stored on disk, the code will read a sub-\nblock of the initial matrix. A WARNING message is issued if the value\nspecified in the input file is larger than the one available in the SCR file.\n\n\nNow we can finally run the calculation. As usual, we have to copy\n~abinit/tests/tutorial/Input/tbs_4.files in the working directory Work_bs,\nthen we have to create a bunch of symbolic links for the input WFK and SCR\nfiles:\n\n\n    ln -s 444_SCR tbs_4i_DS1_SCR\n    ln -s 444_SCR tbs_4i_DS2_SCR\n    ln -s 444_SCR tbs_4i_DS3_SCR\n    ln -s 444_SCR tbs_4i_DS4_SCR\n    ln -s 444_shifted_WFK tbs_4i_DS1_WFK\n    ln -s 444_shifted_WFK tbs_4i_DS2_WFK\n    ln -s 444_shifted_WFK tbs_4i_DS3_WFK\n    ln -s 444_shifted_WFK tbs_4i_DS4_WFK\n\n\n\n\n\nNow issue\n\n\n    abinit < tbs_4.files >\n&\n tbs4.log \n&\n\n\n\n\n\n\nto execute the test (it should take around 2 minutes).\n\n\nOnce the calculation is completed, plot the spectra obtained with different\n\necuteps\n using\n\n\n    \n$\n \ngnu\nplot\n\n    \ngnu\nplot\n>\n  \np\n \n\"tbs_4o_DS1_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n  \np\n \n\"tbs_4o_DS2_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n  \np\n \n\"tbs_4o_DS3_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n    \ngnu\nplot\n>\n  \np\n \n\"tbs_4o_DS4_EXC_MDF\"\n \nu\n \n1\n:\n3\n \nw\n \nl\n\n\n\n\n\n\n\n\nThe spectrum is found to converge quickly in \necuteps\n. The curves obtained\nwith \necuteps\n=3 and 4 Ha are almost indistinguishable from each other. Our\nfinal estimate for \necuteps\n is therefore 3 Ha.\n\n\nNote that this value is smaller than the one required to converge the QP\ncorrections within 0.01 eV (in the \nfirst lesson\n of the GW\ntutorial we obtained 6.0 Ha). This is a general behavior, in the sense that\nBethe-Salpeter spectra, unlike GW corrections, are not usually very sensitive\nto truncations in the planewave expansion of W. Reasonable BS spectra are\nobtained even when W is treated within the diagonal approximation or,\nalternatively, with model dielectric functions.\n\n\nNote also how the two peaks are affected in a different way by the change of\n\necuteps\n, with the first peak affected the most. This behavior is\nconsistent with our affirmation that the first peak of silicon has a strong\nexcitonic character.\n\n\n\n\n6. Convergence with respect to the number of k-points \n\u00b6\n\n\nThe last parameter that should be checked for convergence is the number of\nk-points. This convergence study represents the most tedious and difficult\npart since it requires the generation of new WFK files and of the new SCR file\nfor each k-mesh (the list of k-points for the wavefunctions and the set of\nq-points in the screening must be consistent with each other).\n\n\nThe file ~abinit/tests/tutorial/Input/tbs_5.in gathers the different steps of\na standard BS calculation (generation of two WFK file, screening calculation,\nBS run) into a single input. The calculation is done with the converged\nparameters found in the previous studies, only \nngkpt\n has been\nintentionally left undefined.\n\n\nUse tbs_5.in as a template for performing BS calculations with different\nk-meshes. For example, you might try to compare the three meshes 4x4x4, 5x5x5,\nand 6x6x6. To facilitate the analysis of the results, we suggest to run the\ncalculations in different directories so that we can keep the output results\nseparated.\n\n\nBe aware that both the CPU time as well as the memory requirements increase\nquickly with the number of divisions in the mesh. These are, for example, the\nCPU times required by different k-meshes on Intel Xeon X5570:\n\n\n    4x4x4:    +Overall time at end (sec) : cpu=        112.4  wall=        112.4\n    5x5x5:    +Overall time at end (sec) : cpu=        362.8  wall=        362.8\n    6x6x6:    +Overall time at end (sec) : cpu=        914.8  wall=        914.8\n    8x8x8:    +Overall time at end (sec) : cpu=       5813.3  wall=       5813.3\n    10x10x10: +Overall time at end (sec) : cpu=      20907.1  wall=      20907.1\n    12x12x12: +Overall time at end (sec) : cpu=      62738.2  wall=      62738.2\n\n\n\n\n\n6x6x6 is likely the most dense sampling you can afford on a single-CPU\nmachine. For you convenience, we have collected the results of the convergence\ntest in the figure below.\n\n\n\n\nAs anticipated, the spectrum converges slowly with the number of k-points and\nour first calculation done with the 4x4x4 grid is severely unconverged. The\nmost accurate results are obtained with the 12x12x12 k-mesh, but even this\nsampling leads to converged results only for frequencies below 4.5 eV. This is\na problem common to all BS computations, in the sense that it is extremely\ndifficult to achieve global converge in the spectra. This analysis shows that\nwe can trust the 12x12x12 results in the [0:4,5] eV range while the correct\ndescription of the spectrum at higher energies would require the inclusion of\nmore k-point and, possibly, more bands so that the band dispersion is\ncorrectly taken into account (even the RPA spectrum does not coverge at high\nfrequencies when 12x12x12 is used).\n\n\nIt should be stressed that \nzcut\n plays a very important role in these\nconverge tests. For example, the results obtained with the 8x8x8 or the\n10x10x10 k-mesh can be brought closer to the 12x12x12 by just increasing the\nLorentzian broadening. When comparing theory with experiments, it is common to\ntreat \nzcut\n as an \na posteriori\n parameter chosen to produce the best\nagreement with the experiment.\n\n\n\n\n6. Additional exercises (optional) \n\u00b6\n\n\n\n\nUse \nbs_coupling\n=1 to perform an excitonic calculation for silicon including the coupling term. Compare the imaginary part of the macroscopic dielectric function obtained with and without coupling. Do you find significant differences? (Caveat: calculations with coupling cannot use the Haydock method and are much more CPU demanding. You might have to decrease some input parameters to have results in reasonable time.) \n\n\nCalculate the one-shot GW corrections for silicon following the \nfirst lesson\n of the GW tutorial. Then use the _GW file produced by the code to calculate the absorption spectrum. \n\n\n\n\n\n\n 7. Notes on the MPI implementation.\n\u00b6\n\n\nIn this section, we discuss the approach used to parallelize the two steps of\nthe BS run, \ni.e.\n the construction of the H matrix and the evaluation of the\nmacroscopic dielectric function.\n\n\nFirst of all, it is important to stress that, unlike the GW code, the BS\nroutines do not employ any kind of memory distribution for the wavefunctions.\nThe entire set of orbitals used to construct the transition space is stored on\neach node This choice has been dictated by the fact that the size of H is\nusually much larger than the array used to store the wavefunction, hence it is\nmuch more important to distribute the matrix than the wavefunctions. Besides,\nhaving all the states on each node simplifies the calculation of several\nintermediate quantities needed at run-time.\n\n\nThe memory allocated for the wavefunctions and the screening thus will not\nscale with the number of processors. However, for very memory demanding\ncalculations, the real space orbitals can be calculated on the fly with an\nincrease in computational time instead. This option is controlled by the\nsecond digit of the input variable \ngwmem\n.\n\n\nWhen discussing the MPI parallelization of the Bethe-Salpeter routines, we\nhave to consider the two steps separately.\n\n\nIn the first step, the upper triangle of the resonant (coupling) block is\ndistributed among the nodes. Each CPU computes its own portion and stores the\nresults in a temporary array. At the end of the computation, the portions of\nthe upper triangle are communicated to the master node which writes the binary\nfile BSR (BSC).\n\n\nIn the second step, each node reads the data stored in the external files in\norder to build the excitonic Hamiltonian.  The matrix is distributed using a\ncolumn-block partitioning, so that the matrix-vector multiplications required\nin the Haydock iterative scheme can be easily performed in parallel (see the\nschematic representation reported below). A similar distribution scheme is\nalso employed for the conjugate-gradient minimization. For a balanced\ndistribution of computational work, the number of processors should divide the\ntotal number of resonant transitions.",
            "title": "Bethe-Salpeter"
        },
        {
            "location": "/tutorials/bse/#lesson-on-bethe-salpeter-calculations",
            "text": "This lesson discusses how to calculate the macroscopic dielectric function\nincluding excitonic effects within the Bethe-Salpeter (BS) approach.\nCrystalline silicon is used as test case. A brief description of the formalism\ncan be found in the Bether-Salpeter noted ( theorydoc_bse ).  The user should be familiarized with the four basic lessons of ABINIT and the\nfirst lesson of the GW tutorial, see the  tutorial home page .  This lesson should take about one hour to be completed.     Preparatory steps (generating the WFK and the SCR file)       Computing the absorption spectrum with different approximations       Convergence with respect to the number of bands in the transition space       Convergence with respect to the number of planewaves in the screening       Convergence with respect to the number of k-points       Additional exercises (optional)       Notes on the MPI implementation",
            "title": "Lesson on Bethe-Salpeter calculations"
        },
        {
            "location": "/tutorials/bse/#146-preparatory-steps-generating-the-wfk-and-the-scr-file",
            "text": "Before beginning, you might consider to work in a different subdirectory as\nfor the other lessons. Why not \u201cWork_bs\u201d ?  In the directory ~abinit/tests/tutorial/Input/Work_bs, copy the files file\n~abinit/tests/tutorial/Input/tbs_1.files. Now run immediately the calculation\nwith the command:      $ abinit < tbs_1.files > &  tbs_1.log  &   so that we can analyze the input file while the code is running.  The input file is located in ~abinit/tests/tutorial/Input/tbs_1.in. The header\nreports a brief description of the calculation so read it carefully. Don\u2019t\nworry if some parts are not clear to you as we are going to discuss the\ncalculation in step by step fashion.  This input file generates the two WFK files and the screening file needed for\nthe subsequent Bethe-Salpeter computations. The first dataset performs a\nrather standard ground-state calculation on an unshifted 4x4x4 grid (64 k\npoints in the full Brillouin Zone, folding to 8 k points in the irreducible\nwedge). Then the ground-state density is used in dataset 2 and 3 to generate\ntwo WFK files with a standard NSCF cycle, solved with the conjugate-gradient\nmethod.  Note that the WFK file computed in dataset 2 contains 100 bands on the 4x4x4\ngamma-centered k-mesh whereas the WFK file produced in dataset 3 has only 10\nbands on a 4x4x4 k-mesh that has been shifted along the direction      shiftk3    0.11 0.21 0.31  # This shift breaks the symmetry of the k-mesh.  The gamma-centered  k -mesh contains 8 points in the irreducible zone while the\nshifted k-mesh breaks the symmetry of the crystal leading to 64 points in the\nIBZ (actually the IBZ now coincides with the full Brillouin zone). The second\nmesh is clearly inefficient, so you might wonder why we are using such a\nbizarre sampling and, besides, why we need to generate two different WFK\nfiles!  Indeed this approach strongly differs from the one we followed in the GW\ntutorials, but there is a good reason for doing so. It is anticipated that\noptical spectra converge slowly with the Brillouin zone sampling, and that\nsymmetry-breaking k-meshes lead to faster convergence in  nkpt  than the\nstandard symmetric k-meshes commonly used for ground-state or GW calculations.  This explains the bizarre shift but still why two WFK files? Why don\u2019t we\nsimply use the WFK file on the shifted k-mesh to compute the screening?  The reason is that a screening calculation done with many empty bands on the\nshifted k-mesh would be very memory demanding as the code should allocate a\nhuge portion of memory whose size scales with ( nband  *  nkpt ), and no\nsymmetry can be used to reduce the number of k-points.  To summarize: the WFK with the symmetric k-point sampling and 100 bands will\nbe used to compute the screening, while the WFK file with the shifted k-mesh\nand 10 bands will be used to construct the transition space employed for\nsolving the Bethe-Salpeter equation. The two k-meshes differ just for the\nshift thus they produce the same set of q-points (the list of q-points in the\nscreening is defined as all the possible differences between the k-points of\nthe WFK file). This means that, in the BS run, we can use the SCR file\ngenerated with the symmetric mesh even though the transition space is\nconstructed with the shifted k-mesh.  After this lengthy discussion needed to clarify this rather technical point,\nwe can finally proceed to analyze the screening computation performed in the\nlast dataset of tbs_1.in.  The SCR file is calculated in dataset 4 using  nband =100 and  ecuteps \n6.0 Ha. In the  first lesson  of the GW tutorial, these\nvalues were found to give QP energies converged within 0.01 eV, so we are\nconfident that our SCR file is well converged and it can be safely used for\nperforming convergence tests in the Bethe-Salpeter part.  Note that, for efficiency reasons, only the static limit of W is computed:      nfreqre4  1     # Only the static limit of W is needed for standard BSE calculations.\n    nfreqim4  0  Indeed, in the standard formulation of the Bethe-Salpeter equation, only the\nstatic limit of the screened interaction is needed to construct the Coulomb\nterm of the BS Hamiltonian. Using a single frequency allows us to save some\nCPU time in the screening part, but keep in mind that this SCR file can only\nbe used either for Bethe-Salpeter computations or for GW calculations\nemploying the plasmon-pole models corresponding to  ppmodel =3,4.  At this point the calculation should have completed, but there\u2019s still one\nthing that we have to do before moving to the next paragraph.  As we said, we will need the WFK file on the shifted k-mesh and the SCR file\nfor our BS calculations so do not delete them! It is also a good idea to\nrename these precious files using more meaningful names e.g.:      $ mv tbs_1o_DS2_WFK 444_gamma_WFK\n    $ mv tbs_1o_DS3_WFK 444_shifted_WFK\n    $ mv tbs_1o_DS4_SCR 444_SCR  Keep in mind that henceforth the k-point sampling cannot be changed anymore:\nthe list of k-points specified in the BS input files MUST equal the one used\nto generate the WFK file. Two new WFK files and a new SCR file must be\ngenerated from scratch if we want to change the k-point sampling used to\nconstruct the transition space.",
            "title": "1. Preparatory steps (generating the WFK and the SCR file)."
        },
        {
            "location": "/tutorials/bse/#2-computing-the-absorption-spectrum-within-the-tamm-dancoff-approximation",
            "text": "This section is intended to show how to perform a standard excitonic\ncalculation within the Tamm-Dancoff approximation (TDA) using the Haydock\niterative technique. The input file is ~abinit/tests/tutorial/Input/tbs_2.in.  Before running the job, we have to connect this calculation with the output\nresults produced in tbs_1.in.  Use the Unix commands:      ln -s 444_shifted_WFK tbs_2i_WFK\n    ln -s 444_SCR tbs_2i_SCR  to create two symbolic links for the shifted WFK and the SCR file. The reason\nfor doing so will be clear afterwards once we discuss the input file.  This job lasts 1-2 minutes on a modern machine so it is worth running it\nbefore inspecting the input file.  Copy the files file ~abinit/tests/tutorial/Input/tbs_2.files in the working\ndirectory and issue      $ abinit < tbs_2.files >& tbs_2.log &  to put the job in background so that we can examine tbs_2.in.  Now open ~abinit/tests/tutorial/Input/tbs_2.in in your preferred editor and go\nto the next section where we discuss the most important variables governing a\ntypical BS computation.",
            "title": "2. Computing the absorption spectrum within the Tamm-Dancoff approximation."
        },
        {
            "location": "/tutorials/bse/#2a-the-structure-of-the-input-file",
            "text": "First we need to set  optdriver =99 to call the BSE routines      optdriver  99        # BS calculation  The variables  irdwfk  and  irdscr  are similar to other \u201cird\u201d variables\nof ABINIT and are used to read the files produced in the previous paragraph      irdwfk  1     # Read the WFK file produced in tbs_1 \n    irdscr  1     # Read the SCR file produced in tbs_1   The code expects to find an input WFK file and an input SCR file whose name is\nconstructed according to prefix specified in the files file tbs_2.files (see section 1.1  of the\nabinit_help file). This is the reason why we had to create the two symbolic\nlinks before running the code.  Then we have a list of five variables specifying how to construct the\nexcitonic Hamiltonian.      bs_calctype       1       # L0 is constructed with KS orbitals and energies.\n    mbpt_sciss       0.8 eV   # Scissors operator used to correct the KS band structure.\n    bs_exchange_term  1       # Exchange term included.\n    bs_coulomb_term  11       # Coulomb term included using the full matrix W_GG'\n    bs_coupling       0       # Tamm-Dancoff approximation.  The value  bs_calctype =1 specifies that the independent-particle\npolarizability should be costructed with the Kohn-Sham orbitals and energies\nread from the WFK file. To simulate the self-energy correction, the KS\nenergies are corrected with a scissors operator of energy  mbpt_sciss = 0.8\neV. This permits us to avoid a cumbersome GW calculation for each state\nincluded in our transition space. The use of the scissors operator is a\nreasonable approximation for silicon but it might fail in more complicated\nsystems in which the GW corrections cannot be simulated in terms of a simple\nrigid shift of the initial KS bands structure.  The remaining three variables specify how to construct the excitonic\nHamiltonian.  bs_exchange_term =1 tells the program to calculate the exchage\npart of the kernel, hence this calculation includes local-field effects. The\nvariable  bs_coulomb_term  is used to select among different options that\nare available for the Coulomb term (please take some time to read the\ndescription of the variable and the relevant equations in the Bethe-Salpeter\nnotes ( theorydoc_bse ). Finally  bs_coupling =0 specifies that the off-\ndiagonal coupling blocks should be neglected (Tamm-Dancoff approximation).\nThis particular combination of parameters thus corresponds to a Bethe-Salpeter\ncalculation within the Tamm-Dancoff approximation with local field effects\nincluded.  Then we have the specification of the bands used to construct the transition\nspace:      bs_loband         2 \n    nband             8  In this case all the bands around the gap whose index is between 2 and 8 are\nincluded in the basis set.  The frequency mesh for the macroscopic dielectric function is specified\nthrough  bs_freq_mesh      bs_freq_mesh 0 6 0.02 eV  # Frequency mesh.  This triplet of real values defines a linear mesh that covers the range [0,6]\neV with a step of 0.02 eV. The number of frequency points in the mesh does not\nhave any significant effect on the CPU time, but it is important to stress\nthat the number of bands included in the transition space defines, in\nconjunction with the number of k-points, the frequency range that can be\ndescribed. As a consequence  bs_loband  and  nband  should be subject to\nan accurate converge study.  Then we have the parameters that define and control the algorithm employed to\ncalculate the macroscopic dielectric function      bs_algorithm        2      # Haydock method (this is the default value).\n    bs_haydock_niter   100     # Max number of iterations for the Haydock method.\n    bs_haydock_tol     0.05    # Tolerance for the iterative method.\n    zcut               0.15 eV # Complex shift to avoid divergences in the continued fraction.  bs_algorithm  specifies the algorithm used to calculate the macroscopic\ndielectric function. In this case we use the iterative Haydock technique whose\nmaximum number of iterations is given by  bs_haydock_niter . The iterative\nalgorithm stops when the difference between two consecutive evaluations of the\noptical spectra is less than bs_haydock_tol .\nThe input variable  zcut  gives the complex shift to avoid divergences in\nthe continued fraction. From a physical point of view, this parameters mimics\nthe experimental broadening of the absorption peaks. In this test, due to the\ncoarseness of the k-mesh, we have to use a value slightly larger than the\ndefault one (0.1 eV) in order to facilitate the convergence of the Haydock\nalgorithm. Ideally, one should make a convergence study decreasing the value\nof  zcut  for increasing number of k-points.  The k-point sampling is specified by the set of variables.      # Definition of the k-point grid\n    kptopt 1                  # Option for the automatic generation of k points,\n    ngkpt  4 4 4              # This mesh is too coarse for optical properties.\n    nshiftk 1\n    shiftk    0.11 0.21 0.31  # This shift breaks the symmetry of the k-mesh.\n    chksymbreak 0             # Mandatory for using symmetry-breaking k-meshes in the BS code.  The values of  kptopt ,  ngkpt ,  nshiftk , and  shiftk  MUST equal\nthe ones used to specify the grid for the WFK file.  chksymbreak =0 is used\nto bypass the check on symmetry breaking that, otherwise, would make the code\nstop.  The last section of the input file      ecutwfn 8.0               # Cutoff for the wavefunction.\n    ecuteps 2.0               # Cutoff for W and /bare v used to calculate the BS matrix elements.\n    inclvkb 2                 # The Commutator for the optical limit is correctly evaluated.  specifies the parameters used to calculate the kernel matrix elements and the\nmatrix elements of the dipole operator. We have already encountered these\nvariables in the  first lesson  of the GW tutorial so their\nmeaning is (hopefully) familiar to you. A more detailed discussion of the role\nplayed by these variables in the BS code can be found in the Bether-Salpeter\nnotes theorydoc_bse .",
            "title": "2.a The structure of the input file."
        },
        {
            "location": "/tutorials/bse/#2c-output-files",
            "text": "The output file, tbs_2.out, reports the basic parameters of the calculation\nand eventual WARNINGs that are issued if the iterative method does not\nconverge. Please take some time to understand its structure.  Could you answer the following questions?   How many transitions are included in the basis set?   How many directions are used to evaluate the optical limit?   What is the value of the Lorentzian broadening used in the continued fraction?    After this digression on the main output file, we can finally proceed to\nanalyse the output data of the computation.  The most important results are stored in five different files:   tbs_2o_BSR   tbs_2o_HAYDR_SAVE   tbs_2o_RPA_NLF_MDF   tbs_2o_GW_NLF_MDF   tbs_2o_EXC_MDF    In what follows, we provide a brief description of the format and of the\ncontent of each output file.   tbs_2o_BSR:    This binary file stores the upper triangle of the resonant block (the matrix\nis Hermitian hence only the non-redundant part is computed and saved on file).\nThe BSR file can be used to restart the run from a previous computation using\nthe variables  getbsreso  or  irdbsreso . This restart capability is\nuseful for restarting the Haydock method if convergence was not achieved or to\nexecute Haydock computations with different values of  zcut .  getbsreso \nand  irdbsreso  are also handy if one wants to include the coupling on top\nof a pre-existing TDA calculation since the code uses two different files to\nstore the resonant and the coupling block (BSC is the prefix used for the\nfiles storing the coupling term).   tbs_2o_HAYDR_SAVE:    It is a binary file containing the results of the Haydock method: the\ncoefficient of the tridiagonal matrix and the three vectors employed in the\niterative algorithm. It is usually used to restart the algorithm if\nconvergence has not been achieved (see the related input variables gethaydock  and irdhaydock ).   tbs_2o_RPA_NLF_MDF and tbs_2o_GW_NLF_MDF    The RPA spectrum without local field effects obtained with KS energies and the\nGW energies, respectively (mnemonics: NLF stands for No Local Field, while MDF\nstands for Macroscopic Dielectric Function).   tbs_2o_EXC_MDF:    Formatted file reporting the macroscopic dielectric function with excitonic\neffects. Since this file contains the most important results of our\ncalculation it is worth spending some time to discuss its format.  First we have a header reporting the basic parameters of the calculation      # Macroscopic dielectric function obtained with the BS equation.\n    #  RPA L0 with KS energies and KS wavefunctions     LOCAL FIELD EFFECTS INCLUDED\n    # RESONANT-ONLY calculation\n    # Coulomb term constructed with full W(G1,G2)\n    # Scissor operator energy =  0.8000 [eV]\n    # Tolerance =  0.0500\n    # npweps  = 27\n    # npwwfn  = 283\n    # nbands  = 8\n    # loband  = 2\n    # nkibz   = 64\n    # nkbz    = 64\n    # Lorentzian broadening =  0.1500 [eV]  then the list of q-points giving the direction of the incident photon:      #  List of q-points for the optical limit:\n    # q =  0.938821, 0.000000, 0.000000, [Reduced coords] \n    # q =  0.000000, 0.938821, 0.000000, [Reduced coords] \n    # q =  0.000000, 0.000000, 0.938821, [Reduced coords] \n    # q =  0.000000, 0.813043, 0.813043, [Reduced coords] \n    # q =  0.813043, 0.000000, 0.813043, [Reduced coords] \n    # q =  0.813043, 0.813043, 0.000000, [Reduced coords]   By default the code calculates the macroscopic dielectric function considering\nsix different directions in q-space (the three basis vectors of the reciprocal\nlattice and the three Cartesian axis). It is possible to specify custom\ndirections using the input variables  gw_nqlwl  and  gw_qlwl .  Then comes the section with the real and the imaginary part of the macroscopic\ndielectric as a function of frequency for the different directions:      # omega [eV]    RE(eps(q=1)) IM(eps(q=1) RE(eps(q=2) ) ... \n    0.000  1.8026E+01  0.0000E+00  1.7992E+01  0.0000E+00  1.4292E+01  0.0000E+00  1.3993E+01 0.0000E+00  1.7117E+01  0.0000E+00  1.7080E+01  0.0000E+00\n      .... .... ...  You can visualize the data using your preferred software. For instance,       $   gnu plot \n     gnu plot >    p   \"tbs_2o_EXC_MDF\"   u   1 : 3   w   l   will plot the imaginary part of the macroscopic dielectric function (the\nabsorption spectrum) for the first q-point. You should obtain a graphic\nsimilar to the one reported below   Please note that these results are not converged, we postpone the discussion\nabout convergence tests to the next paragraphs of this tutorial.  The most important feature of the spectrum is the presence of two peaks\nlocated at around 3.4 and 4.3 eV. To understand the nature of these peaks and\nthe role played by the BS kernel, it is useful to compare the excitonic\nspectra with the RPA results obtained without local field effects.  Use the sequence of gnuplot command       $   gnu plot \n     gnu plot >    p     \"tbs_2o_EXC_MDF\"       u   1 : 3   w   l \n     gnu plot >    rep   \"tbs_2o_RPA_NLF_MDF\"   u   1 : 3   w   l \n     gnu plot >    rep   \"tbs_2o_GW_NLF_MDF\"    u   1 : 3   w   l   to plot the absorption spectrum obtained with the three different approaches.\nThe final result is reported in the figure below.   The RPA-KS spectrum underestimates the experimental optical threshold due to\nthe well know band gap problem of DFT. Most importantly, the amplitude of the\nfirst peak is underestimated, a problem than is not solved when local-field\neffects are correctly included in the calculation.  The RPA-GW results with QP corrections simulated with  mbpt_sciss  does not\nshow any significant improvement over RPA-KS: the RPA-GW spectrum is just\nshifted towards higher frequencies due to opening of the gap, but the shape of\nthe two spectra is very similar, in particular the amplitude of the first peak\nis still underestimated.  On the contrary, the inclusion of the BS kernel leads to important changes\nboth in the optical threshold as well as in the amplitude of the first peak.\nThis simple analysis tells us that the first peak in the absorption spectrum\nof silicon has a strong excitonic character that is not correctly described\nwithin the RPA. Our first BS spectrum is not converged at all and it barely\nresembles the experimental result, nevertheless this unconverged calculation\nis already able to capture the most important physics.",
            "title": "2.c Output files."
        },
        {
            "location": "/tutorials/bse/#2c-optional-exercises",
            "text": "Change the value of the Lorentzian broadening  zcut  used to avoid divergences in the continued fraction. Then restart the Haydock algorithm from the _BSR and _HAYDR_SAVE files using the appropriate variables. What is the main effect of the broadening on the final spectrum. Does the number of iterations needed to converge depend on the broadening?   Use the appropriate values for  bs_exchange_term  and  bs_coulomb_term  to calculate the BS spectrum without local field effects. Compare the results obtained with and without local field effects.   Modify the input file tbs_2.in so that the code reads in the resonant block produced in the previous run and calculates the spectrum employing the method based on the direct diagonalization (use  irdbsreso  to restart the run but remember to rename the file with the resonant block). Compare the CPU time needed by the two algorithms as a function of the number of transitions in the transition space. Which one has the best scaling?",
            "title": "2.c Optional Exercises."
        },
        {
            "location": "/tutorials/bse/#2d-preliminary-discussion-about-convergence-studies",
            "text": "Converging the excitonic spectrum requires a careful analysis of many\ndifferent parameters:   bs_loband    nband    ecutwfn    ecuteps    ngkpt    nshiftk    shiftk     Since the memory requirements scale quadratically with the number of k-points\nin the  full  Brillouin zone  times  the number of valence bands times  the number of conduction bands included in the transition space,\nit is very important to find a good compromise between accuracy and\ncomputational efficiency.  First of all one should select the frequency range of interest since this\nchoice has an important effect on the number of valence and conduction states\nthat have to be included in the transition space. The optical spectrum is\nexpected to converge faster in the number of bands than the GW corrections\nsince only those transitions whose energy is \u201cclose\u201d to the frequency range\nunder investigation are expected to contribute.  ecutwfn  usually plays a secondary role since it only affects the accuracy\nof the oscillator matrix elements. We suggest avoiding any truncation of the\ninitial basis set by setting  ecutwfn  to a value slightly larger than the\nvalue of  ecut  used to generate the WFK file. One should truncate the\ninitial planewave basis set only when experiencing memory problems although\nthis kind of problems can be usually solved by just increasing the number of\nprocessors or, alternatively, with an appropriate choice of  gwmem .  The value of  ecuteps  affects the accuracy of the matrix elements of the\nCoulomb term, the fundamental term that drives the creation of the excitons.\nAs a consequence  ecuteps  should be subject to an accurate convergence\ntest. As a rule of thumb,  ecuteps  can be chosen equal or, sometimes, even\nsmaller than the value needed to converge the GW corrections.  As already stated: optical spectra converge slowly with the Brillouin zone\nsampling. The convergence in the number of k-points thus represents the most\nimportant and tedious part of our convergence study. For this reason, this\nstudy should be done once converged values for the other parameters have been\nalready found.",
            "title": "2.d Preliminary discussion about convergence studies"
        },
        {
            "location": "/tutorials/bse/#3-convergence-with-respect-to-the-number-of-bands-in-the-transition-space",
            "text": "In this section we take advantage of the multi-dataset capabilities of ABINIT\nto perform calculations with different values for  bs_loband  and  nband  Before running the test take some time to read the input file\n~abinit/tests/tutorial/Input/tbs_3.in.  The convergence in the number of transitions is performed by defining five\ndatasets with different values for  nband  and  bs_loband      ndtset     5\n    bs_loband1  4 nband1  5\n    bs_loband2  3 nband2  6\n    bs_loband3  2 nband3  7\n    bs_loband4  2 nband4  8\n    bs_loband5  1 nband5  8  The parameters defining how to build the excitonic Hamiltonian are similar to\nthe ones used in tbs_2.in. The only difference is in the value used for bs_coulomb_term , i.e.      bs_coulomb_term      10 # Coulomb term evaluated within the diagonal approximation.  that allows us to save some CPU time during the computation of the Coulomb term.  Also in this case, before running the test, we have to connect tbs_3.in to the\nWFK and the SCR file produced in the first step. Note that tbs_3.in uses irdwfk  and  irdscr  to read the external files, hence we have to create\nsymbolic links for each dataset:      ln -s 444_SCR tbs_3i_DS1_SCR\n    ln -s 444_SCR tbs_3i_DS2_SCR\n    ln -s 444_SCR tbs_3i_DS3_SCR\n    ln -s 444_SCR tbs_3i_DS4_SCR\n    ln -s 444_SCR tbs_3i_DS5_SCR\n    ln -s 444_shifted_WFK tbs_3i_DS1_WFK\n    ln -s 444_shifted_WFK tbs_3i_DS2_WFK\n    ln -s 444_shifted_WFK tbs_3i_DS3_WFK\n    ln -s 444_shifted_WFK tbs_3i_DS4_WFK\n    ln -s 444_shifted_WFK tbs_3i_DS5_WFK  Now we can finally run the test with      abinit < tbs_3.files > &  tbs3.log  &   This job should last 3-4 minutes so be patient!  Let us hope that your calculation has been completed, and that we can examine\nthe output results.  Use the following sequence of gnuplot commands:       $   gnu plot \n     gnu plot >   p     \"tbs_3o_DS1_EXC_MDF\"   u   1 : 3   w   l \n     gnu plot >   rep   \"tbs_3o_DS2_EXC_MDF\"   u   1 : 3   w   l \n     gnu plot >   rep   \"tbs_3o_DS3_EXC_MDF\"   u   1 : 3   w   l \n     gnu plot >   rep   \"tbs_3o_DS4_EXC_MDF\"   u   1 : 3   w   l \n     gnu plot >   rep   \"tbs_3o_DS5_EXC_MDF\"   u   1 : 3   w   l   to plot on the same graphic the absorption spectrum obtained with different\ntransition spaces. You should obtain a graphic similar to this one:   The results obtained with ( bs_loband =4,  nband =5) are clearly\nunconverged as the basis set contains too few transitions that are not able to\ndescribe the frequency-dependence of the polarizability in the energy range\nunder investigation. For a well converged spectrum, we have to include the\nthree higher occupied states and the first four conduction bands (the blue\ncurve corresponding to  bs_loband =2, and  nband =8).  Note that adding the first occupied band, curve (1-8), gives results that are\nalmost on top of (2,8). This is due to the fact that, in silicon, the bottom\nof the first band is located at around 12 eV from the top of the conduction\nband therefore its inclusion does not lead to any significant improvement of\nthe transition space in the frequency range [0,8] eV. For completeness, we\nalso report the results obtained in a separate calculation done with bs_loband =2  nband =9 to show that four empty states are enough to\nconverge the spectrum.  We therefore fix the number of bands for the transition space using the\nconverged values  bs_loband =2,  nband =8, and we proceed to analyse the\nconvergence of the spectrum with respect to the number of planewaves in the\nscreening.",
            "title": "3. Convergence with respect to the number of bands in the transition space"
        },
        {
            "location": "/tutorials/bse/#for-expert-users",
            "text": "The use of  irdwfk  and  irdscr  is not handy when we have several\ndatasets that are reading the SAME external file as we are forced to use\ndifferent names for the input of each dataset. To work around this annoyance,\none can introduce a fictitious dataset (say dataset 99), and let the code use\nthe output of this nonexistent dataset as the input of the real datasets. An\nexample will help clarify: Instead of using the lengthy list of links as done\nbefore, we might use the much simpler sequence of commands      ln -s 444_shifted_WFK tbs_3o_DS99_WFK\n    ln -s 444_SCR         tbs_3o_DS99_SCR  provided that, in the input file, we replace  irdwfk  and  irdscr  with      getwfk  99              # Trick to read the same file tbs_o3_DS99_WFK in each dataset\n    getscr  99              # Same trick for the SCR file",
            "title": "For expert users:"
        },
        {
            "location": "/tutorials/bse/#5-convergence-with-respect-to-the-number-of-planewaves-in-the-screening",
            "text": "First of all, before running the calculation, take some time to understand\nwhat is done in ~abinit/tests/tutorial/Input/tbs_4.in.  The structure of the input file is very similar to the one of tbs_3.in, the\nmain difference is in the first section:      ndtset 4\n    ecuteps: 1 ecuteps+ 2 \n    bs_coulomb_term 11  that instructs the code to execute four calculations where the direct term is\nconstructed using different value of  ecuteps . We also relax the diagonal-\nonly approximation for the screening by setting  bs_coulomb_term =11 so that\nthe non-locality of W(r,r\u2019) is correctly taken into account.  It is important to stress that it is not necessary to recalculate the SCR file\nfrom scratch just to modify the value of  ecuteps  used in the BS run. The\nSCR file calculated in the preparatory step contains G-vectors whose energy\nextends up to ecuteps=6.0 Ha. This is the MAXIMUM cutoff energy that can be\nused in our convergence tests. If the value of  ecuteps  specified in the\ninput file is smaller than the one stored on disk, the code will read a sub-\nblock of the initial matrix. A WARNING message is issued if the value\nspecified in the input file is larger than the one available in the SCR file.  Now we can finally run the calculation. As usual, we have to copy\n~abinit/tests/tutorial/Input/tbs_4.files in the working directory Work_bs,\nthen we have to create a bunch of symbolic links for the input WFK and SCR\nfiles:      ln -s 444_SCR tbs_4i_DS1_SCR\n    ln -s 444_SCR tbs_4i_DS2_SCR\n    ln -s 444_SCR tbs_4i_DS3_SCR\n    ln -s 444_SCR tbs_4i_DS4_SCR\n    ln -s 444_shifted_WFK tbs_4i_DS1_WFK\n    ln -s 444_shifted_WFK tbs_4i_DS2_WFK\n    ln -s 444_shifted_WFK tbs_4i_DS3_WFK\n    ln -s 444_shifted_WFK tbs_4i_DS4_WFK  Now issue      abinit < tbs_4.files > &  tbs4.log  &   to execute the test (it should take around 2 minutes).  Once the calculation is completed, plot the spectra obtained with different ecuteps  using       $   gnu plot \n     gnu plot >    p   \"tbs_4o_DS1_EXC_MDF\"   u   1 : 3   w   l \n     gnu plot >    p   \"tbs_4o_DS2_EXC_MDF\"   u   1 : 3   w   l \n     gnu plot >    p   \"tbs_4o_DS3_EXC_MDF\"   u   1 : 3   w   l \n     gnu plot >    p   \"tbs_4o_DS4_EXC_MDF\"   u   1 : 3   w   l    The spectrum is found to converge quickly in  ecuteps . The curves obtained\nwith  ecuteps =3 and 4 Ha are almost indistinguishable from each other. Our\nfinal estimate for  ecuteps  is therefore 3 Ha.  Note that this value is smaller than the one required to converge the QP\ncorrections within 0.01 eV (in the  first lesson  of the GW\ntutorial we obtained 6.0 Ha). This is a general behavior, in the sense that\nBethe-Salpeter spectra, unlike GW corrections, are not usually very sensitive\nto truncations in the planewave expansion of W. Reasonable BS spectra are\nobtained even when W is treated within the diagonal approximation or,\nalternatively, with model dielectric functions.  Note also how the two peaks are affected in a different way by the change of ecuteps , with the first peak affected the most. This behavior is\nconsistent with our affirmation that the first peak of silicon has a strong\nexcitonic character.",
            "title": "5. Convergence with respect to the number of planewaves in the screening"
        },
        {
            "location": "/tutorials/bse/#6-convergence-with-respect-to-the-number-of-k-points",
            "text": "The last parameter that should be checked for convergence is the number of\nk-points. This convergence study represents the most tedious and difficult\npart since it requires the generation of new WFK files and of the new SCR file\nfor each k-mesh (the list of k-points for the wavefunctions and the set of\nq-points in the screening must be consistent with each other).  The file ~abinit/tests/tutorial/Input/tbs_5.in gathers the different steps of\na standard BS calculation (generation of two WFK file, screening calculation,\nBS run) into a single input. The calculation is done with the converged\nparameters found in the previous studies, only  ngkpt  has been\nintentionally left undefined.  Use tbs_5.in as a template for performing BS calculations with different\nk-meshes. For example, you might try to compare the three meshes 4x4x4, 5x5x5,\nand 6x6x6. To facilitate the analysis of the results, we suggest to run the\ncalculations in different directories so that we can keep the output results\nseparated.  Be aware that both the CPU time as well as the memory requirements increase\nquickly with the number of divisions in the mesh. These are, for example, the\nCPU times required by different k-meshes on Intel Xeon X5570:      4x4x4:    +Overall time at end (sec) : cpu=        112.4  wall=        112.4\n    5x5x5:    +Overall time at end (sec) : cpu=        362.8  wall=        362.8\n    6x6x6:    +Overall time at end (sec) : cpu=        914.8  wall=        914.8\n    8x8x8:    +Overall time at end (sec) : cpu=       5813.3  wall=       5813.3\n    10x10x10: +Overall time at end (sec) : cpu=      20907.1  wall=      20907.1\n    12x12x12: +Overall time at end (sec) : cpu=      62738.2  wall=      62738.2  6x6x6 is likely the most dense sampling you can afford on a single-CPU\nmachine. For you convenience, we have collected the results of the convergence\ntest in the figure below.   As anticipated, the spectrum converges slowly with the number of k-points and\nour first calculation done with the 4x4x4 grid is severely unconverged. The\nmost accurate results are obtained with the 12x12x12 k-mesh, but even this\nsampling leads to converged results only for frequencies below 4.5 eV. This is\na problem common to all BS computations, in the sense that it is extremely\ndifficult to achieve global converge in the spectra. This analysis shows that\nwe can trust the 12x12x12 results in the [0:4,5] eV range while the correct\ndescription of the spectrum at higher energies would require the inclusion of\nmore k-point and, possibly, more bands so that the band dispersion is\ncorrectly taken into account (even the RPA spectrum does not coverge at high\nfrequencies when 12x12x12 is used).  It should be stressed that  zcut  plays a very important role in these\nconverge tests. For example, the results obtained with the 8x8x8 or the\n10x10x10 k-mesh can be brought closer to the 12x12x12 by just increasing the\nLorentzian broadening. When comparing theory with experiments, it is common to\ntreat  zcut  as an  a posteriori  parameter chosen to produce the best\nagreement with the experiment.",
            "title": "6. Convergence with respect to the number of k-points"
        },
        {
            "location": "/tutorials/bse/#6-additional-exercises-optional",
            "text": "Use  bs_coupling =1 to perform an excitonic calculation for silicon including the coupling term. Compare the imaginary part of the macroscopic dielectric function obtained with and without coupling. Do you find significant differences? (Caveat: calculations with coupling cannot use the Haydock method and are much more CPU demanding. You might have to decrease some input parameters to have results in reasonable time.)   Calculate the one-shot GW corrections for silicon following the  first lesson  of the GW tutorial. Then use the _GW file produced by the code to calculate the absorption spectrum.",
            "title": "6. Additional exercises (optional)"
        },
        {
            "location": "/tutorials/bse/#746-notes-on-the-mpi-implementation",
            "text": "In this section, we discuss the approach used to parallelize the two steps of\nthe BS run,  i.e.  the construction of the H matrix and the evaluation of the\nmacroscopic dielectric function.  First of all, it is important to stress that, unlike the GW code, the BS\nroutines do not employ any kind of memory distribution for the wavefunctions.\nThe entire set of orbitals used to construct the transition space is stored on\neach node This choice has been dictated by the fact that the size of H is\nusually much larger than the array used to store the wavefunction, hence it is\nmuch more important to distribute the matrix than the wavefunctions. Besides,\nhaving all the states on each node simplifies the calculation of several\nintermediate quantities needed at run-time.  The memory allocated for the wavefunctions and the screening thus will not\nscale with the number of processors. However, for very memory demanding\ncalculations, the real space orbitals can be calculated on the fly with an\nincrease in computational time instead. This option is controlled by the\nsecond digit of the input variable  gwmem .  When discussing the MPI parallelization of the Bethe-Salpeter routines, we\nhave to consider the two steps separately.  In the first step, the upper triangle of the resonant (coupling) block is\ndistributed among the nodes. Each CPU computes its own portion and stores the\nresults in a temporary array. At the end of the computation, the portions of\nthe upper triangle are communicated to the master node which writes the binary\nfile BSR (BSC).  In the second step, each node reads the data stored in the external files in\norder to build the excitonic Hamiltonian.  The matrix is distributed using a\ncolumn-block partitioning, so that the matrix-vector multiplications required\nin the Haydock iterative scheme can be easily performed in parallel (see the\nschematic representation reported below). A similar distribution scheme is\nalso employed for the conjugate-gradient minimization. For a balanced\ndistribution of computational work, the number of processors should divide the\ntotal number of resonant transitions.",
            "title": "7. Notes on the MPI implementation."
        },
        {
            "location": "/tutorials/basepar/",
            "text": "There are many situations where a sequential code is not enough, often because\nit would take too much time to get a result. There are also cases where you\njust want things to go as fast as your computational resources allow it. By\nusing more than one processor, you might also have access to more memory than\nwith only one processor. To this end, it is possible to use ABINIT in\nparallel, with dozens, hundreds or even thousands processors.\n\n\nThis tutorial offers you a little reconnaissance tour inside the complex world\nthat emerges as soon as you want to use more than one processor. From now on,\nwe will suppose that you are already familiar with ABINIT and that you have\ngone through all four basic tutorials. If this is not the case, we strongly\nadvise you to do so, in order to truly benefit from this tutorial.\n\n\nWe strongly recommend you to acquaint yourself with some basic concepts of\n\nparallel computing\n too. In\nparticular \n Almdalh\u2019s law\n,\nthat rationalizes the fact that, beyond some number of processors, the\ninherently sequential parts will dominate parallel parts, and give a\nlimitation to the maximal speed-up that can be achieved.\n\n\n\n\n\n\n\n\nGeneralities\n\n\n\n\n\n\n\n\n\n\nParallel environments \n\n\nGeneralities\n\n\nMPI\n\n\nOpenMP\n\n\nScalapack\n\n\nFast/slow communications\n\n\n\n\n\n\n\n\n\n\nWhat parts of ABINIT are parallel?\n\n\n\n\n\n\n\n\n\n\nA simple example of parallelism in ABINIT \n\n\nRunning a job\n\n\nParallelism over the k-points\n\n\nParallelism over the spins\n\n\nNumber of computing cores to accomplish a task\n\n\nEvidencing overhead\n\n\n\n\n\n\n\n\n\n\nDetails of the implementation \n\n\nThe MPI toolbox in ABINIT\n\n\nHow to parallelize a routine: some hints\n\n\n\n\n\n\n\n\n\n\n1. Generalities\n\u00b6\n\n\nWith the broad availability of multi-core processors, everybody now has a\nparallel machine at hand. ABINIT will be able to take advantage of the\navailability of several cores for most of its capabilities, be it ground-state\ncalculations, molecular dynamics, linear-response, many-body perturbation\ntheory, \u2026\n\n\nSuch tightly integrated multi-core processors (or so-called SMP machines,\nmeaning Symmetric Multi-Processing) can be interlinked within networks, based\non Ethernet or other types of connections (Quadrics, Myrinet, etc \u2026). The\nnumber of cores in such composite machines can easily exceed one hundred, and\ngo up to a fraction of a million these days. Most ABINIT capabilities can use\nefficiently several hundred computing cores. In some cases, even more than ten\nthousand computing cores can be used efficiently.\n\n\nBefore actually starting this tutorial and the associated ones, we strongly\nadvise you to get familiar with your own parallel environment. It might be\nrelatively simple for a SMP machine, but more difficult for very powerful\nmachines. You will need at least to have MPI (see next section) installed on\nyour machine. Take some time to determine how you can launch a job in parallel\nwith MPI (typically the qsub command and an associated shell script), what are\nthe resources available and the limitations as well, and do not hesitate to\ndiscuss with your system administrator if you feel that something is not clear\nto you.\n\n\nWe will suppose in the following that you know how to run a parallel program\nand that you are familiar with the peculiarities of your system. Please\nremember that, as there is no standard way of setting up a parallel\nenvironment, we are not able to provide you with support beyond ABINIT itself.\n\n\n\n\n2. Characteristics of parallel environments\n\u00b6\n\n\nGeneralities\n\u00b6\n\n\nDifferent software solutions can be used to benefit from parallelism. Most of\nABINIT parallelism is based on MPI, but some additional speed-up (or a better\ndistribution of data, allowing to run bigger calculations) is based on OpenMP.\nAs of writing, efforts also focus on Graphical Processing Units (GPUs), with\nCUDA and MAGMA. The latter will not be described in the present tutorial.\n\n\nMPI\n\u00b6\n\n\nMPI stands for Message Passing Interface. The goal of MPI, simply stated, is\nto develop a widely used standard for writing message- passing programs. As\nsuch the interface attempts to establish a practical, portable, efficient, and\nflexible standard for message passing.\n\n\nThe main advantages of establishing a message-passing standard are portability\nand ease-of-use. In a distributed memory communication environment in which\nthe higher level routines and/or abstractions are build upon lower-level\nmessage-passing routines, the benefits of standardization are particularly\nobvious. Furthermore, the definition of a message-passing standard provides\nvendors with a clearly defined base set of routines that they can implement\nefficiently, or in some cases provide hardware support for, thereby enhancing\nscalability [MPI1].\n\n\nAt some point in its history MPI has reach a critical popularity level, and a\nbunch of projects have popped-up like daisies in the grass. Now the tendency\nis back to gathering and merging. For instance, Open MPI is a project\ncombining technologies and resources from several other projects (FT-MPI, LA-\nMPI, LAM/MPI, and PACX-MPI) in order to build the best MPI library available.\nOpen MPI is a completely new MPI2-compliant implementation, offering\nadvantages for system and software vendors, application developers and\ncomputer science researchers [MPI2].\n\n\n[MPI1] \nhttp://mpi-forum.org\n\n[MPI2] \nhttps://www.open-mpi.org\n\n\nOpenMP\n\u00b6\n\n\nThe OpenMP Application Program Interface (API) supports multi-platform\n\nshared-memory\n parallel programming in C/C++ and Fortran on all\narchitectures, including Unix platforms and Windows NT platforms. Jointly\ndefined by a group of major computer hardware and software vendors, OpenMP is\na portable, scalable model that gives shared-memory parallel programmers a\nsimple and flexible interface for developing parallel applications for\nplatforms ranging from the desktop to the supercomputer [OMP1].\n\n\nOpenMP is rarely used within ABINIT, and only for specific purposes. In any\ncase, the first level of parallelism for these parts is based on MPI. Thus,\nthe use of OpenMP in ABINIT will not be described in this tutorial.\n\n\n[OMP1] \nhttp://www.openmp.org\n\n\nScalapack\n\u00b6\n\n\nScalapack is the parallel version of the popular LAPACK library (for linear\nalgebra). It can play some role in the parallelism of several parts of ABINIT,\nespecially the Band-FFT parallelism, and the parallelism for the Bethe-\nSalpether equation. ScaLAPACK being itself based on MPI, we will not discuss\nits use in ABINIT in this tutorial.\n\n\nFast/slow communications\n\u00b6\n\n\nCharacterizing the data-transfer efficiency between two computing cores (or\nthe whole set of cores) is a complex task. At a quite basic level, one has to\nrecognize that not only the quantity of data that can be transferred per unit\nof time is important, but also the time that is needed to initialize such a\ntransfer (so called \u201clatency\u201d).\n\n\nBroadly speaking, one can categorize computers following the speed of\ncommunications. In the fast communication machines, the latency is very low\nand the transfer time, once initialized, is very low too. For the parallelised\npart of ABINIT, SMP machines and machines with fast interconnect (Quadrics,\nMyrinet \u2026) will usually not be limited by their network characteristics, but\nby the existence of residual sequential parts. The tutorials that have been\ndeveloped for ABINIT have been based on fast communication machines.\n\n\nIf the set of computing cores that you plan to use is not entirely linked\nusing a fast network, but includes some connections based e.g. on Ethernet,\nthen, you might not be able to benefit from the speed-up announced in the\ntutorials. You have to perform some tests on your actual machine to gain\nknowledge of it.\n\n\n\n\n3. What parts of ABINIT are parallel?\n\u00b6\n\n\nParallelizing a code is a very delicate and complicated task, thus do not\nexpect that things will systematically go faster just because you are using a\nparallel version of ABINIT. Please keep also in mind that in some situations,\nparallelization is simply impossible. At the present time, the parts of ABINIT\nthat have been parallelized, and for which a tutorial is available, include:\n\n\n\n\nground state with plane waves\n,\n\n\nground state with wavelets\n,\n\n\nmolecular dynamics\n,\n\n\nparallelism on \u201cimages\u201d\n,\n\n\nresponse functions\n,\n\n\nMany-Body Perturbation Theory\n.\n\n\n\n\nNote that the tutorial on \nground state with plane\nwaves\n presents a complete overview of this\nparallelism, including up to four levels of parallelisation and, as such, is\nrather complex. Of course, it is also quite powerful, and allows to use\nseveral hundreds of processors.\n\n\nActually, the two levels based on\n\n\n\n\nthe treatment of k-points in reciprocal space;\n\n\nthe treatment of spins, for spin-polarized collinear situations (when \nnsppol\n=2);\n\n\n\n\nare, on the contrary, quite easy to use. An example of such parallelism will\nbe given in the next section.\n\n\n\n\n4. A simple example of parallelism in ABINIT\n\u00b6\n\n\nRunning a job\n\u00b6\n\n\nBefore starting, you might consider working in a different subdirectory as\nfor the other lessons. Why not \u201cWork_paral\u201d ?\n\n\nCopy the \nfiles\n file and the input file from the \n~abinit/tests/tutorial\n\ndirectory to your work directory. They are named \ntbasepar_1.files\n and\n\ntbasepar_1.in\n. You can start immediately a sequential run, to have a\nreference CPU time. On a 2.8GHz PC, it runs in about one minute.\n\n\nContrary to the sequential case, it is worth to have a look at the \u201cfiles\u201d\nfile, and to modify it for the parallel execution, as one should avoid\nunnecessary network communications. If every node has its own temporary or\nscratch directory, you can achieve this by providing a path to a local disk\nfor the temporary files in \nabinit.files\n. Supposing each processor has access\nto a local temporary disk space named \n/scratch/user\n, then you might modify\nthe 5th line of the \nfiles\n file so that it becomes:\n\n\ntbasepar_1.in\ntbasepar_1.out\ntbasepar_1i\ntbasepar_1o\n/scratch/user/tbasepar_1\n../../Psps_for_tests/HGH/82pb.4.hgh\n\n\n\n\n\nNote that determining ahead of time the precise resources you will need for\nyour run will save you a lot of time if you are using a batch queue system.\n\n\nParallelism over the k-points\n\u00b6\n\n\nThe most favorable case for a parallel run is to treat the k-points\nconcurrently, since the calculations can be done independently for each one of\nthem.\n\n\nActually, \ntbasepar_1.in\n corresponds to the investigation of a fcc crystal of\nlead, which requires a large number of k-points if one wants to get an\naccurate description of the ground state. Examine this file. Note that the\ncut-off is realistic, as well as the grid of k-points (giving 60 k points in\nthe irreducible Brillouin zone). However, the number of SCF steps, \nnstep\n,\nhas been set to 3 only. This is to keep the CPU time reasonable for this\ntutorial, without affecting the way parallelism on the k points will be able\nto increase the speed. Once done, your output files have likely been produced.\nExamine the timing in the output file (the last line gives the overall CPU and\nWall time), and keep note of it.\n\n\nNow you should run the parallel version of ABINIT. On a multi-core PC, you\nmight succeed to use two compute cores by issuing the run command for your MPI\nimplementation, and mention the number of processors you want to use, as well\nas the abinit command:\n\n\nmpirun -np 2 ../../src/main/abinit < tbasepar_1.files >& tbasepar_1.log &\n\n\n\n\n\nDepending on your particular machine, \u201cmpirun\u201d might have to be replaced by\n\u201cmpiexec\u201d, and \u201c-np\u201d by some other option.\n\n\nOn a cluster, with the MPICH implementation of MPI, you have to set up a file\nwith the addresses of the different CPUs. Let\u2019s suppose you call it \ncluster\n.\nFor a PC bi-processor machine, this file could have only one line, like the\nfollowing:\n\n\nsleepy.pcpm.ucl.ac.be:2\n\n\n\n\n\nFor a cluster of four machines, you might have something like:\n\n\ntux0\ntux1\ntux2\ntux3\n\n\n\n\n\nMore possibilities are mentioned in the file \n~abinit/doc/users/paral_use\n.\n\n\nThen, you have to issue the run command for your MPI implementation, and\nmention the number of processors you want to use, as well as the abinit\ncommand and the file containing the CPU addresses.\n\n\nOn a PC bi-processor machine, this gives the following:\n\n\nmpirun -np 2 -machinefile cluster ../../src/main/abinit < tbasepar_1.files >& tbasepar_1.log &\n\n\n\n\n\nNow, examine the corresponding output file. If you have kept the output from\nthe sequential job, you can make a diff between the two files. You will notice\nthat the numerical results are quite identical. You will also see that 60\nk-points have been kept in the memory in the sequential case, while 30\nk-points have been kept in the memory (per processor !) in the parallel case.\n\n\nThe timing can be found at the end of the file. Here is an example:\n\n\n- Proc.   0 individual time (sec): cpu=         28.3  wall=         28.3\n\n================================================================================\n\n Calculation completed.\n Delivered    1 WARNINGs and   1 COMMENTs to log file.\n+Overall time at end (sec) : cpu=         56.6  wall=         56.6\n\n\n\n\n\nThis corresponds effectively to a speed-up of the job by a factor of two.\nLet\u2019s examine it. The line beginning with \nProc. 0\n corresponds to the CPU and\nWall clock timing seen by the processor number 0 (processor indexing always\nstarts at 0: here the other is number 1): 28.3 sec of CPU time, and the same\namount of Wall clock time. The line that starts with \n+Overall time\n\ncorresponds to the sum of CPU times and Wall clock timing for all processors.\nThe summation is quite meaningful for the CPU time, but not so for the wall\nclock time: the job was finished after 28.3 sec, and not 56.6 sec.\n\n\nNow, you might try to increase the number of processors, and see whether the\nCPU time is shared equally amongst the different processors, so that the Wall\nclock time seen by each processor decreases. At some point (depending on your\nmachine, and the sequential part of ABINIT), you will not be able to decrease\nfurther the Wall clock time seen by one processor. It is not worth to try to\nuse more processors. You should get a curve similar to this one:\n\n\n\n\nThe red curve materializes the speed-up achieved, while the green one is the\n\u201cy = x\u201d line. The shape of the red curve will vary depending on your hardware\nconfiguration. The definition of the speed-up is the time taken in a\nsequential calculation divided by the time for your parallel calculation\n(hopefully > 1) .\n\n\nOne last remark: the number of k-points need not be a multiple of the number\nof processors. As an example, you might try to run the above case with 16\nprocessors: most of the processors will treat 4 k points, but four of them\nwill only treat 3 k points. The maximal speed-up will only be 15 (=60/4),\ninstead of 16.\n\n\nTry to avoid leaving an empty processor as this can make abinit fail with\ncertain compilers. An empty processor happens, for example, if you use 14\nprocessors: you obtain ceiling(60/14) = 5 k points per processor. In this case\n12 processors are filled with 5 k points each (giving 60), and the last 2\nprocessors are completely empty. Obviously there is no point in not reducing\nthe number of processors to 12. The extra processors do no useful work, but\nhave to run anyway, just to confirm to abinit once in a while that all 14\nprocessors are alive.\n\n\nParallelism over the spins\n\u00b6\n\n\nThe parallelization over the spins (up, down) is done along with the one over\nthe k-points, so it works exactly the same way. The files\n\n~abinit/tests/tutorial/tbasepar_2.in\n and\n\n~abinit/tests/tutorial/tbasepar_2.files\n treat a spin-polarized system\n(distorted FCC Iron) with only one k-point in the Irreducible Brillouin Zone.\nThis is quite unphysical, and has the sole purpose to show the spin\nparallelism with as few as two processors: the k-point parallelism has\nprecedence over the spin parallelism, so that with 2 processors, one needs\nonly one k-point to see the spin parallelism.\n\nIf needed, modify the \nfiles\n file, to provide a local temporary disk space.\nRun this test case, in sequential, then in parallel.\n\n\nWhile the jobs are running, read the input and files file. Then look closely\nat the output and log files. They are quite similar. With a diff, you will see\nthe only obvious manifestation of the parallelism in the following:\n\n\n< P newkpt: treating     40 bands with npw=    2698 for ikpt=   1\n< P newkpt: treating     40 bands with npw=    2698 for ikpt=   1\n---\n> P newkpt: treating     40 bands with npw=    2698 for ikpt=   1 by node    0\n> P newkpt: treating     40 bands with npw=    2698 for ikpt=   1 by node    1\n\n\n\n\n\nIn the second case (parallelism), node 0 is taking care of the up state for\nk-point 1, while node 1 is taking care of the down state for k-point 1. The\ntiming analysis is very similar to the k-point parallelism case.\n\n\nIf you have more than 2 processors at hand, you might increase the value of\n\nngkpt\n, so that more\nthan one k-point is available, and see that the k-point and spin parallelism\nindeed work concurrently.\n\n\nNumber of computing cores to accomplish a task\n\u00b6\n\n\nBalancing efficiently the load on the processors is not always\nstraightforward. When using k-point- and spin-parallelism, the ideal numbers\nof processors to use are those that divide the product of \nnsppol\n by\n\nnkpt\n (e.g. for \nnsppol\n*\nnkpt\n, it is quite efficient to use 2, 3, 4,\n6 or 12 processors). ABINIT will nevertheless handle correctly other numbers\nof processors, albeit slightly less efficiently, as the final time will be\ndetermined by the processor that will have the biggest share of the work to\ndo.\n\n\nEvidencing overhead\n\u00b6\n\n\nBeyond a certain number of processors, the efficiency of parallelism\nsaturates, and may even decrease. This is due to the inevitable overhead\nresulting from the increasing amount of communication between the processors.\nThe loss of efficiency is highly dependent on the implementation and linked to\nthe decreasing charge on each processor too.\n\n\n\n\n5. Details of the implementation\n\u00b6\n\n\nThe MPI toolbox in ABINIT\n\u00b6\n\n\nThe ABINIT-specific MPI routines are located in different subdirectories of\n\n~abinit/src\n: 12_hide_mpi/, 51_manage_mpi/, 56_io_mpi/, 79_seqpar_mpi/. They\ninclude:\n\n\n\n\nlow-level communication handlers (xfuncmpi, initmpi_*,xdef_comm);\n\n\nheader I/O helpers (hdr_io, hdr_io_netcdf);\n\n\nwavefunction I/O helpers (Wff*);\n\n\na multiprocess-aware output routine (wrtout);\n\n\na clean exit routine (leave_new).\n\n\n\n\nThey are used by a wide range of routines.\n\n\nYou might want to have a look at the routine headers for more detailed\ndescriptions.\n\n\nHow to parallelize a routine: some hints\n\u00b6\n\n\nHere we will give you some advice on how to parallelize a subroutine of\nABINIT. Do not expect too much, and remember that you remain mostly on your\nown for most decisions. Furthermore, we will suppose that you are familiar\nwith ABINIT internals and source code. Anyway, you can skip this section\nwithout hesitation, as it is primarily intended for advanced developers.\n\n\nFirst, every call to a MPI routine and every purely parallel section of your\nsubroutine \nmust\n be surrounded by the following preprocessing directives:\n\n\n#if defined MPI\n...\n#endif\n\n\n\n\n\nThe first block of this type will likely appear in the \u201clocal variables\u201d\nsection, where you will declare all MPI-specific variables. Please note that\nsome of them will be used in sequential mode as well, and thus will be\ndeclared outside this block (typically \nam_master\n, master, me_loc, etc.).\n\n\nThe MPI communications should be initialized at the very beginning of your\nsubroutine. To do this, we suggest the following piece of code:\n\n\n!Init mpi_comm\n\n \ncall\n \nxcomm_world\n(\nspaceComm\n)\n\n \nam_master\n=.\ntrue\n.\n\n \nmaster\n \n=\n \n0\n\n\n\n!Init ntot proc max\n\n \ncall\n \nxproc_max\n(\nnproc_loc\n,\nierr\n)\n\n\n\n!Define who i am\n\n \ncall\n \nxme_whoiam\n(\nme_loc\n)\n\n\n#\nif\n \ndefined\n \nHAVE_MPI\n\n \nif\n \n(\nme_loc\n/\n=\n0\n)\n \nthen\n\n  \nam_master\n=.\nFALSE\n.\n\n \nendif\n\n\n \nwrite\n(\nmessage\n,\n \n'(a,i3,a)'\n \n)\n \n' <ROUTINE NAME> '\n,\nnproc_loc\n,\n' CPU synchronized'\n\n \ncall\n \nwrtout\n(\nstd_out\n,\nmessage\n,\n'COLL'\n)\n\n \n...\n\n#\nendif\n\n\n\n\n\n\nNote that the first calls to x* are outside the preprocessing - they must be\ncalled in all cases, and have their own pre-processed sections. The cleaning\nand closing of MPI stuff is done in a central part of abinit at the end of the\nrun.",
            "title": "Base"
        },
        {
            "location": "/tutorials/basepar/#146-generalities",
            "text": "With the broad availability of multi-core processors, everybody now has a\nparallel machine at hand. ABINIT will be able to take advantage of the\navailability of several cores for most of its capabilities, be it ground-state\ncalculations, molecular dynamics, linear-response, many-body perturbation\ntheory, \u2026  Such tightly integrated multi-core processors (or so-called SMP machines,\nmeaning Symmetric Multi-Processing) can be interlinked within networks, based\non Ethernet or other types of connections (Quadrics, Myrinet, etc \u2026). The\nnumber of cores in such composite machines can easily exceed one hundred, and\ngo up to a fraction of a million these days. Most ABINIT capabilities can use\nefficiently several hundred computing cores. In some cases, even more than ten\nthousand computing cores can be used efficiently.  Before actually starting this tutorial and the associated ones, we strongly\nadvise you to get familiar with your own parallel environment. It might be\nrelatively simple for a SMP machine, but more difficult for very powerful\nmachines. You will need at least to have MPI (see next section) installed on\nyour machine. Take some time to determine how you can launch a job in parallel\nwith MPI (typically the qsub command and an associated shell script), what are\nthe resources available and the limitations as well, and do not hesitate to\ndiscuss with your system administrator if you feel that something is not clear\nto you.  We will suppose in the following that you know how to run a parallel program\nand that you are familiar with the peculiarities of your system. Please\nremember that, as there is no standard way of setting up a parallel\nenvironment, we are not able to provide you with support beyond ABINIT itself.",
            "title": "1. Generalities"
        },
        {
            "location": "/tutorials/basepar/#246-characteristics-of-parallel-environments",
            "text": "",
            "title": "2. Characteristics of parallel environments"
        },
        {
            "location": "/tutorials/basepar/#generalities",
            "text": "Different software solutions can be used to benefit from parallelism. Most of\nABINIT parallelism is based on MPI, but some additional speed-up (or a better\ndistribution of data, allowing to run bigger calculations) is based on OpenMP.\nAs of writing, efforts also focus on Graphical Processing Units (GPUs), with\nCUDA and MAGMA. The latter will not be described in the present tutorial.",
            "title": "Generalities"
        },
        {
            "location": "/tutorials/basepar/#mpi",
            "text": "MPI stands for Message Passing Interface. The goal of MPI, simply stated, is\nto develop a widely used standard for writing message- passing programs. As\nsuch the interface attempts to establish a practical, portable, efficient, and\nflexible standard for message passing.  The main advantages of establishing a message-passing standard are portability\nand ease-of-use. In a distributed memory communication environment in which\nthe higher level routines and/or abstractions are build upon lower-level\nmessage-passing routines, the benefits of standardization are particularly\nobvious. Furthermore, the definition of a message-passing standard provides\nvendors with a clearly defined base set of routines that they can implement\nefficiently, or in some cases provide hardware support for, thereby enhancing\nscalability [MPI1].  At some point in its history MPI has reach a critical popularity level, and a\nbunch of projects have popped-up like daisies in the grass. Now the tendency\nis back to gathering and merging. For instance, Open MPI is a project\ncombining technologies and resources from several other projects (FT-MPI, LA-\nMPI, LAM/MPI, and PACX-MPI) in order to build the best MPI library available.\nOpen MPI is a completely new MPI2-compliant implementation, offering\nadvantages for system and software vendors, application developers and\ncomputer science researchers [MPI2].  [MPI1]  http://mpi-forum.org \n[MPI2]  https://www.open-mpi.org",
            "title": "MPI"
        },
        {
            "location": "/tutorials/basepar/#openmp",
            "text": "The OpenMP Application Program Interface (API) supports multi-platform shared-memory  parallel programming in C/C++ and Fortran on all\narchitectures, including Unix platforms and Windows NT platforms. Jointly\ndefined by a group of major computer hardware and software vendors, OpenMP is\na portable, scalable model that gives shared-memory parallel programmers a\nsimple and flexible interface for developing parallel applications for\nplatforms ranging from the desktop to the supercomputer [OMP1].  OpenMP is rarely used within ABINIT, and only for specific purposes. In any\ncase, the first level of parallelism for these parts is based on MPI. Thus,\nthe use of OpenMP in ABINIT will not be described in this tutorial.  [OMP1]  http://www.openmp.org",
            "title": "OpenMP"
        },
        {
            "location": "/tutorials/basepar/#scalapack",
            "text": "Scalapack is the parallel version of the popular LAPACK library (for linear\nalgebra). It can play some role in the parallelism of several parts of ABINIT,\nespecially the Band-FFT parallelism, and the parallelism for the Bethe-\nSalpether equation. ScaLAPACK being itself based on MPI, we will not discuss\nits use in ABINIT in this tutorial.",
            "title": "Scalapack"
        },
        {
            "location": "/tutorials/basepar/#fastslow-communications",
            "text": "Characterizing the data-transfer efficiency between two computing cores (or\nthe whole set of cores) is a complex task. At a quite basic level, one has to\nrecognize that not only the quantity of data that can be transferred per unit\nof time is important, but also the time that is needed to initialize such a\ntransfer (so called \u201clatency\u201d).  Broadly speaking, one can categorize computers following the speed of\ncommunications. In the fast communication machines, the latency is very low\nand the transfer time, once initialized, is very low too. For the parallelised\npart of ABINIT, SMP machines and machines with fast interconnect (Quadrics,\nMyrinet \u2026) will usually not be limited by their network characteristics, but\nby the existence of residual sequential parts. The tutorials that have been\ndeveloped for ABINIT have been based on fast communication machines.  If the set of computing cores that you plan to use is not entirely linked\nusing a fast network, but includes some connections based e.g. on Ethernet,\nthen, you might not be able to benefit from the speed-up announced in the\ntutorials. You have to perform some tests on your actual machine to gain\nknowledge of it.",
            "title": "Fast/slow communications"
        },
        {
            "location": "/tutorials/basepar/#346-what-parts-of-abinit-are-parallel",
            "text": "Parallelizing a code is a very delicate and complicated task, thus do not\nexpect that things will systematically go faster just because you are using a\nparallel version of ABINIT. Please keep also in mind that in some situations,\nparallelization is simply impossible. At the present time, the parts of ABINIT\nthat have been parallelized, and for which a tutorial is available, include:   ground state with plane waves ,  ground state with wavelets ,  molecular dynamics ,  parallelism on \u201cimages\u201d ,  response functions ,  Many-Body Perturbation Theory .   Note that the tutorial on  ground state with plane\nwaves  presents a complete overview of this\nparallelism, including up to four levels of parallelisation and, as such, is\nrather complex. Of course, it is also quite powerful, and allows to use\nseveral hundreds of processors.  Actually, the two levels based on   the treatment of k-points in reciprocal space;  the treatment of spins, for spin-polarized collinear situations (when  nsppol =2);   are, on the contrary, quite easy to use. An example of such parallelism will\nbe given in the next section.",
            "title": "3. What parts of ABINIT are parallel?"
        },
        {
            "location": "/tutorials/basepar/#446-a-simple-example-of-parallelism-in-abinit",
            "text": "",
            "title": "4. A simple example of parallelism in ABINIT"
        },
        {
            "location": "/tutorials/basepar/#running-a-job",
            "text": "Before starting, you might consider working in a different subdirectory as\nfor the other lessons. Why not \u201cWork_paral\u201d ?  Copy the  files  file and the input file from the  ~abinit/tests/tutorial \ndirectory to your work directory. They are named  tbasepar_1.files  and tbasepar_1.in . You can start immediately a sequential run, to have a\nreference CPU time. On a 2.8GHz PC, it runs in about one minute.  Contrary to the sequential case, it is worth to have a look at the \u201cfiles\u201d\nfile, and to modify it for the parallel execution, as one should avoid\nunnecessary network communications. If every node has its own temporary or\nscratch directory, you can achieve this by providing a path to a local disk\nfor the temporary files in  abinit.files . Supposing each processor has access\nto a local temporary disk space named  /scratch/user , then you might modify\nthe 5th line of the  files  file so that it becomes:  tbasepar_1.in\ntbasepar_1.out\ntbasepar_1i\ntbasepar_1o\n/scratch/user/tbasepar_1\n../../Psps_for_tests/HGH/82pb.4.hgh  Note that determining ahead of time the precise resources you will need for\nyour run will save you a lot of time if you are using a batch queue system.",
            "title": "Running a job"
        },
        {
            "location": "/tutorials/basepar/#parallelism-over-the-k-points",
            "text": "The most favorable case for a parallel run is to treat the k-points\nconcurrently, since the calculations can be done independently for each one of\nthem.  Actually,  tbasepar_1.in  corresponds to the investigation of a fcc crystal of\nlead, which requires a large number of k-points if one wants to get an\naccurate description of the ground state. Examine this file. Note that the\ncut-off is realistic, as well as the grid of k-points (giving 60 k points in\nthe irreducible Brillouin zone). However, the number of SCF steps,  nstep ,\nhas been set to 3 only. This is to keep the CPU time reasonable for this\ntutorial, without affecting the way parallelism on the k points will be able\nto increase the speed. Once done, your output files have likely been produced.\nExamine the timing in the output file (the last line gives the overall CPU and\nWall time), and keep note of it.  Now you should run the parallel version of ABINIT. On a multi-core PC, you\nmight succeed to use two compute cores by issuing the run command for your MPI\nimplementation, and mention the number of processors you want to use, as well\nas the abinit command:  mpirun -np 2 ../../src/main/abinit < tbasepar_1.files >& tbasepar_1.log &  Depending on your particular machine, \u201cmpirun\u201d might have to be replaced by\n\u201cmpiexec\u201d, and \u201c-np\u201d by some other option.  On a cluster, with the MPICH implementation of MPI, you have to set up a file\nwith the addresses of the different CPUs. Let\u2019s suppose you call it  cluster .\nFor a PC bi-processor machine, this file could have only one line, like the\nfollowing:  sleepy.pcpm.ucl.ac.be:2  For a cluster of four machines, you might have something like:  tux0\ntux1\ntux2\ntux3  More possibilities are mentioned in the file  ~abinit/doc/users/paral_use .  Then, you have to issue the run command for your MPI implementation, and\nmention the number of processors you want to use, as well as the abinit\ncommand and the file containing the CPU addresses.  On a PC bi-processor machine, this gives the following:  mpirun -np 2 -machinefile cluster ../../src/main/abinit < tbasepar_1.files >& tbasepar_1.log &  Now, examine the corresponding output file. If you have kept the output from\nthe sequential job, you can make a diff between the two files. You will notice\nthat the numerical results are quite identical. You will also see that 60\nk-points have been kept in the memory in the sequential case, while 30\nk-points have been kept in the memory (per processor !) in the parallel case.  The timing can be found at the end of the file. Here is an example:  - Proc.   0 individual time (sec): cpu=         28.3  wall=         28.3\n\n================================================================================\n\n Calculation completed.\n Delivered    1 WARNINGs and   1 COMMENTs to log file.\n+Overall time at end (sec) : cpu=         56.6  wall=         56.6  This corresponds effectively to a speed-up of the job by a factor of two.\nLet\u2019s examine it. The line beginning with  Proc. 0  corresponds to the CPU and\nWall clock timing seen by the processor number 0 (processor indexing always\nstarts at 0: here the other is number 1): 28.3 sec of CPU time, and the same\namount of Wall clock time. The line that starts with  +Overall time \ncorresponds to the sum of CPU times and Wall clock timing for all processors.\nThe summation is quite meaningful for the CPU time, but not so for the wall\nclock time: the job was finished after 28.3 sec, and not 56.6 sec.  Now, you might try to increase the number of processors, and see whether the\nCPU time is shared equally amongst the different processors, so that the Wall\nclock time seen by each processor decreases. At some point (depending on your\nmachine, and the sequential part of ABINIT), you will not be able to decrease\nfurther the Wall clock time seen by one processor. It is not worth to try to\nuse more processors. You should get a curve similar to this one:   The red curve materializes the speed-up achieved, while the green one is the\n\u201cy = x\u201d line. The shape of the red curve will vary depending on your hardware\nconfiguration. The definition of the speed-up is the time taken in a\nsequential calculation divided by the time for your parallel calculation\n(hopefully > 1) .  One last remark: the number of k-points need not be a multiple of the number\nof processors. As an example, you might try to run the above case with 16\nprocessors: most of the processors will treat 4 k points, but four of them\nwill only treat 3 k points. The maximal speed-up will only be 15 (=60/4),\ninstead of 16.  Try to avoid leaving an empty processor as this can make abinit fail with\ncertain compilers. An empty processor happens, for example, if you use 14\nprocessors: you obtain ceiling(60/14) = 5 k points per processor. In this case\n12 processors are filled with 5 k points each (giving 60), and the last 2\nprocessors are completely empty. Obviously there is no point in not reducing\nthe number of processors to 12. The extra processors do no useful work, but\nhave to run anyway, just to confirm to abinit once in a while that all 14\nprocessors are alive.",
            "title": "Parallelism over the k-points"
        },
        {
            "location": "/tutorials/basepar/#parallelism-over-the-spins",
            "text": "The parallelization over the spins (up, down) is done along with the one over\nthe k-points, so it works exactly the same way. The files ~abinit/tests/tutorial/tbasepar_2.in  and ~abinit/tests/tutorial/tbasepar_2.files  treat a spin-polarized system\n(distorted FCC Iron) with only one k-point in the Irreducible Brillouin Zone.\nThis is quite unphysical, and has the sole purpose to show the spin\nparallelism with as few as two processors: the k-point parallelism has\nprecedence over the spin parallelism, so that with 2 processors, one needs\nonly one k-point to see the spin parallelism. \nIf needed, modify the  files  file, to provide a local temporary disk space.\nRun this test case, in sequential, then in parallel.  While the jobs are running, read the input and files file. Then look closely\nat the output and log files. They are quite similar. With a diff, you will see\nthe only obvious manifestation of the parallelism in the following:  < P newkpt: treating     40 bands with npw=    2698 for ikpt=   1\n< P newkpt: treating     40 bands with npw=    2698 for ikpt=   1\n---\n> P newkpt: treating     40 bands with npw=    2698 for ikpt=   1 by node    0\n> P newkpt: treating     40 bands with npw=    2698 for ikpt=   1 by node    1  In the second case (parallelism), node 0 is taking care of the up state for\nk-point 1, while node 1 is taking care of the down state for k-point 1. The\ntiming analysis is very similar to the k-point parallelism case.  If you have more than 2 processors at hand, you might increase the value of ngkpt , so that more\nthan one k-point is available, and see that the k-point and spin parallelism\nindeed work concurrently.",
            "title": "Parallelism over the spins"
        },
        {
            "location": "/tutorials/basepar/#number-of-computing-cores-to-accomplish-a-task",
            "text": "Balancing efficiently the load on the processors is not always\nstraightforward. When using k-point- and spin-parallelism, the ideal numbers\nof processors to use are those that divide the product of  nsppol  by nkpt  (e.g. for  nsppol * nkpt , it is quite efficient to use 2, 3, 4,\n6 or 12 processors). ABINIT will nevertheless handle correctly other numbers\nof processors, albeit slightly less efficiently, as the final time will be\ndetermined by the processor that will have the biggest share of the work to\ndo.",
            "title": "Number of computing cores to accomplish a task"
        },
        {
            "location": "/tutorials/basepar/#evidencing-overhead",
            "text": "Beyond a certain number of processors, the efficiency of parallelism\nsaturates, and may even decrease. This is due to the inevitable overhead\nresulting from the increasing amount of communication between the processors.\nThe loss of efficiency is highly dependent on the implementation and linked to\nthe decreasing charge on each processor too.",
            "title": "Evidencing overhead"
        },
        {
            "location": "/tutorials/basepar/#546-details-of-the-implementation",
            "text": "",
            "title": "5. Details of the implementation"
        },
        {
            "location": "/tutorials/basepar/#the-mpi-toolbox-in-abinit",
            "text": "The ABINIT-specific MPI routines are located in different subdirectories of ~abinit/src : 12_hide_mpi/, 51_manage_mpi/, 56_io_mpi/, 79_seqpar_mpi/. They\ninclude:   low-level communication handlers (xfuncmpi, initmpi_*,xdef_comm);  header I/O helpers (hdr_io, hdr_io_netcdf);  wavefunction I/O helpers (Wff*);  a multiprocess-aware output routine (wrtout);  a clean exit routine (leave_new).   They are used by a wide range of routines.  You might want to have a look at the routine headers for more detailed\ndescriptions.",
            "title": "The MPI toolbox in ABINIT"
        },
        {
            "location": "/tutorials/basepar/#how-to-parallelize-a-routine-some-hints",
            "text": "Here we will give you some advice on how to parallelize a subroutine of\nABINIT. Do not expect too much, and remember that you remain mostly on your\nown for most decisions. Furthermore, we will suppose that you are familiar\nwith ABINIT internals and source code. Anyway, you can skip this section\nwithout hesitation, as it is primarily intended for advanced developers.  First, every call to a MPI routine and every purely parallel section of your\nsubroutine  must  be surrounded by the following preprocessing directives:  #if defined MPI\n...\n#endif  The first block of this type will likely appear in the \u201clocal variables\u201d\nsection, where you will declare all MPI-specific variables. Please note that\nsome of them will be used in sequential mode as well, and thus will be\ndeclared outside this block (typically  am_master , master, me_loc, etc.).  The MPI communications should be initialized at the very beginning of your\nsubroutine. To do this, we suggest the following piece of code:  !Init mpi_comm \n  call   xcomm_world ( spaceComm ) \n  am_master =. true . \n  master   =   0  !Init ntot proc max \n  call   xproc_max ( nproc_loc , ierr )  !Define who i am \n  call   xme_whoiam ( me_loc ) \n\n# if   defined   HAVE_MPI \n  if   ( me_loc / = 0 )   then \n   am_master =. FALSE . \n  endif \n\n  write ( message ,   '(a,i3,a)'   )   ' <ROUTINE NAME> ' , nproc_loc , ' CPU synchronized' \n  call   wrtout ( std_out , message , 'COLL' ) \n  ... \n# endif   Note that the first calls to x* are outside the preprocessing - they must be\ncalled in all cases, and have their own pre-processed sections. The cleaning\nand closing of MPI stuff is done in a central part of abinit at the end of the\nrun.",
            "title": "How to parallelize a routine: some hints"
        },
        {
            "location": "/tutorials/paral_mbt/",
            "text": "This lesson aims at showing how to perform parallel calculations with the GW\npart of ABINIT. We will discuss the approaches used to parallelize the\ndifferent steps of a typical G0W0 calculation, and how to setup the parameters\nof the run in order to achieve good speedup. \u03b1-quartz SiO2 is used as test\ncase.\n\n\nIt is supposed that you have some knowledge about UNIX/Linux, and you know how\nto submit MPI jobs.\n\n\nThis lesson should take about 1.5 hour and requires to have at least a 200 CPU\ncore parallel computer.\n\n\nYou are supposed to know already some basics of parallelism in ABINIT,\nexplained in the tutorial \nA first introduction to ABINIT in\nparallel\n.\n\n\nIn the following, when \u201crun ABINIT over nn CPU cores\u201d appears, you have to use\na specific command line according to the operating system and architecture of\nthe computer you are using. This can be for instance:\n\n\nmpirun -n nn abinit < abinit.files\n\n\n\n\n\nor the use of a specific submission file.\n\n\n\n\n1 Generating the WFK file in parallel. \n\n\n2 Computing the screening in parallel using the Adler-Wiser expression \n\n\n3 Computing the screening in parallel using the Hilbert transform method \n\n\n4 Computing the one-shot GW corrections in parallel \n\n\n5 Basic rules for efficient parallel calculations \n\n\n\n\n\n\n** The input files necessary to run the examples related to this tutorial are located in the directory ~abinit/tests/tutoparal/Input. \n\n\nBefore beginning, you should create a working directory whose name might be\n\u201cWork_mbt\u201d (so ~abinit/tests/tutoparal/Input/Work_mbt).\n\n\nWe will do most of the actions of this tutorial in this working directory.\n\n\n1 Generating the WFK file in parallel.\n\u00b6\n\n\nIn the \nfirst lesson\n of the GW tutorial, we have learned how\nto generate the WFK file with the sequential version of the code. Now we will\nperform a similar calculation taking advantage of the k-point parallelism\nimplemented in the ground-state part.\n\n\nFirst of all, you should copy the files file tmbt_1.files in the working\ndirectory Work_mbt:\n\n\n$ \ncd\n Work_mbt\n$ cp ../tmbt_1.files .\n\n\n\n\n\nThe abinit files files is described in \nsection\n1.1\n of the abinit_help\nfile. Please, read it now if you haven\u2019t done it yet!\n\n\nNow open the input file ~abinit/tests/tutoparal/Input/tmbt_1.in in your\npreferred editor, and look at its structure.\n\n\nThe first dataset performs a rather standard SCF calculation to obtain the\nground-state density. The second dataset reads the density file and calculates\nthe Kohn-Sham band structure including many empty states:\n\n\n# DATASET 2 : WFK generation\niscf2      -2      # NSCF\ngetden2    -1      # Read previous density\ntolwfr2    1d-12   # Stopping criterion for the NSCF cycle.\nnband2      160    # Number of (occ and empty) bands computed in the NSCF cycle.\nnbdbuf2     10     # A large buffer helps to reduce the number of NSCF steps.\n\n\n\n\n\nWe have already encountered these variables in the \nfirst\nlesson\n of the GW tutorial so their meaning should be\nfamiliar to you.\n\n\nThe only thing worth stressing is that this calculation solves the NSCF cycle\nwith the conjugate-gradient method (paral_kgb == 0)\n\n\nThe NSCF cycle is executed in parallel using the standard parallelism over\nk-points and spin in which the (\nnkpt\n x \nnsppol\n) blocks of bands are\ndistributed among the nodes. This test uses an unshifted 4x4x3 grid (48 k\npoints in the full Brillouin Zone, folding to 9 k-points in the irreducible\nwedge) hence the theoretical maximum speedup is 9.\n\n\nNow run ABINIT over nn CPU cores using\n\n\n(mpirun ...) abinit < tmbt_1.files >& tmbt_1.log &\n\n\n\n\n\nbut keep in mind that, to avoid idle processors, the number of CPUs should\ndivide 9. At the end of the run, the code will produce the file tmbt_1o_WFK\nneeded for the subsequent GW calculations.\n\n\nWith three nodes, the wall clock time is around 1.5 minutes.\n\n\n$ tail tmbt_1.out\n\n-\n- Proc.   \n0\n individual \ntime\n \n(\nsec\n)\n: \ncpu\n=\n        \n209\n.0  \nwall\n=\n        \n209\n.0\n\n\n================================================================================\n\n\n Calculation completed.\n.Delivered    \n0\n WARNINGs and   \n5\n COMMENTs to log file.\n+Overall \ntime\n at end \n(\nsec\n)\n : \ncpu\n=\n        \n626\n.9  \nwall\n=\n        \n626\n.9\n\n\n\n\n\nA reference output file is given in ~tests/tutoparal/Refs, under the name\ntmbt_1.out.\n\n\nNote that 150 bands are not enough to obtain converged GW results, you might\nincrease the number of bands in proportion to your computing resources.\n\n\n\n\n2. Computing the screening in parallel using the Adler-Wiser expression**\n\u00b6\n\n\nIn this part of the tutorial, we will compute the RPA polarizability with the\nAdler-Wiser approach. The basic equations are discussed in this\n\nsection\n\nof the GW notes.\n\n\nFirst copy the files file tmbt_2.file in the working directory, then create a\nsymbolic link pointing to the WFK file we have generated in the previous step:\n\n\n$ ln -s tmbt_1o_DS2_WFK tmbt_2i_WFK\n\n\n\n\n\nNow open the input file ~abinit/tests/tutoparal/Input/tmbt_2.in so that we can\ndiscuss its structure.\n\n\nThe set of parameters controlling the screening computation is summarized\nbelow:\n\n\noptdriver   3   # Screening run\nirdwfk      1   # Read input WFK file\nsymchi      1   # Use symmetries to speedup the BZ integration\nawtr        1   # Take advantage of time-reversal. Mandatory when gwpara=2 is used.\ngwpara      2   # Parallelization over bands\necutwfn     24  # Cutoff for the wavefunctions.\necuteps     8   # Cutoff for the polarizability.\nnband       50  # Number of bands in the RPA expression (24 occupied bands)\ninclvkb     2   # Correct treatment of the optical limit.\n\n\n\n\n\nMost of the variables have been already discussed in the\n\nfirst\n lesson of the GW tutorial. The only variables that\ndeserve some additional explanation are \ngwpara\n and \nawtr\n.\n\n\ngwpara\n selects the parallel algorithm used to compute the screening. Two\ndifferent approaches are implemented:\n\n\n\n\n\n\ngwpara\n=1 -> Trivial parallelization over the k-points in the full Brillouin \n\n\n\n\n\n\ngwpara\n=2 -> Parallelization over bands with memory distribution \n\n\n\n\n\n\nEach method presents advantages and drawbacks that are discussed in the\ndocumentation of the variable. In this tutorial, we will be focusing on\n\ngwpara\n=2 since this is the algorithm with the best MPI-scalability and,\nmostly important, it is the only one that allows for a significant reduction\nof the memory requirement.\n\n\nThe option \nawtr\n=1 specifies that the system presents time reversal\nsymmetry so that it is possible to halve the number of transitions that have\nto be calculated explicitly (only resonant transitions are needed). Note that\n\nawtr\n=1 is MANDATORY when \ngwpara\n=2 is used.\n\n\nBefore running the calculation in parallel, it is worth discussing some\nimportant technical details of the implementation. For our purposes, it\nsuffices to say that, when \ngwpara\n=2 is used in the screening part, the\ncode distributes the wavefunctions such that each processing unit owns the\nFULL set of occupied bands while the empty states are distributed among the\nnodes. The parallel computation of the inverse dielectric matrix is done in\nthree different steps that can be schematically described as follows:\n\n\n\n\nEach node computes the partial contribution to the RPA polarizability: \n\n\n\n\n\n\n\n\n\n\nThe partial results are collected on each node. \n\n\n\n\n\n\nThe master node performs the matrix inversion to obtain the inverse dielectric matrix and writes the final result on file. \n\n\n\n\n\n\nBoth the first and second step of the algorithm are expected to scale well\nwith the number of processors. Step 3, on the contrary, is performed in\nsequential thus it will have a detrimental effect on the overall scaling,\nespecially in the case of large screening matrices (large \nnpweps\n or large\nnumber of frequency points \u03c9).\n\n\nNote that the maximum number of CPUs that can be used is dictated by the\nnumber of empty states used to compute the polarizability. Most importantly, a\nbalanced distribution of the computing time is obtained when the number of\nprocessors divides the number of conduction states.\n\n\nThe main limitation of the present implementation is represented by the\nstorage of the polarizability. This matrix, indeed, is not distributed hence\neach node must have enough memory to store in memory a table whose size is\ngiven by (\nnpweps\n2 x \nnomega\n x 16 bytes) where \nnomega\n is the total\nnumber of frequencies computed.\n\n\nTests performed at the Barcelona Supercomputing Center (see figures below)\nhave revealed that the first and the second part of the MPI algorithm have a\nvery good scaling. The routines cchi0 and cchi0q0 where the RPA expression is\ncomputed (step 1 and 2) scales almost linearly up to 512 processors. The\ndegradation of the total speedup observed for large number of processors is\nmainly due to the portions of the computation that are not parallelized,\nnamely the reading of the WFK file and the matrix inversion (qloop).\n\n\n\n\n\n\nAt this point, the most important technical details of the implementation have\nbeen covered, and we can finally run ABINIT over nn CPU cores using\n\n\n(mpirun ...) abinit < tmbt_2.files >& tmbt_2.log &\n\n\n\n\n\nRun the input file tmb_2.in using different number of processors and keep\ntrack of the time for each processor number so that we can test the\nscalability of the implementation. The performance analysis reported in the\nfigures above was obtained with PAW using ZnO as tests case, but you should\nobserve a similar behavior also in SiO2.\n\n\nNow let\u2019s have a look at the output results. Since this tutorial mainly\nfocuses on how to run efficient MPI computations, we won\u2019t perform any\nconverge study for SiO2. Most of the parameters used in the input files are\nalready close to converge, only the k-point sampling and the number of empty\nstates should be increased. You might modify the input files to perform the\nstandard converge tests following the procedure described in the \nfirst\nlesson\n of the GW tutorial.\n\n\nIn the main output file, there is a section reporting how the bands are\ndistributed among the nodes. For a sequential calculation, we have\n\n\n screening : taking advantage of time-reversal symmetry\n Maximum band index for partially occupied states nbvw =    24\n Remaining bands to be divided among processors   nbcw =    26\n Number of bands treated by each node ~   26\n\n\n\n\n\nThe value reported in the last line will decrease when the computation is done\nwith more processors.\n\n\nThe memory allocated for the wavefunctions scales with the number of\nprocessors. You can use the grep utility to extract this information from the\nlog file. For a calculation in sequential, we have:\n\n\n$ grep \n\"Memory needed\"\n tmbt_2.log\n\n  Memory needed \nfor\n storing \nug\n=\n         \n29\n.5 \n[\nMb\n]\n\n  Memory needed \nfor\n storing \nur\n=\n        \n180\n.2 \n[\nMb\n]\n\n\n\n\n\n\nug\n denotes the internal buffer used to store the Fourier components of the\norbitals whose size scales linearly with\n\nnpwwfn\n. \nur\n is\nthe array storing the orbitals on the real space FFT mesh. Keep in mind that\nthe size of \nur\n scales linearly with the total number of points in the FFT\nbox, number that is usually much larger than the number of planewaves\n(\nnpwwfn\n). The\nnumber of FFT divisions used in the GW code can be extracted from the main\noutput file using\n\n\n$ grep setmesh tmbt_2.out  -A \n1\n\n setmesh: FFT mesh size \nselected\n  \n=\n  27x 27x \n36\n\n          total number of \npoints\n  \n=\n    \n26244\n\n\n\n\n\n\nAs discussed in this\n\nsection\n of\nthe GW notes, the Fast Fourier Transform represents one of the most CPU\nintensive part of the execution. For this reason the code provides the input\nvariable \nfftgw\n that can be used to decrease the number of FFT points for\nbetter efficiency. The second digit of the input variable \ngwmem\n, instead,\ngoverns the storage of the real space orbitals and can used to avoid the\nstorage of the costly array \nur\n at the price of an increase in computational\ntime.\n\n\n\u00b6\n\n\n 2.d Manual parallelization over q-points.\n\u00b6\n\n\nThe computational effort required by the screening computation scales linearly\nwith the number of q-points. As explained in this\n\nsection\n\nof the GW notes, the code exploits the symmetries of the screening function so\nthat only the irreducible Brillouin zone (IBZ) has to be calculated\nexplicitly. On the other hand, a large number of q-points might be needed to\nachieve converged results. Typical examples are GW calculations in metals or\noptical properties within the Bethe-Salpeter formalism.\n\n\nIf enough processing units are available, the linear factor due to the q-point\nsampling can be trivially absorbed by splitting the calculation of the\nq-points into several independent runs using the variables \nnqptdm\n and\n\nqptdm\n. The results can then be gathered in a unique binary file by means\nof the \nmrgscr\n utility (see also the automatic tests v3/t87, v3/t88 and\nv3/t89).\n\n\n\n\n3. Computing the screening in parallel using the Hilbert transform\n\u00b6\n\n\nmethod**\n\n\nAs discussed in the\n\nGW_notes\n,\nthe algorithm based on the Adler-Wiser expression is not optimal when many\nfrequencies are wanted. In this paragraph, we therefore discuss how to use the\nHilbert transform method to calculate the RPA polarizability on a dense\nfrequency mesh. The equations implemented in the code are documented in \nthis\nsection\n of\nthe GW notes.\n\n\nAs usual, we have to copy the files file tmbt_3.file in the working directory,\nand then create a symbolic link pointing to the WFK file.\n\n\n$ ln -s tmbt_1o_DS2_WFK tmbt_3i_WFK\n\n\n\n\n\nThe input file is ~abinit/tests/tutoparal/Input/tmbt_3.in. Open it so that we\ncan have a look at its structure.\n\n\nA snapshot of the most important parameters governing the algorithm is\nreported below.\n\n\ngwcalctyp   2    # Contour-deformation technique.\nspmeth      1    # Enable the spectral method.\nnomegasf  100    # Number of points for the spectral function. \ngwpara      2    # Parallelization over bands\nawtr        1    # Take advantage of time-reversal. Mandatory when gwpara=2 is used.\nfreqremax  40 eV # Frequency mesh for the polarizability\nnfreqre    20\nnfreqim     5\n\n\n\n\n\nThe input file is similar to the one we used for the Adler-Wiser calculation.\nThe input variable \nspmeth\n enables the spectral method. \nnomegasf\n\ndefines the number of \u03c9\u2032 points in the linear mesh used for the spectral\nfunction i.e. the number of \u03c9\u2032 in the\n\nequation\n\nfor the spectral function.\n\n\nAs discussed in the \nGW\nnotes\n, the\nHilbert transform method is much more memory demanding that the Adler-Wiser\napproach, mainly because of the large value of \nnomegasf\n that is usually\nneeded to converge the results. Fortunately, the particular distribution of\nthe data employed in \ngwpara\n=2 turns out to be well suited for the\ncalculation of the spectral function since each processor has to store and\ntreat only a subset of the entire range of transition energies. The algorithm\ntherefore presents good MPI-scalability since the number of \u03c9\u2032 frequencies\nthat have to be stored and considered in the Hilbert transform decreases with\nthe number of processors.\n\n\nNow run ABINIT over nn CPU cores using\n\n\n(mpirun ...) abinit < tmbt_3.files >& tmbt_3.log &\n\n\n\n\n\nand test the scaling by varying the number of processors. Keep in mind that,\nalso in this case, the distribution of the computing work is well balanced\nwhen the number of CPUs divides the number of conduction states.\n\n\nThe memory needed to store the spectral function is reported in the log file:\n\n\n$ grep \n\"sf_chi0q0\"\n tmbt_3.log\n memory required by sf_chi0q0:           \n1\n.0036 \n[\nGb\n]\n\n\n\n\n\n\nNote how the size of this array decreases when more processors are used.\n\n\nThe figure below shows the electron energy loss function (EELF) of SiO2\ncalculated using the Adler-Wiser and the Hilbert transform method. You might\ntry to reproduce these results (the EELF is reported in the file tmbt_3o_EELF,\na much denser k-sampling is required to achieve convergence).\n\n\n\n\n\n\n4. Computing the one-shot GW corrections in parallel**\n\u00b6\n\n\nIn this last paragraph, we discuss how to calculate G0W0 corrections in\nparallel with \ngwpara\n=2. The basic equations used to compute the self-\nenergy matrix elements are discussed in \nthis\npart\n of\nthe GW notes.\n\n\nBefore running the calculation, copy the files file tmbt_4.file in the working\ndirectory. Then create two symbolic links for the SCR and the WFK file:\n\n\nln -s tmbt_1o_DS2_WFK tmbt_4i_WFK\nln -s tmbt_2o_SCR     tmbt_4i_SCR\n\n\n\n\n\nNow open the input file ~abinit/tests/tutoparal/Input/tmbt_4.in.\n\n\nThe most important parameters of the calculation are reported below:\n\n\noptdriver   4            # Sigma run.\nirdwfk      1  \nirdscr      1\ngwcalctyp   0 ppmodel 1  # G0W0 calculation with the plasmon-pole approximation.\n#gwcalctyp  2            # Uncomment this line to use the contour-deformation technique but remember to change the SCR file!\ngwpara      2            # Parallelization over bands.\nsymsigma    1            # To enable the symmetrization of the self-energy matrix elements.\necutwfn    24            # Cutoff for the wavefunctions.\necuteps     8            # Cutoff in the correlation part.\necutsigx   20            # Cutoff in the exchange part.\nnband       50           # Number of bands for the correlation part.\n\n\n\n\n\nFor our purposes, it suffices to say that this input file defines a standard\none-shot calculation with the plasmon-pole model approximation. We refer to\nthe documentation and to the \nfirst lesson\n of the GW\ntutorial for a more complete description of the meaning of these variables.\n\n\nAlso in this case, we use \ngwpara\n=2 to perform the calculation in parallel.\nNote, however, that the distribution of the orbitals employed in the self-\nenergy part significantly differs from the one used to compute the screening.\nIn what follows, we briefly describe the two-step procedure used to distribute\nthe wavefunctions:\n\n\n\n\n\n\nEach node reads and stores in memory the states where the QP corrections are computed (the list of states specified by \nkptgw\n and \nbdgw\n). \n\n\n\n\n\n\nThe \nnband\n bands are distributed using the following partition scheme: \n\n\n\n\n\n\n\n\nwhere we have assumed a calculation done with four nodes (the index in the box\ndenotes the MPI rank).\n\n\nBy virtue of the particular distribution adopted, the computation of the\ncorrelation part is expected to scale well with the number CPUs. The maximum\nnumber of processors that can be used is limited by \nnband\n. Note, however,\nthat only a subset of processors will receive the occupied states when the\nbands are distributed in step 2. As a consequence, the theoretical maximum\nspeedup that can be obtained in the exchange part is limited by the\navailability of the occupied states on the different MPI nodes involved in the\nrun.\n\n\nThe best-case scenario is when the QP corrections are wanted for all the\noccupied states. In this case, indeed, each node can compute part of the self-\nenergy and almost linear scaling should be reached. The worst-case scenario is\nwhen the quasiparticle corrections are wanted only for a few states (e.g. band\ngap calculations) and NCPU >> Nvalence. In this case, indeed, only\nNvalence processors will participate to the calculation of the exchange part.\n\n\nTo summarize: The MPI computation of the correlation part is efficient when\nthe number of processors divides \nnband\n. Optimal scaling in the exchange\npart is obtained only when each node possesses the full set of occupied\nstates.\n\n\nThe two figures below show the speedup of the sigma part as function of the\nnumber of processors. The self-energy is calculated for 5 quasiparticle states\nusing nband=1024 (205 occupied states). Note that this setup is close to the\nworst-case scenario. The computation of the self-energy matrix elements\n(csigme) scales well up to 64 processors. For large number number of CPUs, the\nscaling departs from the linear behavior due to the unbalanced distribution of\nthe occupied bands. The non-scalable parts of the implementation (init1,\nrdkss) limit the total speedup due to Amdhal\u2019s law.\n\n\n\n\nThe implementation presents good memory scalability since the largest arrays\nare distributed. Only the size of the screening does not scale with the number\nof nodes. By default each CPU stores in memory the entire screening matrix for\nall the q-points and frequencies in order to optimize the computation. In the\ncase of large matrices, however, it possible to opt for an out-of-core\nsolution in which only a single q-point is stored in memory and the data is\nread from the external SCR file (slower but less memory demanding). This\noption is controlled by the first digit of \ngwmem\n.\n\n\nNow that we know how distribute the load efficiently, we can finally run the\ncalculation using\n\n\n(mpirun ...) abinit < tmbt_4.files >& tmbt_4.log &\n\n\n\n\n\nKeep track of the time for each processor number so that we can test the\nscalability of the self-energy part.\n\n\nPlease note that the results of these tests are not converged. A well\nconverged calculation would require a 6x6x6 k-mesh to sample the full BZ, and\na cutoff energy of 10 Ha for the screening matrix. The QP results converge\nextremely slowly with respect to the number of empty states. To converge the\nQP gaps within 0.1 eV accuracy, we had to include 1200 bands in the screening\nand 800 states in the calculation of the self-energy.\n\n\nThe comparison between the LDA band structure and the G0W0 energy bands of\n\u03b1-quartz SiO2 is reported in the figure below. The direct gap at \u0393 is opened\nup significantly from the LDA value of 6.4 eV to about 9.5 eV when the one-\nshot G0W0 method is used. You are invited to reproduce this result (take into\naccount that this calculation has been performed at the theoretical LDA\nparameters, while the experimental structure is used in all the input files of\nthis tutorial).\n\n\n\n\n\n\n5. Basic rules for efficient parallel calculations:\n\u00b6\n\n\n\n\n\n\nRemember that \u201cAnything that can possibly go wrong, does\u201d so, when writing your input file, try to \u201cKeep It Short and Simple\u201d. \n\n\n\n\n\n\nDo one thing and do it well: \n\nAvoid using different values of \noptdriver\n in the same input file. Each\nrunlevel employs different approaches to distribute memory and CPU time, hence\nit is almost impossible to find the number of processors that will produce a\nbalanced run in each dataset.\n\n\n\n\n\n\nPrime number theorem: \n\nConvergence studies should be executed in parallel only when the parameters\nthat are tested do not interfere with the MPI algorithm. For example, the\nconvergence study in the number of bands in the screening should be done in\nseparated input files when \ngwpara\n=2 is used.\n\n\n\n\n\n\nLess is more: \n\nSplit big calculations into smaller runs whenever possible. For example,\nscreening calculations can be split over q-points. The calculation of the\nself-energy can be easily split over\n\nkptgw\n and\n\nbdgw\n.\n\n\n\n\n\n\nLook before you leap: \n\nUse the converge tests to estimate how the CPU-time and the memory\nrequirements depend on the parameter that is tested. Having an estimate of the\ncomputing resources is very helpful when one has to launch the final\ncalculation with converged parameters.",
            "title": "Many-Body"
        },
        {
            "location": "/tutorials/paral_mbt/#1-generating-the-wfk-file-in-parallel",
            "text": "In the  first lesson  of the GW tutorial, we have learned how\nto generate the WFK file with the sequential version of the code. Now we will\nperform a similar calculation taking advantage of the k-point parallelism\nimplemented in the ground-state part.  First of all, you should copy the files file tmbt_1.files in the working\ndirectory Work_mbt:  $  cd  Work_mbt\n$ cp ../tmbt_1.files .  The abinit files files is described in  section\n1.1  of the abinit_help\nfile. Please, read it now if you haven\u2019t done it yet!  Now open the input file ~abinit/tests/tutoparal/Input/tmbt_1.in in your\npreferred editor, and look at its structure.  The first dataset performs a rather standard SCF calculation to obtain the\nground-state density. The second dataset reads the density file and calculates\nthe Kohn-Sham band structure including many empty states:  # DATASET 2 : WFK generation\niscf2      -2      # NSCF\ngetden2    -1      # Read previous density\ntolwfr2    1d-12   # Stopping criterion for the NSCF cycle.\nnband2      160    # Number of (occ and empty) bands computed in the NSCF cycle.\nnbdbuf2     10     # A large buffer helps to reduce the number of NSCF steps.  We have already encountered these variables in the  first\nlesson  of the GW tutorial so their meaning should be\nfamiliar to you.  The only thing worth stressing is that this calculation solves the NSCF cycle\nwith the conjugate-gradient method (paral_kgb == 0)  The NSCF cycle is executed in parallel using the standard parallelism over\nk-points and spin in which the ( nkpt  x  nsppol ) blocks of bands are\ndistributed among the nodes. This test uses an unshifted 4x4x3 grid (48 k\npoints in the full Brillouin Zone, folding to 9 k-points in the irreducible\nwedge) hence the theoretical maximum speedup is 9.  Now run ABINIT over nn CPU cores using  (mpirun ...) abinit < tmbt_1.files >& tmbt_1.log &  but keep in mind that, to avoid idle processors, the number of CPUs should\ndivide 9. At the end of the run, the code will produce the file tmbt_1o_WFK\nneeded for the subsequent GW calculations.  With three nodes, the wall clock time is around 1.5 minutes.  $ tail tmbt_1.out\n\n-\n- Proc.    0  individual  time   ( sec ) :  cpu =          209 .0   wall =          209 .0 ================================================================================ \n\n Calculation completed.\n.Delivered     0  WARNINGs and    5  COMMENTs to log file.\n+Overall  time  at end  ( sec )  :  cpu =          626 .9   wall =          626 .9  A reference output file is given in ~tests/tutoparal/Refs, under the name\ntmbt_1.out.  Note that 150 bands are not enough to obtain converged GW results, you might\nincrease the number of bands in proportion to your computing resources.",
            "title": "1 Generating the WFK file in parallel."
        },
        {
            "location": "/tutorials/paral_mbt/#246-computing-the-screening-in-parallel-using-the-adler-wiser-expression",
            "text": "In this part of the tutorial, we will compute the RPA polarizability with the\nAdler-Wiser approach. The basic equations are discussed in this section \nof the GW notes.  First copy the files file tmbt_2.file in the working directory, then create a\nsymbolic link pointing to the WFK file we have generated in the previous step:  $ ln -s tmbt_1o_DS2_WFK tmbt_2i_WFK  Now open the input file ~abinit/tests/tutoparal/Input/tmbt_2.in so that we can\ndiscuss its structure.  The set of parameters controlling the screening computation is summarized\nbelow:  optdriver   3   # Screening run\nirdwfk      1   # Read input WFK file\nsymchi      1   # Use symmetries to speedup the BZ integration\nawtr        1   # Take advantage of time-reversal. Mandatory when gwpara=2 is used.\ngwpara      2   # Parallelization over bands\necutwfn     24  # Cutoff for the wavefunctions.\necuteps     8   # Cutoff for the polarizability.\nnband       50  # Number of bands in the RPA expression (24 occupied bands)\ninclvkb     2   # Correct treatment of the optical limit.  Most of the variables have been already discussed in the first  lesson of the GW tutorial. The only variables that\ndeserve some additional explanation are  gwpara  and  awtr .  gwpara  selects the parallel algorithm used to compute the screening. Two\ndifferent approaches are implemented:    gwpara =1 -> Trivial parallelization over the k-points in the full Brillouin     gwpara =2 -> Parallelization over bands with memory distribution     Each method presents advantages and drawbacks that are discussed in the\ndocumentation of the variable. In this tutorial, we will be focusing on gwpara =2 since this is the algorithm with the best MPI-scalability and,\nmostly important, it is the only one that allows for a significant reduction\nof the memory requirement.  The option  awtr =1 specifies that the system presents time reversal\nsymmetry so that it is possible to halve the number of transitions that have\nto be calculated explicitly (only resonant transitions are needed). Note that awtr =1 is MANDATORY when  gwpara =2 is used.  Before running the calculation in parallel, it is worth discussing some\nimportant technical details of the implementation. For our purposes, it\nsuffices to say that, when  gwpara =2 is used in the screening part, the\ncode distributes the wavefunctions such that each processing unit owns the\nFULL set of occupied bands while the empty states are distributed among the\nnodes. The parallel computation of the inverse dielectric matrix is done in\nthree different steps that can be schematically described as follows:   Each node computes the partial contribution to the RPA polarizability:       The partial results are collected on each node.     The master node performs the matrix inversion to obtain the inverse dielectric matrix and writes the final result on file.     Both the first and second step of the algorithm are expected to scale well\nwith the number of processors. Step 3, on the contrary, is performed in\nsequential thus it will have a detrimental effect on the overall scaling,\nespecially in the case of large screening matrices (large  npweps  or large\nnumber of frequency points \u03c9).  Note that the maximum number of CPUs that can be used is dictated by the\nnumber of empty states used to compute the polarizability. Most importantly, a\nbalanced distribution of the computing time is obtained when the number of\nprocessors divides the number of conduction states.  The main limitation of the present implementation is represented by the\nstorage of the polarizability. This matrix, indeed, is not distributed hence\neach node must have enough memory to store in memory a table whose size is\ngiven by ( npweps 2 x  nomega  x 16 bytes) where  nomega  is the total\nnumber of frequencies computed.  Tests performed at the Barcelona Supercomputing Center (see figures below)\nhave revealed that the first and the second part of the MPI algorithm have a\nvery good scaling. The routines cchi0 and cchi0q0 where the RPA expression is\ncomputed (step 1 and 2) scales almost linearly up to 512 processors. The\ndegradation of the total speedup observed for large number of processors is\nmainly due to the portions of the computation that are not parallelized,\nnamely the reading of the WFK file and the matrix inversion (qloop).    At this point, the most important technical details of the implementation have\nbeen covered, and we can finally run ABINIT over nn CPU cores using  (mpirun ...) abinit < tmbt_2.files >& tmbt_2.log &  Run the input file tmb_2.in using different number of processors and keep\ntrack of the time for each processor number so that we can test the\nscalability of the implementation. The performance analysis reported in the\nfigures above was obtained with PAW using ZnO as tests case, but you should\nobserve a similar behavior also in SiO2.  Now let\u2019s have a look at the output results. Since this tutorial mainly\nfocuses on how to run efficient MPI computations, we won\u2019t perform any\nconverge study for SiO2. Most of the parameters used in the input files are\nalready close to converge, only the k-point sampling and the number of empty\nstates should be increased. You might modify the input files to perform the\nstandard converge tests following the procedure described in the  first\nlesson  of the GW tutorial.  In the main output file, there is a section reporting how the bands are\ndistributed among the nodes. For a sequential calculation, we have   screening : taking advantage of time-reversal symmetry\n Maximum band index for partially occupied states nbvw =    24\n Remaining bands to be divided among processors   nbcw =    26\n Number of bands treated by each node ~   26  The value reported in the last line will decrease when the computation is done\nwith more processors.  The memory allocated for the wavefunctions scales with the number of\nprocessors. You can use the grep utility to extract this information from the\nlog file. For a calculation in sequential, we have:  $ grep  \"Memory needed\"  tmbt_2.log\n\n  Memory needed  for  storing  ug =           29 .5  [ Mb ] \n  Memory needed  for  storing  ur =          180 .2  [ Mb ]   ug  denotes the internal buffer used to store the Fourier components of the\norbitals whose size scales linearly with npwwfn .  ur  is\nthe array storing the orbitals on the real space FFT mesh. Keep in mind that\nthe size of  ur  scales linearly with the total number of points in the FFT\nbox, number that is usually much larger than the number of planewaves\n( npwwfn ). The\nnumber of FFT divisions used in the GW code can be extracted from the main\noutput file using  $ grep setmesh tmbt_2.out  -A  1 \n setmesh: FFT mesh size  selected    =   27x 27x  36 \n          total number of  points    =      26244   As discussed in this section  of\nthe GW notes, the Fast Fourier Transform represents one of the most CPU\nintensive part of the execution. For this reason the code provides the input\nvariable  fftgw  that can be used to decrease the number of FFT points for\nbetter efficiency. The second digit of the input variable  gwmem , instead,\ngoverns the storage of the real space orbitals and can used to avoid the\nstorage of the costly array  ur  at the price of an increase in computational\ntime.",
            "title": "2. Computing the screening in parallel using the Adler-Wiser expression**"
        },
        {
            "location": "/tutorials/paral_mbt/#2d-manual-parallelization-over-q-points",
            "text": "The computational effort required by the screening computation scales linearly\nwith the number of q-points. As explained in this section \nof the GW notes, the code exploits the symmetries of the screening function so\nthat only the irreducible Brillouin zone (IBZ) has to be calculated\nexplicitly. On the other hand, a large number of q-points might be needed to\nachieve converged results. Typical examples are GW calculations in metals or\noptical properties within the Bethe-Salpeter formalism.  If enough processing units are available, the linear factor due to the q-point\nsampling can be trivially absorbed by splitting the calculation of the\nq-points into several independent runs using the variables  nqptdm  and qptdm . The results can then be gathered in a unique binary file by means\nof the  mrgscr  utility (see also the automatic tests v3/t87, v3/t88 and\nv3/t89).",
            "title": "2.d Manual parallelization over q-points."
        },
        {
            "location": "/tutorials/paral_mbt/#346-computing-the-screening-in-parallel-using-the-hilbert-transform",
            "text": "method**  As discussed in the GW_notes ,\nthe algorithm based on the Adler-Wiser expression is not optimal when many\nfrequencies are wanted. In this paragraph, we therefore discuss how to use the\nHilbert transform method to calculate the RPA polarizability on a dense\nfrequency mesh. The equations implemented in the code are documented in  this\nsection  of\nthe GW notes.  As usual, we have to copy the files file tmbt_3.file in the working directory,\nand then create a symbolic link pointing to the WFK file.  $ ln -s tmbt_1o_DS2_WFK tmbt_3i_WFK  The input file is ~abinit/tests/tutoparal/Input/tmbt_3.in. Open it so that we\ncan have a look at its structure.  A snapshot of the most important parameters governing the algorithm is\nreported below.  gwcalctyp   2    # Contour-deformation technique.\nspmeth      1    # Enable the spectral method.\nnomegasf  100    # Number of points for the spectral function. \ngwpara      2    # Parallelization over bands\nawtr        1    # Take advantage of time-reversal. Mandatory when gwpara=2 is used.\nfreqremax  40 eV # Frequency mesh for the polarizability\nnfreqre    20\nnfreqim     5  The input file is similar to the one we used for the Adler-Wiser calculation.\nThe input variable  spmeth  enables the spectral method.  nomegasf \ndefines the number of \u03c9\u2032 points in the linear mesh used for the spectral\nfunction i.e. the number of \u03c9\u2032 in the equation \nfor the spectral function.  As discussed in the  GW\nnotes , the\nHilbert transform method is much more memory demanding that the Adler-Wiser\napproach, mainly because of the large value of  nomegasf  that is usually\nneeded to converge the results. Fortunately, the particular distribution of\nthe data employed in  gwpara =2 turns out to be well suited for the\ncalculation of the spectral function since each processor has to store and\ntreat only a subset of the entire range of transition energies. The algorithm\ntherefore presents good MPI-scalability since the number of \u03c9\u2032 frequencies\nthat have to be stored and considered in the Hilbert transform decreases with\nthe number of processors.  Now run ABINIT over nn CPU cores using  (mpirun ...) abinit < tmbt_3.files >& tmbt_3.log &  and test the scaling by varying the number of processors. Keep in mind that,\nalso in this case, the distribution of the computing work is well balanced\nwhen the number of CPUs divides the number of conduction states.  The memory needed to store the spectral function is reported in the log file:  $ grep  \"sf_chi0q0\"  tmbt_3.log\n memory required by sf_chi0q0:            1 .0036  [ Gb ]   Note how the size of this array decreases when more processors are used.  The figure below shows the electron energy loss function (EELF) of SiO2\ncalculated using the Adler-Wiser and the Hilbert transform method. You might\ntry to reproduce these results (the EELF is reported in the file tmbt_3o_EELF,\na much denser k-sampling is required to achieve convergence).",
            "title": "3. Computing the screening in parallel using the Hilbert transform"
        },
        {
            "location": "/tutorials/paral_mbt/#446-computing-the-one-shot-gw-corrections-in-parallel",
            "text": "In this last paragraph, we discuss how to calculate G0W0 corrections in\nparallel with  gwpara =2. The basic equations used to compute the self-\nenergy matrix elements are discussed in  this\npart  of\nthe GW notes.  Before running the calculation, copy the files file tmbt_4.file in the working\ndirectory. Then create two symbolic links for the SCR and the WFK file:  ln -s tmbt_1o_DS2_WFK tmbt_4i_WFK\nln -s tmbt_2o_SCR     tmbt_4i_SCR  Now open the input file ~abinit/tests/tutoparal/Input/tmbt_4.in.  The most important parameters of the calculation are reported below:  optdriver   4            # Sigma run.\nirdwfk      1  \nirdscr      1\ngwcalctyp   0 ppmodel 1  # G0W0 calculation with the plasmon-pole approximation.\n#gwcalctyp  2            # Uncomment this line to use the contour-deformation technique but remember to change the SCR file!\ngwpara      2            # Parallelization over bands.\nsymsigma    1            # To enable the symmetrization of the self-energy matrix elements.\necutwfn    24            # Cutoff for the wavefunctions.\necuteps     8            # Cutoff in the correlation part.\necutsigx   20            # Cutoff in the exchange part.\nnband       50           # Number of bands for the correlation part.  For our purposes, it suffices to say that this input file defines a standard\none-shot calculation with the plasmon-pole model approximation. We refer to\nthe documentation and to the  first lesson  of the GW\ntutorial for a more complete description of the meaning of these variables.  Also in this case, we use  gwpara =2 to perform the calculation in parallel.\nNote, however, that the distribution of the orbitals employed in the self-\nenergy part significantly differs from the one used to compute the screening.\nIn what follows, we briefly describe the two-step procedure used to distribute\nthe wavefunctions:    Each node reads and stores in memory the states where the QP corrections are computed (the list of states specified by  kptgw  and  bdgw ).     The  nband  bands are distributed using the following partition scheme:      where we have assumed a calculation done with four nodes (the index in the box\ndenotes the MPI rank).  By virtue of the particular distribution adopted, the computation of the\ncorrelation part is expected to scale well with the number CPUs. The maximum\nnumber of processors that can be used is limited by  nband . Note, however,\nthat only a subset of processors will receive the occupied states when the\nbands are distributed in step 2. As a consequence, the theoretical maximum\nspeedup that can be obtained in the exchange part is limited by the\navailability of the occupied states on the different MPI nodes involved in the\nrun.  The best-case scenario is when the QP corrections are wanted for all the\noccupied states. In this case, indeed, each node can compute part of the self-\nenergy and almost linear scaling should be reached. The worst-case scenario is\nwhen the quasiparticle corrections are wanted only for a few states (e.g. band\ngap calculations) and NCPU >> Nvalence. In this case, indeed, only\nNvalence processors will participate to the calculation of the exchange part.  To summarize: The MPI computation of the correlation part is efficient when\nthe number of processors divides  nband . Optimal scaling in the exchange\npart is obtained only when each node possesses the full set of occupied\nstates.  The two figures below show the speedup of the sigma part as function of the\nnumber of processors. The self-energy is calculated for 5 quasiparticle states\nusing nband=1024 (205 occupied states). Note that this setup is close to the\nworst-case scenario. The computation of the self-energy matrix elements\n(csigme) scales well up to 64 processors. For large number number of CPUs, the\nscaling departs from the linear behavior due to the unbalanced distribution of\nthe occupied bands. The non-scalable parts of the implementation (init1,\nrdkss) limit the total speedup due to Amdhal\u2019s law.   The implementation presents good memory scalability since the largest arrays\nare distributed. Only the size of the screening does not scale with the number\nof nodes. By default each CPU stores in memory the entire screening matrix for\nall the q-points and frequencies in order to optimize the computation. In the\ncase of large matrices, however, it possible to opt for an out-of-core\nsolution in which only a single q-point is stored in memory and the data is\nread from the external SCR file (slower but less memory demanding). This\noption is controlled by the first digit of  gwmem .  Now that we know how distribute the load efficiently, we can finally run the\ncalculation using  (mpirun ...) abinit < tmbt_4.files >& tmbt_4.log &  Keep track of the time for each processor number so that we can test the\nscalability of the self-energy part.  Please note that the results of these tests are not converged. A well\nconverged calculation would require a 6x6x6 k-mesh to sample the full BZ, and\na cutoff energy of 10 Ha for the screening matrix. The QP results converge\nextremely slowly with respect to the number of empty states. To converge the\nQP gaps within 0.1 eV accuracy, we had to include 1200 bands in the screening\nand 800 states in the calculation of the self-energy.  The comparison between the LDA band structure and the G0W0 energy bands of\n\u03b1-quartz SiO2 is reported in the figure below. The direct gap at \u0393 is opened\nup significantly from the LDA value of 6.4 eV to about 9.5 eV when the one-\nshot G0W0 method is used. You are invited to reproduce this result (take into\naccount that this calculation has been performed at the theoretical LDA\nparameters, while the experimental structure is used in all the input files of\nthis tutorial).",
            "title": "4. Computing the one-shot GW corrections in parallel**"
        },
        {
            "location": "/tutorials/paral_mbt/#546-basic-rules-for-efficient-parallel-calculations",
            "text": "Remember that \u201cAnything that can possibly go wrong, does\u201d so, when writing your input file, try to \u201cKeep It Short and Simple\u201d.     Do one thing and do it well:  \nAvoid using different values of  optdriver  in the same input file. Each\nrunlevel employs different approaches to distribute memory and CPU time, hence\nit is almost impossible to find the number of processors that will produce a\nbalanced run in each dataset.    Prime number theorem:  \nConvergence studies should be executed in parallel only when the parameters\nthat are tested do not interfere with the MPI algorithm. For example, the\nconvergence study in the number of bands in the screening should be done in\nseparated input files when  gwpara =2 is used.    Less is more:  \nSplit big calculations into smaller runs whenever possible. For example,\nscreening calculations can be split over q-points. The calculation of the\nself-energy can be easily split over kptgw  and bdgw .    Look before you leap:  \nUse the converge tests to estimate how the CPU-time and the memory\nrequirements depend on the parameter that is tested. Having an estimate of the\ncomputing resources is very helpful when one has to launch the final\ncalculation with converged parameters.",
            "title": "5. Basic rules for efficient parallel calculations:"
        },
        {
            "location": "/theory/theory_mbt/",
            "text": "The aim of this section is to introduce the Green\u2019s function formalism, \nthe concept of self-energy and the set of coupled equations proposed by Hedin\nwhose self-consistent solution, in principle, gives the exact Green\u2019s function of the interacting system. \n\n\nWe mainly focus on the aspects of the theory that are important for understanding \nthe different steps of the calculation and the role played by the input variables used to control the run. \nA much more consistent and rigorous introduction to the physical concept of Green\u2019s\nfunction and self-energy can be found in any standard textbook on Many-Body theory, \nsee for example {% cite Abrikosov %}, {% cite Fetter %} and {% cite Mattuck %} \n\n\n\n\n\n\n\n\n\nGreen\u2019s function and self-energy.\n\n\nHedin\u2019s equations.\n\n\nThe GW approximation.\n\n\nPerturbative approach.\n\n\nThe RPA polarizability in Fourier space.\n\n\nNotes on the calculation of the oscillator matrix elements.\n\n\nThe Hilbert transform method.\n\n\nEvaluation of the GW self-energy.\n\n\nPlasmon-pole models\n\n\nContour deformation technique.\n\n\nNotations\n\n\nReferences\n\n\nOLD\n\n\n\n\n\n\n\n\nGreen\u2019s function and self-energy.\n\u00b6\n\n\nThe time-ordered Green\u2019s function \nG(12)\n, also called the propagator, defines\nthe probability amplitude for the propagation of an added or removed electron\nin a many-body system. Since the probability amplitude is simply given by the\noverlap between the final and the initial state, \nG(12)\n can be expressed as\n\n\n\n\n G(12) = -i \\langle \\Theta^N_0|T\\bigl[\\Psi(1)\\Psi^\\dagger(2)\\bigr]|\\Theta^N_0 \\rangle\n\\label{eq:GreenDef} \n\n\n\n\nwhere the matrix element is taken in the Heisenberg representation, \nT\n is the\ntime-ordering operator and the creation and annihilation field operators act\non the ground state of the \nN\n-electron many-body Hamiltonian \n(the conventions used in the equations are explained in the section on \nnotations\n). \nThe propagator in Eq.\\ref{eq:GreenDef} contains only part of\nthe full information carried by the many-body wave function, but it includes\nthe relevant portion for the study of charged excitations. \nAlso, any single-particle operator acting on the system can be evaluated once the Green\u2019s function is known.\n\n\nUseful physical information about the charged excitation energies of the many-\nbody system can be obtained by expressing the propagator in the so-called\nLehmann representation [1-2-3] {% cite Abrikosov Fetter Mattuck -A %}. \nTo this purpose it is useful to introduce the following notation to denote the \ncharged excitation energies of the \nN\n-electron system [5]:\n\n\n\n\nwhere \nE_{N}^0\n is the ground state energy of the electron system with \nN\n electrons, \nand \ni\n is the set of quantum numbers labeling the excited states with \nN \\pm 1\n electrons. \nFinally, \n\\mu\n is the chemical potential of the system.\nOther important quantities that will be used in the following are the so-called Lehmann amplitudes \ndefined, in the Schrodinger representation, by\n\n\n\n\nThe Lehmann representation of the Green\u2019s function\n\n\n\n\nmakes it clear that, in the frequency domain, the time-ordered Green\u2019s function contains the \ncomplete excitation spectrum corresponding to excitations of an (N-1)-particle and an (N+1)-particle system. \nHence, locating the poles of the Green\u2019s function in the complex plane provides the\ninformation needed to interpret those processes measured in experiments in\nwhich a single electron is inserted to or removed from the system. \nThe figure below gives a schematic representation of the location of the poles of the\ntime-ordered Green\u2019s function.\n\n\n\n\nWhere the ionisation potential is the energy required to remove an electron\nfrom the system, the electron affinity to add an electron, and the chemical\npotential is typically taken to be in the middle of the gap. \nFor a metallic system these energies are all equal to each other, and there is no gap.\n\n\nThe Dyson equation\n\n\n\n\nestablishes a connection between the fully interacting \nG\n and the propagator, \nG_0\n, \nof an approximate non-interacting system through a (non-local, non-Hermitian and time dependent) \npotential called the self-energy, \n\\Sigma\n. \nSince \nG_0\n is supposed to be known exactly, the problem of calculating \nG(12)\n has now\nbeen reduced to the calculation of the self-energy.\n\n\nThe self-energy is not a mere mathematical device used in a roundabout way to\nobtain \nG\n but is has a direct physical meaning. \nThe knowledge of the self-energy operator, allows one to describe the quantum-mechanical state of a\nrenormalized electron in the many-body system by solving the quasiparticle (QP) equation[5]:\n\n\n\n\nThe QP eigenstates so obtained can be used to construct \nG\n according to the Lehmann representation. \nNote that the QP equation departs from the Kohn Sham equation since the QP eigenvectors and eigenvalues \ndo have a direct physical meaning: they can be used to obtain both the charge density of the interacting\nsystem and to describe the properties of charged excitations.  \n\n\n\n\nHedin\u2019s equations.\n\u00b6\n\n\nIn 1965 Hedin {% cite Hedin1965 %} showed how to derive a set of coupled integro-differential\nequations whose self-consistent solution, in principle, gives the exact self-energy of the system \nand therefore the exact \nG\n.\nThe fundamental building blocks employed in the formalism are the irreducible polarizability:\n\n\n\n\nwhich describes the linear response of the density to changes in the total\neffective potential (the superposition of the external potential plus the\ninternal classical Hartree potential) and the dynamically screened interaction, \nW\n, \nthat is related to the bare Coulomb interaction, \nv\n, and to the inverse dielectric function through:\n\n\n\n\nThe dielectric matrix \n\\varepsilon(12)\n is related to the irreducible polarizability\n\n\\chi(12)\n by the following relation:\n\n\n\n\nThe pentagon sketched in the figure below shows how the various physical quantities are interrelated:\n\n\n\n\nThe polarization function renormalises the bare interaction resulting in the screened interaction \nW(12)\n. \nThe screened interaction, \nW(12)\n, the many-body propagator \nG(12)\n, and the vertex function, \n\\Gamma(12;3)\n, \nwhich describe the interactions between virtual hole and electron excitations [5], are the\nessential ingredients for the determination of \n\\Sigma(12)\n.\n\n\nThe iteration starts by setting \nG = G_0\n. Then the set of equations should\nin principle be iterated until self-consistency in all terms is reached.  \n\n\n\n\nThe \nGW\n approximation.\n\u00b6\n\n\nThe practical solution of Hedin\u2019s equations is extremely complicated as they\nare not just numerical relations but contain a functional derivative in the equation for the vertex. \nThe direct evaluation of the vertex function is very challenging. \nThe set of equations can, however, be iterated assuming that only\na few iterations are actually needed to obtain physically meaningful results.\n\n\nA widely used approach to the approximate solution of Hedin\u2019s equations is the\nso-called \nGW\n approximation[6], which consists in approximating the vertex\nfunction with a local and instantaneous function:\n\n\n\n\nThis approximated vertex, once inserted in the full set of Hedin\u2019s equations,\nleads to a considerable simplification in the set of equations:\n\n\n\n\nThanks to the neglect of vertex corrections, the irreducible polarizability \n\\chi(12)\n is now given by\n\n\n\n\nwhich, once rewritten in terms of orbitals and energies, reduces to the RPA expression \nproposed by Adler [7] and Wiser [8].\n\n\nIn real space, the self-energy reduces to a simple direct product of the\ndressed electron propagator, \nG(12)\n, and the dynamically screened interaction, \nW(12)\n:\n\n\n\n\nThe self-energy, a simple product in the space-time domain, becomes a\nconvolution when expressed in frequency-space:\n\n\n\n\nIdeally, the set of \nGW\n equations should still be iterated until self-consistency in all terms is reached; \nthis is the fully self-consistent \nGW\n method (\nSCGW\n).\n\nHowever \nSCGW\n calculations for real systems are still very challenging, and very few have been reported in the literature.\n\nMoreover, the utility of fully \nSCGW\n results are still under debate within the scientific community.\n\n\nThe problem is that self-consistency typically improves total energies, but\nworsens spectral properties (such as band gaps and optical spectra). \nSince obtaining the spectral information is often the main reason for doing such\ndifficult calculations in the first place, many authors agree that a useful\nself-consistent approach would need the inclusion of some kind of vertex\ncorrection during the solution of the equations.\n\n\nFor this reason, the most common approach employed in the ab-initio\ncommunity consists of using the best available approximation for \nG\n and \nW\n\nas a starting point and performing only a single-iteration of the parallelogram \n(the so-called one-shot \nGW\n method, or \nG_0W_0\n). \nIn this case the self-energy is simply given by:\n\n\n\n\nwhere \nG_0^{\\text{KS}}(12)\n is the independent-particle propagator of the Kohn-Sham (\nKS\n)\nHamiltonian, and the screened interaction is approximated with the RPA calculated with  KS energies and wave functions:\n\n\n\n\n\n\nPerturbative approach.\n\u00b6\n\n\nDespite all the fundamental differences between many-body theory and DFT, the\nKohn-Sham exchange-correlation potential can be seen as a static, local and Hermitian approximation to the self-energy. \nIndeed, in many cases the Kohn-Sham energies already provide a reasonable estimate of the band structure and\nare usually in qualitative agreement with experiment.\n\n\nThis observation suggests that a simple, albeit accurate, solution for the QP\nenergies can be obtained using first-order perturbation theory, treating the\nexchange and correlation potential, \nV_{\\text{xc}}\n, as a zeroth-order approximation to\nthe non-local and energy dependent self-energy [11,12]\n\n\nUnder the assumption that the QP wavefunctions equal the KS orbitals, we can\nexpand the self-energy operator around \n\\epsilon\\_{\\text{KS}}\n obtaining a \nclosed expression for \n\\epsilon_{\\text{QP}}\n:\n\n\n\n\nwhere\n\n\n\n\nis the so-called renormalization factor. \nThis corresponds to making a Taylor expansion of the self-energy matrix element \naround the KS energy, as depicted below.\n\n\n\n\n\n\nThe RPA polarizability in Fourier space.\n\u00b6\n\n\nIn the reciprocal space and frequency domain (implying a Fourier transform\n(FT) of the real space coordinates and time variables), the independent-particle polarizability assumes the form:\n\n\n\n\nwhere only the transitions between valence \nv\n and conduction states \nc\n\ncontribute (for simplicity we have assumed a semiconductor with time-reversal invariance, \nthe conventions used for the Fourier transform are discussed in the \nnotations\n section).\n\n\nThe number of bands used to compute the polarizability is specified by \nnband\n\nwhile \nzcut\n gives the small complex shift used to avoid the divergences in the denominators. \nThe frequency mesh is defined by the set of variables\n\nnfreqre\n, \nnfreqim\n, \nfreqremax\n and \nfreqremin\n\n(a number of more exotic grid choices are available through options beginning with \ngw_...\n or \ncd_...\n, \nsee also \ngw_frqim_inzgrid\n.\n\n\n\n\nM\n is a shorthand notation to denote the matrix element of a plane wave\nsandwiched between two wavefunctions (i.e. oscillator matrix elements). \nThe number of planewaves (PW) used to describe the wavefunctions is determined by \necutwfn\n\nwhile the number of \n\\GG\n-vectors used to describe the polarizability (i.e. the\nnumber of \n\\GG\n vectors in the oscillator matrix elements) is determined by \necuteps\n.\nThe oscillators are ubiquitous in the Many-Body part of ABINIT and their\ncalculation represents one of the most CPU intensive part of the execution.\nFor this reason we devote this \nsection\n to the\ndiscussion of some important technical details concerning their computation.\n\n\nIn principle, the set of \n\\qq\n-points in the screening matrix is given by all\nthe possible differences between two crystalline momenta of the wavefunctions\nstored in the WFK file, so it is controlled by the chosen \n\\kk\n-point grid.\nThe code, however, exploits the invariance of the two-point function under the\naction of any symmetry operation of the crystalline space group:\n\n\n  \n\n\nso that only the \n\\qq\n-points in the irreducible Brillouin zone (IBZ) have to\nbe calculated explicitly.\n\n\nIn frequency and reciprocal space, the microscopic dielectric function is\nrelated to the irreducible polarizability by the following relation\n\n\n\n\nfrom which the inverse dielectric function is obtained via matrix inversion.\nFollowing Adler [7,8], the macroscopic dielectric function, \n\\varepsilon^M_{LF}(\\omega)\n, can be\ndirectly related to the inverse of the microscopic dielectric matrix by means of:\n\n\n\n\nThe optical absorption spectrum \u2013 the quantity one can compare with\nexperiments \u2013 is given by the imaginary part: \n\\Im[\\varepsilon^M_{LF}(\\omega)]\n.\n\n\nNote that the equation above differs from\n\n\n\n\ndue to the so called local-field effects introduced by the presence of the crystalline environment. \nThese spectra, if calculated, are typically output as \n\\_LF\n and \n\\_NLF\n files during the course of a calculation.  \n\n\n\n\nNotes on the calculation of the oscillator matrix elements.\n\u00b6\n\n\nMany body calculations require the evaluation of integrals involving the oscillator matrix elements\n\n\n\n\nwhere the \n\\kk\n-point belongs to the full Brillouin zone.\n\n\nThese terms are evaluated by performing a Fast Fourier Transform (FFT) of the\nreal space product of the two wavefunctions (the second expression in the equation above). \nThanks to the FFT algorithm, the CPU-time requirement scales\nalmost linearly with the number of points in the FFT box, moreover the\ncode implements refined algorithms (for instance zero-padded FFTs, FFTW3\ninterface) to optimize the computation.\n\n\nThere can be a significant speed-up in this component depending on the\nnumerical FFT library used. If possible, it should always be advantageous to\nlink and use the FFTW3 library in \nGW\n calculations (controlled by setting \nfftalg\n 312). \nThe performance of the various FFT libraries for a given type of\ncalculation can be benchmarked with the \nfftprof\n utility.\n\n\nFor a given set of indeces (\nb\\_1\n, \nb\\_2\n, \n\\kk\n, \n\\qq\n), the calculation of the\noscillator is done in four different steps:\n\n\n\n\nThe two wavefunctions in the irreducible wedge are FFT transformed from the \n\\GG\n-space to the real space representation, \n\n\nThe orbitals are rotated in real space on the FFT mesh to obtain the points \n\\kk\n and \n\\kk-\\qq\n in the full Brillouin zone. \n\n\nComputation of the wavefunction product. \n\n\nFFT transform of the product to obtain \nM\n\n\n\n\n\n\nEach oscillator thus requires three different FFTs (two transforms to\nconstruct the product, one FFT to get \nM\n). The number of FFTs can be\nsignificantly reduced by precomputing and storing in memory the real space\nrepresentation of the orbitals at the price of a reasonable increase of the\nmemory allocated. However, for very memory demanding calculations, the real\nspace orbitals can be calculated on the fly with an increase in computational time instead. \nThis option is controlled by the second digit of the input variable \ngwmem\n\n\nThe third term in the equation defining the oscillators makes it clear that\nthe product of the periodic part of the orbitals has non-zero Fourier\ncomponents in a sphere whose radius is 2\ufffd\nRwfn\n where \nRwfn\n is the radius of\nthe \n\\GG\n-sphere used for the wavefunctions (set by \necutwfn\n).\nTo avoid aliasing errors in the FFT one should therefore use an FFT box that encloses the sphere with\nradius \n2 R_{\\text{wfn}\n, but this leads to a significant increase in the computing\neffort as well as in the memory requirements. \nThe input variable [[fftgw] specifies how to setup the FFT box for the oscillators and should be used to\ntest how the aliasing errors affect the final results. \nThe default setting of \nfftgw 21\n is safe, a setting of \nfftgw 11\n is fast but can be inaccurate,\nand a setting of \nfftgw 31\n gives the maximum possible accuracy at a significant computational cost.  \n\n\n\n\nThe Hilbert transform method.\n\u00b6\n\n\nThe computational effort for the evaluation of the RPA polarizability with the\nAdler-Wiser expression scales linearly with the number of frequencies computed (\nnfreqre\n, \nnfreqim\n)\nalbeit with a large prefactor which increases with the fourth power of the number of atoms. \nThe main reason for the linear scaling is that the frequency dependence cannot be factorised out \nof the sum over transitions, hence a distinct and expensive summation over transitions has to be performed\nseparately for each frequency.\n\n\nThis linear scaling represents a serious problem, especially when many\nfrequencies are wanted, for example when computing QP corrections within the\ncontour deformation technique described in the \nsecond lesson\n of the \nGW\n tutorial.\n\n\nThis computational bottleneck can be removed, under certain circumstances, by\nemploying an efficient algorithm proposed in [13] and subsequently revisited\nin [14], in which only the spectral function\n\n\n\n\nhas to be evaluated in terms of electronic transitions between valence and\nconduction states. The Dirac delta function can be approximated either by\nmeans of a triangular function centered at the energy transition following\n[14] or a gaussian approximant following [13] \n(see the related input variables \nspmeth\n and \nspbroad\n.\nThe spectral function is evaluated on a linear frequency mesh which\ncovers the entire set of transition energies included in the calculation. \nThe number of points in the mesh is given by \nnomegasf\n.\n\n\nThe evaluation of the spectral function is rather efficient thanks to the\npresence of the delta-function in the expression above. For example, when\n\nspmeth\n = 1, the CPU time required to compute the spectral function on an arbitrarily dense\nfrequency mesh is just twice that required by a single static computation\nbased on the standard Adler-Wiser expression.\n\n\nThe full polarizability is then efficiently retrieved by means of a less\nexpensive frequency integration (a Hilbert transform):\n\n\n\n\nThe price to be paid, however, is that a large table for the spectral function\nhas to be stored in memory and a Hilbert transform has to be performed for\neach pair (\n\\GG_1\n, \n\\GG_2\n). Since the computing time required for the\ntransform scales quadratically with the number of vectors in the\npolarizability (governed by \necuteps\n, the CPU time spent in this part will overcome\nthe computing time of the standard Adler-Wiser formalism for large \necuteps\n.\nA theoretical estimate of the crossover point is hard to give because it\ndepends on many factors. However, if many frequencies are needed, such as for\nthe evaluation of optical spectra, or accurate contour deformation\nintegrations, or even mapping full grids in the complex plane, the Hilbert\ntransform method can be significantly faster, and its use is well worth considering.  \n\n\n\n\nEvaluation of the \nGW\n self-energy.\n\u00b6\n\n\nFollowing the standard approach, we separate the screened interaction into the\nstatic bare Coulomb term and a frequency-dependent contribution according to:\n\n\n\n\nwhere matrix notation is used.\n\n\nThis particular decomposition of \nW\n, once inserted in the convolution\ndefining \n\\Sigma\n, leads to the split of the self-energy into two different\ncontributions (exchange and correlation):\n\n\n\n\nThe exchange part is static and turns out to have the same mathematical\nstructure as the Fock operator in Hartree-Fock theory, albeit constructed with\nquasiparticle amplitudes\n\n\n\n\nwhile the dynamic part \n\\Sigma_c(\\omega)\n accounts for correlation effects beyond \n\\Sigma_x\n.\n\n\nIt is important to stress that, for computational efficiency, the code does\nnot compute the full self-energy operator by default. Only its matrix elements\nfor the states specified by \nkptgw\n and \nbdgw\n are computed and used to obtain the QP corrections.\n\n\nWhen expressed in reciprocal space, the diagonal matrix elements of the\nexchange part are given by:\n\n\n\n\nThe evaluation of these terms represents a minor fraction of the overall CPU\ntime since only occupied states are involved. However we should always keep in\nmind that, due to the long range of the bare Coulomb interaction, the\nconvergence with respect to the number of plane waves used in the oscillators\n\nM\n (\necutsigx\n is usually slow, much slower than the convergence of the correlation\npart, which is short-ranged. This plane wave cutoff can be converged\nindependently of others if neceessary, and given a much larger value in\ncomparison to \necut\n, \necutwfn\n and \necuteps\n.\n\n\nAnother point worth noting is the presence in the expression of the Coulomb\nsingularity for \n|\\qq+\\GG| \\rightarrow 0\n. From a mathematical point of view, the\nintegral is well-defined since the singularity is integrable in three-\ndimensional space once the thermodynamical limit, \nN_\\qq \\rightarrow \\infty\n, is reached. On\nthe other hand, only a finite number of \n\\qq\n-points can be used for practical\napplications, and a careful numerical treatment is needed to avoid an\nexceedingly slow convergence with respect to the BZ sampling. To accelerate\nthe convergence in the number of \n\\qq\n-points, the code implements several\ntechniques proposed in the literature. \nWe refer to the documentation of \nicutcoul\n for a more extensive discussion.\n\n\nThe expression for the matrix elements of the correlation part is instead given by:\n\n\n\n\nwhere all dynamical effects are now contained in the frequency convolution integral \nJ\n.\n\n\nThe explicit expression for \nJ\n depends on the method used to treat the\nscreened interaction. The code implements four different plasmon-pole\ntechniques to model the frequency dependence of \nW\n in an efficient but\napproximate way, alternatively, it is possible to use the more sophisticated\nfrequency integration of the contour deformation method [15] for accurate QP\ncalculations (see the related variables \nppmodel\n and \ngwcalctyp\n.\n\n\nThe double sum over \n\\GG\n-vectors is performed for all the plane waves\ncontained within a sphere of energy \necuteps\n\n(it cannot be larger than the value used to generate the SCR file). For each\nstate, the correlated matrix elements are evaluated on a linear frequency mesh\ncentered around the initial KS energy and the derivative needed for the\nrenormalization factor is obtained numerically (see \nnomegasrd\n and \nomegasrdmax\n)\n\n\nNote that here, in contrast to the exchange term, the sum over the band index\n\nn\n should extend up to infinity although in practice only a finite number of\nstates can be used (specified by \nnband\n).\n\n\n\n\nPlasmon-pole models\n\u00b6\n\n\nOne of the major computational efforts in self-energy calculations is\nrepresented by the calculation of the frequency dependence of the screened\ninteraction, which is needed for the evaluation of the convolution. Due to the\nragged behavior of \nG(\\omega)\n and \nW(\\omega)\n along the real axis, numerous real\nfrequencies are in principle required to converge the results (note that the\nmaximum frequencies needed are now reported if \nprtvol\n > 9). \nOn the other hand, since the fine details of \nW(\\omega)\n are integrated over,\nit is reasonable to expect that approximate models, able to capture the main\nphysical features of the screened interaction, should give sufficiently\naccurate results with a considerably reduction of computational effort. This\nis the basic idea behind the so-called plasmon-pole models in which the\nfrequency dependence of \nW(\\omega)\n is modelled in terms of analytic expressions\ndepending on coefficients that are derived from first principles, i.e. without\nany adjustable external parameters.\n\n\nFour different plasmon-pole techniques are available in ABINIT and the input\nvariable \nppmodel\n selects the method to be used.\n\n\nWhen \nppmodel\n =1,2 the frequency dependence of the inverse dielectric function is\nmodeled according to\n\n\n\n\n\n\nThe two models differ in the approach used to compute the parameters. \n\nppmodel\n = 1 derives the parameters such that the inverse dielectric matrix is correctly\nreproduced at two different explicitly calculated frequencies: the static\nlimit (\n\\omega=0\n) and an additional imaginary point located at \nppmfrq\n.\nUnless the user overrides this, the default value is calculated from the\naverage electronic density of the system. The plasmon-pole parameters of \nppmodel\n = 2\nare calculated so as to reproduce the static limit exactly and to fulfill a\ngeneralized frequency sum rule relating the imaginary part of the many-body\ninverse dielectric matrix to the plasma frequency and the charge density [12]\n\n\nFor a discussion of the models corresponding to \nppmodel\n = 3,4\nwe refer the reader to the original papers cited in the documentation of the variable.  \n\n\n\n\nContour deformation technique.\n\u00b6\n\n\nThe contour deformation method was proposed in order to avoid having to deal\nwith quantities close to the real axis as much as possible [15]. The integral\nover the real frequency axis can be transformed into an integral over the\ncontour depicted in red in the figure below. The integral over real frequency\nis traded with an integration along the imaginary axis plus contributions\ncoming from the poles of the integrand lying inside the contour:\n\n\n\n\n\n\nIn the above equation, the first sum is restricted to the poles lying inside\nthe path \nC\n. \nW_c(z)\n represents the frequency dependent part of the\nscreened interaction, whose expression in reciprocal space is given by:\n\n\n\n\nThe integration along the imaginary axis is expected to converge quickly with\nrespect to the number of sampled frequencies since the integrand is typically\nvery smooth. Only the residues of the integrand have to be evaluated at the\ncomplex poles contributed by the Green\u2019s function whose frequency dependence\nis known.  \n\n\n\n\nNotations\n\u00b6\n\n\nThe following shorthand notations are employed:\n\n\n\n\nwhere \nv(\\rr_1, \\rr_2)\n represents the bare Coulomb interaction, and \n\\eta\n is a\npositive infinitesimal.\n\n\nThe Fourier transforms for periodic lattice quantities are defined as\n\n\n\n\nThe volume of the unit cell is denoted with \n\\Omega\n, while \nV\n is the total volume\nof the crystal simulated employing Born-von Karman periodic boundary\ncondition. Unless otherwise specified, Hartree atomic units will be used throughout.\n\n\n\n\nReferences\n\u00b6\n\n\n{% bibliography \u2013cited %}\n\n\nOLD\n\u00b6\n\n\n\n\nAbrikosov, Gorkov, and Dzyaloshinskii. Methods of quantum field theory in statistical physics, Dover, New York, (1975) \n\n\nFetter, and Walecka. Quantum Theory of Many-Particle Systems, McGraw-Hill, New York, (1971) \n\n\nR.D Mattuck. A guide to Feynman diagrams in the many-body problem, Dover, New York, (1992) \n\n\nW. G. Aulbur, L. J\ufffdnsson and J. W. Wilkins, Solid State Physics \n54\n, 1 (2000) \n\n\nG. Onida et al. Phys. Rev. Lett. \n75\n, 818 (1995) \n\n\nL. Hedin Phys. Rev. \n139\n, A796, (1965) \n\n\nS. L. Adler, Phys. Rev. \n126\n, 413 (1962)\n\n\nN. Wiser, Phys. Rev. \n129\n, 72 (1963)\n\n\nA. Kutepov, S. Y. Savrasov and G. Kotliar Phys. Rev. B \n80\n, 041103(R) (2009) \n\n\nA. Kutepov, S. Y. Savrasov and G. Kotliar Phys. Rev. B \n80\n, 041103(R) (2009) \n\n\nM.S. Hybertsen, and S.G Louie. Phys. Rev. Lett. \n55\n, 1418 (1985) \n\n\nM.S. Hybertsen, and S.G Louie. Phys. Rev. B \n34\n, 5390 (1986) \n\n\nT. Miyake, and F. Aryasetiawan. Phys. Rev. B, \n61\n, 7172 (2000) \n\n\nM. Shishkin, and G. Kresse. Phys. Rev. B, \n74\n, 035101 (2006) \n\n\nS. Lebegue, B. Arnaud, M. Alouani, and P.E. Bloechl. Phys. Rev. B, \n67\n, 155208 (2003)",
            "title": "MBPT"
        },
        {
            "location": "/theory/theory_mbt/#greens-function-and-self-energy",
            "text": "The time-ordered Green\u2019s function  G(12) , also called the propagator, defines\nthe probability amplitude for the propagation of an added or removed electron\nin a many-body system. Since the probability amplitude is simply given by the\noverlap between the final and the initial state,  G(12)  can be expressed as    G(12) = -i \\langle \\Theta^N_0|T\\bigl[\\Psi(1)\\Psi^\\dagger(2)\\bigr]|\\Theta^N_0 \\rangle\n\\label{eq:GreenDef}    where the matrix element is taken in the Heisenberg representation,  T  is the\ntime-ordering operator and the creation and annihilation field operators act\non the ground state of the  N -electron many-body Hamiltonian \n(the conventions used in the equations are explained in the section on  notations ). \nThe propagator in Eq.\\ref{eq:GreenDef} contains only part of\nthe full information carried by the many-body wave function, but it includes\nthe relevant portion for the study of charged excitations. \nAlso, any single-particle operator acting on the system can be evaluated once the Green\u2019s function is known.  Useful physical information about the charged excitation energies of the many-\nbody system can be obtained by expressing the propagator in the so-called\nLehmann representation [1-2-3] {% cite Abrikosov Fetter Mattuck -A %}. \nTo this purpose it is useful to introduce the following notation to denote the \ncharged excitation energies of the  N -electron system [5]:   where  E_{N}^0  is the ground state energy of the electron system with  N  electrons, \nand  i  is the set of quantum numbers labeling the excited states with  N \\pm 1  electrons. \nFinally,  \\mu  is the chemical potential of the system.\nOther important quantities that will be used in the following are the so-called Lehmann amplitudes \ndefined, in the Schrodinger representation, by   The Lehmann representation of the Green\u2019s function   makes it clear that, in the frequency domain, the time-ordered Green\u2019s function contains the \ncomplete excitation spectrum corresponding to excitations of an (N-1)-particle and an (N+1)-particle system. \nHence, locating the poles of the Green\u2019s function in the complex plane provides the\ninformation needed to interpret those processes measured in experiments in\nwhich a single electron is inserted to or removed from the system. \nThe figure below gives a schematic representation of the location of the poles of the\ntime-ordered Green\u2019s function.   Where the ionisation potential is the energy required to remove an electron\nfrom the system, the electron affinity to add an electron, and the chemical\npotential is typically taken to be in the middle of the gap. \nFor a metallic system these energies are all equal to each other, and there is no gap.  The Dyson equation   establishes a connection between the fully interacting  G  and the propagator,  G_0 , \nof an approximate non-interacting system through a (non-local, non-Hermitian and time dependent) \npotential called the self-energy,  \\Sigma . \nSince  G_0  is supposed to be known exactly, the problem of calculating  G(12)  has now\nbeen reduced to the calculation of the self-energy.  The self-energy is not a mere mathematical device used in a roundabout way to\nobtain  G  but is has a direct physical meaning. \nThe knowledge of the self-energy operator, allows one to describe the quantum-mechanical state of a\nrenormalized electron in the many-body system by solving the quasiparticle (QP) equation[5]:   The QP eigenstates so obtained can be used to construct  G  according to the Lehmann representation. \nNote that the QP equation departs from the Kohn Sham equation since the QP eigenvectors and eigenvalues \ndo have a direct physical meaning: they can be used to obtain both the charge density of the interacting\nsystem and to describe the properties of charged excitations.",
            "title": "Green's function and self-energy."
        },
        {
            "location": "/theory/theory_mbt/#hedins-equations",
            "text": "In 1965 Hedin {% cite Hedin1965 %} showed how to derive a set of coupled integro-differential\nequations whose self-consistent solution, in principle, gives the exact self-energy of the system \nand therefore the exact  G .\nThe fundamental building blocks employed in the formalism are the irreducible polarizability:   which describes the linear response of the density to changes in the total\neffective potential (the superposition of the external potential plus the\ninternal classical Hartree potential) and the dynamically screened interaction,  W , \nthat is related to the bare Coulomb interaction,  v , and to the inverse dielectric function through:   The dielectric matrix  \\varepsilon(12)  is related to the irreducible polarizability \\chi(12)  by the following relation:   The pentagon sketched in the figure below shows how the various physical quantities are interrelated:   The polarization function renormalises the bare interaction resulting in the screened interaction  W(12) . \nThe screened interaction,  W(12) , the many-body propagator  G(12) , and the vertex function,  \\Gamma(12;3) , \nwhich describe the interactions between virtual hole and electron excitations [5], are the\nessential ingredients for the determination of  \\Sigma(12) .  The iteration starts by setting  G = G_0 . Then the set of equations should\nin principle be iterated until self-consistency in all terms is reached.",
            "title": "Hedin's equations."
        },
        {
            "location": "/theory/theory_mbt/#the-gw-approximation",
            "text": "The practical solution of Hedin\u2019s equations is extremely complicated as they\nare not just numerical relations but contain a functional derivative in the equation for the vertex. \nThe direct evaluation of the vertex function is very challenging. \nThe set of equations can, however, be iterated assuming that only\na few iterations are actually needed to obtain physically meaningful results.  A widely used approach to the approximate solution of Hedin\u2019s equations is the\nso-called  GW  approximation[6], which consists in approximating the vertex\nfunction with a local and instantaneous function:   This approximated vertex, once inserted in the full set of Hedin\u2019s equations,\nleads to a considerable simplification in the set of equations:   Thanks to the neglect of vertex corrections, the irreducible polarizability  \\chi(12)  is now given by   which, once rewritten in terms of orbitals and energies, reduces to the RPA expression \nproposed by Adler [7] and Wiser [8].  In real space, the self-energy reduces to a simple direct product of the\ndressed electron propagator,  G(12) , and the dynamically screened interaction,  W(12) :   The self-energy, a simple product in the space-time domain, becomes a\nconvolution when expressed in frequency-space:   Ideally, the set of  GW  equations should still be iterated until self-consistency in all terms is reached; \nthis is the fully self-consistent  GW  method ( SCGW ). \nHowever  SCGW  calculations for real systems are still very challenging, and very few have been reported in the literature. \nMoreover, the utility of fully  SCGW  results are still under debate within the scientific community.  The problem is that self-consistency typically improves total energies, but\nworsens spectral properties (such as band gaps and optical spectra). \nSince obtaining the spectral information is often the main reason for doing such\ndifficult calculations in the first place, many authors agree that a useful\nself-consistent approach would need the inclusion of some kind of vertex\ncorrection during the solution of the equations.  For this reason, the most common approach employed in the ab-initio\ncommunity consists of using the best available approximation for  G  and  W \nas a starting point and performing only a single-iteration of the parallelogram \n(the so-called one-shot  GW  method, or  G_0W_0 ). \nIn this case the self-energy is simply given by:   where  G_0^{\\text{KS}}(12)  is the independent-particle propagator of the Kohn-Sham ( KS )\nHamiltonian, and the screened interaction is approximated with the RPA calculated with  KS energies and wave functions:",
            "title": "The GW approximation."
        },
        {
            "location": "/theory/theory_mbt/#perturbative-approach",
            "text": "Despite all the fundamental differences between many-body theory and DFT, the\nKohn-Sham exchange-correlation potential can be seen as a static, local and Hermitian approximation to the self-energy. \nIndeed, in many cases the Kohn-Sham energies already provide a reasonable estimate of the band structure and\nare usually in qualitative agreement with experiment.  This observation suggests that a simple, albeit accurate, solution for the QP\nenergies can be obtained using first-order perturbation theory, treating the\nexchange and correlation potential,  V_{\\text{xc}} , as a zeroth-order approximation to\nthe non-local and energy dependent self-energy [11,12]  Under the assumption that the QP wavefunctions equal the KS orbitals, we can\nexpand the self-energy operator around  \\epsilon\\_{\\text{KS}}  obtaining a \nclosed expression for  \\epsilon_{\\text{QP}} :   where   is the so-called renormalization factor. \nThis corresponds to making a Taylor expansion of the self-energy matrix element \naround the KS energy, as depicted below.",
            "title": "Perturbative approach."
        },
        {
            "location": "/theory/theory_mbt/#the-rpa-polarizability-in-fourier-space",
            "text": "In the reciprocal space and frequency domain (implying a Fourier transform\n(FT) of the real space coordinates and time variables), the independent-particle polarizability assumes the form:   where only the transitions between valence  v  and conduction states  c \ncontribute (for simplicity we have assumed a semiconductor with time-reversal invariance, \nthe conventions used for the Fourier transform are discussed in the  notations  section).  The number of bands used to compute the polarizability is specified by  nband \nwhile  zcut  gives the small complex shift used to avoid the divergences in the denominators. \nThe frequency mesh is defined by the set of variables nfreqre ,  nfreqim ,  freqremax  and  freqremin \n(a number of more exotic grid choices are available through options beginning with  gw_...  or  cd_... , \nsee also  gw_frqim_inzgrid .   M  is a shorthand notation to denote the matrix element of a plane wave\nsandwiched between two wavefunctions (i.e. oscillator matrix elements). \nThe number of planewaves (PW) used to describe the wavefunctions is determined by  ecutwfn \nwhile the number of  \\GG -vectors used to describe the polarizability (i.e. the\nnumber of  \\GG  vectors in the oscillator matrix elements) is determined by  ecuteps .\nThe oscillators are ubiquitous in the Many-Body part of ABINIT and their\ncalculation represents one of the most CPU intensive part of the execution.\nFor this reason we devote this  section  to the\ndiscussion of some important technical details concerning their computation.  In principle, the set of  \\qq -points in the screening matrix is given by all\nthe possible differences between two crystalline momenta of the wavefunctions\nstored in the WFK file, so it is controlled by the chosen  \\kk -point grid.\nThe code, however, exploits the invariance of the two-point function under the\naction of any symmetry operation of the crystalline space group:      so that only the  \\qq -points in the irreducible Brillouin zone (IBZ) have to\nbe calculated explicitly.  In frequency and reciprocal space, the microscopic dielectric function is\nrelated to the irreducible polarizability by the following relation   from which the inverse dielectric function is obtained via matrix inversion.\nFollowing Adler [7,8], the macroscopic dielectric function,  \\varepsilon^M_{LF}(\\omega) , can be\ndirectly related to the inverse of the microscopic dielectric matrix by means of:   The optical absorption spectrum \u2013 the quantity one can compare with\nexperiments \u2013 is given by the imaginary part:  \\Im[\\varepsilon^M_{LF}(\\omega)] .  Note that the equation above differs from   due to the so called local-field effects introduced by the presence of the crystalline environment. \nThese spectra, if calculated, are typically output as  \\_LF  and  \\_NLF  files during the course of a calculation.",
            "title": "The RPA polarizability in Fourier space."
        },
        {
            "location": "/theory/theory_mbt/#notes-on-the-calculation-of-the-oscillator-matrix-elements",
            "text": "Many body calculations require the evaluation of integrals involving the oscillator matrix elements   where the  \\kk -point belongs to the full Brillouin zone.  These terms are evaluated by performing a Fast Fourier Transform (FFT) of the\nreal space product of the two wavefunctions (the second expression in the equation above). \nThanks to the FFT algorithm, the CPU-time requirement scales\nalmost linearly with the number of points in the FFT box, moreover the\ncode implements refined algorithms (for instance zero-padded FFTs, FFTW3\ninterface) to optimize the computation.  There can be a significant speed-up in this component depending on the\nnumerical FFT library used. If possible, it should always be advantageous to\nlink and use the FFTW3 library in  GW  calculations (controlled by setting  fftalg  312). \nThe performance of the various FFT libraries for a given type of\ncalculation can be benchmarked with the  fftprof  utility.  For a given set of indeces ( b\\_1 ,  b\\_2 ,  \\kk ,  \\qq ), the calculation of the\noscillator is done in four different steps:   The two wavefunctions in the irreducible wedge are FFT transformed from the  \\GG -space to the real space representation,   The orbitals are rotated in real space on the FFT mesh to obtain the points  \\kk  and  \\kk-\\qq  in the full Brillouin zone.   Computation of the wavefunction product.   FFT transform of the product to obtain  M    Each oscillator thus requires three different FFTs (two transforms to\nconstruct the product, one FFT to get  M ). The number of FFTs can be\nsignificantly reduced by precomputing and storing in memory the real space\nrepresentation of the orbitals at the price of a reasonable increase of the\nmemory allocated. However, for very memory demanding calculations, the real\nspace orbitals can be calculated on the fly with an increase in computational time instead. \nThis option is controlled by the second digit of the input variable  gwmem  The third term in the equation defining the oscillators makes it clear that\nthe product of the periodic part of the orbitals has non-zero Fourier\ncomponents in a sphere whose radius is 2\ufffd Rwfn  where  Rwfn  is the radius of\nthe  \\GG -sphere used for the wavefunctions (set by  ecutwfn ).\nTo avoid aliasing errors in the FFT one should therefore use an FFT box that encloses the sphere with\nradius  2 R_{\\text{wfn} , but this leads to a significant increase in the computing\neffort as well as in the memory requirements. \nThe input variable [[fftgw] specifies how to setup the FFT box for the oscillators and should be used to\ntest how the aliasing errors affect the final results. \nThe default setting of  fftgw 21  is safe, a setting of  fftgw 11  is fast but can be inaccurate,\nand a setting of  fftgw 31  gives the maximum possible accuracy at a significant computational cost.",
            "title": "Notes on the calculation of the oscillator matrix elements."
        },
        {
            "location": "/theory/theory_mbt/#the-hilbert-transform-method",
            "text": "The computational effort for the evaluation of the RPA polarizability with the\nAdler-Wiser expression scales linearly with the number of frequencies computed ( nfreqre ,  nfreqim )\nalbeit with a large prefactor which increases with the fourth power of the number of atoms. \nThe main reason for the linear scaling is that the frequency dependence cannot be factorised out \nof the sum over transitions, hence a distinct and expensive summation over transitions has to be performed\nseparately for each frequency.  This linear scaling represents a serious problem, especially when many\nfrequencies are wanted, for example when computing QP corrections within the\ncontour deformation technique described in the  second lesson  of the  GW  tutorial.  This computational bottleneck can be removed, under certain circumstances, by\nemploying an efficient algorithm proposed in [13] and subsequently revisited\nin [14], in which only the spectral function   has to be evaluated in terms of electronic transitions between valence and\nconduction states. The Dirac delta function can be approximated either by\nmeans of a triangular function centered at the energy transition following\n[14] or a gaussian approximant following [13] \n(see the related input variables  spmeth  and  spbroad .\nThe spectral function is evaluated on a linear frequency mesh which\ncovers the entire set of transition energies included in the calculation. \nThe number of points in the mesh is given by  nomegasf .  The evaluation of the spectral function is rather efficient thanks to the\npresence of the delta-function in the expression above. For example, when spmeth  = 1, the CPU time required to compute the spectral function on an arbitrarily dense\nfrequency mesh is just twice that required by a single static computation\nbased on the standard Adler-Wiser expression.  The full polarizability is then efficiently retrieved by means of a less\nexpensive frequency integration (a Hilbert transform):   The price to be paid, however, is that a large table for the spectral function\nhas to be stored in memory and a Hilbert transform has to be performed for\neach pair ( \\GG_1 ,  \\GG_2 ). Since the computing time required for the\ntransform scales quadratically with the number of vectors in the\npolarizability (governed by  ecuteps , the CPU time spent in this part will overcome\nthe computing time of the standard Adler-Wiser formalism for large  ecuteps .\nA theoretical estimate of the crossover point is hard to give because it\ndepends on many factors. However, if many frequencies are needed, such as for\nthe evaluation of optical spectra, or accurate contour deformation\nintegrations, or even mapping full grids in the complex plane, the Hilbert\ntransform method can be significantly faster, and its use is well worth considering.",
            "title": "The Hilbert transform method."
        },
        {
            "location": "/theory/theory_mbt/#evaluation-of-the-gw-self-energy",
            "text": "Following the standard approach, we separate the screened interaction into the\nstatic bare Coulomb term and a frequency-dependent contribution according to:   where matrix notation is used.  This particular decomposition of  W , once inserted in the convolution\ndefining  \\Sigma , leads to the split of the self-energy into two different\ncontributions (exchange and correlation):   The exchange part is static and turns out to have the same mathematical\nstructure as the Fock operator in Hartree-Fock theory, albeit constructed with\nquasiparticle amplitudes   while the dynamic part  \\Sigma_c(\\omega)  accounts for correlation effects beyond  \\Sigma_x .  It is important to stress that, for computational efficiency, the code does\nnot compute the full self-energy operator by default. Only its matrix elements\nfor the states specified by  kptgw  and  bdgw  are computed and used to obtain the QP corrections.  When expressed in reciprocal space, the diagonal matrix elements of the\nexchange part are given by:   The evaluation of these terms represents a minor fraction of the overall CPU\ntime since only occupied states are involved. However we should always keep in\nmind that, due to the long range of the bare Coulomb interaction, the\nconvergence with respect to the number of plane waves used in the oscillators M  ( ecutsigx  is usually slow, much slower than the convergence of the correlation\npart, which is short-ranged. This plane wave cutoff can be converged\nindependently of others if neceessary, and given a much larger value in\ncomparison to  ecut ,  ecutwfn  and  ecuteps .  Another point worth noting is the presence in the expression of the Coulomb\nsingularity for  |\\qq+\\GG| \\rightarrow 0 . From a mathematical point of view, the\nintegral is well-defined since the singularity is integrable in three-\ndimensional space once the thermodynamical limit,  N_\\qq \\rightarrow \\infty , is reached. On\nthe other hand, only a finite number of  \\qq -points can be used for practical\napplications, and a careful numerical treatment is needed to avoid an\nexceedingly slow convergence with respect to the BZ sampling. To accelerate\nthe convergence in the number of  \\qq -points, the code implements several\ntechniques proposed in the literature. \nWe refer to the documentation of  icutcoul  for a more extensive discussion.  The expression for the matrix elements of the correlation part is instead given by:   where all dynamical effects are now contained in the frequency convolution integral  J .  The explicit expression for  J  depends on the method used to treat the\nscreened interaction. The code implements four different plasmon-pole\ntechniques to model the frequency dependence of  W  in an efficient but\napproximate way, alternatively, it is possible to use the more sophisticated\nfrequency integration of the contour deformation method [15] for accurate QP\ncalculations (see the related variables  ppmodel  and  gwcalctyp .  The double sum over  \\GG -vectors is performed for all the plane waves\ncontained within a sphere of energy  ecuteps \n(it cannot be larger than the value used to generate the SCR file). For each\nstate, the correlated matrix elements are evaluated on a linear frequency mesh\ncentered around the initial KS energy and the derivative needed for the\nrenormalization factor is obtained numerically (see  nomegasrd  and  omegasrdmax )  Note that here, in contrast to the exchange term, the sum over the band index n  should extend up to infinity although in practice only a finite number of\nstates can be used (specified by  nband ).",
            "title": "Evaluation of the GW self-energy."
        },
        {
            "location": "/theory/theory_mbt/#plasmon-pole-models",
            "text": "One of the major computational efforts in self-energy calculations is\nrepresented by the calculation of the frequency dependence of the screened\ninteraction, which is needed for the evaluation of the convolution. Due to the\nragged behavior of  G(\\omega)  and  W(\\omega)  along the real axis, numerous real\nfrequencies are in principle required to converge the results (note that the\nmaximum frequencies needed are now reported if  prtvol  > 9). \nOn the other hand, since the fine details of  W(\\omega)  are integrated over,\nit is reasonable to expect that approximate models, able to capture the main\nphysical features of the screened interaction, should give sufficiently\naccurate results with a considerably reduction of computational effort. This\nis the basic idea behind the so-called plasmon-pole models in which the\nfrequency dependence of  W(\\omega)  is modelled in terms of analytic expressions\ndepending on coefficients that are derived from first principles, i.e. without\nany adjustable external parameters.  Four different plasmon-pole techniques are available in ABINIT and the input\nvariable  ppmodel  selects the method to be used.  When  ppmodel  =1,2 the frequency dependence of the inverse dielectric function is\nmodeled according to    The two models differ in the approach used to compute the parameters.  ppmodel  = 1 derives the parameters such that the inverse dielectric matrix is correctly\nreproduced at two different explicitly calculated frequencies: the static\nlimit ( \\omega=0 ) and an additional imaginary point located at  ppmfrq .\nUnless the user overrides this, the default value is calculated from the\naverage electronic density of the system. The plasmon-pole parameters of  ppmodel  = 2\nare calculated so as to reproduce the static limit exactly and to fulfill a\ngeneralized frequency sum rule relating the imaginary part of the many-body\ninverse dielectric matrix to the plasma frequency and the charge density [12]  For a discussion of the models corresponding to  ppmodel  = 3,4\nwe refer the reader to the original papers cited in the documentation of the variable.",
            "title": "Plasmon-pole models"
        },
        {
            "location": "/theory/theory_mbt/#contour-deformation-technique",
            "text": "The contour deformation method was proposed in order to avoid having to deal\nwith quantities close to the real axis as much as possible [15]. The integral\nover the real frequency axis can be transformed into an integral over the\ncontour depicted in red in the figure below. The integral over real frequency\nis traded with an integration along the imaginary axis plus contributions\ncoming from the poles of the integrand lying inside the contour:    In the above equation, the first sum is restricted to the poles lying inside\nthe path  C .  W_c(z)  represents the frequency dependent part of the\nscreened interaction, whose expression in reciprocal space is given by:   The integration along the imaginary axis is expected to converge quickly with\nrespect to the number of sampled frequencies since the integrand is typically\nvery smooth. Only the residues of the integrand have to be evaluated at the\ncomplex poles contributed by the Green\u2019s function whose frequency dependence\nis known.",
            "title": "Contour deformation technique."
        },
        {
            "location": "/theory/theory_mbt/#notations",
            "text": "The following shorthand notations are employed:   where  v(\\rr_1, \\rr_2)  represents the bare Coulomb interaction, and  \\eta  is a\npositive infinitesimal.  The Fourier transforms for periodic lattice quantities are defined as   The volume of the unit cell is denoted with  \\Omega , while  V  is the total volume\nof the crystal simulated employing Born-von Karman periodic boundary\ncondition. Unless otherwise specified, Hartree atomic units will be used throughout.",
            "title": "Notations"
        },
        {
            "location": "/theory/theory_mbt/#references",
            "text": "{% bibliography \u2013cited %}",
            "title": "References"
        },
        {
            "location": "/theory/theory_mbt/#old",
            "text": "Abrikosov, Gorkov, and Dzyaloshinskii. Methods of quantum field theory in statistical physics, Dover, New York, (1975)   Fetter, and Walecka. Quantum Theory of Many-Particle Systems, McGraw-Hill, New York, (1971)   R.D Mattuck. A guide to Feynman diagrams in the many-body problem, Dover, New York, (1992)   W. G. Aulbur, L. J\ufffdnsson and J. W. Wilkins, Solid State Physics  54 , 1 (2000)   G. Onida et al. Phys. Rev. Lett.  75 , 818 (1995)   L. Hedin Phys. Rev.  139 , A796, (1965)   S. L. Adler, Phys. Rev.  126 , 413 (1962)  N. Wiser, Phys. Rev.  129 , 72 (1963)  A. Kutepov, S. Y. Savrasov and G. Kotliar Phys. Rev. B  80 , 041103(R) (2009)   A. Kutepov, S. Y. Savrasov and G. Kotliar Phys. Rev. B  80 , 041103(R) (2009)   M.S. Hybertsen, and S.G Louie. Phys. Rev. Lett.  55 , 1418 (1985)   M.S. Hybertsen, and S.G Louie. Phys. Rev. B  34 , 5390 (1986)   T. Miyake, and F. Aryasetiawan. Phys. Rev. B,  61 , 7172 (2000)   M. Shishkin, and G. Kresse. Phys. Rev. B,  74 , 035101 (2006)   S. Lebegue, B. Arnaud, M. Alouani, and P.E. Bloechl. Phys. Rev. B,  67 , 155208 (2003)",
            "title": "OLD"
        },
        {
            "location": "/theory/additional_material/",
            "text": "PDF files\n\u00b6\n\n\nNotes on elastic properties by O. Oganov. \n\nDownload\n\n\n\n   \nDownload!\n\n\n\n\nDownload!",
            "title": "Additional Material"
        },
        {
            "location": "/theory/additional_material/#pdf-files",
            "text": "Notes on elastic properties by O. Oganov.  Download  \n    Download!   Download!",
            "title": "PDF files"
        },
        {
            "location": "/bibliography/",
            "text": "Albrecht1998\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Ab Initio Calculation of Excitonic Effects in the Optical Spectra of Semiconductors\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20181998\u2019), (\u2018volume\u2019, \u201880\u2019), (\u2018pages\u2019, \u20184510\u20134513\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.80.4510\u2019), (\u2018numpages\u2019, \u20183\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Albrecht, S.\u2019), Person(\u2018Reining, L.\u2019), Person(\u2018Del Sole, R.\u2019), Person(\u2018Onida, G.\u2019)])]))\n\n\nAllen1976\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theory of the temperature dependence of electronic band structures\u2019), (\u2018journal\u2019, \u2018J. of Phys. C: Solid State Physics\u2019), (\u2018year\u2019, \u20181976\u2019), (\u2018volume\u2019, \u20189\u2019), (\u2018pages\u2019, \u20182305\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Allen, P. B.\u2019), Person(\u2018Heine, V.\u2019)])]))\n\n\nAllen1978\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u201cNew method for solving Boltzmann\u2019s equation for electrons in metals\u201d), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181978\u2019), (\u2018volume\u2019, \u201817\u2019), (\u2018pages\u2019, \u20183725\u20133734\u2019), (\u2018optdoi\u2019, \u201810.1103/PhysRevB.17.3725\u2019), (\u2018issue\u2019, \u201810\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Allen, P. B.\u2019)])]))\n\n\nAllen1981\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theory of the temperature dependence of the direct gap of germanium\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181981\u2019), (\u2018volume\u2019, \u201823\u2019), (\u2018pages\u2019, \u20181495\u20131505\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Allen, P. B.\u2019), Person(\u2018Cardona, M.\u2019)])]))\n\n\nAllen1983\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Temperature dependence of the direct gap of {S}i and {G}e\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181983\u2019), (\u2018volume\u2019, \u201827\u2019), (\u2018pages\u2019, \u20184760\u20134769\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Allen, P. B.\u2019), Person(\u2018Cardona, M.\u2019)])]))\n\n\nAllen1996\n\u00b6\n\n\nEntry(\u2018incollection\u2019, fields=[(\u2018TITLE\u2019, \u2018Boltzmann Theory and Resistivity of Metals\u2019), (\u2018BOOKTITLE\u2019, \u2018Quantum Theory of Real Materials\u2019), (\u2018PUBLISHER\u2019, \u2018Kl{\\\u201cu}wer\u2019), (\u2018ADDRESS\u2019, \u2018Boston\u2019), (\u2018PAGES\u2019, \u2018219-250\u2019), (\u2018YEAR\u2019, \u20181996\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018AUTHOR\u2019, [Person(\u2018Allen, P. B.\u2019)]), (\u2018EDITOR\u2019, [Person(\u2018Chelikowsky, J. R.\u2019), Person(\u2018Louie, S. G.\u2019)])]))\n\n\nAllen2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Recovering hidden Bloch character: Unfolding electrons, phonons, and slabs\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182013\u2019), (\u2018Pages\u2019, \u2018085322\u2019), (\u2018Volume\u2019, \u201887\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Allen, P. B.\u2019), Person(\u2018Berlijn, T.\u2019), Person(\u2018Casavant, D. A.\u2019), Person(\u2018Soler, J. M.\u2019)])]))\n\n\nAmadon2006\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018The \n\\\\alpha\n-\n\\\\gamma\n {T}ransition of {C}erium {I}s {E}ntropy {D}riven\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018volume\u2019, \u201896\u2019), (\u2018pages\u2019, \u2018066402\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.96.066402\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Cerium/DMFT/PhysRevLett.96.066402.pdf:PDF\u2019), (\u2018issue\u2019, \u20186\u2019), (\u2018numpages\u2019, \u20184\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Biermann, S.\u2019), Person(\u2018Georges, A.\u2019), Person(\u2018Aryasetiawan, F.\u2019)])]))\n\n\nAmadon2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Plane-wave based electronic structure calculations for correlated materials using dynamical mean-field theory and projected local orbitals\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018volume\u2019, \u201877\u2019), (\u2018pages\u2019, \u2018205112\u2019), (\u2018number\u2019, \u201820\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/DMFT/PhysRevB.77.205112.pdf:PDF\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.77.205112\u2019), (\u2018timestamp\u2019, \u20182012.08.08\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.77.205112\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Lechermann, F.\u2019), Person(\u2018Georges, A.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Wehling, T. O.\u2019), Person(\u2018Liechtenstein, A. I.\u2019)])]))\n\n\nAmadon2008a\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018\n\\\\gamma\n and \n\\\\beta\n cerium: {LDA}+{U} calculations of ground-state parameters\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018volume\u2019, \u201877\u2019), (\u2018pages\u2019, \u2018155104\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.77.155104\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Cerium/PhysRevB.77.155104-1.pdf:PDF\u2019), (\u2018issue\u2019, \u201815\u2019), (\u2018numpages\u2019, \u201810\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019)])]))\n\n\nAmadon2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018A self-consistent {DFT}+{DMFT} scheme in the projector augmented wave method: applications to cerium, {C}e\n_2\n{O}\n_3\n and {P}u\n_2\n{O}\n_3\n with the {H}ubbard {I} solver and comparison to {DFT}+{U}\u2019), (\u2018journal\u2019, \u2018J. Phys.: Cond. Matt.\u2019), (\u2018year\u2019, \u20182012\u2019), (\u2018volume\u2019, \u201824\u2019), (\u2018pages\u2019, \u2018075604\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/DMFT/0953-8984_24_7_075604.pdf:PDF\u2019), (\u2018issn\u2019, \u20180953-8984\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018timestamp\u2019, \u20182012.08.08\u2019), (\u2018url\u2019, \u2018http://iopscience.iop.org/article/10.1088/0953-8984/24/7/075604\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019)])]))\n\n\nAmadon2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Screened Coulomb interaction calculations: c{RPA} implementation and applications to dynamical screening and self-consistency in uranium dioxide and cerium\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018pages\u2019, \u2018125110\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.125110\u2019), (\u2018issue\u2019, \u201812\u2019), (\u2018numpages\u2019, \u201810\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Applencourt, T.\u2019), Person(\u2018Bruneval, F.\u2019)])]))\n\n\nAmadon2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Comparative analysis of models for the \n\\\\alpha\n-\n\\\\gamma\n phase transition in cerium: A DFT+DMFT study using Wannier orbitals\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018volume\u2019, \u201891\u2019), (\u2018pages\u2019, \u2018161103\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.91.161103\u2019), (\u2018issue\u2019, \u201816\u2019), (\u2018numpages\u2019, \u20185\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Gerossier, A.\u2019)])]))\n\n\nAmbrosetti2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018van der {W}aals interactions in density functional theory using Wannier functions: Improved {C}6 and {C}3 coefficients by a different approach\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182012\u2019), (\u2018volume\u2019, \u201885\u2019), (\u2018pages\u2019, \u2018073101\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Ambrosetti, A.\u2019), Person(\u2018Silvestrelli, P. L.\u2019)])]))\n\n\nAnisimov1991\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Density-functional calculation of effective Coulomb interactions in metals\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181991\u2019), (\u2018volume\u2019, \u201843\u2019), (\u2018pages\u2019, \u20187570\u20137574\u2019), (\u2018number\u2019, \u201810\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.43.7570\u2019), (\u2018timestamp\u2019, \u20182013.07.03\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.43.7570\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Anisimov, V. I.\u2019), Person(\u2018Gunnarsson, O.\u2019)])]))\n\n\nAntonius2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Many-Body Effects on the Zero-Point Renormalization of the Band Structure\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u2018112\u2019), (\u2018pages\u2019, \u2018215501\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Antonius, G.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Boulanger, P.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d), Person(\u2018Gonze, X.\u2019)])]))\n\n\nAntonius2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Dynamical and anharmonic effects on the electron-phonon coupling and the zero-point renormalization of the electronic structure\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018volume\u2019, \u201892\u2019), (\u2018pages\u2019, \u2018085137\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Antonius, G.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Lantagne-Hurtubise, E.\u2019), Person(\u2018Auclair, G.\u2019), Person(\u2018Gonze, X.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d)])]))\n\n\nArponen1979\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Angular correlation in positron annihilation\u2019), (\u2018doi\u2019, \u201810.1088/0305-4608/9/12/009\u2019), (\u2018journal\u2019, \u2018J. Phys. F\u2019), (\u2018volume\u2019, \u20189\u2019), (\u2018pages\u2019, \u20182359\u2019), (\u2018year\u2019, \u20181979\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Arponen, J.\u2019), Person(\u2018Pajanne, E.\u2019)])]))\n\n\nAryasetiawan2004\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Frequency-dependent local interactions and low-energy effective models from electronic structure calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182004\u2019), (\u2018volume\u2019, \u201870\u2019), (\u2018pages\u2019, \u2018195104\u2013\u2018), (\u2018number\u2019, \u201819\u2019), (\u2018keywords\u2019, \u2018cRPA\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.70.195104\u2019), (\u2018timestamp\u2019, \u20182013.03.15\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.70.195104\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Aryasetiawan, F.\u2019), Person(\u2018Imada, M.\u2019), Person(\u2018Georges, A.\u2019), Person(\u2018Kotliar, G.\u2019), Person(\u2018Biermann, S.\u2019), Person(\u2018Liechtenstein, A. I.\u2019)])]))\n\n\nAudouze2006\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201873\u2019), (\u2018pages\u2019, \u2018235101\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018title\u2019, \u2018Projector augmented-wave approach to density-functional perturbation theory\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Audouze, C.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nAudouze2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201878\u2019), (\u2018pages\u2019, \u2018035105\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018title\u2019, \u2018Comparison between projector augmented-wave and ultrasoft pseudopotential formalisms at the density-functional perturbation theory level\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Audouze, C.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nBachelet1982\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Pseudopotentials that work: From {H} to {P}u\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181982\u2019), (\u2018volume\u2019, \u201826\u2019), (\u2018pages\u2019, \u20184199\u20134228\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.26.4199\u2019), (\u2018numpages\u2019, \u201829\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bachelet, G.B.\u2019), Person(\u2018Hamann, D.R.\u2019), Person(\u2018Schl\\\u201cuter, M.\u2019)])]))\n\n\nBader1994\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Atoms in Molecules: A Quantum Theory\u2019), (\u2018journal\u2019, \u2018Oxford University Press.\u2019), (\u2018year\u2019, \u20181994\u2019), (\u2018volume\u2019, \u2018ISBN 978-0-19-855865-1\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018\u2019), (\u2018url\u2019, \u2018\u2019), (\u2018doi\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bader, R. F. W.\u2019)])]))\n\n\nBarbiellini1996\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Calculation of positron states and annihilation in solids: A density-gradient-correction scheme\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201853\u2019), (\u2018issue\u2019, \u201824\u2019), (\u2018pages\u2019, \u201816201\u2019), (\u2018year\u2019, \u20181996\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.53.16201\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Barbiellini, B.\u2019), Person(\u2018Puska, M. J.\u2019), Person(\u2018Korhonen, T.\u2019), Person(\u2018Harju, A.\u2019), Person(\u2018Torsti, T.\u2019), Person(\u2018Nieminen, R. M.\u2019)])]))\n\n\nBaroni1987\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u201cGreen\u2019s-function approach to linear response in solids\u201d), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20181987\u2019), (\u2018volume\u2019, \u201858\u2019), (\u2018pages\u2019, \u20181861\u20131864\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Baroni, S.\u2019), Person(\u2018Giannozzi, P.\u2019), Person(\u2018Testa, A.\u2019)])]))\n\n\nBecke1990\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018A simple measure of electron localization in atomic and molecular systems\u2019), (\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018year\u2019, \u20181990\u2019), (\u2018volume\u2019, \u201892\u2019), (\u2018number\u2019, \u20189\u2019), (\u2018pages\u2019, \u20185397-5403\u2019), (\u2018url\u2019, \u2018http://scitation.aip.org/content/aip/journal/jcp/92/9/10.1063/1.458517\u2019), (\u2018doi\u2019, \u201810.1063/1.458517\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Becke, A. D.\u2019), Person(\u2018Edgecombe, K. E.\u2019)])]))\n\n\nBenedict1998\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Optical Absorption of Insulators and the Electron-Hole Interaction: An \\textit{Ab Initio} Calculation\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u201880\u2019), (\u2018issue\u2019, \u201820\u2019), (\u2018pages\u2019, \u20184514\u20134517\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181998\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.80.4514\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Benedict, L. X.\u2019), Person(\u2018Shirley, E. L.\u2019), Person(\u2018Bohn, R. B.\u2019)])]))\n\n\nBengone2000\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Implementation of the projector augmented-wave {LDA}+{U} method: Application to the electronic structure of {N}i{O}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201862\u2019), (\u2018pages\u2019, \u201816392\u2019), (\u2018year\u2019, \u20181994\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018O. Bengone, M. Alouani, P. Bl\\\u201cochl,\u2019), Person(\u2018Hugel, J.\u2019)])]))\n\n\nBergeron2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Algorithms for optimized maximum entropy and diagnostic tools for analytic continuation\u2019), (\u2018journal\u2019, \u2018arXiv e-prints\u2019), (\u2018archivePrefix\u2019, \u2018arXiv:cond-mat.str-el\u2019), (\u2018eprint\u2019, \u20181507.01012\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018month\u2019, \u2018jul\u2019), (\u2018adsurl\u2019, \u2018http://adsabs.harvard.edu/abs/2015arXiv150701012B\u2019), (\u2018adsnote\u2019, \u2018Provided by the SAO/NASA Astrophysics Data System\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bergeron, D.\u2019), Person(\u2018Tremblay, A.-M. S.\u2019)])]))\n\n\nBieder2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Thermodynamics of the \n\\\\alpha\n-\n\\\\gamma\n transition in cerium from first principles\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018pages\u2019, \u2018195132\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.195132\u2019), (\u2018issue\u2019, \u201819\u2019), (\u2018numpages\u2019, \u20187\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bieder, J.\u2019), Person(\u2018Amadon, B.\u2019)])]))\n\n\nBloechl1994\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Projector augmented-wave method\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181994\u2019), (\u2018volume\u2019, \u201850\u2019), (\u2018pages\u2019, \u201817953-17979\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.50.17953\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bl\\\u201c{o}chl, P.E.\u2019)])]))\n\n\nBockstedte1997\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Density-functional theory calculations for poly-atomic systems: electronic structure, static and elastic properties and ab initio molecular dynamics\u2019), (\u2018Journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018Volume\u2019, \u2018107\u2019), (\u2018Pages\u2019, \u2018187\u2019), (\u2018Year\u2019, \u20181997\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Bockstedte, M.\u2019), Person(\u2018Kley, A.\u2019), Person(\u2018Neugebauer, J.\u2019), Person(\u2018Scheffler, M.\u2019)])]))\n\n\nBoronski1986\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electron-positron density-functional theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201834\u2019), (\u2018issue\u2019, \u20186\u2019), (\u2018pages\u2019, \u20183820\u2019), (\u2018year\u2019, \u20181986\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.34.3820\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cBoro\\\u2018nski, E.\u201d), Person(\u2018Nieminen, R. M.\u2019)])]))\n\n\nBottin2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Large-scale ab initio calculations based on three levels of parallelization\u2019), (\u2018journal\u2019, \u2018Comp. Mat. Sci.\u2019), (\u2018volume\u2019, \u201842\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u2018329\u2013336\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018publisher\u2019, \u2018Elsevier\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bottin, F.\u2019), Person(\u2018Leroux, S.\u2019), Person(\u2018Knyazev, A.\u2019), Person(\u201cZ{\\\u2018e}rah, G.\u201d)])]))\n\n\nBousquet2011\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Unexpectedly Large Electronic Contribution to Linear Magnetoelectricity\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018106\u2019), (\u2018pages\u2019, \u2018107202\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.106.107202\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bousquet, E.\u2019), Person(\u2018Spaldin, N. A.\u2019), Person(\u2018Delaney, K. T.\u2019)])]))\n\n\nBruneval2006\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Effect of self-consistency on quasiparticles in solids\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201874\u2019), (\u2018pages\u2019, \u2018045102\u2019), (\u2018year\u2019, \u20182006\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bruneval, F.\u2019), Person(\u2018Vast, N.\u2019), Person(\u2018Reining, L.\u2019)])]))\n\n\nBruneval2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Accurate {GW} self-energies in a plane-wave basis using only a few empty states: Towards large systems\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201878\u2019), (\u2018issue\u2019, \u20188\u2019), (\u2018pages\u2019, \u2018085125\u2019), (\u2018numpages\u2019, \u20189\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.78.085125\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bruneval, F.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nBruneval2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Range-Separated Approach to the {RPA} Correlation Applied to the van der Waals Bond and to Diffusion of Defects\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018108\u2019), (\u2018issue\u2019, \u201825\u2019), (\u2018pages\u2019, \u2018256403\u2019), (\u2018numpages\u2019, \u20185\u2019), (\u2018year\u2019, \u20182012\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.108.256403\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bruneval, F.\u2019)])]))\n\n\nBruneval2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Consistent treatment of charged systems within periodic boundary conditions: The projector augmented-wave and pseudopotential methods revisited\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018issue\u2019, \u20184\u2019), (\u2018pages\u2019, \u2018045116\u2019), (\u2018numpages\u2019, \u201813\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.045116\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bruneval, F.\u2019), Person(\u2018Crocombette, J.-P.\u2019), Person(\u2018Gonze, X.\u2019), Person(\u2018Dorado, B.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Jollet, F.\u2019)])]))\n\n\nCalloni2005\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Positron localization effects on the Doppler broadening of the annihilation line: Aluminum as a case study\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201872\u2019), (\u2018number\u2019, \u20185\u2019), (\u2018pages\u2019, \u2018054112\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Calloni, A.\u2019), Person(\u2018Dupasquier, A.\u2019), Person(\u2018Ferragut, R.\u2019), Person(\u2018Folegati, P.\u2019), Person(\u2018Iglesias, M.M.\u2019), Person(\u2018Makkonen, I.\u2019), Person(\u2018Puska, M.J.\u2019)])]))\n\n\nCampillo1998\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic stopping power of aluminum crystal\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201858\u2019), (\u2018issue\u2019, \u201816\u2019), (\u2018pages\u2019, \u201810307 - 10314\u2019), (\u2018year\u2019, \u20181998\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.58.10307\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Campillo, I.\u2019), Person(\u2018Pitarke, J. M.\u2019), Person(\u2018Eguiluz, A. G.\u2019)])]))\n\n\nCappellini1993\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Model dielectric function for semiconductors\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201847\u2019), (\u2018issue\u2019, \u201815\u2019), (\u2018pages\u2019, \u20189892\u20139895\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181993\u2019), (\u2018month\u2019, \u2018Apr\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.47.9892\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Cappellini, G.\u2019), Person(\u2018Del Sole, R.\u2019), Person(\u2018Reining, L.\u2019), Person(\u2018Bechstedt, F.\u2019)])]))\n\n\nCaracas2007\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Prediction of polar ordered oxynitride perovskites\u2019), (\u2018journal\u2019, \u2018J. Appl. Phys. Lett.\u2019), (\u2018volume\u2019, \u201891\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018092902\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018doi\u2019, \u201810.1063/1.2776370\u2019), (\u2018publisher\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Caracas, R.\u2019), Person(\u2018Cohen, R.E.\u2019)])]))\n\n\nCaracas2007a\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Post-perovskite phase in selected sesquioxides from density-functional calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201876\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018184101\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018doi\u2019, \u2018\u2019), (\u2018publisher\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Caracas, R.\u2019), Person(\u2018Cohen, R.E.\u2019)])]))\n\n\nCaracas2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Dynamical Instabilities of Ice X\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018101\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018085502\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.101.085502\u2019), (\u2018publisher\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Caracas, R.\u2019)])]))\n\n\nCococcioni2005\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Linear response approach to the calculation of the effective interaction parameters in the {LDA}+{U} method\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018volume\u2019, \u201871\u2019), (\u2018pages\u2019, \u2018035105\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/PhysRevB.71.035105.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018DFTU interaction, cRPA\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.71.035105\u2019), (\u2018timestamp\u2019, \u20182012.06.21\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.71.035105\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Cococcioni, M.\u2019), Person(\u2018de Gironcoli, S.\u2019)])]))\n\n\nColeman2015\n\u00b6\n\n\nEntry(\u2018book\u2019, fields=[(\u2018title\u2019, \u2018Introduction to Many-Body Physics\u2019), (\u2018publisher\u2019, \u2018Cambridge University Press\u2019), (\u2018year\u2019, \u20182015\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Coleman, Piers\u2019)])]))\n\n\nCzyzyk1994\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Local-density functional and on-site correlations: {T}he electronic structure of {L}a\n_2\n{C}u{O}\n_4\n and {L}a{C}u{O}\n_3\n\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201849\u2019), (\u2018pages\u2019, \u201814211\u2019), (\u2018year\u2019, \u20181994\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Czyzyk, M. T.\u2019), Person(\u2018Sawatzky, G. A.\u2019)])]))\n\n\nDaubechies1992\n\u00b6\n\n\nEntry(\u2018book\u2019, fields=[(\u2018title\u2019, \u201810 Lectures on Wavelets\u2019), (\u2018publisher\u2019, \u2018Society for Industrial and Applied Mathematics ({SIAM}, 3600 {M}arket {S}treet, {F}loor 6, {P}hiladelphia, {PA} 19104)\u2019), (\u2018year\u2019, \u20181992\u2019), (\u2018isbn\u2019, \u20189780898712742\u2019), (\u2018keywords\u2019, \u2018Mathematics / General, Mathematics / Infinity, Mathematics / Mathematical Analysis, Science / Waves \\& Wave Mechanics, Technology \\& Engineering / General\u2019), (\u2018language\u2019, \u2018en\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Daubechies, I.\u2019)])]))\n\n\nDion2004\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Van der Waals Density Functional for General Geometries\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u201892\u2019), (\u2018pages\u2019, \u2018246401\u2019), (\u2018year\u2019, \u20182004\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.92.246401\u2019), (\u2018note\u2019, \u2018Erratum: DOI:10.1103/PhysRevLett.95.109902\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Dion, M.\u2019), Person(\u2018Rydberg, H.\u2019), Person(\u2018Schr\\\u201coder, E.\u2019), Person(\u2018Langreth, D. C.\u2019), Person(\u2018Lundqvist, B. I.\u2019)])]))\n\n\nEspejo2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Wannier functions approach to van der Waals interactions in {ABINIT}\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018183\u2019), (\u2018pages\u2019, \u2018480\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Espejo, C.\u2019), Person(\u2018Rangel, T.\u2019), Person(\u2018Pouillon, Y.\u2019), Person(\u2018Romero, A. H.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nFolegati2007\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Analysis of electron-positron momentum spectra of metallic alloys as supported by first-principles calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201875\u2019), (\u2018number\u2019, \u20185\u2019), (\u2018pages\u2019, \u2018054201\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Folegati, P.\u2019), Person(\u2018Makkonen, I.\u2019), Person(\u2018Ferragut, R.\u2019), Person(\u2018Puska, M.J.\u2019)])]))\n\n\nFreund1995\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Software for simplified {L}anczos and {QMR} algorithms\u2019), (\u2018journal\u2019, \u2018Applied Numerical Mathematics\u2019), (\u2018year\u2019, \u20181995\u2019), (\u2018volume\u2019, \u201819\u2019), (\u2018pages\u2019, \u2018319\u2019), (\u2018doi\u2019, \u201810.1016/0168-9274(95)00089-5\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Freund, R. W.\u2019), Person(\u2018Nachtigal, N. M.\u2019)])]))\n\n\nFuchs1999\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Ab initio pseudopotentials for electronic structure calculations of poly-atomic systems using density-functional theory\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018119\u2019), (\u2018number\u2019, \u20181\u2019), (\u2018pages\u2019, \u201867 - 98\u2019), (\u2018year\u2019, \u20181999\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180010-4655\u2019), (\u2018doi\u2019, \u201810.1016/S0010-4655(98)00201-X\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S001046559800201X\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Fuchs, M.\u2019), Person(\u2018Scheffler, M.\u2019)])]))\n\n\nGarrity2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Pseudopotentials for high-throughput {DFT} calculations\u2019), (\u2018journal\u2019, \u2018Comp. Mat. Sci.\u2019), (\u2018volume\u2019, \u201881\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018446 - 452\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180927-0256\u2019), (\u2018doi\u2019, \u201810.1016/j.commatsci.2013.08.053\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S0927025613005077\u2019), (\u2018keywords\u2019, \u2018Density functional theory\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Garrity, K.F.\u2019), Person(\u2018Bennett, J.W.\u2019), Person(\u2018Rabe, K.M.\u2019), Person(\u2018Vanderbilt, D.\u2019)])]))\n\n\nGeneste2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Strong Isotope Effect in Phase {I}{I} of Dense Solid Hydrogen and Deuterium\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Volume\u2019, \u2018109\u2019), (\u2018Pages\u2019, \u2018155303\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Geneste, G.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Bottin, F.\u2019), Person(\u2018Loubeyre, P.\u2019)])]))\n\n\nGeneste2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Proton transport in barium stannate: classical, semi-classical and quantum regimes\u2019), (\u2018Journal\u2019, \u2018Phys. Chem. Chem. Phys.\u2019), (\u2018Volume\u2019, \u201817\u2019), (\u2018Pages\u2019, \u201819104\u2019), (\u2018year\u2019, \u20182015\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Geneste, G.\u2019), Person(\u2018Ottochian, A.\u2019), Person(\u2018Hermet, J.\u2019), Person(\u2018Dezanneau, G.\u2019)])]))\n\n\nGenovese2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Daubechies wavelets as a basis set for density functional pseudopotential calculations\u2019), (\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018volume\u2019, \u2018129\u2019), (\u2018pages\u2019, \u2018014109\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Genovese, L.\u2019), Person(\u2018Neelov, L.\u2019), Person(\u2018Goedecker, S.\u2019), Person(\u2018Deutsch, T.\u2019), Person(\u2018Alireza Ghasemi, S.\u2019), Person(\u2018Willand, A.\u2019), Person(\u2018Caliste, D.\u2019), Person(\u2018Zilberberg, O.\u2019), Person(\u2018Rayson, M.\u2019), Person(\u2018Bergman, A.\u2019), Person(\u2018Schneider, R.\u2019)])]))\n\n\nGenovese2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Density Functional Theory calculation on many-cores hybrid {CPU}-{GPU} architectures in hybrid architecture\u2019), (\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018volume\u2019, \u2018131\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018034103\u2019), (\u2018year\u2019, \u20182009\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Genovese, L.\u2019), Person(\u2018Ospici, M.\u2019), Person(\u2018Deutsch, T.\u2019), Person(\u201cM\\\u2018ehaut, J.-F.\u201d), Person(\u2018Neelov, A.\u2019), Person(\u2018Goedecker, S.\u2019)])]))\n\n\nGeorges1996\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Dynamical mean-field theory of strongly correlated fermion systems and the limit of infinite dimensions\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018year\u2019, \u20181996\u2019), (\u2018volume\u2019, \u201868\u2019), (\u2018pages\u2019, \u201813\u2013125\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.68.13\u2019), (\u2018issue\u2019, \u20181\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Georges, A.\u2019), Person(\u2018Kotliar, G.\u2019), Person(\u2018Krauth, W.\u2019), Person(\u2018Rozenberg, M.J.\u2019)])]))\n\n\nGeorges2004\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Strongly Correlated Electron Materials: Dynamical Mean-Field Theory and Electronic Structure\u2019), (\u2018journal\u2019, \u2018{AIP} {C}onf. {P}roc.\u2019), (\u2018year\u2019, \u20182004\u2019), (\u2018volume\u2019, \u2018715\u2019), (\u2018pages\u2019, \u20183\u201374\u2019), (\u2018number\u2019, \u20181\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/DMFT/APC000003.pdf:PDF\u2019), (\u2018keywords\u2019, \u201cstrongly correlated electron systems, metal-insulator transition, density functional theory, electronic structure, band theory, Green\u2019s function methods, spin systems, transport processes, critical phenomena, transition metal compounds, rare earth compounds, actinide compounds, oxygen compounds\u201d), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018AIP\u2019), (\u2018timestamp\u2019, \u20182012.10.18\u2019), (\u2018doi\u2019, \u201810.1063/1.1800733\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Georges, A.\u2019)])]))\n\n\nGiannozzi2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018{QUANTUM} {ESPRESSO}: a modular and open-source software project for quantum simulations of materials\u2019), (\u2018journal\u2019, \u2018J. Phys.: Cond. Matt.\u2019), (\u2018volume\u2019, \u201821\u2019), (\u2018number\u2019, \u201839\u2019), (\u2018pages\u2019, \u2018395502\u2019), (\u2018url\u2019, \u2018http://iopscience.iop.org/article/10.1088/0953-8984/21/39/395502\u2019), (\u2018year\u2019, \u20182009\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Giannozzi, P.\u2019), Person(\u2018Baroni, S.\u2019), Person(\u2018Bonini, N.\u2019), Person(\u2018Calandra, M.\u2019), Person(\u2018Car, R.\u2019), Person(\u2018Cavazzoni, C.\u2019), Person(\u2018Ceresoli, D.\u2019), Person(\u2018Chiarotti, G.L.\u2019), Person(\u2018Cococcioni, M.\u2019), Person(\u2018Dabo, I.\u2019), Person(\u2018Dal Corso, A.\u2019), Person(\u2018de Gironcoli, S.\u2019), Person(\u2018Fabris, S.\u2019), Person(\u2018Fratesi, G.\u2019), Person(\u2018Gebauer, R.\u2019), Person(\u2018Gerstmann, U.\u2019), Person(\u2018Gougoussis, C.\u2019), Person(\u2018Kokalj, A.\u2019), Person(\u2018Lazzeri, M.\u2019), Person(\u2018Martin-Samos, L.\u2019), Person(\u2018Marzari, N.\u2019), Person(\u2018Mauri, F.\u2019), Person(\u2018Mazzarello, R.\u2019), Person(\u2018Paolini, S.\u2019), Person(\u2018Pasquarello, A.\u2019), Person(\u2018Paulatto, L.\u2019), Person(\u2018Sbraccia, C.\u2019), Person(\u2018Scandolo, S.\u2019), Person(\u2018Sclauzero, G.\u2019), Person(\u2018Seitsonen, A.P.\u2019), Person(\u2018Smogunov, A.\u2019), Person(\u2018Umari, P.\u2019), Person(\u2018Wentzcovitch, R.M.\u2019)])]))\n\n\nGiantomassi2011\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018{Electronic properties of interfaces and defects from many-body perturbation theory: Recent developments and applications}\u2019), (\u2018journal\u2019, \u2018Physica Status Solidi B\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018volume\u2019, \u2018248\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u2018275\u2013289\u2019), (\u2018doi\u2019, \u201810.1002/pssb.201046094\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Giantomassi, M.\u2019), Person(\u2018Stankovski, M.\u2019), Person(\u2018Shaltaf, R.\u2019), Person(\u2018Gruning, M.\u2019), Person(\u2018Bruneval, F.\u2019), Person(\u2018Rinke, P.\u2019), Person(\u2018Rignanese, G.M.\u2019)])]))\n\n\nGillet2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018First-principles study of excitonic effects in Raman intensities\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182013\u2019), (\u2018Pages\u2019, \u2018094305\u2019), (\u2018Volume\u2019, \u201888\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.88.094305\u2019), (\u2018File\u2019, \u2018Gillet2013.pdf:Gillet2013.pdf:PDF;Gillet2013.pdf:Gillet2013.pdf:PDF\u2019), (\u2018Issue\u2019, \u20189\u2019), (\u2018Numpages\u2019, \u20189\u2019), (\u2018Publisher\u2019, \u2018American Physical Society\u2019), (\u2018Url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.88.094305\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Gillet, Y.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nGillet2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Efficient Interpolation Technique for {B}ethe-{S}alpeter Calculation of Optical Spectra\u2019), (\u2018Year\u2019, \u20182016\u2019), (\u2018volume\u2019, \u2018203C\u2019), (\u2018pages\u2019, \u201883-93\u2019), (\u2018Journal\u2019, \u2018Comput. Phys. Comm.\u2019), (\u2018Doi\u2019, \u201810.1016/j.cpc.2016.02.008\u2019), (\u2018Owner\u2019, \u2018yannick\u2019), (\u2018Timestamp\u2019, \u20182015.08.27\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Gillet, Y.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nGoedecker1996\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Separable dual-space Gaussian pseudopotentials\u2019), (\u2018volume\u2019, \u201854\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181996\u2019), (\u2018pages\u2019, \u20181703\u20131710\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Goedecker, S.\u2019), Person(\u2018Teter, M.\u2019), Person(\u2018H\\\u201cutter, J.\u2019)])]))\n\n\nGonze1991\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Analysis of separable potentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201844\u2019), (\u2018issue\u2019, \u201816\u2019), (\u2018pages\u2019, \u20188503\u20138513\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181991\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.44.8503\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Stumpf, R.\u2019), Person(\u2018Scheffler, M.\u2019)])]))\n\n\nGonze1995\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Adiabatic density-functional perturbation theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. A\u2019), (\u2018year\u2019, \u20181995\u2019), (\u2018volume\u2019, \u201852\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u20181096\u20131114\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevA.52.1096\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019)])]))\n\n\nGonze1997\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-principles responses of solids to atomic displacements and homogeneous electric fields: Implementation of a conjugate-gradient algorithm\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181997\u2019), (\u2018volume\u2019, \u201855\u2019), (\u2018pages\u2019, \u201810337\u201310354\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019)])]))\n\n\nGonze1997a\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201855\u2019), (\u2018pages\u2019, \u201810355\u2019), (\u2018year\u2019, \u20181997\u2019), (\u2018title\u2019, \u2018Dynamical matrices, Born effective charges, dielectric permittivity tensors, and interatomic force constants from density-functional perturbation theory\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Lee, C.\u2019)])]))\n\n\nGonze2002\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Comp. Mat. Science\u2019), (\u2018volume\u2019, \u201825\u2019), (\u2018pages\u2019, \u2018478\u2013492\u2019), (\u2018year\u2019, \u20182002\u2019), (\u2018title\u2019, \u2018First-principles computation of material properties : the ABINIT software project\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Beuken, J.-M.\u2019), Person(\u2018Caracas, R.\u2019), Person(\u2018Detraux, F.\u2019), Person(\u2018Fuchs, M.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Sindic, L.\u2019), Person(\u2018Verstraete, M.\u2019), Person(\u2018Zerah, G.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Roy, A.\u2019), Person(\u2018Mikami, M.\u2019), Person(\u2018Ghosez, Ph.\u2019), Person(\u2018Raty, J.-Y.\u2019), Person(\u2018Allan, D.C.\u2019)])]))\n\n\nGonze2005\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Zeit. Kristallogr\u2019), (\u2018volume\u2019, \u2018220\u2019), (\u2018pages\u2019, \u2018558-562\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018title\u2019, \u2018A brief introduction to the ABINIT software package\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Verstraete, M.\u2019), Person(\u2018Beuken, J.-M.\u2019), Person(\u2018Pouillon, Y.\u2019), Person(\u2018Caracas, R.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Zerah, G.\u2019), Person(\u2018Mikami, M.\u2019), Person(\u2018Ghosez, Ph.\u2019), Person(\u2018Veithen, M.\u2019), Person(\u2018Raty, J.-Y.\u2019), Person(\u2018Olevano, V.\u2019), Person(\u2018Bruneval, F.\u2019), Person(\u2018Reining, L.\u2019), Person(\u2018Godby, R.\u2019), Person(\u2018Onida, G.\u2019), Person(\u2018an D.C. Allan, D.R. Hamann\u2019)])]))\n\n\nGonze2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018180\u2019), (\u2018pages\u2019, \u20182582-2615\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018title\u2019, \u2018{ABINIT}: First-Principle approach to material and nanosystem properties\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Amadon, B.\u2019), Person(\u2018Anglade, P.-M.\u2019), Person(\u2018Beuken, J.-M.\u2019), Person(\u2018Bottin, F.\u2019), Person(\u2018Boulanger, P.\u2019), Person(\u2018Bruneval, F.\u2019), Person(\u2018Caliste, D.\u2019), Person(\u2018Caracas, R.\u2019), Person(\u201cC\\^{o}t\\\u2018{e}, M.\u201d), Person(\u2018Deutsch, T.\u2019), Person(\u2018Genovese, L.\u2019), Person(\u2018Ghosez, Ph.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Goedecker, S.\u2019), Person(\u2018Hamann, D.R.\u2019), Person(\u2018Hermet, P.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Leroux, S.\u2019), Person(\u2018Mancini, M.\u2019), Person(\u2018Mazevet, S.\u2019), Person(\u2018Oliveira, M.J.T.\u2019), Person(\u2018Onida, G.\u2019), Person(\u2018Pouillon, Y.\u2019), Person(\u2018Rangel, T.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Sangalli, D.\u2019), Person(\u2018Shaltaf, R.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Verstraete, M.J.\u2019), Person(\u2018Zerah, G.\u2019), Person(\u2018Zwanziger, J.W.\u2019)])]))\n\n\nGonze2011\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theoretical approaches to the temperature and zero-point motion effects on the electronic band structure.\u2019), (\u2018journal\u2019, \u2018Annalen der Physik\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018volume\u2019, \u2018523\u2019), (\u2018pages\u2019, \u2018168\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Boulanger, P.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d)])]))\n\n\nGonze2016\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Recent developments in the {ABINIT} software package\u2019), (\u2018journal\u2019, \u2018Computer Physics Communications\u2019), (\u2018volume\u2019, \u2018205\u2019), (\u2018pages\u2019, \u2018106\u2019), (\u2018year\u2019, \u20182016\u2019), (\u2018issn\u2019, \u20180010-4655\u2019), (\u2018doi\u2019, \u201810.1016/j.cpc.2016.04.003\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S0010465516300923\u2019), (\u2018keywords\u2019, \u2018Many-Body Perturbation Theory\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Araujo, F. Abreu\u2019), Person(\u2018Adams, D.\u2019), Person(\u2018Amadon, B.\u2019), Person(\u2018Applencourt, T.\u2019), Person(\u2018Audouze, C.\u2019), Person(\u2018Beuken, J.-M.\u2019), Person(\u2018Bieder, J.\u2019), Person(\u2018Bokhanchuk, A.\u2019), Person(\u2018Bousquet, E.\u2019), Person(\u2018Bruneval, F.\u2019), Person(\u2018Caliste, D.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d), Person(\u2018Dahm, F.\u2019), Person(\u2018Pieve, F. Da\u2019), Person(\u2018Delaveau, M.\u2019), Person(\u2018Gennaro, M. Di\u2019), Person(\u2018Dorado, B.\u2019), Person(\u2018Espejo, C.\u2019), Person(\u2018Geneste, G.\u2019), Person(\u2018Genovese, L.\u2019), Person(\u2018Gerossier, A.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Gillet, Y.\u2019), Person(\u2018Hamann, D.R.\u2019), Person(\u2018He, L.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Janssen, J. Laflamme\u2019), Person(\u2018Roux, S. Le\u2019), Person(\u2018Levitt, A.\u2019), Person(\u2018Lherbier, A.\u2019), Person(\u2018Liu, F.\u2019), Person(\u2018Lukacevic, I.\u2019), Person(\u2018Martin, A.\u2019), Person(\u2018Martins, C.\u2019), Person(\u2018Oliveira, M.J.T.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Pouillon, Y.\u2019), Person(\u2018Rangel, T.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Romero, A.H.\u2019), Person(\u2018Rousseau, B.\u2019), Person(\u2018Rubel, O.\u2019), Person(\u2018Shukri, A.A.\u2019), Person(\u2018Stankovski, M.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Setten, M.J. Van\u2019), Person(\u2018troeye, B. Van\u2019), Person(\u2018Verstraete, M.J.\u2019), Person(\u2018Waroquier, D.\u2019), Person(\u2018Wiktor, J.\u2019), Person(\u2018Xue, B.\u2019), Person(\u2018Zhou, A.\u2019), Person(\u2018Zwanziger, J.W.\u2019)])]))\n\n\nGrimme2006\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Semiempirical {GGA}-Type Density Functional Constructed with a Long-Range Dispersion Correction\u2019), (\u2018Journal\u2019, \u2018J. Comput. Chem.\u2019), (\u2018Volume\u2019, \u201827\u2019), (\u2018Pages\u2019, \u20181787\u2019), (\u2018year\u2019, \u20182006\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Grimme, S.\u2019)])]))\n\n\nGrimme2010\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018A consistent and accurate ab initio parametrization of density functional dispersion correction (DFT-D) for the 94 elements H-Pu\u2019), (\u2018Journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018Volume\u2019, \u2018132\u2019), (\u2018Pages\u2019, \u2018154104\u2019), (\u2018year\u2019, \u20182010\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Grimme, S.\u2019), Person(\u2018Anthony, J.\u2019), Person(\u2018Ehrlich, S.\u2019), Person(\u2018Krieg, H.\u2019)])]))\n\n\nGrimme2010a\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Effect of the Damping Function in Dispersion Corrected Density Functional Theory\u2019), (\u2018Journal\u2019, \u2018J. Comput. Chem.\u2019), (\u2018Volume\u2019, \u201832\u2019), (\u2018Pages\u2019, \u20181456-1465\u2019), (\u2018year\u2019, \u20182011\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Grimme, S.\u2019), Person(\u2018Ehrlich, S.\u2019), Person(\u2018Goerigk, L.\u2019)])]))\n\n\nGrimvall1981\n\u00b6\n\n\nEntry(\u2018book\u2019, fields=[(\u2018YEAR\u2019, \u20181981\u2019), (\u2018TITLE\u2019, \u2018The electron phonon interaction in metals\u2019), (\u2018ADDRESS\u2019, \u2018Amsterdam\u2019), (\u2018PUBLISHER\u2019, \u2018North-Holland\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018AUTHOR\u2019, [Person(\u2018Grimvall, G.\u2019)])]))\n\n\nGull2011\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Continuous-time Monte Carlo methods for quantum impurity models\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018volume\u2019, \u201883\u2019), (\u2018pages\u2019, \u2018349\u2013404\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/RevModPhys.83.349-1.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018interaction CTQMC\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/RevModPhys.83.349\u2019), (\u2018timestamp\u2019, \u20182012.06.22\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.83.349\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gull, E.\u2019), Person(\u2018Millis, A.J.\u2019), Person(\u2018Liechtenstein, A. I.\u2019), Person(\u2018Rubtsov, A.N.\u2019), Person(\u2018Troyer, M.\u2019), Person(\u2018Werner, P.\u2019)])]))\n\n\nHamann1979\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Norm-Conserving Pseudopotentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20181979\u2019), (\u2018volume\u2019, \u201843\u2019), (\u2018pages\u2019, \u20181494\u20131497\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.43.1494\u2019), (\u2018numpages\u2019, \u20183\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hamann, D.R.\u2019), Person(\u2018Schl\\\u201cuter, M.\u2019), Person(\u2018Chiang, C.\u2019)])]))\n\n\nHamann1989\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Generalized norm-conserving pseudopotentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201840\u2019), (\u2018issue\u2019, \u20185\u2019), (\u2018pages\u2019, \u20182980\u20132987\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181989\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.40.2980\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hamann, D. R.\u2019)])]))\n\n\nHamann2005\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Metric tensor formulation of strain in density-functional perturbation theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201871\u2019), (\u2018pages\u2019, \u2018035117\u2019), (\u2018year\u2019, \u20182005\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hamann, D. R.\u2019), Person(\u2018Wu, X.\u2019), Person(\u2018Rabe, K. M.\u2019), Person(\u2018Vanderbilt, D.\u2019)])]))\n\n\nHamann2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Optimized norm-conserving Vanderbilt pseudopotentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201888\u2019), (\u2018issue\u2019, \u20188\u2019), (\u2018pages\u2019, \u2018085117\u2019), (\u2018numpages\u2019, \u201810\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.88.085117\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hamann, D. R.\u2019)])]))\n\n\nHarju2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Computational Physics on Graphics Processing Units\u2019), (\u2018journal\u2019, \u2018Lecture Notes in Computer Science\u2019), (\u2018volume\u2019, \u20187782\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u20183\u201326\u2019), (\u2018year\u2019, \u20182013\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Harju, A.\u2019), Person(\u2018Siro, T.\u2019), Person(\u2018Federici Canova, F.\u2019), Person(\u2018Hakala, S.\u2019), Person(\u2018Rantalaiho, T.\u2019)])]))\n\n\nHarl2010\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Assessing the quality of the random phase approximation for lattice constants and atomization energies of solids\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201881\u2019), (\u2018issue\u2019, \u201811\u2019), (\u2018pages\u2019, \u2018115126\u2019), (\u2018numpages\u2019, \u201818\u2019), (\u2018year\u2019, \u20182010\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.81.115126\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Harl, J.\u2019), Person(\u2018Schimka, L.\u2019), Person(\u2018Kresse, G.\u2019)])]))\n\n\nHartwigsen1998\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Relativistic separable dual-space {G}aussian pseudopotentials from {H} to {R}n\u2019), (\u2018volume\u2019, \u201858\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181998\u2019), (\u2018pages\u2019, \u20183641\u20133662\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hartwigsen, C.\u2019), Person(\u2018Goedecker, S.\u2019), Person(\u2018H\\\u201cutter, J.\u2019)])]))\n\n\nHaydock1980\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018The recursive solution of the {S}chr\\\u201c{o}dinger equation\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u201820\u2019), (\u2018number\u2019, \u20181\u2019), (\u2018pages\u2019, \u201811 - 16\u2019), (\u2018year\u2019, \u20181980\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180010-4655\u2019), (\u2018doi\u2019, \u201810.1016/0010-4655(80)90101-0\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/0010465580901010\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Haydock, R.\u2019)])]))\n\n\nHe2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Accuracy of generalized gradient approximation functionals for density-functional perturbation theory calculations\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Pages\u2019, \u2018064305\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.064305\u2019), (\u2018Volume\u2019, \u201889\u2019), (\u2018Year\u2019, \u20182014\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018He, L.\u2019), Person(\u2018Liu, F.\u2019), Person(\u2018Hautier, G.\u2019), Person(\u2018Oliveira, M. J. T.\u2019), Person(\u2018Marques, M. A. L.\u2019), Person(\u2018Vila, F. D.\u2019), Person(\u2018Rehr, J. J.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Zhou, A.\u2019)])]))\n\n\nHedin1965\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u201cNew Method for Calculating the One-Particle Green\u2019s Function with Application to the Electron-Gas Problem\u201d), (\u2018journal\u2019, \u2018Phys. Rev. A\u2019), (\u2018volume\u2019, \u2018139\u2019), (\u2018pages\u2019, \u2018796\u2019), (\u2018year\u2019, \u20181965\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hedin, L.\u2019)])]))\n\n\nHellwege1985\n\u00b6\n\n\nEntry(\u2018book\u2019, fields=[(\u2018Date-Added\u2019, \u20182014-02-21 11:07:18 +0000\u2019), (\u2018Date-Modified\u2019, \u20182014-03-04 10:21:33 +0000\u2019), (\u2018Publisher\u2019, \u2018Springer\u2019), (\u2018Address\u2019, \u2018Berlin Heidelberg\u2019), (\u2018Title\u2019, \u2018Electrical Resistivity, Thermoelectrical Power and Optical Properties\u2019), (\u2018Volume\u2019, \u201815b\u2019), (\u2018Year\u2019, \u20181985\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Hellwege, K.-H.\u2019), Person(\u2018Olsen, J.L. (Eds.)\u2019)])]))\n\n\nHenkelman2000\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Improved tangent estimate in the nudged elastic band method for finding minimum energy paths and saddle points\u2019), (\u2018journal\u2019, \u2018The Journal of chemical physics\u2019), (\u2018volume\u2019, \u2018113\u2019), (\u2018number\u2019, \u201822\u2019), (\u2018pages\u2019, \u20189978\u20139985\u2019), (\u2018year\u2019, \u20182000\u2019), (\u2018publisher\u2019, \u2018AIP Publishing\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Henkelman, G.\u2019), Person(\u201cJ{\\\u2018o}nsson, H.\u201d)])]))\n\n\nHermet2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Raman scattering intensities in BaTiO(3) and PbTiO(3) prototypical ferroelectrics from density functional theory.\u2019), (\u2018journal\u2019, \u2018J. Phys. : Condens. Matter\u2019), (\u2018volume\u2019, \u201821\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018215901\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018doi\u2019, \u201810.1088/0953-8984/21/21/215901\u2019), (\u2018publisher\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hermet, P.\u2019), Person(\u2018Veithen, M.\u2019), Person(\u2018Ghosez, P.\u2019)])]))\n\n\nHohenberg1964\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Inhomogeneous Electron Gas\u2019), (\u2018journal\u2019, \u2018Phys. Rev.\u2019), (\u2018volume\u2019, \u2018136\u2019), (\u2018number\u2019, \u20183B\u2019), (\u2018pages\u2019, \u2018B864\u2013B871\u2019), (\u2018year\u2019, \u20181964\u2019), (\u2018doi\u2019, \u201810.1103/PhysRev.136.B864\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hohenberg, P.\u2019), Person(\u2018Kohn, W.\u2019)])]))\n\n\nHolzwarth2001\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018A Projector Augmented Wave ({PAW}) code for electronic structure calculations, Part {I}: {ATOMPAW} for generating atom-centered functions\u2019), (\u2018Journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018Volume\u2019, \u2018135\u2019), (\u2018Pages\u2019, \u2018329\u2019), (\u2018year\u2019, \u20182001\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Holzwarth, N.A.W.\u2019), Person(\u2018Tackett, A.R.\u2019), Person(\u2018Matthews, G.E.\u2019)])]))\n\n\nHughes1996\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Calculation of second-order optical response in semiconductors\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20181996\u2019), (\u2018Pages\u2019, \u201810751\u201310763\u2019), (\u2018Volume\u2019, \u201853\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.53.10751\u2019), (\u2018Issue\u2019, \u201816\u2019), (\u2018Owner\u2019, \u2018yannick\u2019), (\u2018Publisher\u2019, \u2018American Physical Society\u2019), (\u2018Timestamp\u2019, \u20182015.11.12\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Hughes, J. L. P.\u2019), Person(\u2018Sipe, J. E.\u2019)])]))\n\n\nJanssen2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Efficient dielectric matrix calculations using the {L}anczos algorithm for fast many-body {G}\n_0\n{W}\n_0\n implementations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018volume\u2019, \u201891\u2019), (\u2018number\u2019, \u201812\u2019), (\u2018pages\u2019, \u2018125120\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.91.125120\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Laflamme Janssen, J.\u2019), Person(\u2018Rousseau, B.\u2019), Person(\u201cC{\\^o}t{\\\u2018e}, M.\u201d)])]))\n\n\nJollet2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201880\u2019), (\u2018pages\u2019, \u2018235109\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018title\u2019, \u2018Hybrid functional for correlated electrons in the projector augmented-wave formalism: Study of multiple minima for actinide oxides\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Jollet, F.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Amadon, B.\u2019), Person(\u2018Crocombette, J.P.\u2019), Person(\u2018Torumba, D.\u2019)])]))\n\n\nJollet2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018185\u2019), (\u2018pages\u2019, \u20181246-1254\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018title\u2019, \u2018Generation of Projector Augmented-Wave atomic data: a 71 element validated table in the {XML} format\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Holzwarth, N.\u2019)])]))\n\n\nKawasuso2005\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electron-positron momentum distributions associated with isolated silicon vacancies in 3 {C}-{S}i {C}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201872\u2019), (\u2018number\u2019, \u20184\u2019), (\u2018pages\u2019, \u2018045204\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Kawasuso, A.\u2019), Person(\u2018Yoshikawa, M.\u2019), Person(\u2018Itoh, H.\u2019), Person(\u2018Chiba, T.\u2019), Person(\u2018Higuchi, T.\u2019), Person(\u2018Betsuyaku, K.\u2019), Person(\u2018Redmann, F.\u2019), Person(\u2018Krause-Rehberg, R.\u2019)])]))\n\n\nKingsmith1993\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theory of polarization of crystalline solids\u2019), (\u2018journal\u2019, \u2018Phys. rev. B\u2019), (\u2018volume\u2019, \u201847\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018pages\u2019, \u20181651\u20131654\u2019), (\u2018year\u2019, \u20181993\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018King-Smith, R. D.\u2019), Person(\u2018Vanderbilt, D.\u2019)])]))\n\n\nKohn1965\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Self-Consistent Equations Including Exchange and Correlation Effects\u2019), (\u2018journal\u2019, \u2018Phys. Rev.\u2019), (\u2018volume\u2019, \u2018140\u2019), (\u2018number\u2019, \u20184A\u2019), (\u2018pages\u2019, \u2018A1133\u2013A1138\u2019), (\u2018year\u2019, \u20181965\u2019), (\u2018doi\u2019, \u201810.1103/PhysRev.140.A1133\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Kohn, W.\u2019), Person(\u2018Sham, L. J.\u2019)])]))\n\n\nKolos1960\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Accurate Electronic Wave Functions for the H\n_2\n Molecule\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201832\u2019), (\u2018pages\u2019, \u2018219\u2019), (\u2018year\u2019, \u20181960\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Kolos, W.\u2019), Person(\u2018Roothaan, C.C.J.\u2019)])]))\n\n\nKotliar2006\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic structure calculations with dynamical mean-field theory\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018volume\u2019, \u201878\u2019), (\u2018pages\u2019, \u2018865\u2013951\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Review/RMP2006.pdf:PDF\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/RevModPhys.78.865\u2019), (\u2018timestamp\u2019, \u20182012.07.13\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.78.865\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Kotliar, G.\u2019), Person(\u2018Savrasov, S. Y.\u2019), Person(\u2018Haule, K.\u2019), Person(\u2018Oudovenko, V. S.\u2019), Person(\u2018Parcollet, O.\u2019), Person(\u2018Marianetti, C. A.\u2019)])]))\n\n\nLaflamme2016\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Title\u2019, \u2018Precise Effective Masses from Density Functional Perturbation Theory\u2019), (\u2018year\u2019, \u20182016\u2019), (\u2018pages\u2019, \u2018205147\u2019), (\u2018volume\u2019, \u201893\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Laflamme Janssen, J.\u2019), Person(\u2018Gillet, Y.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Martin, A.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nLebegue2010\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Title\u2019, \u2018Cohesive Properties and Asymptotics of the Dispersion Interaction in Graphite by the Random Phase Approximation\u2019), (\u2018year\u2019, \u20182010\u2019), (\u2018pages\u2019, \u2018196401\u2019), (\u2018volume\u2019, \u2018105\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Leb\\`egue, S.\u2019), Person(\u2018Harl, J.\u2019), Person(\u2018Gould, T.\u2019), Person(\u201c\\\u2018Angy\\\u2018an, J. G.\u201d), Person(\u2018Kresse, G.\u2019), Person(\u2018Dobson, J. F.\u2019)])]))\n\n\nLee1995\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Ab-initio calculation of the thermodynamic properties and atomic temperature factors of SiO\n_2\n\n\n\\\\alpha\n-quartz and stishovite\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201851\u2019), (\u2018pages\u2019, \u20188610\u2019), (\u2018year\u2019, \u20181995\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Lee, C.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nLejaeghere2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Error estimates for solid-state density-functional theory predictions: an overview by means of the ground-state elemental crystals\u2019), (\u2018Journal\u2019, \u2018Crit. Rev. Solid State Mater. Sci.\u2019), (\u2018Volume\u2019, \u201839\u2019), (\u2018Pages\u2019, \u20181\u2019), (\u2018year\u2019, \u20182014\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Lejaeghere, K.\u2019), Person(\u2018{V}an {S}peybroeck, V.\u2019), Person(\u2018{V}an {O}ost, G.\u2019), Person(\u2018Cottenier, S.\u2019)])]))\n\n\nLevitt2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Parallel eigensolvers in plane-wave Density Functional Theory\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018187\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u201898\u2013105\u2019), (\u2018year\u2019, \u20182015\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Levitt, A.\u2019), Person(\u2018Torrent, M.\u2019)])]))\n\n\nLiechtenstein1995\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Density-functional theory and strong interactions: Orbital ordering in Mott-Hubbard insulators\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181995\u2019), (\u2018volume\u2019, \u201852\u2019), (\u2018pages\u2019, \u2018R5467\u2013R5470\u2019), (\u2018number\u2019, \u20188\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/PhysRevB.52.R5467.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018interaction, LDA+U GGA+U DFT+U\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.52.R5467\u2019), (\u2018timestamp\u2019, \u20182012.06.14\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.52.R5467\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Liechtenstein, A. I.\u2019), Person(\u2018Anisimov, V. I.\u2019), Person(\u2018Zaanen, J.\u2019)])]))\n\n\nLindhard1954\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018On the properties of a gas of charged particles\u2019), (\u2018journal\u2019, \u2018Mat. Fys. Medd. Dan. Vid. Selsk.\u2019), (\u2018year\u2019, \u20181954\u2019), (\u2018volume\u2019, \u201828\u2019), (\u2018pages\u2019, \u20188\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Lindhard, J.\u2019)])]))\n\n\nLuttinger1955\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018{Motion of Electrons and Holes in Perturbed Periodic Fields}\u2019), (\u2018journal\u2019, \u2018Phys. Rev.\u2019), (\u2018year\u2019, \u20181955\u2019), (\u2018volume\u2019, \u201897\u2019), (\u2018number\u2019, \u20184\u2019), (\u2018pages\u2019, \u2018869\u2013883\u2019), (\u2018doi\u2019, \u201810.1103/PhysRev.97.869\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Luttinger, J.M.\u2019), Person(\u2018Kohn, W.\u2019)])]))\n\n\nMa2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Constrained density functional for noncollinear magnetism\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201891\u2019), (\u2018issue\u2019, \u20185\u2019), (\u2018pages\u2019, \u2018054420\u2019), (\u2018numpages\u2019, \u201811\u2019), (\u2018year\u2019, \u20182015\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Ma, Pui-Wai\u2019), Person(\u2018Dudarev, S. L.\u2019)])]))\n\n\nMaintz2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Speeding up plane-wave electronic-structure calculations using graphics-processing units\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018182\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018pages\u2019, \u20181421\u20131427\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Maintz, S.\u2019), Person(\u2018Eck, B.\u2019), Person(\u2018Dronskowski, R.\u2019)])]))\n\n\nMarek2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018The {ELPA} library: scalable parallel eigenvalue solutions for electronic structure theory and computational science\u2019), (\u2018journal\u2019, \u2018J. Phys.: Cond. Matt.\u2019), (\u2018volume\u2019, \u201826\u2019), (\u2018number\u2019, \u201821\u2019), (\u2018pages\u2019, \u20181\u201315\u2019), (\u2018year\u2019, \u20182014\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Marek, A.\u2019), Person(\u2018Blum, V.\u2019), Person(\u2018Johanni, R.\u2019), Person(\u2018Havu, V.\u2019), Person(\u2018Lang, B.\u2019), Person(\u2018Auckenthaler, T.\u2019), Person(\u2018Heinecke, A.\u2019), Person(\u2018Bungartz, H.-J.\u2019), Person(\u2018Lederer, H.\u2019)])]))\n\n\nMarques2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018doi\u2019, \u201810.1016/j.cpc.2012.05.007\u2019), (\u2018issn\u2019, \u201800104655\u2019), (\u2018journal\u2019, \u2018Comput. Phys. Commun.\u2019), (\u2018pages\u2019, \u20182272\u20132281\u2019), (\u2018title\u2019, \u2018{Libxc: A library of exchange and correlation functionals for density functional theory}\u2019), (\u2018volume\u2019, \u2018183\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Marques, M. A. L.\u2019), Person(\u2018Oliveira, M. J. T.\u2019), Person(\u2018Burnus, T.\u2019)])]))\n\n\nMarx1996\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Ab initio path integral molecular dynamics: Basic ideas\u2019), (\u2018Journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018Volume\u2019, \u2018104\u2019), (\u2018Pages\u2019, \u20184077\u2019), (\u2018year\u2019, \u20181996\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Marx, D.\u2019), Person(\u2018Parrinello, M.\u2019)])]))\n\n\nMecholsky2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018{Theory of band warping and its effects on thermoelectronic transport properties}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018number\u2019, \u201815\u2019), (\u2018pages\u2019, \u2018155131\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.155131\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Mecholsky, N.A.\u2019), Person(\u2018Resca, L.\u2019), Person(\u2018Pegg, I.L.\u2019), Person(\u2018Fornari, M.\u2019)])]))\n\n\nMedeiros2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Effects of extrinsic and intrinsic perturbations on the electronic structure of graphene: Retaining an effective primitive cell band structure by band unfolding\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182014\u2019), (\u2018Pages\u2019, \u2018041407\u2019), (\u2018Volume\u2019, \u201889\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Medeiros, Paulo V. C.\u2019), Person(\u2018Stafstr\\\u201com, Sven\u2019), Person(\u2018Bj\\\u201cork, Jonas\u2019)])]))\n\n\nMethfessel1989\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018High-precision sampling for Brillouin-Zone integration in metals\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201840\u2019), (\u2018pages\u2019, \u20183616\u2019), (\u2018year\u2019, \u20181989\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Methfessel, M.\u2019), Person(\u2018Paxton, T.\u2019)])]))\n\n\nMills1994\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Quantum and thermal effects in H\n_2\n dissociative adsorption: Evaluation of free energy barriers in multidimensional quantum systems\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u201872\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018pages\u2019, \u20181124\u2019), (\u2018year\u2019, \u20181994\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Mills, G.\u2019), Person(\u201cJ{\\\u2018o}nsson, H.\u201d)])]))\n\n\nMomma2011\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018{VESTA}3 for three-dimensional visualization of crystal, volumetric and morphology data\u2019), (\u2018Journal\u2019, \u2018J. Appl. Crystallogr.\u2019), (\u2018Year\u2019, \u20182011\u2019), (\u2018Number\u2019, \u20186\u2019), (\u2018Pages\u2019, \u20181272\u20131276\u2019), (\u2018Volume\u2019, \u201844\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Momma, K.\u2019), Person(\u2018Izumi, F.\u2019)])]))\n\n\nMoscaconte2007\n\u00b6\n\n\nEntry(\u2018phdthesis\u2019, fields=[(\u2018title\u2019, \u2018Quantum mechanical modeling of nano magnetism\u2019), (\u2018school\u2019, \u2018SISSA\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018address\u2019, \u2018Trieste Italy\u2019), (\u2018optURI\u2019, \u2018http://hdl.handle.net/20.500.11767/3935\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Mosca Conte, A.\u2019)])]))\n\n\nNieminen1985\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Two-component density-functional theory: Application to positron states\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201832\u2019), (\u2018issue\u2019, \u20182\u2019), (\u2018pages\u2019, \u20181377\u2019), (\u2018year\u2019, \u20181985\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.32.1377\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Nieminen, R. M.\u2019), Person(\u201cBoro\\\u2018nski, E.\u201d), Person(\u2018Lantto, L. J.\u2019)])]))\n\n\nNunes2001\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Berry-phase treatment of the homogeneous electric field perturbation in insulators\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201863\u2019), (\u2018number\u2019, \u201815\u2019), (\u2018pages\u2019, \u2018155107\u2019), (\u2018year\u2019, \u20182001\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Nunes, R. W.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nOng2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Python Materials Genomics (pymatgen): A robust, open-source python library for materials analysis\u2019), (\u2018journal\u2019, \u2018Comp. Mat. Sci.\u2019), (\u2018volume\u2019, \u201868\u2019), (\u2018number\u2019, \u20180\u2019), (\u2018pages\u2019, \u2018314 - 319\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180927-0256\u2019), (\u2018doi\u2019, \u201810.1016/j.commatsci.2012.10.028\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S0927025612006295\u2019), (\u2018keywords\u2019, \u2018High-throughput\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Ong, S.P.\u2019), Person(\u2018Richards, W.D.\u2019), Person(\u2018Jain, A.\u2019), Person(\u2018Hautier, G.\u2019), Person(\u2018Kocher, M.\u2019), Person(\u2018Cholia, S.\u2019), Person(\u2018Gunter, D.\u2019), Person(\u2018Chevrier, V.L.\u2019), Person(\u2018Persson, K.A.\u2019), Person(\u2018Ceder, G.\u2019)])]))\n\n\nOnida2002\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u201cElectronic excitations: density-functional versus many-body Green\u2019s-function approaches\u201d), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018year\u2019, \u20182002\u2019), (\u2018volume\u2019, \u201874\u2019), (\u2018pages\u2019, \u2018601\u2013659\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.74.601\u2019), (\u2018numpages\u2019, \u201858\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Onida, G.\u2019), Person(\u2018Reining, L.\u2019), Person(\u2018Rubio, A.\u2019)])]))\n\n\nPayne1992\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Iterative minimization techniques for \\textit{ab initio} total-energy calculations: molecular dynamics and conjugate gradients\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201864\u2019), (\u2018issue\u2019, \u20184\u2019), (\u2018pages\u2019, \u20181045\u20131097\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181992\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.64.1045\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Payne, M. C.\u2019), Person(\u2018Teter, M. P.\u2019), Person(\u2018Allan, D. C.\u2019), Person(\u2018Arias, T. A.\u2019), Person(\u2018Joannopoulos, J. D.\u2019)])]))\n\n\nPerdew1981\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Self-interaction correction to density-functional approximations for many-electron systems\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201823\u2019), (\u2018pages\u2019, \u20185048\u2019), (\u2018year\u2019, \u20181981\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Perdew, J.P.\u2019), Person(\u2018Zunger, A.\u2019)])]))\n\n\nPerrot1979\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Gradient correction to the statistical electronic free energy at non-zero temperatures: Application to equation-of-state calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. A\u2019), (\u2018volume\u2019, \u201820\u2019), (\u2018pages\u2019, \u2018586-594\u2019), (\u2018year\u2019, \u20181979\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Perrot, F.\u2019)])]))\n\n\nPickett1988\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Smooth Fourier interpolation of periodic functions\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201838\u2019), (\u2018pages\u2019, \u20182721\u2019), (\u2018year\u2019, \u20181988\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Warren E. Pickett, Henry Krakauer,\u2019), Person(\u2018Allen, Philip B.\u2019)])]))\n\n\nPonce2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Verification of first-principles codes: Comparison of total energies, phonon frequencies, electron\u2013phonon coupling and zero-point motion correction to the gap between {ABINIT} and {QE}/{Y}ambo\u2019), (\u2018journal\u2019, \u2018Comp. Mat. Sci.\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201883\u2019), (\u2018pages\u2019, \u2018341 - 348\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Antonius, G.\u2019), Person(\u2018Boulanger, P.\u2019), Person(\u2018Cannuccia, E.\u2019), Person(\u2018Marini, A.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d), Person(\u2018Gonze, X.\u2019)])]))\n\n\nPonce2014a\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Temperature dependence of electronic eigenenergies in the adiabatic harmonic approximation\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201890\u2019), (\u2018pages\u2019, \u2018214304\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Antonius, G.\u2019), Person(\u2018Gillet, Y.\u2019), Person(\u2018Boulanger, P.\u2019), Person(\u2018Laflamme Janssen, J.\u2019), Person(\u2018Marini, A.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d), Person(\u2018Gonze, X.\u2019)])]))\n\n\nPonce2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Temperature dependence of the electronic structure of semiconductors and insulators\u2019), (\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018volume\u2019, \u2018143\u2019), (\u2018pages\u2019, \u2018102813\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Gillet, Y.\u2019), Person(\u2018Laflamme Janssen, J.\u2019), Person(\u2018Marini, A.\u2019), Person(\u2018Verstraete, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nPopescu2010\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Effective Band Structure of Random Alloys\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Year\u2019, \u20182010\u2019), (\u2018Pages\u2019, \u2018236403\u2019), (\u2018Volume\u2019, \u2018104\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Popescu, V.\u2019), Person(\u2018Zunger, A.\u2019)])]))\n\n\nPopescu2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Extracting E versus k effective band structure from supercell calculations on alloys and impurities\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182012\u2019), (\u2018Pages\u2019, \u2018085201\u2019), (\u2018Volume\u2019, \u201885\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Popescu, V.\u2019), Person(\u2018Zunger, A.\u2019)])]))\n\n\nPouillon2011\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Organizing software growth and distributed development: the case of {ABINIT}\u2019), (\u2018Journal\u2019, \u2018Comput. Sci. Eng.\u2019), (\u2018Volume\u2019, \u201813\u2019), (\u2018Pages\u2019, \u201862\u2019), (\u2018year\u2019, \u20182011\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Pouillon, Y.\u2019), Person(\u2018Beuken, J. -M.\u2019), Person(\u2018Deutsch, T.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nPuska1994\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theory of positrons in solids and on solid surfaces\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201866\u2019), (\u2018issue\u2019, \u20183\u2019), (\u2018pages\u2019, \u2018841\u2019), (\u2018year\u2019, \u20181994\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.66.841\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Puska, M. J.\u2019), Person(\u2018Nieminen, R. M.\u2019)])]))\n\n\nPuska1995\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electron-positron {C}ar-{P}arrinello methods: {S}elf-consistent treatment of charge densities and ionic relaxations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201852\u2019), (\u2018issue\u2019, \u201815\u2019), (\u2018pages\u2019, \u201810947\u2019), (\u2018year\u2019, \u20181995\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.52.10947\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Puska, M. J.\u2019), Person(\u2018Seitsonen, A. P.\u2019), Person(\u2018Nieminen, R. M.\u2019)])]))\n\n\nRangel2016\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018A wavelet-based Projector Augmented-Wave ({PAW}) method: {R}eaching frozen-core all-electron precision with a systematic, adaptive and localized wavelet basis set\u2019), (\u2018volume\u2019, \u2018208\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018journal\u2019, \u2018Computer Physics Communication\u2019), (\u2018year\u2019, \u20182016\u2019), (\u2018pages\u2019, \u20181-8\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rangel, T.\u2019), Person(\u2018Caliste, D.\u2019), Person(\u2018Genovese, L.\u2019), Person(\u2018Torrent, M.\u2019)])]))\n\n\nRappe1990\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Optimized pseudopotentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201841\u2019), (\u2018issue\u2019, \u20182\u2019), (\u2018pages\u2019, \u20181227\u20131230\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181990\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.41.1227\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rappe, A.M.\u2019), Person(\u2018Rabe, K.M.\u2019), Person(\u2018Kaxiras, E.S.\u2019), Person(\u2018Joannopoulos, J.D.\u2019)])]))\n\n\nRauch2011\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Identifying vacancy complexes in compound semiconductors with positron annihilation spectroscopy: A case study of {I}n{N}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201884\u2019), (\u2018number\u2019, \u201812\u2019), (\u2018pages\u2019, \u2018125201\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rauch, C.\u2019), Person(\u2018Makkonen, I.\u2019), Person(\u2018Tuomisto, F.\u2019)])]))\n\n\nResta1994\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Macroscopic polarization in crystalline dielectrics: the geometric phase approach\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201866\u2019), (\u2018pages\u2019, \u2018899\u2013915\u2019), (\u2018year\u2019, \u20181994\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Resta, R.\u2019)])]))\n\n\nRestrepo2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-principles calculations of electron mobilities in silicon: Phonon and Coulomb scattering\u2019), (\u2018journal\u2019, \u2018App. Phys. Lett.\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018volume\u2019, \u201894\u2019), (\u2018number\u2019, \u201821\u2019), (\u2018eid\u2019, \u2018212103\u2019), (\u2018pages\u2019, \u2018\u2019), (\u2018url\u2019, \u2018http://scitation.aip.org/content/aip/journal/apl/94/21/10.1063/1.3147189\u2019), (\u2018doi\u2019, \u201810.1063/1.3147189\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Restrepo, O. D.\u2019), Person(\u2018Varga, K.\u2019), Person(\u2018Pantelides, S. T.\u2019)])]))\n\n\nRieger1999\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018The {GW} space-time method for the self-energy of large systems\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018year\u2019, \u20181999\u2019), (\u2018volume\u2019, \u2018117\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018pages\u2019, \u2018211\u2013228\u2019), (\u2018doi\u2019, \u201810.1016/S0010-4655(98)00174-X\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rieger, M.\u2019), Person(\u2018Steinbeck, L.\u2019), Person(\u2018White, I. D.\u2019), Person(\u2018Rojas, H. N.\u2019), Person(\u2018Godby, R. W.\u2019)])]))\n\n\nRohlfing2000\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Electron-hole excitations and optical spectra from first principles\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182000\u2019), (\u2018Pages\u2019, \u20184927\u20134944\u2019), (\u2018Volume\u2019, \u201862\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.62.4927\u2019), (\u2018File\u2019, \u2018Rohlfing2000.pdf:Rohlfing2000.pdf:PDF;Rohlfing2000.pdf:Rohlfing2000.pdf:PDF\u2019), (\u2018Issue\u2019, \u20188\u2019), (\u2018Publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Rohlfing, M.\u2019), Person(\u2018Louie, S.G.\u2019)])]))\n\n\nRomanperez2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Efficient Implementation of a {V}an der {W}aals Density Functional: Application to Double-Wall Carbon Nanotubes\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018103\u2019), (\u2018pages\u2019, \u2018096102\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.103.096102\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cRom\\\u2018an-P\\\u2018erez, G.\u201d), Person(\u2018Soler, J.M.\u2019)])]))\n\n\nRostgaard2006\n\u00b6\n\n\nEntry(\u2018mastersthesis\u2019, fields=[(\u2018Title\u2019, \u2018Exact exchange in density functional calculations\u2019), (\u2018School\u2019, \u2018Technical University of Denmark\u2019), (\u2018Address\u2019, \u2018Lyngby\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018url\u2019, \u2018https://wiki.fysik.dtu.dk/gpaw/_downloads/rostgaard_master.pdf\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Rostgaard, C.\u2019)])]))\n\n\nRubel2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Unfolding the band structure of disordered solids: from bound states to high-mobility Kane fermions\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182014\u2019), (\u2018Pages\u2019, \u2018115202\u2019), (\u2018Volume\u2019, \u201890\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Rubel, O.\u2019), Person(\u2018Bokhanchuk, A.\u2019), Person(\u2018Ahmed, S. J.\u2019), Person(\u2018Assmann, E.\u2019)])]))\n\n\nRutishauser1970\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Simultaneous iteration method for symmetric matrices\u2019), (\u2018journal\u2019, \u2018Numerische Mathematik\u2019), (\u2018volume\u2019, \u201816\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018pages\u2019, \u2018205\u2013223\u2019), (\u2018year\u2019, \u20181970\u2019), (\u2018publisher\u2019, \u2018Springer\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rutishauser, H.\u2019)])]))\n\n\nSakuma2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-principles calculations of dynamical screened interactions for the transition metal oxides {MO} ({M}={M}n, {F}e, {C}o, {N}i)\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018volume\u2019, \u201887\u2019), (\u2018pages\u2019, \u2018165118\u2019), (\u2018number\u2019, \u201816\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/PhysRevB.87.165118.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018cRPA\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.87.165118\u2019), (\u2018timestamp\u2019, \u20182013.06.04\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.87.165118\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Sakuma, R.\u2019), Person(\u2018Aryasetiawan, F.\u2019)])]))\n\n\nSavin1992\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electron Localization in Solid-State Structures of the Elements: the Diamond Structure\u2019), (\u2018journal\u2019, \u2018Angewandte Chemie International Edition in English\u2019), (\u2018volume\u2019, \u201831\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018doi\u2019, \u201810.1002/anie.199201871\u2019), (\u2018pages\u2019, \u2018187\u2013188\u2019), (\u2018year\u2019, \u20181992\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Savin, A.\u2019), Person(\u2018Jepsen, O.\u2019), Person(\u2018Flad, J.\u2019), Person(\u2018Andersen, O. K.\u2019), Person(\u2018Preuss, H.\u2019), Person(\u2018von Schnering, H. G.\u2019)])]))\n\n\nSavrasov1996\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018PAGES\u2019, \u201816487\u2019), (\u2018YEAR\u2019, \u20181996\u2019), (\u2018TITLE\u2019, \u2018Electron-phonon interactions and related physical properties of metals from linear-response theory\u2019), (\u2018VOLUME\u2019, \u201854\u2019), (\u2018JOURNAL\u2019, \u2018Phys. Rev. B\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018AUTHOR\u2019, [Person(\u2018Savrasov, S.Y.\u2019), Person(\u2018Savrasov, D.Y.\u2019)])]))\n\n\nSharma2003\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Linear and second-order optical response of {III}-{V} monolayer superlattices\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182003\u2019), (\u2018Pages\u2019, \u2018165332\u2019), (\u2018Volume\u2019, \u201867\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.67.165332\u2019), (\u2018Issue\u2019, \u201816\u2019), (\u2018Url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.67.165332\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Sharma, S.\u2019), Person(\u2018Dewhurst, J. K.\u2019), Person(\u2018Ambrosch-Draxl, C.\u2019)])]))\n\n\nSharma2004\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018{S}econd-{H}armonic Optical Response from First Principles\u2019), (\u2018Journal\u2019, \u2018Phys. Scripta\u2019), (\u2018Year\u2019, \u20182004\u2019), (\u2018Pages\u2019, \u2018128\u2019), (\u2018Volume\u2019, \u20182004\u2019), (\u2018Url\u2019, \u2018http://iopscience.iop.org/article/10.1238/Physica.Topical.109a00128\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Sharma, S.\u2019), Person(\u2018{A}mbrosch-{D}raxl, C.\u2019)])]))\n\n\nShih2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Screened Coulomb interaction of localized electrons in solids from first principles\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182012\u2019), (\u2018volume\u2019, \u201885\u2019), (\u2018pages\u2019, \u2018045132\u2019), (\u2018number\u2019, \u20184\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/PhysRevB.85.045132.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018cRPA pseudopotentials\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.85.045132\u2019), (\u2018timestamp\u2019, \u20182012.06.19\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.85.045132\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Shih, B.-C.\u2019), Person(\u2018Zhang, Y.\u2019), Person(\u2018Zhang, W.\u2019), Person(\u2018Zhang, P.\u2019)])]))\n\n\nSilvestrelli2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018053002\u2019), (\u2018title\u2019, \u2018van der {W}aals Interactions in {DFT} Made Easy by {W}annier Functions\u2019), (\u2018volume\u2019, \u2018100\u2019), (\u2018year\u2019, \u20182008\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Silvestrelli, P. L.\u2019)])]))\n\n\nSilvestrelli2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018J. Phys. Chem. A\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u20185224\u2019), (\u2018title\u2019, \u2018van der {W}aals Interactions in Density Functional Theory Using {W}annier Functions\u2019), (\u2018volume\u2019, \u2018113\u2019), (\u2018year\u2019, \u20182009\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Silvestrelli, P. L.\u2019)])]))\n\n\nSilvestrelli2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018054106\u2019), (\u2018title\u2019, \u2018van der {W}aals interactions in density functional theory by combining the quantum harmonic oscillator-model with localized {W}annier functions\u2019), (\u2018volume\u2019, \u2018139\u2019), (\u2018year\u2019, \u20182013\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Silvestrelli, P. L.\u2019)])]))\n\n\nSipe1993\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Nonlinear optical response of semiconductors in the independent-particle approximation\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20181993\u2019), (\u2018Pages\u2019, \u201811705\u201311722\u2019), (\u2018Volume\u2019, \u201848\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.48.11705\u2019), (\u2018Issue\u2019, \u201816\u2019), (\u2018Url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.48.11705\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Sipe, J. E.\u2019), Person(\u2018Ghahramani, E.\u2019)])]))\n\n\nSnyder2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Nature Materials\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u2018105\u2013114\u2019), (\u2018title\u2019, \u2018Complex thermoelectric materials\u2019), (\u2018volume\u2019, \u20187\u2019), (\u2018year\u2019, \u20182008\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Snyder, G. J.\u2019), Person(\u2018Toberer, E. S.\u2019)])]))\n\n\nSouza2002\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-Principles Approach to Insulators in Finite Electric Fields\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018pages\u2019, \u2018117602\u2019), (\u2018year\u2019, \u20182002\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Souza, I.\u2019), Person(\u201c\\\u2018I\\ niguez, J.\u201d), Person(\u2018Vanderbilt, D.\u2019)])]))\n\n\nSterne1991\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-principles calculation of positron lifetimes in solids\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201843\u2019), (\u2018number\u2019, \u201817\u2019), (\u2018pages\u2019, \u201813892\u2019), (\u2018year\u2019, \u20181991\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Sterne, P.A.\u2019), Person(\u2018Kaiser, J.H.\u2019)])]))\n\n\nTorrent2008\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Implementation of the projector augmented-wave method in the {ABINIT} code: Application to the study of iron under pressure\u2019), (\u2018journal\u2019, \u2018Computational Materials Science\u2019), (\u2018volume\u2019, \u201842\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u2018337 - 351\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180927-0256\u2019), (\u2018doi\u2019, \u201810.1016/j.commatsci.2007.07.020\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S0927025607002108\u2019), (\u2018keywords\u2019, \u2018Iron under pressure\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Torrent, Marc\u2019), Person(\u2018Jollet, Fran\\c{c}ois\u2019), Person(\u2018Bottin, Fran\\c{c}ois\u2019), Person(\u201cZ\\\u2018erah, Gilles\u201d), Person(\u2018Gonze, Xavier\u2019)])]))\n\n\nTran2009\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Accurate Band Gaps of Semiconductors and Insulators with a Semilocal Exchange-Correlation Potential\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018102\u2019), (\u2018issue\u2019, \u201822\u2019), (\u2018pages\u2019, \u2018226401\u2019), (\u2018numpages\u2019, \u20184\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.102.226401\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevLett.102.226401\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Tran, F.\u2019), Person(\u2018Blaha, P.\u2019)])]))\n\n\nTremblay2017\n\u00b6\n\n\nEntry(\u2018misc\u2019, fields=[(\u2018title\u2019, \u2018Probl\\\neme \\\\\na N-corps\u2019), (\u2018note\u2019, \u2018Notes de cours\u2019), (\u2018howpublished\u2019, \u2018available \nhere\n\u2018), (\u2018url\u2019, \u2018https://www.physique.usherbrooke.ca/pages/en/node/3436\u2019), (\u2018year\u2019, \u20182017\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cTremblay, Andr\\\u2018e-Marie\u201d)])]))\n\n\nTroullier1991\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Pages\u2019, \u20181993\u2019), (\u2018Title\u2019, \u2018Efficient pseudopotentials for plane-wave calculation\u2019), (\u2018Volume\u2019, \u201843\u2019), (\u2018Year\u2019, \u20181991\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Troullier, N.\u2019), Person(\u2018Martins, J.L.\u2019)])]))\n\n\nTuckerman1996\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Efficient and general algorithms for path integral {C}ar\u2013{P}arrinello molecular dynamics\u2019), (\u2018Journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018Volume\u2019, \u2018104\u2019), (\u2018Pages\u2019, \u20185579\u2019), (\u2018year\u2019, \u20181996\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Tuckerman, M. E.\u2019), Person(\u2018Marx, D.\u2019), Person(\u2018Klein, M. L.\u2019), Person(\u2018Parrinello, M.\u2019)])]))\n\n\nTuomisto2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Defect identification in semiconductors with positron annihilation: Experiment and theory\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201885\u2019), (\u2018issue\u2019, \u20184\u2019), (\u2018pages\u2019, \u20181583\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.85.1583\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Tuomisto, F.\u2019), Person(\u2018Makkonen, I.\u2019)])]))\n\n\nUehara2000\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Calculations of transport properties with the linearized augmented plane-wave method\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201861\u2019), (\u2018pages\u2019, \u20181639\u2019), (\u2018year\u2019, \u20182000\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Uehara, Kentaro\u2019), Person(\u2018Tse, John S.\u2019)])]))\n\n\nVanderbilt1998\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic polarization in the ultrasoft pseudopotential formalism\u2019), (\u2018journal\u2019, \u2018arXiv/cond-mat\u2019), (\u2018eprint\u2019, \u20189801177\u2019), (\u2018url\u2019, \u2018https://arxiv.org/abs/cond-mat/9801177\u2019), (\u2018year\u2019, \u20181998\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Vanderbilt, D.\u2019), Person(\u2018{K}ing-{S}mith, R. D.\u2019)])]))\n\n\nVantroeye2016\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Interatomic force constants including the DFT-D dispersion contribution\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201893\u2019), (\u2018pages\u2019, \u2018144304\u2019), (\u2018year\u2019, \u20182016\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Troeye, B. Van\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nVeithen2005\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Nonlinear optical susceptibilities, Raman efficiencies, and electrooptic tensors from first\u2013principles density functional theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201871\u2019), (\u2018pages\u2019, \u2018125107\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.71.125107\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Veithen, M.\u2019), Person(\u2018Gonze, X.\u2019), Person(\u2018Ghosez, Ph.\u2019)])]))\n\n\nVeithen2005a\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Temperature dependence of the electro-optic tensor and refractive indices of Ba Ti O 3 from first principles\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201871\u2019), (\u2018pages\u2019, \u2018132101\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.71.132101\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Veithen, M.\u2019), Person(\u2018Ghosez, Ph.\u2019)])]))\n\n\nWang1998\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Majority Representation of Alloy Electronic States\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Year\u2019, \u20181998\u2019), (\u2018Pages\u2019, \u20184725\u2019), (\u2018Volume\u2019, \u201880\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Wang, L.-W.\u2019), Person(\u2018Bellaiche, L.\u2019), Person(\u2018Wei, S.-H.\u2019), Person(\u2018Zunger, A.\u2019)])]))\n\n\nWang2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018The Criteria for Beneficial Disorder in Thermoelectric Solid Solutions\u2019), (\u2018Journal\u2019, \u2018Adv. Funct. Mater.\u2019), (\u2018Year\u2019, \u20182013\u2019), (\u2018Number\u2019, \u201812\u2019), (\u2018Pages\u2019, \u20181586\u20131596\u2019), (\u2018Volume\u2019, \u201823\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Wang, H.\u2019), Person(\u2018LaLonde, A. D.\u2019), Person(\u2018Pei, Y.\u2019), Person(\u2018Snyder, G. J.\u2019)])]))\n\n\nWaroquiers2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Band widths and gaps from the {T}ran-{B}laha functional: Comparison with many-body perturbation theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018volume\u2019, \u201887\u2019), (\u2018pages\u2019, \u2018075121\u2019), (\u2018doi\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Waroquiers, D.\u2019), Person(\u2018Lherbier, A.\u2019), Person(\u2018Miglio, A.\u2019), Person(\u2018Stankovski, M.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Oliveira, M.J.T.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nWeinan2007\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Simplified and improved string method for computing the minimum energy paths in barrier-crossing events\u2019), (\u2018journal\u2019, \u2018The Journal of Chemical Physics\u2019), (\u2018volume\u2019, \u2018126\u2019), (\u2018number\u2019, \u201816\u2019), (\u2018pages\u2019, \u2018164103\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018publisher\u2019, \u2018AIP Publishing\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Weinan, E.\u2019), Person(\u2018Ren, W.\u2019), Person(\u2018Vanden-Eijnden, E.\u2019)])]))\n\n\nWerner2006\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Continuous-Time Solver for Quantum Impurity Models\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018volume\u2019, \u201897\u2019), (\u2018pages\u2019, \u2018076405\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevLett.97.076405\u2019), (\u2018timestamp\u2019, \u20182013.05.22\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevLett.97.076405\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Werner, P.\u2019), Person(\u2018Comanac, A.\u2019), Person(\u2018de Medici, L.\u2019), Person(\u2018Troyer, M.\u2019), Person(\u2018Millis, A.J.\u2019)])]))\n\n\nWiktor2013\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic structure investigation of energetics and positron lifetimes of fully relaxed monovacancies with various charge states in 3{C}-{S}i{C} and 6{H}-{S}i{C}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201887\u2019), (\u2018pages\u2019, \u2018235207\u2019), (\u2018numpages\u2019, \u201812\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.87.235207\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Bertolus, M.\u2019)])]))\n\n\nWiktor2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Positron annihilation spectroscopy investigation of vacancy clusters in silicon carbide: Combining experiments and electronic structure calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018number\u2019, \u201815\u2019), (\u2018pages\u2019, \u2018155203\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Kerbiriou, X.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Esnouf, S.\u2019), Person(\u2018Barthe, M.-F.\u2019), Person(\u2018Bertolus, M.\u2019)])]))\n\n\nWiktor2014a\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Coupled experimental and {DFT}+{U} investigation of positron lifetimes in {U}{O}\n_2\n\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201890\u2019), (\u2018number\u2019, \u201818\u2019), (\u2018pages\u2019, \u2018184101\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Barthe, M.-F.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Freyss, M.\u2019), Person(\u2018Bertolus, M.\u2019)])]))\n\n\nWiktor2014b\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic structure calculations of positron lifetimes in {S}i{C}: Self-consistent schemes and relaxation effect\u2019), (\u2018journal\u2019, \u2018Nucl. Instrum. Meth.\u2019), (\u2018volume\u2019, \u2018327\u2019), (\u2018pages\u2019, \u201863\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018doi\u2019, \u201810.1016/j.nimb.2013.09.050\u2019), (\u2018publisher\u2019, \u2018Elsevier\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Bertolus, M.\u2019)])]))\n\n\nWiktor2015\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Two-component density functional theory within the projector augmented-wave approach: Accurate and self-consistent computations of positron lifetimes and momentum distributions\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201892\u2019), (\u2018issue\u2019, \u201812\u2019), (\u2018pages\u2019, \u2018125113\u2019), (\u2018numpages\u2019, \u201815\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018month\u2019, \u2018Sep\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.92.125113\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.92.125113\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Torrent, M.\u2019)])]))\n\n\nXu2014\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018Doi\u2019, \u201810.1103/PhysRevLett.112.196603\u2019), (\u2018Issue\u2019, \u201819\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Numpages\u2019, \u20185\u2019), (\u2018Pages\u2019, \u2018196603\u2019), (\u2018Publisher\u2019, \u2018American Physical Society\u2019), (\u2018Title\u2019, \u2018First Principles Explanation of the Positive Seebeck Coefficient of {L}ithium\u2019), (\u2018Volume\u2019, \u2018112\u2019), (\u2018Year\u2019, \u20182014\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Xu, B.\u2019), Person(\u2018Verstraete, M. J.\u2019)])]))\n\n\nZhou2006\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Parallel self-consistent-field calculations via Chebyshev-filtered subspace acceleration\u2019), (\u2018journal\u2019, \u2018Phys. Rev. E\u2019), (\u2018volume\u2019, \u201874\u2019), (\u2018issue\u2019, \u20186\u2019), (\u2018pages\u2019, \u2018066704\u2019), (\u2018numpages\u2019, \u20188\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevE.74.066704\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevE.74.066704\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Zhou, Y.\u2019), Person(\u2018Saad, Y.\u2019), Person(\u2018Tiago, M.L.\u2019), Person(\u2018Chelikowsky, J.R.\u2019)])]))\n\n\nZhou2006a\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Self-consistent-field calculations using Chebyshev-filtered subspace iteration\u2019), (\u2018journal\u2019, \u2018J. Comp. Phys.\u2019), (\u2018volume\u2019, \u2018219\u2019), (\u2018number\u2019, \u20181\u2019), (\u2018pages\u2019, \u2018172\u2013184\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018publisher\u2019, \u2018Elsevier\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Zhou, Y.\u2019), Person(\u2018Saad, Y.\u2019), Person(\u2018Tiago, M.L\u2019), Person(\u2018Chelikowsky, J. R.\u2019)])]))\n\n\nZiman1960\n\u00b6\n\n\nEntry(\u2018book\u2019, fields=[(\u2018title\u2019, \u2018Electrons and phonons\u2019), (\u2018publisher\u2019, \u2018Oxford University Press\u2019), (\u2018year\u2019, \u20181960\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Ziman, J. M.\u2019)])]))\n\n\nZwanziger2012\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Finite homogeneous electric fields in the projector augmented wave formalism: Applications to linear and nonlinear response\u2019), (\u2018journal\u2019, \u2018Comput. Mater. Sci.\u2019), (\u2018volume\u2019, \u201858\u2019), (\u2018pages\u2019, \u2018113\u2013118\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Zwanziger, J.W.\u2019), Person(\u2018Galbraith, J.\u2019), Person(\u2018Kipouros, Y.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))\n\n\nLechermann2006\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Dynamical mean-field theory using Wannier functions: A flexible route to electronic structure calculations of strongly correlated materials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201874\u2019), (\u2018pages\u2019, \u2018125120\u2019), (\u2018year\u2019, \u20182006\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Lechermann, F.\u2019), Person(\u2018Georges, A.\u2019), Person(\u2018Poteryaev, S.\u2019), Person(\u2018Biermann, S.\u2019), Person(\u2018Posternak, M.\u2019), Person(\u2018Yamasaki, A.\u2019), Person(\u2018Andersen, O. K.\u2019)])]))\n\n\nFresard1997\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Interplay of Mott transition and ferromagnetism in the orbitally degenerate Hubbard model\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201856\u2019), (\u2018pages\u2019, \u201812909\u2019), (\u2018year\u2019, \u20181997\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cFr\\\u2018esard, Raymond\u201d), Person(\u2018Kotliar, Gabriel\u2019)])]))\n\n\nBergeron2016\n\u00b6\n\n\nEntry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Algorithms for optimized maximum entropy and diagnostic tools for analytic continuation\u2019), (\u2018journal\u2019, \u2018Phys. Rev. E\u2019), (\u2018volume\u2019, \u201894\u2019), (\u2018pages\u2019, \u2018023303\u2019), (\u2018year\u2019, \u20182016\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bergeron, D.\u2019), Person(\u2018Tremblay, A.-M.S.\u2019)])]))",
            "title": "Bibliography"
        },
        {
            "location": "/bibliography/#albrecht1998",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Ab Initio Calculation of Excitonic Effects in the Optical Spectra of Semiconductors\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20181998\u2019), (\u2018volume\u2019, \u201880\u2019), (\u2018pages\u2019, \u20184510\u20134513\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.80.4510\u2019), (\u2018numpages\u2019, \u20183\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Albrecht, S.\u2019), Person(\u2018Reining, L.\u2019), Person(\u2018Del Sole, R.\u2019), Person(\u2018Onida, G.\u2019)])]))",
            "title": "Albrecht1998"
        },
        {
            "location": "/bibliography/#allen1976",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theory of the temperature dependence of electronic band structures\u2019), (\u2018journal\u2019, \u2018J. of Phys. C: Solid State Physics\u2019), (\u2018year\u2019, \u20181976\u2019), (\u2018volume\u2019, \u20189\u2019), (\u2018pages\u2019, \u20182305\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Allen, P. B.\u2019), Person(\u2018Heine, V.\u2019)])]))",
            "title": "Allen1976"
        },
        {
            "location": "/bibliography/#allen1978",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u201cNew method for solving Boltzmann\u2019s equation for electrons in metals\u201d), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181978\u2019), (\u2018volume\u2019, \u201817\u2019), (\u2018pages\u2019, \u20183725\u20133734\u2019), (\u2018optdoi\u2019, \u201810.1103/PhysRevB.17.3725\u2019), (\u2018issue\u2019, \u201810\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Allen, P. B.\u2019)])]))",
            "title": "Allen1978"
        },
        {
            "location": "/bibliography/#allen1981",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theory of the temperature dependence of the direct gap of germanium\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181981\u2019), (\u2018volume\u2019, \u201823\u2019), (\u2018pages\u2019, \u20181495\u20131505\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Allen, P. B.\u2019), Person(\u2018Cardona, M.\u2019)])]))",
            "title": "Allen1981"
        },
        {
            "location": "/bibliography/#allen1983",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Temperature dependence of the direct gap of {S}i and {G}e\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181983\u2019), (\u2018volume\u2019, \u201827\u2019), (\u2018pages\u2019, \u20184760\u20134769\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Allen, P. B.\u2019), Person(\u2018Cardona, M.\u2019)])]))",
            "title": "Allen1983"
        },
        {
            "location": "/bibliography/#allen1996",
            "text": "Entry(\u2018incollection\u2019, fields=[(\u2018TITLE\u2019, \u2018Boltzmann Theory and Resistivity of Metals\u2019), (\u2018BOOKTITLE\u2019, \u2018Quantum Theory of Real Materials\u2019), (\u2018PUBLISHER\u2019, \u2018Kl{\\\u201cu}wer\u2019), (\u2018ADDRESS\u2019, \u2018Boston\u2019), (\u2018PAGES\u2019, \u2018219-250\u2019), (\u2018YEAR\u2019, \u20181996\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018AUTHOR\u2019, [Person(\u2018Allen, P. B.\u2019)]), (\u2018EDITOR\u2019, [Person(\u2018Chelikowsky, J. R.\u2019), Person(\u2018Louie, S. G.\u2019)])]))",
            "title": "Allen1996"
        },
        {
            "location": "/bibliography/#allen2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Recovering hidden Bloch character: Unfolding electrons, phonons, and slabs\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182013\u2019), (\u2018Pages\u2019, \u2018085322\u2019), (\u2018Volume\u2019, \u201887\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Allen, P. B.\u2019), Person(\u2018Berlijn, T.\u2019), Person(\u2018Casavant, D. A.\u2019), Person(\u2018Soler, J. M.\u2019)])]))",
            "title": "Allen2013"
        },
        {
            "location": "/bibliography/#amadon2006",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018The  \\\\alpha - \\\\gamma  {T}ransition of {C}erium {I}s {E}ntropy {D}riven\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018volume\u2019, \u201896\u2019), (\u2018pages\u2019, \u2018066402\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.96.066402\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Cerium/DMFT/PhysRevLett.96.066402.pdf:PDF\u2019), (\u2018issue\u2019, \u20186\u2019), (\u2018numpages\u2019, \u20184\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Biermann, S.\u2019), Person(\u2018Georges, A.\u2019), Person(\u2018Aryasetiawan, F.\u2019)])]))",
            "title": "Amadon2006"
        },
        {
            "location": "/bibliography/#amadon2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Plane-wave based electronic structure calculations for correlated materials using dynamical mean-field theory and projected local orbitals\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018volume\u2019, \u201877\u2019), (\u2018pages\u2019, \u2018205112\u2019), (\u2018number\u2019, \u201820\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/DMFT/PhysRevB.77.205112.pdf:PDF\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.77.205112\u2019), (\u2018timestamp\u2019, \u20182012.08.08\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.77.205112\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Lechermann, F.\u2019), Person(\u2018Georges, A.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Wehling, T. O.\u2019), Person(\u2018Liechtenstein, A. I.\u2019)])]))",
            "title": "Amadon2008"
        },
        {
            "location": "/bibliography/#amadon2008a",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018 \\\\gamma  and  \\\\beta  cerium: {LDA}+{U} calculations of ground-state parameters\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018volume\u2019, \u201877\u2019), (\u2018pages\u2019, \u2018155104\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.77.155104\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Cerium/PhysRevB.77.155104-1.pdf:PDF\u2019), (\u2018issue\u2019, \u201815\u2019), (\u2018numpages\u2019, \u201810\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019)])]))",
            "title": "Amadon2008a"
        },
        {
            "location": "/bibliography/#amadon2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018A self-consistent {DFT}+{DMFT} scheme in the projector augmented wave method: applications to cerium, {C}e _2 {O} _3  and {P}u _2 {O} _3  with the {H}ubbard {I} solver and comparison to {DFT}+{U}\u2019), (\u2018journal\u2019, \u2018J. Phys.: Cond. Matt.\u2019), (\u2018year\u2019, \u20182012\u2019), (\u2018volume\u2019, \u201824\u2019), (\u2018pages\u2019, \u2018075604\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/DMFT/0953-8984_24_7_075604.pdf:PDF\u2019), (\u2018issn\u2019, \u20180953-8984\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018timestamp\u2019, \u20182012.08.08\u2019), (\u2018url\u2019, \u2018http://iopscience.iop.org/article/10.1088/0953-8984/24/7/075604\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019)])]))",
            "title": "Amadon2012"
        },
        {
            "location": "/bibliography/#amadon2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Screened Coulomb interaction calculations: c{RPA} implementation and applications to dynamical screening and self-consistency in uranium dioxide and cerium\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018pages\u2019, \u2018125110\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.125110\u2019), (\u2018issue\u2019, \u201812\u2019), (\u2018numpages\u2019, \u201810\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Applencourt, T.\u2019), Person(\u2018Bruneval, F.\u2019)])]))",
            "title": "Amadon2014"
        },
        {
            "location": "/bibliography/#amadon2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Comparative analysis of models for the  \\\\alpha - \\\\gamma  phase transition in cerium: A DFT+DMFT study using Wannier orbitals\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018volume\u2019, \u201891\u2019), (\u2018pages\u2019, \u2018161103\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.91.161103\u2019), (\u2018issue\u2019, \u201816\u2019), (\u2018numpages\u2019, \u20185\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Amadon, B.\u2019), Person(\u2018Gerossier, A.\u2019)])]))",
            "title": "Amadon2015"
        },
        {
            "location": "/bibliography/#ambrosetti2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018van der {W}aals interactions in density functional theory using Wannier functions: Improved {C}6 and {C}3 coefficients by a different approach\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182012\u2019), (\u2018volume\u2019, \u201885\u2019), (\u2018pages\u2019, \u2018073101\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Ambrosetti, A.\u2019), Person(\u2018Silvestrelli, P. L.\u2019)])]))",
            "title": "Ambrosetti2012"
        },
        {
            "location": "/bibliography/#anisimov1991",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Density-functional calculation of effective Coulomb interactions in metals\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181991\u2019), (\u2018volume\u2019, \u201843\u2019), (\u2018pages\u2019, \u20187570\u20137574\u2019), (\u2018number\u2019, \u201810\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.43.7570\u2019), (\u2018timestamp\u2019, \u20182013.07.03\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.43.7570\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Anisimov, V. I.\u2019), Person(\u2018Gunnarsson, O.\u2019)])]))",
            "title": "Anisimov1991"
        },
        {
            "location": "/bibliography/#antonius2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Many-Body Effects on the Zero-Point Renormalization of the Band Structure\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u2018112\u2019), (\u2018pages\u2019, \u2018215501\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Antonius, G.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Boulanger, P.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Antonius2014"
        },
        {
            "location": "/bibliography/#antonius2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Dynamical and anharmonic effects on the electron-phonon coupling and the zero-point renormalization of the electronic structure\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018volume\u2019, \u201892\u2019), (\u2018pages\u2019, \u2018085137\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Antonius, G.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Lantagne-Hurtubise, E.\u2019), Person(\u2018Auclair, G.\u2019), Person(\u2018Gonze, X.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d)])]))",
            "title": "Antonius2015"
        },
        {
            "location": "/bibliography/#arponen1979",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Angular correlation in positron annihilation\u2019), (\u2018doi\u2019, \u201810.1088/0305-4608/9/12/009\u2019), (\u2018journal\u2019, \u2018J. Phys. F\u2019), (\u2018volume\u2019, \u20189\u2019), (\u2018pages\u2019, \u20182359\u2019), (\u2018year\u2019, \u20181979\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Arponen, J.\u2019), Person(\u2018Pajanne, E.\u2019)])]))",
            "title": "Arponen1979"
        },
        {
            "location": "/bibliography/#aryasetiawan2004",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Frequency-dependent local interactions and low-energy effective models from electronic structure calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182004\u2019), (\u2018volume\u2019, \u201870\u2019), (\u2018pages\u2019, \u2018195104\u2013\u2018), (\u2018number\u2019, \u201819\u2019), (\u2018keywords\u2019, \u2018cRPA\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.70.195104\u2019), (\u2018timestamp\u2019, \u20182013.03.15\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.70.195104\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Aryasetiawan, F.\u2019), Person(\u2018Imada, M.\u2019), Person(\u2018Georges, A.\u2019), Person(\u2018Kotliar, G.\u2019), Person(\u2018Biermann, S.\u2019), Person(\u2018Liechtenstein, A. I.\u2019)])]))",
            "title": "Aryasetiawan2004"
        },
        {
            "location": "/bibliography/#audouze2006",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201873\u2019), (\u2018pages\u2019, \u2018235101\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018title\u2019, \u2018Projector augmented-wave approach to density-functional perturbation theory\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Audouze, C.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Audouze2006"
        },
        {
            "location": "/bibliography/#audouze2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201878\u2019), (\u2018pages\u2019, \u2018035105\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018title\u2019, \u2018Comparison between projector augmented-wave and ultrasoft pseudopotential formalisms at the density-functional perturbation theory level\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Audouze, C.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Audouze2008"
        },
        {
            "location": "/bibliography/#bachelet1982",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Pseudopotentials that work: From {H} to {P}u\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181982\u2019), (\u2018volume\u2019, \u201826\u2019), (\u2018pages\u2019, \u20184199\u20134228\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.26.4199\u2019), (\u2018numpages\u2019, \u201829\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bachelet, G.B.\u2019), Person(\u2018Hamann, D.R.\u2019), Person(\u2018Schl\\\u201cuter, M.\u2019)])]))",
            "title": "Bachelet1982"
        },
        {
            "location": "/bibliography/#bader1994",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Atoms in Molecules: A Quantum Theory\u2019), (\u2018journal\u2019, \u2018Oxford University Press.\u2019), (\u2018year\u2019, \u20181994\u2019), (\u2018volume\u2019, \u2018ISBN 978-0-19-855865-1\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018\u2019), (\u2018url\u2019, \u2018\u2019), (\u2018doi\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bader, R. F. W.\u2019)])]))",
            "title": "Bader1994"
        },
        {
            "location": "/bibliography/#barbiellini1996",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Calculation of positron states and annihilation in solids: A density-gradient-correction scheme\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201853\u2019), (\u2018issue\u2019, \u201824\u2019), (\u2018pages\u2019, \u201816201\u2019), (\u2018year\u2019, \u20181996\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.53.16201\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Barbiellini, B.\u2019), Person(\u2018Puska, M. J.\u2019), Person(\u2018Korhonen, T.\u2019), Person(\u2018Harju, A.\u2019), Person(\u2018Torsti, T.\u2019), Person(\u2018Nieminen, R. M.\u2019)])]))",
            "title": "Barbiellini1996"
        },
        {
            "location": "/bibliography/#baroni1987",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u201cGreen\u2019s-function approach to linear response in solids\u201d), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20181987\u2019), (\u2018volume\u2019, \u201858\u2019), (\u2018pages\u2019, \u20181861\u20131864\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Baroni, S.\u2019), Person(\u2018Giannozzi, P.\u2019), Person(\u2018Testa, A.\u2019)])]))",
            "title": "Baroni1987"
        },
        {
            "location": "/bibliography/#becke1990",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018A simple measure of electron localization in atomic and molecular systems\u2019), (\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018year\u2019, \u20181990\u2019), (\u2018volume\u2019, \u201892\u2019), (\u2018number\u2019, \u20189\u2019), (\u2018pages\u2019, \u20185397-5403\u2019), (\u2018url\u2019, \u2018http://scitation.aip.org/content/aip/journal/jcp/92/9/10.1063/1.458517\u2019), (\u2018doi\u2019, \u201810.1063/1.458517\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Becke, A. D.\u2019), Person(\u2018Edgecombe, K. E.\u2019)])]))",
            "title": "Becke1990"
        },
        {
            "location": "/bibliography/#benedict1998",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Optical Absorption of Insulators and the Electron-Hole Interaction: An \\textit{Ab Initio} Calculation\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u201880\u2019), (\u2018issue\u2019, \u201820\u2019), (\u2018pages\u2019, \u20184514\u20134517\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181998\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.80.4514\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Benedict, L. X.\u2019), Person(\u2018Shirley, E. L.\u2019), Person(\u2018Bohn, R. B.\u2019)])]))",
            "title": "Benedict1998"
        },
        {
            "location": "/bibliography/#bengone2000",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Implementation of the projector augmented-wave {LDA}+{U} method: Application to the electronic structure of {N}i{O}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201862\u2019), (\u2018pages\u2019, \u201816392\u2019), (\u2018year\u2019, \u20181994\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018O. Bengone, M. Alouani, P. Bl\\\u201cochl,\u2019), Person(\u2018Hugel, J.\u2019)])]))",
            "title": "Bengone2000"
        },
        {
            "location": "/bibliography/#bergeron2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Algorithms for optimized maximum entropy and diagnostic tools for analytic continuation\u2019), (\u2018journal\u2019, \u2018arXiv e-prints\u2019), (\u2018archivePrefix\u2019, \u2018arXiv:cond-mat.str-el\u2019), (\u2018eprint\u2019, \u20181507.01012\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018month\u2019, \u2018jul\u2019), (\u2018adsurl\u2019, \u2018http://adsabs.harvard.edu/abs/2015arXiv150701012B\u2019), (\u2018adsnote\u2019, \u2018Provided by the SAO/NASA Astrophysics Data System\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bergeron, D.\u2019), Person(\u2018Tremblay, A.-M. S.\u2019)])]))",
            "title": "Bergeron2015"
        },
        {
            "location": "/bibliography/#bieder2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Thermodynamics of the  \\\\alpha - \\\\gamma  transition in cerium from first principles\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018pages\u2019, \u2018195132\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.195132\u2019), (\u2018issue\u2019, \u201819\u2019), (\u2018numpages\u2019, \u20187\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bieder, J.\u2019), Person(\u2018Amadon, B.\u2019)])]))",
            "title": "Bieder2014"
        },
        {
            "location": "/bibliography/#bloechl1994",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Projector augmented-wave method\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181994\u2019), (\u2018volume\u2019, \u201850\u2019), (\u2018pages\u2019, \u201817953-17979\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.50.17953\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bl\\\u201c{o}chl, P.E.\u2019)])]))",
            "title": "Bloechl1994"
        },
        {
            "location": "/bibliography/#bockstedte1997",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Density-functional theory calculations for poly-atomic systems: electronic structure, static and elastic properties and ab initio molecular dynamics\u2019), (\u2018Journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018Volume\u2019, \u2018107\u2019), (\u2018Pages\u2019, \u2018187\u2019), (\u2018Year\u2019, \u20181997\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Bockstedte, M.\u2019), Person(\u2018Kley, A.\u2019), Person(\u2018Neugebauer, J.\u2019), Person(\u2018Scheffler, M.\u2019)])]))",
            "title": "Bockstedte1997"
        },
        {
            "location": "/bibliography/#boronski1986",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electron-positron density-functional theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201834\u2019), (\u2018issue\u2019, \u20186\u2019), (\u2018pages\u2019, \u20183820\u2019), (\u2018year\u2019, \u20181986\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.34.3820\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cBoro\\\u2018nski, E.\u201d), Person(\u2018Nieminen, R. M.\u2019)])]))",
            "title": "Boronski1986"
        },
        {
            "location": "/bibliography/#bottin2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Large-scale ab initio calculations based on three levels of parallelization\u2019), (\u2018journal\u2019, \u2018Comp. Mat. Sci.\u2019), (\u2018volume\u2019, \u201842\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u2018329\u2013336\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018publisher\u2019, \u2018Elsevier\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bottin, F.\u2019), Person(\u2018Leroux, S.\u2019), Person(\u2018Knyazev, A.\u2019), Person(\u201cZ{\\\u2018e}rah, G.\u201d)])]))",
            "title": "Bottin2008"
        },
        {
            "location": "/bibliography/#bousquet2011",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Unexpectedly Large Electronic Contribution to Linear Magnetoelectricity\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018106\u2019), (\u2018pages\u2019, \u2018107202\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.106.107202\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bousquet, E.\u2019), Person(\u2018Spaldin, N. A.\u2019), Person(\u2018Delaney, K. T.\u2019)])]))",
            "title": "Bousquet2011"
        },
        {
            "location": "/bibliography/#bruneval2006",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Effect of self-consistency on quasiparticles in solids\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201874\u2019), (\u2018pages\u2019, \u2018045102\u2019), (\u2018year\u2019, \u20182006\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bruneval, F.\u2019), Person(\u2018Vast, N.\u2019), Person(\u2018Reining, L.\u2019)])]))",
            "title": "Bruneval2006"
        },
        {
            "location": "/bibliography/#bruneval2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Accurate {GW} self-energies in a plane-wave basis using only a few empty states: Towards large systems\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201878\u2019), (\u2018issue\u2019, \u20188\u2019), (\u2018pages\u2019, \u2018085125\u2019), (\u2018numpages\u2019, \u20189\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.78.085125\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bruneval, F.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Bruneval2008"
        },
        {
            "location": "/bibliography/#bruneval2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Range-Separated Approach to the {RPA} Correlation Applied to the van der Waals Bond and to Diffusion of Defects\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018108\u2019), (\u2018issue\u2019, \u201825\u2019), (\u2018pages\u2019, \u2018256403\u2019), (\u2018numpages\u2019, \u20185\u2019), (\u2018year\u2019, \u20182012\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.108.256403\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bruneval, F.\u2019)])]))",
            "title": "Bruneval2012"
        },
        {
            "location": "/bibliography/#bruneval2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Consistent treatment of charged systems within periodic boundary conditions: The projector augmented-wave and pseudopotential methods revisited\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018issue\u2019, \u20184\u2019), (\u2018pages\u2019, \u2018045116\u2019), (\u2018numpages\u2019, \u201813\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.045116\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bruneval, F.\u2019), Person(\u2018Crocombette, J.-P.\u2019), Person(\u2018Gonze, X.\u2019), Person(\u2018Dorado, B.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Jollet, F.\u2019)])]))",
            "title": "Bruneval2014"
        },
        {
            "location": "/bibliography/#calloni2005",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Positron localization effects on the Doppler broadening of the annihilation line: Aluminum as a case study\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201872\u2019), (\u2018number\u2019, \u20185\u2019), (\u2018pages\u2019, \u2018054112\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Calloni, A.\u2019), Person(\u2018Dupasquier, A.\u2019), Person(\u2018Ferragut, R.\u2019), Person(\u2018Folegati, P.\u2019), Person(\u2018Iglesias, M.M.\u2019), Person(\u2018Makkonen, I.\u2019), Person(\u2018Puska, M.J.\u2019)])]))",
            "title": "Calloni2005"
        },
        {
            "location": "/bibliography/#campillo1998",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic stopping power of aluminum crystal\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201858\u2019), (\u2018issue\u2019, \u201816\u2019), (\u2018pages\u2019, \u201810307 - 10314\u2019), (\u2018year\u2019, \u20181998\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.58.10307\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Campillo, I.\u2019), Person(\u2018Pitarke, J. M.\u2019), Person(\u2018Eguiluz, A. G.\u2019)])]))",
            "title": "Campillo1998"
        },
        {
            "location": "/bibliography/#cappellini1993",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Model dielectric function for semiconductors\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201847\u2019), (\u2018issue\u2019, \u201815\u2019), (\u2018pages\u2019, \u20189892\u20139895\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181993\u2019), (\u2018month\u2019, \u2018Apr\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.47.9892\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Cappellini, G.\u2019), Person(\u2018Del Sole, R.\u2019), Person(\u2018Reining, L.\u2019), Person(\u2018Bechstedt, F.\u2019)])]))",
            "title": "Cappellini1993"
        },
        {
            "location": "/bibliography/#caracas2007",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Prediction of polar ordered oxynitride perovskites\u2019), (\u2018journal\u2019, \u2018J. Appl. Phys. Lett.\u2019), (\u2018volume\u2019, \u201891\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018092902\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018doi\u2019, \u201810.1063/1.2776370\u2019), (\u2018publisher\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Caracas, R.\u2019), Person(\u2018Cohen, R.E.\u2019)])]))",
            "title": "Caracas2007"
        },
        {
            "location": "/bibliography/#caracas2007a",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Post-perovskite phase in selected sesquioxides from density-functional calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201876\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018184101\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018doi\u2019, \u2018\u2019), (\u2018publisher\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Caracas, R.\u2019), Person(\u2018Cohen, R.E.\u2019)])]))",
            "title": "Caracas2007a"
        },
        {
            "location": "/bibliography/#caracas2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Dynamical Instabilities of Ice X\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018101\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018085502\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.101.085502\u2019), (\u2018publisher\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Caracas, R.\u2019)])]))",
            "title": "Caracas2008"
        },
        {
            "location": "/bibliography/#cococcioni2005",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Linear response approach to the calculation of the effective interaction parameters in the {LDA}+{U} method\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018volume\u2019, \u201871\u2019), (\u2018pages\u2019, \u2018035105\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/PhysRevB.71.035105.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018DFTU interaction, cRPA\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.71.035105\u2019), (\u2018timestamp\u2019, \u20182012.06.21\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.71.035105\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Cococcioni, M.\u2019), Person(\u2018de Gironcoli, S.\u2019)])]))",
            "title": "Cococcioni2005"
        },
        {
            "location": "/bibliography/#coleman2015",
            "text": "Entry(\u2018book\u2019, fields=[(\u2018title\u2019, \u2018Introduction to Many-Body Physics\u2019), (\u2018publisher\u2019, \u2018Cambridge University Press\u2019), (\u2018year\u2019, \u20182015\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Coleman, Piers\u2019)])]))",
            "title": "Coleman2015"
        },
        {
            "location": "/bibliography/#czyzyk1994",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Local-density functional and on-site correlations: {T}he electronic structure of {L}a _2 {C}u{O} _4  and {L}a{C}u{O} _3 \u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201849\u2019), (\u2018pages\u2019, \u201814211\u2019), (\u2018year\u2019, \u20181994\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Czyzyk, M. T.\u2019), Person(\u2018Sawatzky, G. A.\u2019)])]))",
            "title": "Czyzyk1994"
        },
        {
            "location": "/bibliography/#daubechies1992",
            "text": "Entry(\u2018book\u2019, fields=[(\u2018title\u2019, \u201810 Lectures on Wavelets\u2019), (\u2018publisher\u2019, \u2018Society for Industrial and Applied Mathematics ({SIAM}, 3600 {M}arket {S}treet, {F}loor 6, {P}hiladelphia, {PA} 19104)\u2019), (\u2018year\u2019, \u20181992\u2019), (\u2018isbn\u2019, \u20189780898712742\u2019), (\u2018keywords\u2019, \u2018Mathematics / General, Mathematics / Infinity, Mathematics / Mathematical Analysis, Science / Waves \\& Wave Mechanics, Technology \\& Engineering / General\u2019), (\u2018language\u2019, \u2018en\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Daubechies, I.\u2019)])]))",
            "title": "Daubechies1992"
        },
        {
            "location": "/bibliography/#dion2004",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Van der Waals Density Functional for General Geometries\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u201892\u2019), (\u2018pages\u2019, \u2018246401\u2019), (\u2018year\u2019, \u20182004\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.92.246401\u2019), (\u2018note\u2019, \u2018Erratum: DOI:10.1103/PhysRevLett.95.109902\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Dion, M.\u2019), Person(\u2018Rydberg, H.\u2019), Person(\u2018Schr\\\u201coder, E.\u2019), Person(\u2018Langreth, D. C.\u2019), Person(\u2018Lundqvist, B. I.\u2019)])]))",
            "title": "Dion2004"
        },
        {
            "location": "/bibliography/#espejo2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Wannier functions approach to van der Waals interactions in {ABINIT}\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018183\u2019), (\u2018pages\u2019, \u2018480\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Espejo, C.\u2019), Person(\u2018Rangel, T.\u2019), Person(\u2018Pouillon, Y.\u2019), Person(\u2018Romero, A. H.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Espejo2012"
        },
        {
            "location": "/bibliography/#folegati2007",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Analysis of electron-positron momentum spectra of metallic alloys as supported by first-principles calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201875\u2019), (\u2018number\u2019, \u20185\u2019), (\u2018pages\u2019, \u2018054201\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Folegati, P.\u2019), Person(\u2018Makkonen, I.\u2019), Person(\u2018Ferragut, R.\u2019), Person(\u2018Puska, M.J.\u2019)])]))",
            "title": "Folegati2007"
        },
        {
            "location": "/bibliography/#freund1995",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Software for simplified {L}anczos and {QMR} algorithms\u2019), (\u2018journal\u2019, \u2018Applied Numerical Mathematics\u2019), (\u2018year\u2019, \u20181995\u2019), (\u2018volume\u2019, \u201819\u2019), (\u2018pages\u2019, \u2018319\u2019), (\u2018doi\u2019, \u201810.1016/0168-9274(95)00089-5\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Freund, R. W.\u2019), Person(\u2018Nachtigal, N. M.\u2019)])]))",
            "title": "Freund1995"
        },
        {
            "location": "/bibliography/#fuchs1999",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Ab initio pseudopotentials for electronic structure calculations of poly-atomic systems using density-functional theory\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018119\u2019), (\u2018number\u2019, \u20181\u2019), (\u2018pages\u2019, \u201867 - 98\u2019), (\u2018year\u2019, \u20181999\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180010-4655\u2019), (\u2018doi\u2019, \u201810.1016/S0010-4655(98)00201-X\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S001046559800201X\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Fuchs, M.\u2019), Person(\u2018Scheffler, M.\u2019)])]))",
            "title": "Fuchs1999"
        },
        {
            "location": "/bibliography/#garrity2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Pseudopotentials for high-throughput {DFT} calculations\u2019), (\u2018journal\u2019, \u2018Comp. Mat. Sci.\u2019), (\u2018volume\u2019, \u201881\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018446 - 452\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180927-0256\u2019), (\u2018doi\u2019, \u201810.1016/j.commatsci.2013.08.053\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S0927025613005077\u2019), (\u2018keywords\u2019, \u2018Density functional theory\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Garrity, K.F.\u2019), Person(\u2018Bennett, J.W.\u2019), Person(\u2018Rabe, K.M.\u2019), Person(\u2018Vanderbilt, D.\u2019)])]))",
            "title": "Garrity2014"
        },
        {
            "location": "/bibliography/#geneste2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Strong Isotope Effect in Phase {I}{I} of Dense Solid Hydrogen and Deuterium\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Volume\u2019, \u2018109\u2019), (\u2018Pages\u2019, \u2018155303\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Geneste, G.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Bottin, F.\u2019), Person(\u2018Loubeyre, P.\u2019)])]))",
            "title": "Geneste2012"
        },
        {
            "location": "/bibliography/#geneste2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Proton transport in barium stannate: classical, semi-classical and quantum regimes\u2019), (\u2018Journal\u2019, \u2018Phys. Chem. Chem. Phys.\u2019), (\u2018Volume\u2019, \u201817\u2019), (\u2018Pages\u2019, \u201819104\u2019), (\u2018year\u2019, \u20182015\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Geneste, G.\u2019), Person(\u2018Ottochian, A.\u2019), Person(\u2018Hermet, J.\u2019), Person(\u2018Dezanneau, G.\u2019)])]))",
            "title": "Geneste2015"
        },
        {
            "location": "/bibliography/#genovese2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Daubechies wavelets as a basis set for density functional pseudopotential calculations\u2019), (\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018volume\u2019, \u2018129\u2019), (\u2018pages\u2019, \u2018014109\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Genovese, L.\u2019), Person(\u2018Neelov, L.\u2019), Person(\u2018Goedecker, S.\u2019), Person(\u2018Deutsch, T.\u2019), Person(\u2018Alireza Ghasemi, S.\u2019), Person(\u2018Willand, A.\u2019), Person(\u2018Caliste, D.\u2019), Person(\u2018Zilberberg, O.\u2019), Person(\u2018Rayson, M.\u2019), Person(\u2018Bergman, A.\u2019), Person(\u2018Schneider, R.\u2019)])]))",
            "title": "Genovese2008"
        },
        {
            "location": "/bibliography/#genovese2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Density Functional Theory calculation on many-cores hybrid {CPU}-{GPU} architectures in hybrid architecture\u2019), (\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018volume\u2019, \u2018131\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018034103\u2019), (\u2018year\u2019, \u20182009\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Genovese, L.\u2019), Person(\u2018Ospici, M.\u2019), Person(\u2018Deutsch, T.\u2019), Person(\u201cM\\\u2018ehaut, J.-F.\u201d), Person(\u2018Neelov, A.\u2019), Person(\u2018Goedecker, S.\u2019)])]))",
            "title": "Genovese2009"
        },
        {
            "location": "/bibliography/#georges1996",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Dynamical mean-field theory of strongly correlated fermion systems and the limit of infinite dimensions\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018year\u2019, \u20181996\u2019), (\u2018volume\u2019, \u201868\u2019), (\u2018pages\u2019, \u201813\u2013125\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.68.13\u2019), (\u2018issue\u2019, \u20181\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Georges, A.\u2019), Person(\u2018Kotliar, G.\u2019), Person(\u2018Krauth, W.\u2019), Person(\u2018Rozenberg, M.J.\u2019)])]))",
            "title": "Georges1996"
        },
        {
            "location": "/bibliography/#georges2004",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Strongly Correlated Electron Materials: Dynamical Mean-Field Theory and Electronic Structure\u2019), (\u2018journal\u2019, \u2018{AIP} {C}onf. {P}roc.\u2019), (\u2018year\u2019, \u20182004\u2019), (\u2018volume\u2019, \u2018715\u2019), (\u2018pages\u2019, \u20183\u201374\u2019), (\u2018number\u2019, \u20181\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/DMFT/APC000003.pdf:PDF\u2019), (\u2018keywords\u2019, \u201cstrongly correlated electron systems, metal-insulator transition, density functional theory, electronic structure, band theory, Green\u2019s function methods, spin systems, transport processes, critical phenomena, transition metal compounds, rare earth compounds, actinide compounds, oxygen compounds\u201d), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018AIP\u2019), (\u2018timestamp\u2019, \u20182012.10.18\u2019), (\u2018doi\u2019, \u201810.1063/1.1800733\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Georges, A.\u2019)])]))",
            "title": "Georges2004"
        },
        {
            "location": "/bibliography/#giannozzi2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018{QUANTUM} {ESPRESSO}: a modular and open-source software project for quantum simulations of materials\u2019), (\u2018journal\u2019, \u2018J. Phys.: Cond. Matt.\u2019), (\u2018volume\u2019, \u201821\u2019), (\u2018number\u2019, \u201839\u2019), (\u2018pages\u2019, \u2018395502\u2019), (\u2018url\u2019, \u2018http://iopscience.iop.org/article/10.1088/0953-8984/21/39/395502\u2019), (\u2018year\u2019, \u20182009\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Giannozzi, P.\u2019), Person(\u2018Baroni, S.\u2019), Person(\u2018Bonini, N.\u2019), Person(\u2018Calandra, M.\u2019), Person(\u2018Car, R.\u2019), Person(\u2018Cavazzoni, C.\u2019), Person(\u2018Ceresoli, D.\u2019), Person(\u2018Chiarotti, G.L.\u2019), Person(\u2018Cococcioni, M.\u2019), Person(\u2018Dabo, I.\u2019), Person(\u2018Dal Corso, A.\u2019), Person(\u2018de Gironcoli, S.\u2019), Person(\u2018Fabris, S.\u2019), Person(\u2018Fratesi, G.\u2019), Person(\u2018Gebauer, R.\u2019), Person(\u2018Gerstmann, U.\u2019), Person(\u2018Gougoussis, C.\u2019), Person(\u2018Kokalj, A.\u2019), Person(\u2018Lazzeri, M.\u2019), Person(\u2018Martin-Samos, L.\u2019), Person(\u2018Marzari, N.\u2019), Person(\u2018Mauri, F.\u2019), Person(\u2018Mazzarello, R.\u2019), Person(\u2018Paolini, S.\u2019), Person(\u2018Pasquarello, A.\u2019), Person(\u2018Paulatto, L.\u2019), Person(\u2018Sbraccia, C.\u2019), Person(\u2018Scandolo, S.\u2019), Person(\u2018Sclauzero, G.\u2019), Person(\u2018Seitsonen, A.P.\u2019), Person(\u2018Smogunov, A.\u2019), Person(\u2018Umari, P.\u2019), Person(\u2018Wentzcovitch, R.M.\u2019)])]))",
            "title": "Giannozzi2009"
        },
        {
            "location": "/bibliography/#giantomassi2011",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018{Electronic properties of interfaces and defects from many-body perturbation theory: Recent developments and applications}\u2019), (\u2018journal\u2019, \u2018Physica Status Solidi B\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018volume\u2019, \u2018248\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u2018275\u2013289\u2019), (\u2018doi\u2019, \u201810.1002/pssb.201046094\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Giantomassi, M.\u2019), Person(\u2018Stankovski, M.\u2019), Person(\u2018Shaltaf, R.\u2019), Person(\u2018Gruning, M.\u2019), Person(\u2018Bruneval, F.\u2019), Person(\u2018Rinke, P.\u2019), Person(\u2018Rignanese, G.M.\u2019)])]))",
            "title": "Giantomassi2011"
        },
        {
            "location": "/bibliography/#gillet2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018First-principles study of excitonic effects in Raman intensities\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182013\u2019), (\u2018Pages\u2019, \u2018094305\u2019), (\u2018Volume\u2019, \u201888\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.88.094305\u2019), (\u2018File\u2019, \u2018Gillet2013.pdf:Gillet2013.pdf:PDF;Gillet2013.pdf:Gillet2013.pdf:PDF\u2019), (\u2018Issue\u2019, \u20189\u2019), (\u2018Numpages\u2019, \u20189\u2019), (\u2018Publisher\u2019, \u2018American Physical Society\u2019), (\u2018Url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.88.094305\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Gillet, Y.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Gillet2013"
        },
        {
            "location": "/bibliography/#gillet2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Efficient Interpolation Technique for {B}ethe-{S}alpeter Calculation of Optical Spectra\u2019), (\u2018Year\u2019, \u20182016\u2019), (\u2018volume\u2019, \u2018203C\u2019), (\u2018pages\u2019, \u201883-93\u2019), (\u2018Journal\u2019, \u2018Comput. Phys. Comm.\u2019), (\u2018Doi\u2019, \u201810.1016/j.cpc.2016.02.008\u2019), (\u2018Owner\u2019, \u2018yannick\u2019), (\u2018Timestamp\u2019, \u20182015.08.27\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Gillet, Y.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Gillet2015"
        },
        {
            "location": "/bibliography/#goedecker1996",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Separable dual-space Gaussian pseudopotentials\u2019), (\u2018volume\u2019, \u201854\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181996\u2019), (\u2018pages\u2019, \u20181703\u20131710\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Goedecker, S.\u2019), Person(\u2018Teter, M.\u2019), Person(\u2018H\\\u201cutter, J.\u2019)])]))",
            "title": "Goedecker1996"
        },
        {
            "location": "/bibliography/#gonze1991",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Analysis of separable potentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201844\u2019), (\u2018issue\u2019, \u201816\u2019), (\u2018pages\u2019, \u20188503\u20138513\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181991\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.44.8503\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Stumpf, R.\u2019), Person(\u2018Scheffler, M.\u2019)])]))",
            "title": "Gonze1991"
        },
        {
            "location": "/bibliography/#gonze1995",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Adiabatic density-functional perturbation theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. A\u2019), (\u2018year\u2019, \u20181995\u2019), (\u2018volume\u2019, \u201852\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u20181096\u20131114\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevA.52.1096\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Gonze1995"
        },
        {
            "location": "/bibliography/#gonze1997",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-principles responses of solids to atomic displacements and homogeneous electric fields: Implementation of a conjugate-gradient algorithm\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181997\u2019), (\u2018volume\u2019, \u201855\u2019), (\u2018pages\u2019, \u201810337\u201310354\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Gonze1997"
        },
        {
            "location": "/bibliography/#gonze1997a",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201855\u2019), (\u2018pages\u2019, \u201810355\u2019), (\u2018year\u2019, \u20181997\u2019), (\u2018title\u2019, \u2018Dynamical matrices, Born effective charges, dielectric permittivity tensors, and interatomic force constants from density-functional perturbation theory\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Lee, C.\u2019)])]))",
            "title": "Gonze1997a"
        },
        {
            "location": "/bibliography/#gonze2002",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Comp. Mat. Science\u2019), (\u2018volume\u2019, \u201825\u2019), (\u2018pages\u2019, \u2018478\u2013492\u2019), (\u2018year\u2019, \u20182002\u2019), (\u2018title\u2019, \u2018First-principles computation of material properties : the ABINIT software project\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Beuken, J.-M.\u2019), Person(\u2018Caracas, R.\u2019), Person(\u2018Detraux, F.\u2019), Person(\u2018Fuchs, M.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Sindic, L.\u2019), Person(\u2018Verstraete, M.\u2019), Person(\u2018Zerah, G.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Roy, A.\u2019), Person(\u2018Mikami, M.\u2019), Person(\u2018Ghosez, Ph.\u2019), Person(\u2018Raty, J.-Y.\u2019), Person(\u2018Allan, D.C.\u2019)])]))",
            "title": "Gonze2002"
        },
        {
            "location": "/bibliography/#gonze2005",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Zeit. Kristallogr\u2019), (\u2018volume\u2019, \u2018220\u2019), (\u2018pages\u2019, \u2018558-562\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018title\u2019, \u2018A brief introduction to the ABINIT software package\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Verstraete, M.\u2019), Person(\u2018Beuken, J.-M.\u2019), Person(\u2018Pouillon, Y.\u2019), Person(\u2018Caracas, R.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Zerah, G.\u2019), Person(\u2018Mikami, M.\u2019), Person(\u2018Ghosez, Ph.\u2019), Person(\u2018Veithen, M.\u2019), Person(\u2018Raty, J.-Y.\u2019), Person(\u2018Olevano, V.\u2019), Person(\u2018Bruneval, F.\u2019), Person(\u2018Reining, L.\u2019), Person(\u2018Godby, R.\u2019), Person(\u2018Onida, G.\u2019), Person(\u2018an D.C. Allan, D.R. Hamann\u2019)])]))",
            "title": "Gonze2005"
        },
        {
            "location": "/bibliography/#gonze2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018180\u2019), (\u2018pages\u2019, \u20182582-2615\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018title\u2019, \u2018{ABINIT}: First-Principle approach to material and nanosystem properties\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Amadon, B.\u2019), Person(\u2018Anglade, P.-M.\u2019), Person(\u2018Beuken, J.-M.\u2019), Person(\u2018Bottin, F.\u2019), Person(\u2018Boulanger, P.\u2019), Person(\u2018Bruneval, F.\u2019), Person(\u2018Caliste, D.\u2019), Person(\u2018Caracas, R.\u2019), Person(\u201cC\\^{o}t\\\u2018{e}, M.\u201d), Person(\u2018Deutsch, T.\u2019), Person(\u2018Genovese, L.\u2019), Person(\u2018Ghosez, Ph.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Goedecker, S.\u2019), Person(\u2018Hamann, D.R.\u2019), Person(\u2018Hermet, P.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Leroux, S.\u2019), Person(\u2018Mancini, M.\u2019), Person(\u2018Mazevet, S.\u2019), Person(\u2018Oliveira, M.J.T.\u2019), Person(\u2018Onida, G.\u2019), Person(\u2018Pouillon, Y.\u2019), Person(\u2018Rangel, T.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Sangalli, D.\u2019), Person(\u2018Shaltaf, R.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Verstraete, M.J.\u2019), Person(\u2018Zerah, G.\u2019), Person(\u2018Zwanziger, J.W.\u2019)])]))",
            "title": "Gonze2009"
        },
        {
            "location": "/bibliography/#gonze2011",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theoretical approaches to the temperature and zero-point motion effects on the electronic band structure.\u2019), (\u2018journal\u2019, \u2018Annalen der Physik\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018volume\u2019, \u2018523\u2019), (\u2018pages\u2019, \u2018168\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Boulanger, P.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d)])]))",
            "title": "Gonze2011"
        },
        {
            "location": "/bibliography/#gonze2016",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Recent developments in the {ABINIT} software package\u2019), (\u2018journal\u2019, \u2018Computer Physics Communications\u2019), (\u2018volume\u2019, \u2018205\u2019), (\u2018pages\u2019, \u2018106\u2019), (\u2018year\u2019, \u20182016\u2019), (\u2018issn\u2019, \u20180010-4655\u2019), (\u2018doi\u2019, \u201810.1016/j.cpc.2016.04.003\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S0010465516300923\u2019), (\u2018keywords\u2019, \u2018Many-Body Perturbation Theory\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gonze, X.\u2019), Person(\u2018Jollet, F.\u2019), Person(\u2018Araujo, F. Abreu\u2019), Person(\u2018Adams, D.\u2019), Person(\u2018Amadon, B.\u2019), Person(\u2018Applencourt, T.\u2019), Person(\u2018Audouze, C.\u2019), Person(\u2018Beuken, J.-M.\u2019), Person(\u2018Bieder, J.\u2019), Person(\u2018Bokhanchuk, A.\u2019), Person(\u2018Bousquet, E.\u2019), Person(\u2018Bruneval, F.\u2019), Person(\u2018Caliste, D.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d), Person(\u2018Dahm, F.\u2019), Person(\u2018Pieve, F. Da\u2019), Person(\u2018Delaveau, M.\u2019), Person(\u2018Gennaro, M. Di\u2019), Person(\u2018Dorado, B.\u2019), Person(\u2018Espejo, C.\u2019), Person(\u2018Geneste, G.\u2019), Person(\u2018Genovese, L.\u2019), Person(\u2018Gerossier, A.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Gillet, Y.\u2019), Person(\u2018Hamann, D.R.\u2019), Person(\u2018He, L.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Janssen, J. Laflamme\u2019), Person(\u2018Roux, S. Le\u2019), Person(\u2018Levitt, A.\u2019), Person(\u2018Lherbier, A.\u2019), Person(\u2018Liu, F.\u2019), Person(\u2018Lukacevic, I.\u2019), Person(\u2018Martin, A.\u2019), Person(\u2018Martins, C.\u2019), Person(\u2018Oliveira, M.J.T.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Pouillon, Y.\u2019), Person(\u2018Rangel, T.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Romero, A.H.\u2019), Person(\u2018Rousseau, B.\u2019), Person(\u2018Rubel, O.\u2019), Person(\u2018Shukri, A.A.\u2019), Person(\u2018Stankovski, M.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Setten, M.J. Van\u2019), Person(\u2018troeye, B. Van\u2019), Person(\u2018Verstraete, M.J.\u2019), Person(\u2018Waroquier, D.\u2019), Person(\u2018Wiktor, J.\u2019), Person(\u2018Xue, B.\u2019), Person(\u2018Zhou, A.\u2019), Person(\u2018Zwanziger, J.W.\u2019)])]))",
            "title": "Gonze2016"
        },
        {
            "location": "/bibliography/#grimme2006",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Semiempirical {GGA}-Type Density Functional Constructed with a Long-Range Dispersion Correction\u2019), (\u2018Journal\u2019, \u2018J. Comput. Chem.\u2019), (\u2018Volume\u2019, \u201827\u2019), (\u2018Pages\u2019, \u20181787\u2019), (\u2018year\u2019, \u20182006\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Grimme, S.\u2019)])]))",
            "title": "Grimme2006"
        },
        {
            "location": "/bibliography/#grimme2010",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018A consistent and accurate ab initio parametrization of density functional dispersion correction (DFT-D) for the 94 elements H-Pu\u2019), (\u2018Journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018Volume\u2019, \u2018132\u2019), (\u2018Pages\u2019, \u2018154104\u2019), (\u2018year\u2019, \u20182010\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Grimme, S.\u2019), Person(\u2018Anthony, J.\u2019), Person(\u2018Ehrlich, S.\u2019), Person(\u2018Krieg, H.\u2019)])]))",
            "title": "Grimme2010"
        },
        {
            "location": "/bibliography/#grimme2010a",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Effect of the Damping Function in Dispersion Corrected Density Functional Theory\u2019), (\u2018Journal\u2019, \u2018J. Comput. Chem.\u2019), (\u2018Volume\u2019, \u201832\u2019), (\u2018Pages\u2019, \u20181456-1465\u2019), (\u2018year\u2019, \u20182011\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Grimme, S.\u2019), Person(\u2018Ehrlich, S.\u2019), Person(\u2018Goerigk, L.\u2019)])]))",
            "title": "Grimme2010a"
        },
        {
            "location": "/bibliography/#grimvall1981",
            "text": "Entry(\u2018book\u2019, fields=[(\u2018YEAR\u2019, \u20181981\u2019), (\u2018TITLE\u2019, \u2018The electron phonon interaction in metals\u2019), (\u2018ADDRESS\u2019, \u2018Amsterdam\u2019), (\u2018PUBLISHER\u2019, \u2018North-Holland\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018AUTHOR\u2019, [Person(\u2018Grimvall, G.\u2019)])]))",
            "title": "Grimvall1981"
        },
        {
            "location": "/bibliography/#gull2011",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Continuous-time Monte Carlo methods for quantum impurity models\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018volume\u2019, \u201883\u2019), (\u2018pages\u2019, \u2018349\u2013404\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/RevModPhys.83.349-1.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018interaction CTQMC\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/RevModPhys.83.349\u2019), (\u2018timestamp\u2019, \u20182012.06.22\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.83.349\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Gull, E.\u2019), Person(\u2018Millis, A.J.\u2019), Person(\u2018Liechtenstein, A. I.\u2019), Person(\u2018Rubtsov, A.N.\u2019), Person(\u2018Troyer, M.\u2019), Person(\u2018Werner, P.\u2019)])]))",
            "title": "Gull2011"
        },
        {
            "location": "/bibliography/#hamann1979",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Norm-Conserving Pseudopotentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20181979\u2019), (\u2018volume\u2019, \u201843\u2019), (\u2018pages\u2019, \u20181494\u20131497\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.43.1494\u2019), (\u2018numpages\u2019, \u20183\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hamann, D.R.\u2019), Person(\u2018Schl\\\u201cuter, M.\u2019), Person(\u2018Chiang, C.\u2019)])]))",
            "title": "Hamann1979"
        },
        {
            "location": "/bibliography/#hamann1989",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Generalized norm-conserving pseudopotentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201840\u2019), (\u2018issue\u2019, \u20185\u2019), (\u2018pages\u2019, \u20182980\u20132987\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181989\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.40.2980\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hamann, D. R.\u2019)])]))",
            "title": "Hamann1989"
        },
        {
            "location": "/bibliography/#hamann2005",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Metric tensor formulation of strain in density-functional perturbation theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201871\u2019), (\u2018pages\u2019, \u2018035117\u2019), (\u2018year\u2019, \u20182005\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hamann, D. R.\u2019), Person(\u2018Wu, X.\u2019), Person(\u2018Rabe, K. M.\u2019), Person(\u2018Vanderbilt, D.\u2019)])]))",
            "title": "Hamann2005"
        },
        {
            "location": "/bibliography/#hamann2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Optimized norm-conserving Vanderbilt pseudopotentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201888\u2019), (\u2018issue\u2019, \u20188\u2019), (\u2018pages\u2019, \u2018085117\u2019), (\u2018numpages\u2019, \u201810\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.88.085117\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hamann, D. R.\u2019)])]))",
            "title": "Hamann2013"
        },
        {
            "location": "/bibliography/#harju2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Computational Physics on Graphics Processing Units\u2019), (\u2018journal\u2019, \u2018Lecture Notes in Computer Science\u2019), (\u2018volume\u2019, \u20187782\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u20183\u201326\u2019), (\u2018year\u2019, \u20182013\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Harju, A.\u2019), Person(\u2018Siro, T.\u2019), Person(\u2018Federici Canova, F.\u2019), Person(\u2018Hakala, S.\u2019), Person(\u2018Rantalaiho, T.\u2019)])]))",
            "title": "Harju2013"
        },
        {
            "location": "/bibliography/#harl2010",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Assessing the quality of the random phase approximation for lattice constants and atomization energies of solids\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201881\u2019), (\u2018issue\u2019, \u201811\u2019), (\u2018pages\u2019, \u2018115126\u2019), (\u2018numpages\u2019, \u201818\u2019), (\u2018year\u2019, \u20182010\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.81.115126\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Harl, J.\u2019), Person(\u2018Schimka, L.\u2019), Person(\u2018Kresse, G.\u2019)])]))",
            "title": "Harl2010"
        },
        {
            "location": "/bibliography/#hartwigsen1998",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Relativistic separable dual-space {G}aussian pseudopotentials from {H} to {R}n\u2019), (\u2018volume\u2019, \u201858\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181998\u2019), (\u2018pages\u2019, \u20183641\u20133662\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hartwigsen, C.\u2019), Person(\u2018Goedecker, S.\u2019), Person(\u2018H\\\u201cutter, J.\u2019)])]))",
            "title": "Hartwigsen1998"
        },
        {
            "location": "/bibliography/#haydock1980",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018The recursive solution of the {S}chr\\\u201c{o}dinger equation\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u201820\u2019), (\u2018number\u2019, \u20181\u2019), (\u2018pages\u2019, \u201811 - 16\u2019), (\u2018year\u2019, \u20181980\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180010-4655\u2019), (\u2018doi\u2019, \u201810.1016/0010-4655(80)90101-0\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/0010465580901010\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Haydock, R.\u2019)])]))",
            "title": "Haydock1980"
        },
        {
            "location": "/bibliography/#he2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Accuracy of generalized gradient approximation functionals for density-functional perturbation theory calculations\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Pages\u2019, \u2018064305\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.064305\u2019), (\u2018Volume\u2019, \u201889\u2019), (\u2018Year\u2019, \u20182014\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018He, L.\u2019), Person(\u2018Liu, F.\u2019), Person(\u2018Hautier, G.\u2019), Person(\u2018Oliveira, M. J. T.\u2019), Person(\u2018Marques, M. A. L.\u2019), Person(\u2018Vila, F. D.\u2019), Person(\u2018Rehr, J. J.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Zhou, A.\u2019)])]))",
            "title": "He2014"
        },
        {
            "location": "/bibliography/#hedin1965",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u201cNew Method for Calculating the One-Particle Green\u2019s Function with Application to the Electron-Gas Problem\u201d), (\u2018journal\u2019, \u2018Phys. Rev. A\u2019), (\u2018volume\u2019, \u2018139\u2019), (\u2018pages\u2019, \u2018796\u2019), (\u2018year\u2019, \u20181965\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hedin, L.\u2019)])]))",
            "title": "Hedin1965"
        },
        {
            "location": "/bibliography/#hellwege1985",
            "text": "Entry(\u2018book\u2019, fields=[(\u2018Date-Added\u2019, \u20182014-02-21 11:07:18 +0000\u2019), (\u2018Date-Modified\u2019, \u20182014-03-04 10:21:33 +0000\u2019), (\u2018Publisher\u2019, \u2018Springer\u2019), (\u2018Address\u2019, \u2018Berlin Heidelberg\u2019), (\u2018Title\u2019, \u2018Electrical Resistivity, Thermoelectrical Power and Optical Properties\u2019), (\u2018Volume\u2019, \u201815b\u2019), (\u2018Year\u2019, \u20181985\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Hellwege, K.-H.\u2019), Person(\u2018Olsen, J.L. (Eds.)\u2019)])]))",
            "title": "Hellwege1985"
        },
        {
            "location": "/bibliography/#henkelman2000",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Improved tangent estimate in the nudged elastic band method for finding minimum energy paths and saddle points\u2019), (\u2018journal\u2019, \u2018The Journal of chemical physics\u2019), (\u2018volume\u2019, \u2018113\u2019), (\u2018number\u2019, \u201822\u2019), (\u2018pages\u2019, \u20189978\u20139985\u2019), (\u2018year\u2019, \u20182000\u2019), (\u2018publisher\u2019, \u2018AIP Publishing\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Henkelman, G.\u2019), Person(\u201cJ{\\\u2018o}nsson, H.\u201d)])]))",
            "title": "Henkelman2000"
        },
        {
            "location": "/bibliography/#hermet2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Raman scattering intensities in BaTiO(3) and PbTiO(3) prototypical ferroelectrics from density functional theory.\u2019), (\u2018journal\u2019, \u2018J. Phys. : Condens. Matter\u2019), (\u2018volume\u2019, \u201821\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018215901\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018doi\u2019, \u201810.1088/0953-8984/21/21/215901\u2019), (\u2018publisher\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hermet, P.\u2019), Person(\u2018Veithen, M.\u2019), Person(\u2018Ghosez, P.\u2019)])]))",
            "title": "Hermet2009"
        },
        {
            "location": "/bibliography/#hohenberg1964",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Inhomogeneous Electron Gas\u2019), (\u2018journal\u2019, \u2018Phys. Rev.\u2019), (\u2018volume\u2019, \u2018136\u2019), (\u2018number\u2019, \u20183B\u2019), (\u2018pages\u2019, \u2018B864\u2013B871\u2019), (\u2018year\u2019, \u20181964\u2019), (\u2018doi\u2019, \u201810.1103/PhysRev.136.B864\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Hohenberg, P.\u2019), Person(\u2018Kohn, W.\u2019)])]))",
            "title": "Hohenberg1964"
        },
        {
            "location": "/bibliography/#holzwarth2001",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018A Projector Augmented Wave ({PAW}) code for electronic structure calculations, Part {I}: {ATOMPAW} for generating atom-centered functions\u2019), (\u2018Journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018Volume\u2019, \u2018135\u2019), (\u2018Pages\u2019, \u2018329\u2019), (\u2018year\u2019, \u20182001\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Holzwarth, N.A.W.\u2019), Person(\u2018Tackett, A.R.\u2019), Person(\u2018Matthews, G.E.\u2019)])]))",
            "title": "Holzwarth2001"
        },
        {
            "location": "/bibliography/#hughes1996",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Calculation of second-order optical response in semiconductors\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20181996\u2019), (\u2018Pages\u2019, \u201810751\u201310763\u2019), (\u2018Volume\u2019, \u201853\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.53.10751\u2019), (\u2018Issue\u2019, \u201816\u2019), (\u2018Owner\u2019, \u2018yannick\u2019), (\u2018Publisher\u2019, \u2018American Physical Society\u2019), (\u2018Timestamp\u2019, \u20182015.11.12\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Hughes, J. L. P.\u2019), Person(\u2018Sipe, J. E.\u2019)])]))",
            "title": "Hughes1996"
        },
        {
            "location": "/bibliography/#janssen2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Efficient dielectric matrix calculations using the {L}anczos algorithm for fast many-body {G} _0 {W} _0  implementations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018volume\u2019, \u201891\u2019), (\u2018number\u2019, \u201812\u2019), (\u2018pages\u2019, \u2018125120\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.91.125120\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Laflamme Janssen, J.\u2019), Person(\u2018Rousseau, B.\u2019), Person(\u201cC{\\^o}t{\\\u2018e}, M.\u201d)])]))",
            "title": "Janssen2015"
        },
        {
            "location": "/bibliography/#jollet2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201880\u2019), (\u2018pages\u2019, \u2018235109\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018title\u2019, \u2018Hybrid functional for correlated electrons in the projector augmented-wave formalism: Study of multiple minima for actinide oxides\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Jollet, F.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Amadon, B.\u2019), Person(\u2018Crocombette, J.P.\u2019), Person(\u2018Torumba, D.\u2019)])]))",
            "title": "Jollet2009"
        },
        {
            "location": "/bibliography/#jollet2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018185\u2019), (\u2018pages\u2019, \u20181246-1254\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018title\u2019, \u2018Generation of Projector Augmented-Wave atomic data: a 71 element validated table in the {XML} format\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Jollet, F.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Holzwarth, N.\u2019)])]))",
            "title": "Jollet2014"
        },
        {
            "location": "/bibliography/#kawasuso2005",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electron-positron momentum distributions associated with isolated silicon vacancies in 3 {C}-{S}i {C}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201872\u2019), (\u2018number\u2019, \u20184\u2019), (\u2018pages\u2019, \u2018045204\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Kawasuso, A.\u2019), Person(\u2018Yoshikawa, M.\u2019), Person(\u2018Itoh, H.\u2019), Person(\u2018Chiba, T.\u2019), Person(\u2018Higuchi, T.\u2019), Person(\u2018Betsuyaku, K.\u2019), Person(\u2018Redmann, F.\u2019), Person(\u2018Krause-Rehberg, R.\u2019)])]))",
            "title": "Kawasuso2005"
        },
        {
            "location": "/bibliography/#kingsmith1993",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theory of polarization of crystalline solids\u2019), (\u2018journal\u2019, \u2018Phys. rev. B\u2019), (\u2018volume\u2019, \u201847\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018pages\u2019, \u20181651\u20131654\u2019), (\u2018year\u2019, \u20181993\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018King-Smith, R. D.\u2019), Person(\u2018Vanderbilt, D.\u2019)])]))",
            "title": "Kingsmith1993"
        },
        {
            "location": "/bibliography/#kohn1965",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Self-Consistent Equations Including Exchange and Correlation Effects\u2019), (\u2018journal\u2019, \u2018Phys. Rev.\u2019), (\u2018volume\u2019, \u2018140\u2019), (\u2018number\u2019, \u20184A\u2019), (\u2018pages\u2019, \u2018A1133\u2013A1138\u2019), (\u2018year\u2019, \u20181965\u2019), (\u2018doi\u2019, \u201810.1103/PhysRev.140.A1133\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Kohn, W.\u2019), Person(\u2018Sham, L. J.\u2019)])]))",
            "title": "Kohn1965"
        },
        {
            "location": "/bibliography/#kolos1960",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Accurate Electronic Wave Functions for the H _2  Molecule\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201832\u2019), (\u2018pages\u2019, \u2018219\u2019), (\u2018year\u2019, \u20181960\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Kolos, W.\u2019), Person(\u2018Roothaan, C.C.J.\u2019)])]))",
            "title": "Kolos1960"
        },
        {
            "location": "/bibliography/#kotliar2006",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic structure calculations with dynamical mean-field theory\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018volume\u2019, \u201878\u2019), (\u2018pages\u2019, \u2018865\u2013951\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Review/RMP2006.pdf:PDF\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/RevModPhys.78.865\u2019), (\u2018timestamp\u2019, \u20182012.07.13\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.78.865\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Kotliar, G.\u2019), Person(\u2018Savrasov, S. Y.\u2019), Person(\u2018Haule, K.\u2019), Person(\u2018Oudovenko, V. S.\u2019), Person(\u2018Parcollet, O.\u2019), Person(\u2018Marianetti, C. A.\u2019)])]))",
            "title": "Kotliar2006"
        },
        {
            "location": "/bibliography/#laflamme2016",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Title\u2019, \u2018Precise Effective Masses from Density Functional Perturbation Theory\u2019), (\u2018year\u2019, \u20182016\u2019), (\u2018pages\u2019, \u2018205147\u2019), (\u2018volume\u2019, \u201893\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Laflamme Janssen, J.\u2019), Person(\u2018Gillet, Y.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Martin, A.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Laflamme2016"
        },
        {
            "location": "/bibliography/#lebegue2010",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Title\u2019, \u2018Cohesive Properties and Asymptotics of the Dispersion Interaction in Graphite by the Random Phase Approximation\u2019), (\u2018year\u2019, \u20182010\u2019), (\u2018pages\u2019, \u2018196401\u2019), (\u2018volume\u2019, \u2018105\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Leb\\`egue, S.\u2019), Person(\u2018Harl, J.\u2019), Person(\u2018Gould, T.\u2019), Person(\u201c\\\u2018Angy\\\u2018an, J. G.\u201d), Person(\u2018Kresse, G.\u2019), Person(\u2018Dobson, J. F.\u2019)])]))",
            "title": "Lebegue2010"
        },
        {
            "location": "/bibliography/#lee1995",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Ab-initio calculation of the thermodynamic properties and atomic temperature factors of SiO _2  \\\\alpha -quartz and stishovite\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201851\u2019), (\u2018pages\u2019, \u20188610\u2019), (\u2018year\u2019, \u20181995\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Lee, C.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Lee1995"
        },
        {
            "location": "/bibliography/#lejaeghere2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Error estimates for solid-state density-functional theory predictions: an overview by means of the ground-state elemental crystals\u2019), (\u2018Journal\u2019, \u2018Crit. Rev. Solid State Mater. Sci.\u2019), (\u2018Volume\u2019, \u201839\u2019), (\u2018Pages\u2019, \u20181\u2019), (\u2018year\u2019, \u20182014\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Lejaeghere, K.\u2019), Person(\u2018{V}an {S}peybroeck, V.\u2019), Person(\u2018{V}an {O}ost, G.\u2019), Person(\u2018Cottenier, S.\u2019)])]))",
            "title": "Lejaeghere2014"
        },
        {
            "location": "/bibliography/#levitt2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Parallel eigensolvers in plane-wave Density Functional Theory\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018187\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u201898\u2013105\u2019), (\u2018year\u2019, \u20182015\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Levitt, A.\u2019), Person(\u2018Torrent, M.\u2019)])]))",
            "title": "Levitt2015"
        },
        {
            "location": "/bibliography/#liechtenstein1995",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Density-functional theory and strong interactions: Orbital ordering in Mott-Hubbard insulators\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20181995\u2019), (\u2018volume\u2019, \u201852\u2019), (\u2018pages\u2019, \u2018R5467\u2013R5470\u2019), (\u2018number\u2019, \u20188\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/PhysRevB.52.R5467.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018interaction, LDA+U GGA+U DFT+U\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.52.R5467\u2019), (\u2018timestamp\u2019, \u20182012.06.14\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.52.R5467\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Liechtenstein, A. I.\u2019), Person(\u2018Anisimov, V. I.\u2019), Person(\u2018Zaanen, J.\u2019)])]))",
            "title": "Liechtenstein1995"
        },
        {
            "location": "/bibliography/#lindhard1954",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018On the properties of a gas of charged particles\u2019), (\u2018journal\u2019, \u2018Mat. Fys. Medd. Dan. Vid. Selsk.\u2019), (\u2018year\u2019, \u20181954\u2019), (\u2018volume\u2019, \u201828\u2019), (\u2018pages\u2019, \u20188\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Lindhard, J.\u2019)])]))",
            "title": "Lindhard1954"
        },
        {
            "location": "/bibliography/#luttinger1955",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018{Motion of Electrons and Holes in Perturbed Periodic Fields}\u2019), (\u2018journal\u2019, \u2018Phys. Rev.\u2019), (\u2018year\u2019, \u20181955\u2019), (\u2018volume\u2019, \u201897\u2019), (\u2018number\u2019, \u20184\u2019), (\u2018pages\u2019, \u2018869\u2013883\u2019), (\u2018doi\u2019, \u201810.1103/PhysRev.97.869\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Luttinger, J.M.\u2019), Person(\u2018Kohn, W.\u2019)])]))",
            "title": "Luttinger1955"
        },
        {
            "location": "/bibliography/#ma2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Constrained density functional for noncollinear magnetism\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201891\u2019), (\u2018issue\u2019, \u20185\u2019), (\u2018pages\u2019, \u2018054420\u2019), (\u2018numpages\u2019, \u201811\u2019), (\u2018year\u2019, \u20182015\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Ma, Pui-Wai\u2019), Person(\u2018Dudarev, S. L.\u2019)])]))",
            "title": "Ma2015"
        },
        {
            "location": "/bibliography/#maintz2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Speeding up plane-wave electronic-structure calculations using graphics-processing units\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018volume\u2019, \u2018182\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018pages\u2019, \u20181421\u20131427\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Maintz, S.\u2019), Person(\u2018Eck, B.\u2019), Person(\u2018Dronskowski, R.\u2019)])]))",
            "title": "Maintz2012"
        },
        {
            "location": "/bibliography/#marek2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018The {ELPA} library: scalable parallel eigenvalue solutions for electronic structure theory and computational science\u2019), (\u2018journal\u2019, \u2018J. Phys.: Cond. Matt.\u2019), (\u2018volume\u2019, \u201826\u2019), (\u2018number\u2019, \u201821\u2019), (\u2018pages\u2019, \u20181\u201315\u2019), (\u2018year\u2019, \u20182014\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Marek, A.\u2019), Person(\u2018Blum, V.\u2019), Person(\u2018Johanni, R.\u2019), Person(\u2018Havu, V.\u2019), Person(\u2018Lang, B.\u2019), Person(\u2018Auckenthaler, T.\u2019), Person(\u2018Heinecke, A.\u2019), Person(\u2018Bungartz, H.-J.\u2019), Person(\u2018Lederer, H.\u2019)])]))",
            "title": "Marek2014"
        },
        {
            "location": "/bibliography/#marques2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018doi\u2019, \u201810.1016/j.cpc.2012.05.007\u2019), (\u2018issn\u2019, \u201800104655\u2019), (\u2018journal\u2019, \u2018Comput. Phys. Commun.\u2019), (\u2018pages\u2019, \u20182272\u20132281\u2019), (\u2018title\u2019, \u2018{Libxc: A library of exchange and correlation functionals for density functional theory}\u2019), (\u2018volume\u2019, \u2018183\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Marques, M. A. L.\u2019), Person(\u2018Oliveira, M. J. T.\u2019), Person(\u2018Burnus, T.\u2019)])]))",
            "title": "Marques2012"
        },
        {
            "location": "/bibliography/#marx1996",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Ab initio path integral molecular dynamics: Basic ideas\u2019), (\u2018Journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018Volume\u2019, \u2018104\u2019), (\u2018Pages\u2019, \u20184077\u2019), (\u2018year\u2019, \u20181996\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Marx, D.\u2019), Person(\u2018Parrinello, M.\u2019)])]))",
            "title": "Marx1996"
        },
        {
            "location": "/bibliography/#mecholsky2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018{Theory of band warping and its effects on thermoelectronic transport properties}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018number\u2019, \u201815\u2019), (\u2018pages\u2019, \u2018155131\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.89.155131\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Mecholsky, N.A.\u2019), Person(\u2018Resca, L.\u2019), Person(\u2018Pegg, I.L.\u2019), Person(\u2018Fornari, M.\u2019)])]))",
            "title": "Mecholsky2014"
        },
        {
            "location": "/bibliography/#medeiros2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Effects of extrinsic and intrinsic perturbations on the electronic structure of graphene: Retaining an effective primitive cell band structure by band unfolding\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182014\u2019), (\u2018Pages\u2019, \u2018041407\u2019), (\u2018Volume\u2019, \u201889\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Medeiros, Paulo V. C.\u2019), Person(\u2018Stafstr\\\u201com, Sven\u2019), Person(\u2018Bj\\\u201cork, Jonas\u2019)])]))",
            "title": "Medeiros2014"
        },
        {
            "location": "/bibliography/#methfessel1989",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018High-precision sampling for Brillouin-Zone integration in metals\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201840\u2019), (\u2018pages\u2019, \u20183616\u2019), (\u2018year\u2019, \u20181989\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Methfessel, M.\u2019), Person(\u2018Paxton, T.\u2019)])]))",
            "title": "Methfessel1989"
        },
        {
            "location": "/bibliography/#mills1994",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Quantum and thermal effects in H _2  dissociative adsorption: Evaluation of free energy barriers in multidimensional quantum systems\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u201872\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018pages\u2019, \u20181124\u2019), (\u2018year\u2019, \u20181994\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Mills, G.\u2019), Person(\u201cJ{\\\u2018o}nsson, H.\u201d)])]))",
            "title": "Mills1994"
        },
        {
            "location": "/bibliography/#momma2011",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018{VESTA}3 for three-dimensional visualization of crystal, volumetric and morphology data\u2019), (\u2018Journal\u2019, \u2018J. Appl. Crystallogr.\u2019), (\u2018Year\u2019, \u20182011\u2019), (\u2018Number\u2019, \u20186\u2019), (\u2018Pages\u2019, \u20181272\u20131276\u2019), (\u2018Volume\u2019, \u201844\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Momma, K.\u2019), Person(\u2018Izumi, F.\u2019)])]))",
            "title": "Momma2011"
        },
        {
            "location": "/bibliography/#moscaconte2007",
            "text": "Entry(\u2018phdthesis\u2019, fields=[(\u2018title\u2019, \u2018Quantum mechanical modeling of nano magnetism\u2019), (\u2018school\u2019, \u2018SISSA\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018address\u2019, \u2018Trieste Italy\u2019), (\u2018optURI\u2019, \u2018http://hdl.handle.net/20.500.11767/3935\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Mosca Conte, A.\u2019)])]))",
            "title": "Moscaconte2007"
        },
        {
            "location": "/bibliography/#nieminen1985",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Two-component density-functional theory: Application to positron states\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201832\u2019), (\u2018issue\u2019, \u20182\u2019), (\u2018pages\u2019, \u20181377\u2019), (\u2018year\u2019, \u20181985\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.32.1377\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Nieminen, R. M.\u2019), Person(\u201cBoro\\\u2018nski, E.\u201d), Person(\u2018Lantto, L. J.\u2019)])]))",
            "title": "Nieminen1985"
        },
        {
            "location": "/bibliography/#nunes2001",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Berry-phase treatment of the homogeneous electric field perturbation in insulators\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201863\u2019), (\u2018number\u2019, \u201815\u2019), (\u2018pages\u2019, \u2018155107\u2019), (\u2018year\u2019, \u20182001\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Nunes, R. W.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Nunes2001"
        },
        {
            "location": "/bibliography/#ong2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Python Materials Genomics (pymatgen): A robust, open-source python library for materials analysis\u2019), (\u2018journal\u2019, \u2018Comp. Mat. Sci.\u2019), (\u2018volume\u2019, \u201868\u2019), (\u2018number\u2019, \u20180\u2019), (\u2018pages\u2019, \u2018314 - 319\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180927-0256\u2019), (\u2018doi\u2019, \u201810.1016/j.commatsci.2012.10.028\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S0927025612006295\u2019), (\u2018keywords\u2019, \u2018High-throughput\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Ong, S.P.\u2019), Person(\u2018Richards, W.D.\u2019), Person(\u2018Jain, A.\u2019), Person(\u2018Hautier, G.\u2019), Person(\u2018Kocher, M.\u2019), Person(\u2018Cholia, S.\u2019), Person(\u2018Gunter, D.\u2019), Person(\u2018Chevrier, V.L.\u2019), Person(\u2018Persson, K.A.\u2019), Person(\u2018Ceder, G.\u2019)])]))",
            "title": "Ong2013"
        },
        {
            "location": "/bibliography/#onida2002",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u201cElectronic excitations: density-functional versus many-body Green\u2019s-function approaches\u201d), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018year\u2019, \u20182002\u2019), (\u2018volume\u2019, \u201874\u2019), (\u2018pages\u2019, \u2018601\u2013659\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.74.601\u2019), (\u2018numpages\u2019, \u201858\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Onida, G.\u2019), Person(\u2018Reining, L.\u2019), Person(\u2018Rubio, A.\u2019)])]))",
            "title": "Onida2002"
        },
        {
            "location": "/bibliography/#payne1992",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Iterative minimization techniques for \\textit{ab initio} total-energy calculations: molecular dynamics and conjugate gradients\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201864\u2019), (\u2018issue\u2019, \u20184\u2019), (\u2018pages\u2019, \u20181045\u20131097\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181992\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.64.1045\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Payne, M. C.\u2019), Person(\u2018Teter, M. P.\u2019), Person(\u2018Allan, D. C.\u2019), Person(\u2018Arias, T. A.\u2019), Person(\u2018Joannopoulos, J. D.\u2019)])]))",
            "title": "Payne1992"
        },
        {
            "location": "/bibliography/#perdew1981",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Self-interaction correction to density-functional approximations for many-electron systems\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201823\u2019), (\u2018pages\u2019, \u20185048\u2019), (\u2018year\u2019, \u20181981\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Perdew, J.P.\u2019), Person(\u2018Zunger, A.\u2019)])]))",
            "title": "Perdew1981"
        },
        {
            "location": "/bibliography/#perrot1979",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Gradient correction to the statistical electronic free energy at non-zero temperatures: Application to equation-of-state calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. A\u2019), (\u2018volume\u2019, \u201820\u2019), (\u2018pages\u2019, \u2018586-594\u2019), (\u2018year\u2019, \u20181979\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Perrot, F.\u2019)])]))",
            "title": "Perrot1979"
        },
        {
            "location": "/bibliography/#pickett1988",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Smooth Fourier interpolation of periodic functions\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201838\u2019), (\u2018pages\u2019, \u20182721\u2019), (\u2018year\u2019, \u20181988\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Warren E. Pickett, Henry Krakauer,\u2019), Person(\u2018Allen, Philip B.\u2019)])]))",
            "title": "Pickett1988"
        },
        {
            "location": "/bibliography/#ponce2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Verification of first-principles codes: Comparison of total energies, phonon frequencies, electron\u2013phonon coupling and zero-point motion correction to the gap between {ABINIT} and {QE}/{Y}ambo\u2019), (\u2018journal\u2019, \u2018Comp. Mat. Sci.\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201883\u2019), (\u2018pages\u2019, \u2018341 - 348\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Antonius, G.\u2019), Person(\u2018Boulanger, P.\u2019), Person(\u2018Cannuccia, E.\u2019), Person(\u2018Marini, A.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Ponce2014"
        },
        {
            "location": "/bibliography/#ponce2014a",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Temperature dependence of electronic eigenenergies in the adiabatic harmonic approximation\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018volume\u2019, \u201890\u2019), (\u2018pages\u2019, \u2018214304\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Antonius, G.\u2019), Person(\u2018Gillet, Y.\u2019), Person(\u2018Boulanger, P.\u2019), Person(\u2018Laflamme Janssen, J.\u2019), Person(\u2018Marini, A.\u2019), Person(\u201cC\\^ot\\\u2018e, M.\u201d), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Ponce2014a"
        },
        {
            "location": "/bibliography/#ponce2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Temperature dependence of the electronic structure of semiconductors and insulators\u2019), (\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018volume\u2019, \u2018143\u2019), (\u2018pages\u2019, \u2018102813\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Gillet, Y.\u2019), Person(\u2018Laflamme Janssen, J.\u2019), Person(\u2018Marini, A.\u2019), Person(\u2018Verstraete, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Ponce2015"
        },
        {
            "location": "/bibliography/#popescu2010",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Effective Band Structure of Random Alloys\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Year\u2019, \u20182010\u2019), (\u2018Pages\u2019, \u2018236403\u2019), (\u2018Volume\u2019, \u2018104\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Popescu, V.\u2019), Person(\u2018Zunger, A.\u2019)])]))",
            "title": "Popescu2010"
        },
        {
            "location": "/bibliography/#popescu2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Extracting E versus k effective band structure from supercell calculations on alloys and impurities\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182012\u2019), (\u2018Pages\u2019, \u2018085201\u2019), (\u2018Volume\u2019, \u201885\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Popescu, V.\u2019), Person(\u2018Zunger, A.\u2019)])]))",
            "title": "Popescu2012"
        },
        {
            "location": "/bibliography/#pouillon2011",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Organizing software growth and distributed development: the case of {ABINIT}\u2019), (\u2018Journal\u2019, \u2018Comput. Sci. Eng.\u2019), (\u2018Volume\u2019, \u201813\u2019), (\u2018Pages\u2019, \u201862\u2019), (\u2018year\u2019, \u20182011\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Pouillon, Y.\u2019), Person(\u2018Beuken, J. -M.\u2019), Person(\u2018Deutsch, T.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Pouillon2011"
        },
        {
            "location": "/bibliography/#puska1994",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Theory of positrons in solids and on solid surfaces\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201866\u2019), (\u2018issue\u2019, \u20183\u2019), (\u2018pages\u2019, \u2018841\u2019), (\u2018year\u2019, \u20181994\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.66.841\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Puska, M. J.\u2019), Person(\u2018Nieminen, R. M.\u2019)])]))",
            "title": "Puska1994"
        },
        {
            "location": "/bibliography/#puska1995",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electron-positron {C}ar-{P}arrinello methods: {S}elf-consistent treatment of charge densities and ionic relaxations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201852\u2019), (\u2018issue\u2019, \u201815\u2019), (\u2018pages\u2019, \u201810947\u2019), (\u2018year\u2019, \u20181995\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.52.10947\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Puska, M. J.\u2019), Person(\u2018Seitsonen, A. P.\u2019), Person(\u2018Nieminen, R. M.\u2019)])]))",
            "title": "Puska1995"
        },
        {
            "location": "/bibliography/#rangel2016",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018A wavelet-based Projector Augmented-Wave ({PAW}) method: {R}eaching frozen-core all-electron precision with a systematic, adaptive and localized wavelet basis set\u2019), (\u2018volume\u2019, \u2018208\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018journal\u2019, \u2018Computer Physics Communication\u2019), (\u2018year\u2019, \u20182016\u2019), (\u2018pages\u2019, \u20181-8\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rangel, T.\u2019), Person(\u2018Caliste, D.\u2019), Person(\u2018Genovese, L.\u2019), Person(\u2018Torrent, M.\u2019)])]))",
            "title": "Rangel2016"
        },
        {
            "location": "/bibliography/#rappe1990",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Optimized pseudopotentials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201841\u2019), (\u2018issue\u2019, \u20182\u2019), (\u2018pages\u2019, \u20181227\u20131230\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20181990\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.41.1227\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rappe, A.M.\u2019), Person(\u2018Rabe, K.M.\u2019), Person(\u2018Kaxiras, E.S.\u2019), Person(\u2018Joannopoulos, J.D.\u2019)])]))",
            "title": "Rappe1990"
        },
        {
            "location": "/bibliography/#rauch2011",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Identifying vacancy complexes in compound semiconductors with positron annihilation spectroscopy: A case study of {I}n{N}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201884\u2019), (\u2018number\u2019, \u201812\u2019), (\u2018pages\u2019, \u2018125201\u2019), (\u2018year\u2019, \u20182011\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rauch, C.\u2019), Person(\u2018Makkonen, I.\u2019), Person(\u2018Tuomisto, F.\u2019)])]))",
            "title": "Rauch2011"
        },
        {
            "location": "/bibliography/#resta1994",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Macroscopic polarization in crystalline dielectrics: the geometric phase approach\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201866\u2019), (\u2018pages\u2019, \u2018899\u2013915\u2019), (\u2018year\u2019, \u20181994\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Resta, R.\u2019)])]))",
            "title": "Resta1994"
        },
        {
            "location": "/bibliography/#restrepo2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-principles calculations of electron mobilities in silicon: Phonon and Coulomb scattering\u2019), (\u2018journal\u2019, \u2018App. Phys. Lett.\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018volume\u2019, \u201894\u2019), (\u2018number\u2019, \u201821\u2019), (\u2018eid\u2019, \u2018212103\u2019), (\u2018pages\u2019, \u2018\u2019), (\u2018url\u2019, \u2018http://scitation.aip.org/content/aip/journal/apl/94/21/10.1063/1.3147189\u2019), (\u2018doi\u2019, \u201810.1063/1.3147189\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Restrepo, O. D.\u2019), Person(\u2018Varga, K.\u2019), Person(\u2018Pantelides, S. T.\u2019)])]))",
            "title": "Restrepo2009"
        },
        {
            "location": "/bibliography/#rieger1999",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018The {GW} space-time method for the self-energy of large systems\u2019), (\u2018journal\u2019, \u2018Comp. Phys. Comm.\u2019), (\u2018year\u2019, \u20181999\u2019), (\u2018volume\u2019, \u2018117\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018pages\u2019, \u2018211\u2013228\u2019), (\u2018doi\u2019, \u201810.1016/S0010-4655(98)00174-X\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rieger, M.\u2019), Person(\u2018Steinbeck, L.\u2019), Person(\u2018White, I. D.\u2019), Person(\u2018Rojas, H. N.\u2019), Person(\u2018Godby, R. W.\u2019)])]))",
            "title": "Rieger1999"
        },
        {
            "location": "/bibliography/#rohlfing2000",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Electron-hole excitations and optical spectra from first principles\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182000\u2019), (\u2018Pages\u2019, \u20184927\u20134944\u2019), (\u2018Volume\u2019, \u201862\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.62.4927\u2019), (\u2018File\u2019, \u2018Rohlfing2000.pdf:Rohlfing2000.pdf:PDF;Rohlfing2000.pdf:Rohlfing2000.pdf:PDF\u2019), (\u2018Issue\u2019, \u20188\u2019), (\u2018Publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Rohlfing, M.\u2019), Person(\u2018Louie, S.G.\u2019)])]))",
            "title": "Rohlfing2000"
        },
        {
            "location": "/bibliography/#romanperez2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Efficient Implementation of a {V}an der {W}aals Density Functional: Application to Double-Wall Carbon Nanotubes\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018103\u2019), (\u2018pages\u2019, \u2018096102\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.103.096102\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cRom\\\u2018an-P\\\u2018erez, G.\u201d), Person(\u2018Soler, J.M.\u2019)])]))",
            "title": "Romanperez2009"
        },
        {
            "location": "/bibliography/#rostgaard2006",
            "text": "Entry(\u2018mastersthesis\u2019, fields=[(\u2018Title\u2019, \u2018Exact exchange in density functional calculations\u2019), (\u2018School\u2019, \u2018Technical University of Denmark\u2019), (\u2018Address\u2019, \u2018Lyngby\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018url\u2019, \u2018https://wiki.fysik.dtu.dk/gpaw/_downloads/rostgaard_master.pdf\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Rostgaard, C.\u2019)])]))",
            "title": "Rostgaard2006"
        },
        {
            "location": "/bibliography/#rubel2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Unfolding the band structure of disordered solids: from bound states to high-mobility Kane fermions\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182014\u2019), (\u2018Pages\u2019, \u2018115202\u2019), (\u2018Volume\u2019, \u201890\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Rubel, O.\u2019), Person(\u2018Bokhanchuk, A.\u2019), Person(\u2018Ahmed, S. J.\u2019), Person(\u2018Assmann, E.\u2019)])]))",
            "title": "Rubel2014"
        },
        {
            "location": "/bibliography/#rutishauser1970",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Simultaneous iteration method for symmetric matrices\u2019), (\u2018journal\u2019, \u2018Numerische Mathematik\u2019), (\u2018volume\u2019, \u201816\u2019), (\u2018number\u2019, \u20183\u2019), (\u2018pages\u2019, \u2018205\u2013223\u2019), (\u2018year\u2019, \u20181970\u2019), (\u2018publisher\u2019, \u2018Springer\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Rutishauser, H.\u2019)])]))",
            "title": "Rutishauser1970"
        },
        {
            "location": "/bibliography/#sakuma2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-principles calculations of dynamical screened interactions for the transition metal oxides {MO} ({M}={M}n, {F}e, {C}o, {N}i)\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018volume\u2019, \u201887\u2019), (\u2018pages\u2019, \u2018165118\u2019), (\u2018number\u2019, \u201816\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/PhysRevB.87.165118.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018cRPA\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.87.165118\u2019), (\u2018timestamp\u2019, \u20182013.06.04\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.87.165118\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Sakuma, R.\u2019), Person(\u2018Aryasetiawan, F.\u2019)])]))",
            "title": "Sakuma2013"
        },
        {
            "location": "/bibliography/#savin1992",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electron Localization in Solid-State Structures of the Elements: the Diamond Structure\u2019), (\u2018journal\u2019, \u2018Angewandte Chemie International Edition in English\u2019), (\u2018volume\u2019, \u201831\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018doi\u2019, \u201810.1002/anie.199201871\u2019), (\u2018pages\u2019, \u2018187\u2013188\u2019), (\u2018year\u2019, \u20181992\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Savin, A.\u2019), Person(\u2018Jepsen, O.\u2019), Person(\u2018Flad, J.\u2019), Person(\u2018Andersen, O. K.\u2019), Person(\u2018Preuss, H.\u2019), Person(\u2018von Schnering, H. G.\u2019)])]))",
            "title": "Savin1992"
        },
        {
            "location": "/bibliography/#savrasov1996",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018PAGES\u2019, \u201816487\u2019), (\u2018YEAR\u2019, \u20181996\u2019), (\u2018TITLE\u2019, \u2018Electron-phonon interactions and related physical properties of metals from linear-response theory\u2019), (\u2018VOLUME\u2019, \u201854\u2019), (\u2018JOURNAL\u2019, \u2018Phys. Rev. B\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018AUTHOR\u2019, [Person(\u2018Savrasov, S.Y.\u2019), Person(\u2018Savrasov, D.Y.\u2019)])]))",
            "title": "Savrasov1996"
        },
        {
            "location": "/bibliography/#sharma2003",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Linear and second-order optical response of {III}-{V} monolayer superlattices\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20182003\u2019), (\u2018Pages\u2019, \u2018165332\u2019), (\u2018Volume\u2019, \u201867\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.67.165332\u2019), (\u2018Issue\u2019, \u201816\u2019), (\u2018Url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.67.165332\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Sharma, S.\u2019), Person(\u2018Dewhurst, J. K.\u2019), Person(\u2018Ambrosch-Draxl, C.\u2019)])]))",
            "title": "Sharma2003"
        },
        {
            "location": "/bibliography/#sharma2004",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018{S}econd-{H}armonic Optical Response from First Principles\u2019), (\u2018Journal\u2019, \u2018Phys. Scripta\u2019), (\u2018Year\u2019, \u20182004\u2019), (\u2018Pages\u2019, \u2018128\u2019), (\u2018Volume\u2019, \u20182004\u2019), (\u2018Url\u2019, \u2018http://iopscience.iop.org/article/10.1238/Physica.Topical.109a00128\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Sharma, S.\u2019), Person(\u2018{A}mbrosch-{D}raxl, C.\u2019)])]))",
            "title": "Sharma2004"
        },
        {
            "location": "/bibliography/#shih2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Screened Coulomb interaction of localized electrons in solids from first principles\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182012\u2019), (\u2018volume\u2019, \u201885\u2019), (\u2018pages\u2019, \u2018045132\u2019), (\u2018number\u2019, \u20184\u2019), (\u2018file\u2019, \u2018:/media/disk_iomega/BIBLIO/Interaction/PhysRevB.85.045132.pdf:PDF\u2019), (\u2018keywords\u2019, \u2018cRPA pseudopotentials\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevB.85.045132\u2019), (\u2018timestamp\u2019, \u20182012.06.19\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.85.045132\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Shih, B.-C.\u2019), Person(\u2018Zhang, Y.\u2019), Person(\u2018Zhang, W.\u2019), Person(\u2018Zhang, P.\u2019)])]))",
            "title": "Shih2012"
        },
        {
            "location": "/bibliography/#silvestrelli2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018053002\u2019), (\u2018title\u2019, \u2018van der {W}aals Interactions in {DFT} Made Easy by {W}annier Functions\u2019), (\u2018volume\u2019, \u2018100\u2019), (\u2018year\u2019, \u20182008\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Silvestrelli, P. L.\u2019)])]))",
            "title": "Silvestrelli2008"
        },
        {
            "location": "/bibliography/#silvestrelli2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018J. Phys. Chem. A\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u20185224\u2019), (\u2018title\u2019, \u2018van der {W}aals Interactions in Density Functional Theory Using {W}annier Functions\u2019), (\u2018volume\u2019, \u2018113\u2019), (\u2018year\u2019, \u20182009\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Silvestrelli, P. L.\u2019)])]))",
            "title": "Silvestrelli2009"
        },
        {
            "location": "/bibliography/#silvestrelli2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018number\u2019, \u2018\u2019), (\u2018pages\u2019, \u2018054106\u2019), (\u2018title\u2019, \u2018van der {W}aals interactions in density functional theory by combining the quantum harmonic oscillator-model with localized {W}annier functions\u2019), (\u2018volume\u2019, \u2018139\u2019), (\u2018year\u2019, \u20182013\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Silvestrelli, P. L.\u2019)])]))",
            "title": "Silvestrelli2013"
        },
        {
            "location": "/bibliography/#sipe1993",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Nonlinear optical response of semiconductors in the independent-particle approximation\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Year\u2019, \u20181993\u2019), (\u2018Pages\u2019, \u201811705\u201311722\u2019), (\u2018Volume\u2019, \u201848\u2019), (\u2018Doi\u2019, \u201810.1103/PhysRevB.48.11705\u2019), (\u2018Issue\u2019, \u201816\u2019), (\u2018Url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.48.11705\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Sipe, J. E.\u2019), Person(\u2018Ghahramani, E.\u2019)])]))",
            "title": "Sipe1993"
        },
        {
            "location": "/bibliography/#snyder2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018journal\u2019, \u2018Nature Materials\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u2018105\u2013114\u2019), (\u2018title\u2019, \u2018Complex thermoelectric materials\u2019), (\u2018volume\u2019, \u20187\u2019), (\u2018year\u2019, \u20182008\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Snyder, G. J.\u2019), Person(\u2018Toberer, E. S.\u2019)])]))",
            "title": "Snyder2008"
        },
        {
            "location": "/bibliography/#souza2002",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-Principles Approach to Insulators in Finite Electric Fields\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018pages\u2019, \u2018117602\u2019), (\u2018year\u2019, \u20182002\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Souza, I.\u2019), Person(\u201c\\\u2018I\\ niguez, J.\u201d), Person(\u2018Vanderbilt, D.\u2019)])]))",
            "title": "Souza2002"
        },
        {
            "location": "/bibliography/#sterne1991",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018First-principles calculation of positron lifetimes in solids\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201843\u2019), (\u2018number\u2019, \u201817\u2019), (\u2018pages\u2019, \u201813892\u2019), (\u2018year\u2019, \u20181991\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Sterne, P.A.\u2019), Person(\u2018Kaiser, J.H.\u2019)])]))",
            "title": "Sterne1991"
        },
        {
            "location": "/bibliography/#torrent2008",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Implementation of the projector augmented-wave method in the {ABINIT} code: Application to the study of iron under pressure\u2019), (\u2018journal\u2019, \u2018Computational Materials Science\u2019), (\u2018volume\u2019, \u201842\u2019), (\u2018number\u2019, \u20182\u2019), (\u2018pages\u2019, \u2018337 - 351\u2019), (\u2018year\u2019, \u20182008\u2019), (\u2018note\u2019, \u2018\u2019), (\u2018issn\u2019, \u20180927-0256\u2019), (\u2018doi\u2019, \u201810.1016/j.commatsci.2007.07.020\u2019), (\u2018url\u2019, \u2018http://www.sciencedirect.com/science/article/pii/S0927025607002108\u2019), (\u2018keywords\u2019, \u2018Iron under pressure\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Torrent, Marc\u2019), Person(\u2018Jollet, Fran\\c{c}ois\u2019), Person(\u2018Bottin, Fran\\c{c}ois\u2019), Person(\u201cZ\\\u2018erah, Gilles\u201d), Person(\u2018Gonze, Xavier\u2019)])]))",
            "title": "Torrent2008"
        },
        {
            "location": "/bibliography/#tran2009",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Accurate Band Gaps of Semiconductors and Insulators with a Semilocal Exchange-Correlation Potential\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018volume\u2019, \u2018102\u2019), (\u2018issue\u2019, \u201822\u2019), (\u2018pages\u2019, \u2018226401\u2019), (\u2018numpages\u2019, \u20184\u2019), (\u2018year\u2019, \u20182009\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevLett.102.226401\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevLett.102.226401\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Tran, F.\u2019), Person(\u2018Blaha, P.\u2019)])]))",
            "title": "Tran2009"
        },
        {
            "location": "/bibliography/#tremblay2017",
            "text": "Entry(\u2018misc\u2019, fields=[(\u2018title\u2019, \u2018Probl\\ eme \\\\ a N-corps\u2019), (\u2018note\u2019, \u2018Notes de cours\u2019), (\u2018howpublished\u2019, \u2018available  here \u2018), (\u2018url\u2019, \u2018https://www.physique.usherbrooke.ca/pages/en/node/3436\u2019), (\u2018year\u2019, \u20182017\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cTremblay, Andr\\\u2018e-Marie\u201d)])]))",
            "title": "Tremblay2017"
        },
        {
            "location": "/bibliography/#troullier1991",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018Pages\u2019, \u20181993\u2019), (\u2018Title\u2019, \u2018Efficient pseudopotentials for plane-wave calculation\u2019), (\u2018Volume\u2019, \u201843\u2019), (\u2018Year\u2019, \u20181991\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Troullier, N.\u2019), Person(\u2018Martins, J.L.\u2019)])]))",
            "title": "Troullier1991"
        },
        {
            "location": "/bibliography/#tuckerman1996",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Efficient and general algorithms for path integral {C}ar\u2013{P}arrinello molecular dynamics\u2019), (\u2018Journal\u2019, \u2018J. Chem. Phys.\u2019), (\u2018Volume\u2019, \u2018104\u2019), (\u2018Pages\u2019, \u20185579\u2019), (\u2018year\u2019, \u20181996\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Tuckerman, M. E.\u2019), Person(\u2018Marx, D.\u2019), Person(\u2018Klein, M. L.\u2019), Person(\u2018Parrinello, M.\u2019)])]))",
            "title": "Tuckerman1996"
        },
        {
            "location": "/bibliography/#tuomisto2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Defect identification in semiconductors with positron annihilation: Experiment and theory\u2019), (\u2018journal\u2019, \u2018Rev. Mod. Phys.\u2019), (\u2018volume\u2019, \u201885\u2019), (\u2018issue\u2019, \u20184\u2019), (\u2018pages\u2019, \u20181583\u2019), (\u2018numpages\u2019, \u20180\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/RevModPhys.85.1583\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Tuomisto, F.\u2019), Person(\u2018Makkonen, I.\u2019)])]))",
            "title": "Tuomisto2013"
        },
        {
            "location": "/bibliography/#uehara2000",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Calculations of transport properties with the linearized augmented plane-wave method\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201861\u2019), (\u2018pages\u2019, \u20181639\u2019), (\u2018year\u2019, \u20182000\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Uehara, Kentaro\u2019), Person(\u2018Tse, John S.\u2019)])]))",
            "title": "Uehara2000"
        },
        {
            "location": "/bibliography/#vanderbilt1998",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic polarization in the ultrasoft pseudopotential formalism\u2019), (\u2018journal\u2019, \u2018arXiv/cond-mat\u2019), (\u2018eprint\u2019, \u20189801177\u2019), (\u2018url\u2019, \u2018https://arxiv.org/abs/cond-mat/9801177\u2019), (\u2018year\u2019, \u20181998\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Vanderbilt, D.\u2019), Person(\u2018{K}ing-{S}mith, R. D.\u2019)])]))",
            "title": "Vanderbilt1998"
        },
        {
            "location": "/bibliography/#vantroeye2016",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Interatomic force constants including the DFT-D dispersion contribution\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201893\u2019), (\u2018pages\u2019, \u2018144304\u2019), (\u2018year\u2019, \u20182016\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Troeye, B. Van\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Vantroeye2016"
        },
        {
            "location": "/bibliography/#veithen2005",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Nonlinear optical susceptibilities, Raman efficiencies, and electrooptic tensors from first\u2013principles density functional theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201871\u2019), (\u2018pages\u2019, \u2018125107\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.71.125107\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Veithen, M.\u2019), Person(\u2018Gonze, X.\u2019), Person(\u2018Ghosez, Ph.\u2019)])]))",
            "title": "Veithen2005"
        },
        {
            "location": "/bibliography/#veithen2005a",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Temperature dependence of the electro-optic tensor and refractive indices of Ba Ti O 3 from first principles\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201871\u2019), (\u2018pages\u2019, \u2018132101\u2019), (\u2018year\u2019, \u20182005\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.71.132101\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Veithen, M.\u2019), Person(\u2018Ghosez, Ph.\u2019)])]))",
            "title": "Veithen2005a"
        },
        {
            "location": "/bibliography/#wang1998",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018Majority Representation of Alloy Electronic States\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Year\u2019, \u20181998\u2019), (\u2018Pages\u2019, \u20184725\u2019), (\u2018Volume\u2019, \u201880\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Wang, L.-W.\u2019), Person(\u2018Bellaiche, L.\u2019), Person(\u2018Wei, S.-H.\u2019), Person(\u2018Zunger, A.\u2019)])]))",
            "title": "Wang1998"
        },
        {
            "location": "/bibliography/#wang2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Title\u2019, \u2018The Criteria for Beneficial Disorder in Thermoelectric Solid Solutions\u2019), (\u2018Journal\u2019, \u2018Adv. Funct. Mater.\u2019), (\u2018Year\u2019, \u20182013\u2019), (\u2018Number\u2019, \u201812\u2019), (\u2018Pages\u2019, \u20181586\u20131596\u2019), (\u2018Volume\u2019, \u201823\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Wang, H.\u2019), Person(\u2018LaLonde, A. D.\u2019), Person(\u2018Pei, Y.\u2019), Person(\u2018Snyder, G. J.\u2019)])]))",
            "title": "Wang2013"
        },
        {
            "location": "/bibliography/#waroquiers2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Band widths and gaps from the {T}ran-{B}laha functional: Comparison with many-body perturbation theory\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018volume\u2019, \u201887\u2019), (\u2018pages\u2019, \u2018075121\u2019), (\u2018doi\u2019, \u2018\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Waroquiers, D.\u2019), Person(\u2018Lherbier, A.\u2019), Person(\u2018Miglio, A.\u2019), Person(\u2018Stankovski, M.\u2019), Person(\u201cPonc\\\u2018e, S.\u201d), Person(\u2018Oliveira, M.J.T.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Rignanese, G.-M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Waroquiers2013"
        },
        {
            "location": "/bibliography/#weinan2007",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Simplified and improved string method for computing the minimum energy paths in barrier-crossing events\u2019), (\u2018journal\u2019, \u2018The Journal of Chemical Physics\u2019), (\u2018volume\u2019, \u2018126\u2019), (\u2018number\u2019, \u201816\u2019), (\u2018pages\u2019, \u2018164103\u2019), (\u2018year\u2019, \u20182007\u2019), (\u2018publisher\u2019, \u2018AIP Publishing\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Weinan, E.\u2019), Person(\u2018Ren, W.\u2019), Person(\u2018Vanden-Eijnden, E.\u2019)])]))",
            "title": "Weinan2007"
        },
        {
            "location": "/bibliography/#werner2006",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Continuous-Time Solver for Quantum Impurity Models\u2019), (\u2018journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018volume\u2019, \u201897\u2019), (\u2018pages\u2019, \u2018076405\u2019), (\u2018number\u2019, \u20187\u2019), (\u2018owner\u2019, \u2018amadonb\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018refid\u2019, \u201810.1103/PhysRevLett.97.076405\u2019), (\u2018timestamp\u2019, \u20182013.05.22\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevLett.97.076405\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Werner, P.\u2019), Person(\u2018Comanac, A.\u2019), Person(\u2018de Medici, L.\u2019), Person(\u2018Troyer, M.\u2019), Person(\u2018Millis, A.J.\u2019)])]))",
            "title": "Werner2006"
        },
        {
            "location": "/bibliography/#wiktor2013",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic structure investigation of energetics and positron lifetimes of fully relaxed monovacancies with various charge states in 3{C}-{S}i{C} and 6{H}-{S}i{C}\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201887\u2019), (\u2018pages\u2019, \u2018235207\u2019), (\u2018numpages\u2019, \u201812\u2019), (\u2018year\u2019, \u20182013\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.87.235207\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Bertolus, M.\u2019)])]))",
            "title": "Wiktor2013"
        },
        {
            "location": "/bibliography/#wiktor2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Positron annihilation spectroscopy investigation of vacancy clusters in silicon carbide: Combining experiments and electronic structure calculations\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201889\u2019), (\u2018number\u2019, \u201815\u2019), (\u2018pages\u2019, \u2018155203\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Kerbiriou, X.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Esnouf, S.\u2019), Person(\u2018Barthe, M.-F.\u2019), Person(\u2018Bertolus, M.\u2019)])]))",
            "title": "Wiktor2014"
        },
        {
            "location": "/bibliography/#wiktor2014a",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Coupled experimental and {DFT}+{U} investigation of positron lifetimes in {U}{O} _2 \u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201890\u2019), (\u2018number\u2019, \u201818\u2019), (\u2018pages\u2019, \u2018184101\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018publisher\u2019, \u2018APS\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Barthe, M.-F.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Freyss, M.\u2019), Person(\u2018Bertolus, M.\u2019)])]))",
            "title": "Wiktor2014a"
        },
        {
            "location": "/bibliography/#wiktor2014b",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Electronic structure calculations of positron lifetimes in {S}i{C}: Self-consistent schemes and relaxation effect\u2019), (\u2018journal\u2019, \u2018Nucl. Instrum. Meth.\u2019), (\u2018volume\u2019, \u2018327\u2019), (\u2018pages\u2019, \u201863\u2019), (\u2018year\u2019, \u20182014\u2019), (\u2018doi\u2019, \u201810.1016/j.nimb.2013.09.050\u2019), (\u2018publisher\u2019, \u2018Elsevier\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Bertolus, M.\u2019)])]))",
            "title": "Wiktor2014b"
        },
        {
            "location": "/bibliography/#wiktor2015",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Two-component density functional theory within the projector augmented-wave approach: Accurate and self-consistent computations of positron lifetimes and momentum distributions\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201892\u2019), (\u2018issue\u2019, \u201812\u2019), (\u2018pages\u2019, \u2018125113\u2019), (\u2018numpages\u2019, \u201815\u2019), (\u2018year\u2019, \u20182015\u2019), (\u2018month\u2019, \u2018Sep\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevB.92.125113\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevB.92.125113\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Wiktor, J.\u2019), Person(\u2018Jomard, G.\u2019), Person(\u2018Torrent, M.\u2019)])]))",
            "title": "Wiktor2015"
        },
        {
            "location": "/bibliography/#xu2014",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018Doi\u2019, \u201810.1103/PhysRevLett.112.196603\u2019), (\u2018Issue\u2019, \u201819\u2019), (\u2018Journal\u2019, \u2018Phys. Rev. Lett.\u2019), (\u2018Numpages\u2019, \u20185\u2019), (\u2018Pages\u2019, \u2018196603\u2019), (\u2018Publisher\u2019, \u2018American Physical Society\u2019), (\u2018Title\u2019, \u2018First Principles Explanation of the Positive Seebeck Coefficient of {L}ithium\u2019), (\u2018Volume\u2019, \u2018112\u2019), (\u2018Year\u2019, \u20182014\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018Author\u2019, [Person(\u2018Xu, B.\u2019), Person(\u2018Verstraete, M. J.\u2019)])]))",
            "title": "Xu2014"
        },
        {
            "location": "/bibliography/#zhou2006",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Parallel self-consistent-field calculations via Chebyshev-filtered subspace acceleration\u2019), (\u2018journal\u2019, \u2018Phys. Rev. E\u2019), (\u2018volume\u2019, \u201874\u2019), (\u2018issue\u2019, \u20186\u2019), (\u2018pages\u2019, \u2018066704\u2019), (\u2018numpages\u2019, \u20188\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018publisher\u2019, \u2018American Physical Society\u2019), (\u2018doi\u2019, \u201810.1103/PhysRevE.74.066704\u2019), (\u2018url\u2019, \u2018http://link.aps.org/doi/10.1103/PhysRevE.74.066704\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Zhou, Y.\u2019), Person(\u2018Saad, Y.\u2019), Person(\u2018Tiago, M.L.\u2019), Person(\u2018Chelikowsky, J.R.\u2019)])]))",
            "title": "Zhou2006"
        },
        {
            "location": "/bibliography/#zhou2006a",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Self-consistent-field calculations using Chebyshev-filtered subspace iteration\u2019), (\u2018journal\u2019, \u2018J. Comp. Phys.\u2019), (\u2018volume\u2019, \u2018219\u2019), (\u2018number\u2019, \u20181\u2019), (\u2018pages\u2019, \u2018172\u2013184\u2019), (\u2018year\u2019, \u20182006\u2019), (\u2018publisher\u2019, \u2018Elsevier\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Zhou, Y.\u2019), Person(\u2018Saad, Y.\u2019), Person(\u2018Tiago, M.L\u2019), Person(\u2018Chelikowsky, J. R.\u2019)])]))",
            "title": "Zhou2006a"
        },
        {
            "location": "/bibliography/#ziman1960",
            "text": "Entry(\u2018book\u2019, fields=[(\u2018title\u2019, \u2018Electrons and phonons\u2019), (\u2018publisher\u2019, \u2018Oxford University Press\u2019), (\u2018year\u2019, \u20181960\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Ziman, J. M.\u2019)])]))",
            "title": "Ziman1960"
        },
        {
            "location": "/bibliography/#zwanziger2012",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Finite homogeneous electric fields in the projector augmented wave formalism: Applications to linear and nonlinear response\u2019), (\u2018journal\u2019, \u2018Comput. Mater. Sci.\u2019), (\u2018volume\u2019, \u201858\u2019), (\u2018pages\u2019, \u2018113\u2013118\u2019), (\u2018year\u2019, \u20182012\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Zwanziger, J.W.\u2019), Person(\u2018Galbraith, J.\u2019), Person(\u2018Kipouros, Y.\u2019), Person(\u2018Torrent, M.\u2019), Person(\u2018Giantomassi, M.\u2019), Person(\u2018Gonze, X.\u2019)])]))",
            "title": "Zwanziger2012"
        },
        {
            "location": "/bibliography/#lechermann2006",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Dynamical mean-field theory using Wannier functions: A flexible route to electronic structure calculations of strongly correlated materials\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201874\u2019), (\u2018pages\u2019, \u2018125120\u2019), (\u2018year\u2019, \u20182006\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Lechermann, F.\u2019), Person(\u2018Georges, A.\u2019), Person(\u2018Poteryaev, S.\u2019), Person(\u2018Biermann, S.\u2019), Person(\u2018Posternak, M.\u2019), Person(\u2018Yamasaki, A.\u2019), Person(\u2018Andersen, O. K.\u2019)])]))",
            "title": "Lechermann2006"
        },
        {
            "location": "/bibliography/#fresard1997",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Interplay of Mott transition and ferromagnetism in the orbitally degenerate Hubbard model\u2019), (\u2018journal\u2019, \u2018Phys. Rev. B\u2019), (\u2018volume\u2019, \u201856\u2019), (\u2018pages\u2019, \u201812909\u2019), (\u2018year\u2019, \u20181997\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u201cFr\\\u2018esard, Raymond\u201d), Person(\u2018Kotliar, Gabriel\u2019)])]))",
            "title": "Fresard1997"
        },
        {
            "location": "/bibliography/#bergeron2016",
            "text": "Entry(\u2018article\u2019, fields=[(\u2018title\u2019, \u2018Algorithms for optimized maximum entropy and diagnostic tools for analytic continuation\u2019), (\u2018journal\u2019, \u2018Phys. Rev. E\u2019), (\u2018volume\u2019, \u201894\u2019), (\u2018pages\u2019, \u2018023303\u2019), (\u2018year\u2019, \u20182016\u2019)], persons=OrderedCaseInsensitiveDict([(\u2018author\u2019, [Person(\u2018Bergeron, D.\u2019), Person(\u2018Tremblay, A.-M.S.\u2019)])]))",
            "title": "Bergeron2016"
        },
        {
            "location": "/about/release-notes/",
            "text": "v8.4\n\n\nv8.2\n\n\n\n\n\n\nv8.4\n\u00b6\n\n\nMany thanks to the contributors to the ABINIT project between\nJanuary 2017 and May 2017. \nThese release notes are relative to modifications/improvements of ABINITv8.4 with respect to v8.2.\n\n\nThe list of contributors includes :\nF. Altvater, G. Antonius, L. Baguet, J.-M. Beuken, J. Bieder, E. Bousquet, \nW. Chen, G. Geneste, M. Giantomassi, Y. Gillet, X. Gonze, F. Jollet, A. Martin, \nF. Naccarato, G. Petretto, S. Prokhorenko, F. Ricci, M. Torrent , M. Verstraete, J. Zwanziger\n\n\nIt is worth to read carefully all the modifications that are mentioned in the present file,\nand examine the links to help files or test cases \u2026\nThis might take some time \u2026\n\n\nXavier\n\n\n\n\nVersion 8.4, released on June 2, 2017.\n\n\nChanges with respect to version 8.2 :\n\n\nA. Warnings and important remarks \nB. Most noticeable achievements (for users)\nC. Changes in the package, for developers\nD. Other changes (or on-going developments, not finalized)\n\n\n\n\nA.  Warnings and important remarks\n\n\nA.1 The Github ABINIT Web page, at https://github.com/abinit, allows one to\n    access the mirror of the repository of ABINIT, as well as some other projects\n    related to ABINIT, like AbiPy or the pseudo-dojo.\n\n\nA.2 The content of the ABINIT Web portal, specifically for the pages related to the presentation of \n    ABINIT (http://www.abinit.org/about/what-is-abinit), has been upgraded.  \n\n\n\n\nB.  Most noticeable achievements\n\n\nB.1 Implementation of algorithms to interpolate the electronic band structure,\n    based either on \u201cstar functions\u201d of on \u201cB-splines\u201d (as alternatives to Wannier function interpolation).\n    See the input variables einterp, nkpath, and prtebands, and tests Tlibxc#42, Tv8#04.\n    Work by M. Giantomassi\n\n\nB.2 The Fock mixing factor for the HSE hybrid functional can be tuned thanks to the input variable gwfockmix  .\n    (Warning : this is for the GW-type approach to electronic structure only, not for total energies)\n    See test Tlibxc#43 .\n    Work by W. Chen.\n\n\nB.3 Implementation of spatially-varying chemical potential, for each atomic species.\n    See the input variables chempot and nzchempot, and tests Tv8#30 and 31.\n    Work by X. Gonze\n\n\nB.4 Linear geometrical constraints can now be imposed on PIMD runs.\n    This allows ABINIT to use the blue moon sampling technique.\n    See the input variable pimd_contraint, and test Tv8#05\n    The use of history (HIST) files is now possible with images.\n    Work by G. Geneste and M. Torrent.\n\n\nB.5 Computation of linear reponse (optics executable as well as BSE part of ABINIT)\n    in the case of temperature-dependent electronic structure.\n    See tests Tv67mbpt#50-53.\n    WARNING : This capability of ABINIT has not been fully tested. However, the\n    basic tests for non-spin-polarized simple semiconductors are OK.\n    As usual, use at your own risk.\n    Work by Y. Gillet and M. Giantomassi.\n\n\nB.6 Computation of Gruneisen parameters by finite differences, within ANADDB.\n    See test v8#45\n    Work by M. Giantomassi\n\n\nB.7 New LOBPCG implementation wfoptalg=114.\n    This is the default when paral_kgb=1.\n    Performances are equivalent in standard use (MPI alone) and much better with openmp+multithreaded linalg. \n    It also allows to have only one block for large system and to reduce memory copies.\n    This version has been developed keeping in mind the next generation of HPC.\n    Work by J. Bieder\n\n\nB.8 New algorithms for the displacement of nuclei (ionmov) :\n    - Hybrid Monte Carlo (HMC) predictor (ionmov=25)\n    - Velocity Verlet (VV) NVE molecular dynamics predictor (ionmov=24)\n    See Tv8#12 for ionmov=24. \n    Work by S. Prokhorenko\n\n\nB.9 Refactoring of ANADDB for the production of DOS and other thermodynamic quantities,\n    also the mean square displacement and mean square velocity.\n    The DOS is obtained using usual DOS methods, instead of the histogram method,\n    and converges much faster with ng2qpt. Activated with prtdos 1 or 2 in anaddb.\n    Work by M. Verstraete.\n\n\n\n\nC. Changes for the developers (also compilers)\n\n\nC.1 Management of the test farm : the new bot ubu_intel_17_openmpi \n    has been activated, so that Intel 17 is now supported.\n    Also, replacement of shiva_gnu_6.3_py3k by inca_gnu_6.3_py3k,\n    update of graphene (MacPorts) to gcc6.3 + scalapack.\n    By J.M. Beuken.\n\n\n\n\nD.  Other changes (or on-going developments, not yet finalized).\n\n\nD.1 The printing of potentials (e.g. prtvxc \u2026) works now for DFPT.\n    By M. Verstraete.\n\n\nD.2 New input variable prtphbands.\n    See tests v7#88 and v8#46.\n    By M. Giantomassi\n\n\nD.3 In case the ANADDB interpolation of phonon frequencies produces\n    erroneously a negative slope around gamma, the new nsphere=-1 possibility\n    allows ANADDB to select a set of IFCs that does not lead to such non-physical behaviour.\n    See test v8#46.\n    Work by M. Giantomassi.\n\n\nD.4 Added new value for nlflag=3 that computes only the non-linear susceptibility.\n    By F. Naccarato.\n\n\nD.5 Computation of forces is now possible in the Wavelets + PAW case.\n    By M. Torrent.\n\n\nD.6 Ongoing work concerning the new \u201cdriver\u201d optdrive=7 specifically dealing with electron-phonon \n    related computations (including zero-point renormalisation). \n    See new tests v8#41 to 44.\n    Work by M. Giantomassi.\n\n\nD.7 Ongoing work : Raman intensities, in the PAW case, using DFPT. \n    By L. Baguet and M. Torrent\n\n\nD.8 Ongoing work related to non-collinear DFPT.\n    Definition of the new input variable rfmagn, as well as Tv8#20 .\n    DFPT with static B-field (Zeeman term only) works for q=(0 0 0).\n    Adjustmanet of dfpt corrections for metals to non-collinear case.\n    Bug fix for GS calculations with finite magnetic field (case of collinear spins).\n    By S. Prokhorenko, F. Ricci, and E. Bousquet\n\n\nD.9 Ongoing work on the multibinit project.\n    NPT simulations are possible.\n    New tests v8#06 and paral#100, to check the correct IO of XML files.\n    Note that tests Tv7#120-124 have been renumbered Tv8#07-11.\n    Work by A. Martin\n\n\nD.10 New test paral#62, to make sure paralkgb=0 works when there are some idle procs.\n     By M. Giantomassi\n\n\nD.11 Ongoing work on forces and stresses for hybrid functionals.\n     By F. Jollet \n\n\nD.12 Ongoing work on the electron-phonon postprocessor ElectronPhononCoupling.\n     Fix bug affecting MPI runs. \n     By G. Antonius.\n\n\nD.13 Improvement of zheevd using MAGMA (from a msg on the forum)\n     By M. Torrent\n\n\nD.14 Implemented KSS.nc output with netcdf primitives\n     By M. Giantomassi\n\n\nD.15 Concerning  the Fourier interpolation of the phonon band structure,\n     inside ANADDB, work by G Petretto :\n     - Updates in the calculation of sound velocity, \n     - Small modifications for nlflag==3 and added some quantities to the anaddb netcdf file,\n     - Fix a bug in the implementation of the new weights\n\n\nD.16 Concerning Path Integral Molecular Dynamics with Quantum Thermal Bath :\n     allow restart from history file.\n     By M. Torrent\n\n\nD.17 Refactored the computation of the electric dipole moment.\n     By M. Torrent\n\n\nD.18 The energy width for the bands in the Boltztrap intrans file is now automatically set.\n     Previously a constant 0.4 Ryd, and the user should have checked by hand if\n     the value was sufficient. Should be considered a bug fix.\n     By M Verstraete\n\n\nD.19 Numerous miscellaneous additional bug fixes and improvements of documentation by :\n     F. Altvater, G. Antonius, J. Bieder, M. Giantomassi, F. Jollet, \n     G. Petretto, M. Verstraete, M. Torrent, J. Zwanziger. \n\n\n\n\nv8.2\n\u00b6\n\n\nMany thanks to the contributors to the ABINIT project between\nJune 2016 and January 2017. These release notes\nare relative to modifications/improvements of ABINITv8.2 with respect to v8.0.\n\n\nMoreover, most of them are also described in the Computer Physics Communications 2016 ABINIT paper, \ndoi:10.1016/j.cpc.2016.04.003\n\n\nThe list of contributors includes :\nB. Amadon, G. Antonius, L. Baguet, J.-M. Beuken, J. Bieder, E. Bousquet, F. Bruneval,\nW. Chen, M. Giantomassi, Y. Gillet, X. Gonze, G. Petretto, F. Jollet, A. Martin,\nV. Planes, Y. Pouillon, T. Rangel, F. Ricci, M. Torrent , M. Verstraete\n\n\nIt is worth to read carefully all the modifications that are mentioned in the present file,\nand examine the links to help files or test cases \u2026\nThis might take some time \u2026\n\n\nXavier\n\n\n\n\nVersion 8.2, released on February 16, 2017.\n\n\nChanges with respect to version 8.0 :\n\n\nA. WARNINGS.\nB. Most noticeable achievements (for users)\nC. Changes in the package, for developers\nD. Other changes (or on-going developments, not finalized)\n\n\n\n\nA.  WARNINGS AND IMPORTANT REMARKS\n\n\nA.0 The 2016 article by the ABINIT group is now mentioned in the acknowledgments :\n    \u201cRecent developments in the ABINIT software package. \n    Computer. Phys. Communications 205, 106 (2016)\u201d.\n    See http://www.abinit.org/doc/helpfiles/for-v8.2/users/acknowledgments.html , as well as\n    the notice at the end of ABINIT runs.\n\n\nA.1 inclvkb 1 has been removed. Now the possible values are either 0 or 2\n\n\nA.2 The default strategy of so_psp has been changed \n    (see the description of the input variable so_psp).\n\n\n\n\nB.  Most noticeable achievements\n\n\nB.1 Implementation of the Limited-memory Broyden-Fletcher-Goldfarb-Shanno (LBFGS) \n    minimization algorithm.  Activate this algorithm using ionmov=22. \n    From the tests that have been run, this algorithm can be much better\n    than the native implementation of BFGS in ABINIT when one approaches convergence, \n    perhaps because of better treatment of numerical details. \n    This algorithm might become the default in ABINIT, if the better behaviour is confirmed.\n    Test case : v8#02 .\n    The working routines were based on the original implementation of J. Nocera \n    available on netlib.org.  They have been reshaped and translated into modern fortran, \n    then interfaced to ABINIT by F. Bruneval (sources in 45_geomoptim/m_lbfgs.F90).\n\n\nB.2 A new tutorial is available : a lesson on the calculation of the effective interactions U and J \n    using constrained Random Phase Approximation (cRPA) for DFT+DMFT (or DFT+U) calculations.\n    See doc/tutorial/lesson_ucalc_crpa.html as well as the automatic tests tutorial/tucrpa#1-5 .\n    This lesson was prepared by B. Amadon.\n\n\nB.3 Implementation of temperature-dependent spectral functions \n    (electronic spectral function, with electron-phonon interactions),\n    as well as real part of phonon self-energy (Pi) for gapped systems.\n    Also, automatic test for spectral function, v7#89, and improved documentation.\n    Work by G. Antonius.\n\n\nB.4 The RPA one-shot bootstrap fxc kernel has been implemented for GW calculations (gwgamma=-8).\n    See Rigamonti et al PRL 114, 146402 (2014) and Berger PRL 115, 137402 (2015).\n    The test v67mbpt#36 has been updated.\n    Work by W. Chen.\n\n\n\n\nC. Changes for the developers (also compilers)\n\n\nC.1 The version control system that is used for the development of ABINIT has been changed : \n    the whole ABINIT project\n    has been ported from bzr to git.\n    Work by J.-M. Beuken, Y. Pouillon, M. Giantomassi, X. Gonze, \n    with discussions with many developers.\n\n\nC.2 New versions of Fortran compilers have been integrated in the test farm:\n    - intel 16.0\n    - gnu 6.1 and 6.2\n    - IBM xlf compiler 14.1\n    - NAG 5.3\n    Corresponding examples are available in doc/config/build-examples.\n    On the contrary, g95 is not tested anymore.\n    Work by J.-M. Beuken\n\n\nC.3 The v8 directory for tests has been initialized.\n    By Matteo Giantomassi.\n\n\nC.4 Python 3 >= 3.4 is now supported in build system scripts \n    (compatibility with py2_ version >= is maintained).\n    By Matteo Giantomassi.\n\n\n\n\nD.  Other changes\n(or on-going developments, not yet finalized).\n\n\nD.1 The main executable \u201cmultibinit\u201d has been created.\n    Its goal is to perform \u201csecond-principles calculations\u201d, building model Hamiltonians\n    using the data provided by the DDB (or other info from ABINIT).\n    Tests v7#120-124 (should be renamed) as well as paral#95-98.\n    Work by A. Martin.\n\n\nD.2 A new \u201cdriver\u201d within ABINIT has been defined, specifically dealing with electron-phonon \n    related computations (including zero-point renormalisation). \n    Set optdriver=7 . \n    New input variables : ddb_shiftq, eph_task, eph_transport, prtphdos, prtphsurf.\n    See tests v7#88 and 89.\n    Work by M. Giantomassi and G. Antonius.\n\n\nD.3 The generation of k-point meshes with kptrlatt and shiftk is now tested.\n    See test v8#03 .\n    Work by M. Giantomassi\n\n\nD.4 As a follow-up of the Achievement B3 in the release notes of ABINITv8.0 (DMFT + TRIQS),\n    new input variables have been defined for DMFT : dmft_tolfreq and dmftctqmc_triqs_nleg.\n    Automatic tests have been set-up, tests v8#01 and paral#99.\n    Work by B. Amadon and V. Planes\n\n\nD.5 More systematic tests of the IO in parallel (different files) have been set up,\n    in the norm-conserving, PAW and PAW + spin-orbit cases.\n    See tests mpiio#26, 27 and 28.\n    Also, the case paral_kgb=0 is now tested with idle processors. See test paral#62.\n    Work by M. Giantomassi\n\n\nD.6 The load balancing for the repartition of the plane waves among procs is now monitored,\n    and a dynamical equilibration is made possible thanks to the new input variable pw_unbal_thresh.\n    See test mpiio#26.\n    Work by M. Torrent\n\n\nD.7 The capability to output spin-resolved DOS in case of spin-orbit NC pseudopotential\n    calculations has been checked, and a test has been set-up (test v7#17).\n    Work by M. Giantomassi\n\n\nD.8 Files generated by ABINIT, and used by BOLTZTRAP are now tested.\n    See v6#11.\n    Work by M. Giantomassi\n\n\nD.9 Unit tests (fftprof) have been set up for the use of the MKL-DFTI routines : \n    unitary#tfftmkl_03 and 04.\n    Work by M. Giantomassi\n\n\nD.10 Ongoing work : Raman intensities, in the PAW case, using DFPT. \n     By L. Baguet and M. Torrent\n\n\nD.11 prtvcbm working with all parallelizations.\n     Tests mpiio 26:28 have been reactivated on 4 processors.\n     By M. Torrent\n\n\nD.12 On going work related to non-collinear DFPT.\n     By F. Ricci, S. Prokhorenko, and E. Bousquet\n\n\nD.13 MBPT : support for the commutator [Vnl r] in the case of NC pseudos \n     with more than one projector per l-channel has been added. \n     Tests in v67mbpt[40] (GW run with psp8 files).\n     SOC is not yet available, though.\n     The KSS file continues to use the old implementation to maintain backward compatibility \n     hence outkss won\u2019t produce the file if multiple-projectors are detected\n     inclvkb 1 has been removed. Now the possible values are either 0 or 2\n     By M Giantomassi\n\n\nD.14 For Hirshfeld and Bader : doc and warning.\n     For Hirshfeld charges the output was unclear: the density integral (electrons only) \n     was called the hirshfeld charge, as opposed to the net one. \n     For Bader there was no check that the core charge file \n     corresponded to the pseudopotential used. \n     Now checks at least that it integrates to znucl-zion, which is a first step. \n     Important as the default fc files on the web do not have semicore electrons, \n     whereas many of the psp8 will.\n     Contribution by M. Verstraete.\n\n\nD.15 Updated acknowledgments, including the 2016 paper.\n     By X. Gonze\n\n\nD.16 Ongoing work on forces and stresses for hybrid functionals.\n     By F. Jollet \n\n\nD.17 Ongoing work concerning weights for the Fourier interpolation inside ANADDB.\n     By G. Petretto\n\n\nD.18 Numerous miscellaneous additional bug fixes \n     (to the sources, as well as to the build system, including patches for the fallbacks), \n     and improvements of documentation by :\n     G. Antonius, L. Baguet, J. Bieder, F. Bruneval,\n     M. Giantomassi, Y. Gillet, G. Petretto, Y. Pouillon,\n     M. Verstraete, M. Torrent (in particular, for DFPT+PAW).",
            "title": "Release Notes"
        },
        {
            "location": "/about/release-notes/#v84",
            "text": "Many thanks to the contributors to the ABINIT project between\nJanuary 2017 and May 2017. \nThese release notes are relative to modifications/improvements of ABINITv8.4 with respect to v8.2.  The list of contributors includes :\nF. Altvater, G. Antonius, L. Baguet, J.-M. Beuken, J. Bieder, E. Bousquet, \nW. Chen, G. Geneste, M. Giantomassi, Y. Gillet, X. Gonze, F. Jollet, A. Martin, \nF. Naccarato, G. Petretto, S. Prokhorenko, F. Ricci, M. Torrent , M. Verstraete, J. Zwanziger  It is worth to read carefully all the modifications that are mentioned in the present file,\nand examine the links to help files or test cases \u2026\nThis might take some time \u2026  Xavier   Version 8.4, released on June 2, 2017.  Changes with respect to version 8.2 :  A. Warnings and important remarks \nB. Most noticeable achievements (for users)\nC. Changes in the package, for developers\nD. Other changes (or on-going developments, not finalized)   A.  Warnings and important remarks  A.1 The Github ABINIT Web page, at https://github.com/abinit, allows one to\n    access the mirror of the repository of ABINIT, as well as some other projects\n    related to ABINIT, like AbiPy or the pseudo-dojo.  A.2 The content of the ABINIT Web portal, specifically for the pages related to the presentation of \n    ABINIT (http://www.abinit.org/about/what-is-abinit), has been upgraded.     B.  Most noticeable achievements  B.1 Implementation of algorithms to interpolate the electronic band structure,\n    based either on \u201cstar functions\u201d of on \u201cB-splines\u201d (as alternatives to Wannier function interpolation).\n    See the input variables einterp, nkpath, and prtebands, and tests Tlibxc#42, Tv8#04.\n    Work by M. Giantomassi  B.2 The Fock mixing factor for the HSE hybrid functional can be tuned thanks to the input variable gwfockmix  .\n    (Warning : this is for the GW-type approach to electronic structure only, not for total energies)\n    See test Tlibxc#43 .\n    Work by W. Chen.  B.3 Implementation of spatially-varying chemical potential, for each atomic species.\n    See the input variables chempot and nzchempot, and tests Tv8#30 and 31.\n    Work by X. Gonze  B.4 Linear geometrical constraints can now be imposed on PIMD runs.\n    This allows ABINIT to use the blue moon sampling technique.\n    See the input variable pimd_contraint, and test Tv8#05\n    The use of history (HIST) files is now possible with images.\n    Work by G. Geneste and M. Torrent.  B.5 Computation of linear reponse (optics executable as well as BSE part of ABINIT)\n    in the case of temperature-dependent electronic structure.\n    See tests Tv67mbpt#50-53.\n    WARNING : This capability of ABINIT has not been fully tested. However, the\n    basic tests for non-spin-polarized simple semiconductors are OK.\n    As usual, use at your own risk.\n    Work by Y. Gillet and M. Giantomassi.  B.6 Computation of Gruneisen parameters by finite differences, within ANADDB.\n    See test v8#45\n    Work by M. Giantomassi  B.7 New LOBPCG implementation wfoptalg=114.\n    This is the default when paral_kgb=1.\n    Performances are equivalent in standard use (MPI alone) and much better with openmp+multithreaded linalg. \n    It also allows to have only one block for large system and to reduce memory copies.\n    This version has been developed keeping in mind the next generation of HPC.\n    Work by J. Bieder  B.8 New algorithms for the displacement of nuclei (ionmov) :\n    - Hybrid Monte Carlo (HMC) predictor (ionmov=25)\n    - Velocity Verlet (VV) NVE molecular dynamics predictor (ionmov=24)\n    See Tv8#12 for ionmov=24. \n    Work by S. Prokhorenko  B.9 Refactoring of ANADDB for the production of DOS and other thermodynamic quantities,\n    also the mean square displacement and mean square velocity.\n    The DOS is obtained using usual DOS methods, instead of the histogram method,\n    and converges much faster with ng2qpt. Activated with prtdos 1 or 2 in anaddb.\n    Work by M. Verstraete.   C. Changes for the developers (also compilers)  C.1 Management of the test farm : the new bot ubu_intel_17_openmpi \n    has been activated, so that Intel 17 is now supported.\n    Also, replacement of shiva_gnu_6.3_py3k by inca_gnu_6.3_py3k,\n    update of graphene (MacPorts) to gcc6.3 + scalapack.\n    By J.M. Beuken.   D.  Other changes (or on-going developments, not yet finalized).  D.1 The printing of potentials (e.g. prtvxc \u2026) works now for DFPT.\n    By M. Verstraete.  D.2 New input variable prtphbands.\n    See tests v7#88 and v8#46.\n    By M. Giantomassi  D.3 In case the ANADDB interpolation of phonon frequencies produces\n    erroneously a negative slope around gamma, the new nsphere=-1 possibility\n    allows ANADDB to select a set of IFCs that does not lead to such non-physical behaviour.\n    See test v8#46.\n    Work by M. Giantomassi.  D.4 Added new value for nlflag=3 that computes only the non-linear susceptibility.\n    By F. Naccarato.  D.5 Computation of forces is now possible in the Wavelets + PAW case.\n    By M. Torrent.  D.6 Ongoing work concerning the new \u201cdriver\u201d optdrive=7 specifically dealing with electron-phonon \n    related computations (including zero-point renormalisation). \n    See new tests v8#41 to 44.\n    Work by M. Giantomassi.  D.7 Ongoing work : Raman intensities, in the PAW case, using DFPT. \n    By L. Baguet and M. Torrent  D.8 Ongoing work related to non-collinear DFPT.\n    Definition of the new input variable rfmagn, as well as Tv8#20 .\n    DFPT with static B-field (Zeeman term only) works for q=(0 0 0).\n    Adjustmanet of dfpt corrections for metals to non-collinear case.\n    Bug fix for GS calculations with finite magnetic field (case of collinear spins).\n    By S. Prokhorenko, F. Ricci, and E. Bousquet  D.9 Ongoing work on the multibinit project.\n    NPT simulations are possible.\n    New tests v8#06 and paral#100, to check the correct IO of XML files.\n    Note that tests Tv7#120-124 have been renumbered Tv8#07-11.\n    Work by A. Martin  D.10 New test paral#62, to make sure paralkgb=0 works when there are some idle procs.\n     By M. Giantomassi  D.11 Ongoing work on forces and stresses for hybrid functionals.\n     By F. Jollet   D.12 Ongoing work on the electron-phonon postprocessor ElectronPhononCoupling.\n     Fix bug affecting MPI runs. \n     By G. Antonius.  D.13 Improvement of zheevd using MAGMA (from a msg on the forum)\n     By M. Torrent  D.14 Implemented KSS.nc output with netcdf primitives\n     By M. Giantomassi  D.15 Concerning  the Fourier interpolation of the phonon band structure,\n     inside ANADDB, work by G Petretto :\n     - Updates in the calculation of sound velocity, \n     - Small modifications for nlflag==3 and added some quantities to the anaddb netcdf file,\n     - Fix a bug in the implementation of the new weights  D.16 Concerning Path Integral Molecular Dynamics with Quantum Thermal Bath :\n     allow restart from history file.\n     By M. Torrent  D.17 Refactored the computation of the electric dipole moment.\n     By M. Torrent  D.18 The energy width for the bands in the Boltztrap intrans file is now automatically set.\n     Previously a constant 0.4 Ryd, and the user should have checked by hand if\n     the value was sufficient. Should be considered a bug fix.\n     By M Verstraete  D.19 Numerous miscellaneous additional bug fixes and improvements of documentation by :\n     F. Altvater, G. Antonius, J. Bieder, M. Giantomassi, F. Jollet, \n     G. Petretto, M. Verstraete, M. Torrent, J. Zwanziger.",
            "title": "v8.4"
        },
        {
            "location": "/about/release-notes/#v82",
            "text": "Many thanks to the contributors to the ABINIT project between\nJune 2016 and January 2017. These release notes\nare relative to modifications/improvements of ABINITv8.2 with respect to v8.0.  Moreover, most of them are also described in the Computer Physics Communications 2016 ABINIT paper, \ndoi:10.1016/j.cpc.2016.04.003  The list of contributors includes :\nB. Amadon, G. Antonius, L. Baguet, J.-M. Beuken, J. Bieder, E. Bousquet, F. Bruneval,\nW. Chen, M. Giantomassi, Y. Gillet, X. Gonze, G. Petretto, F. Jollet, A. Martin,\nV. Planes, Y. Pouillon, T. Rangel, F. Ricci, M. Torrent , M. Verstraete  It is worth to read carefully all the modifications that are mentioned in the present file,\nand examine the links to help files or test cases \u2026\nThis might take some time \u2026  Xavier   Version 8.2, released on February 16, 2017.  Changes with respect to version 8.0 :  A. WARNINGS.\nB. Most noticeable achievements (for users)\nC. Changes in the package, for developers\nD. Other changes (or on-going developments, not finalized)   A.  WARNINGS AND IMPORTANT REMARKS  A.0 The 2016 article by the ABINIT group is now mentioned in the acknowledgments :\n    \u201cRecent developments in the ABINIT software package. \n    Computer. Phys. Communications 205, 106 (2016)\u201d.\n    See http://www.abinit.org/doc/helpfiles/for-v8.2/users/acknowledgments.html , as well as\n    the notice at the end of ABINIT runs.  A.1 inclvkb 1 has been removed. Now the possible values are either 0 or 2  A.2 The default strategy of so_psp has been changed \n    (see the description of the input variable so_psp).   B.  Most noticeable achievements  B.1 Implementation of the Limited-memory Broyden-Fletcher-Goldfarb-Shanno (LBFGS) \n    minimization algorithm.  Activate this algorithm using ionmov=22. \n    From the tests that have been run, this algorithm can be much better\n    than the native implementation of BFGS in ABINIT when one approaches convergence, \n    perhaps because of better treatment of numerical details. \n    This algorithm might become the default in ABINIT, if the better behaviour is confirmed.\n    Test case : v8#02 .\n    The working routines were based on the original implementation of J. Nocera \n    available on netlib.org.  They have been reshaped and translated into modern fortran, \n    then interfaced to ABINIT by F. Bruneval (sources in 45_geomoptim/m_lbfgs.F90).  B.2 A new tutorial is available : a lesson on the calculation of the effective interactions U and J \n    using constrained Random Phase Approximation (cRPA) for DFT+DMFT (or DFT+U) calculations.\n    See doc/tutorial/lesson_ucalc_crpa.html as well as the automatic tests tutorial/tucrpa#1-5 .\n    This lesson was prepared by B. Amadon.  B.3 Implementation of temperature-dependent spectral functions \n    (electronic spectral function, with electron-phonon interactions),\n    as well as real part of phonon self-energy (Pi) for gapped systems.\n    Also, automatic test for spectral function, v7#89, and improved documentation.\n    Work by G. Antonius.  B.4 The RPA one-shot bootstrap fxc kernel has been implemented for GW calculations (gwgamma=-8).\n    See Rigamonti et al PRL 114, 146402 (2014) and Berger PRL 115, 137402 (2015).\n    The test v67mbpt#36 has been updated.\n    Work by W. Chen.   C. Changes for the developers (also compilers)  C.1 The version control system that is used for the development of ABINIT has been changed : \n    the whole ABINIT project\n    has been ported from bzr to git.\n    Work by J.-M. Beuken, Y. Pouillon, M. Giantomassi, X. Gonze, \n    with discussions with many developers.  C.2 New versions of Fortran compilers have been integrated in the test farm:\n    - intel 16.0\n    - gnu 6.1 and 6.2\n    - IBM xlf compiler 14.1\n    - NAG 5.3\n    Corresponding examples are available in doc/config/build-examples.\n    On the contrary, g95 is not tested anymore.\n    Work by J.-M. Beuken  C.3 The v8 directory for tests has been initialized.\n    By Matteo Giantomassi.  C.4 Python 3 >= 3.4 is now supported in build system scripts \n    (compatibility with py2_ version >= is maintained).\n    By Matteo Giantomassi.   D.  Other changes\n(or on-going developments, not yet finalized).  D.1 The main executable \u201cmultibinit\u201d has been created.\n    Its goal is to perform \u201csecond-principles calculations\u201d, building model Hamiltonians\n    using the data provided by the DDB (or other info from ABINIT).\n    Tests v7#120-124 (should be renamed) as well as paral#95-98.\n    Work by A. Martin.  D.2 A new \u201cdriver\u201d within ABINIT has been defined, specifically dealing with electron-phonon \n    related computations (including zero-point renormalisation). \n    Set optdriver=7 . \n    New input variables : ddb_shiftq, eph_task, eph_transport, prtphdos, prtphsurf.\n    See tests v7#88 and 89.\n    Work by M. Giantomassi and G. Antonius.  D.3 The generation of k-point meshes with kptrlatt and shiftk is now tested.\n    See test v8#03 .\n    Work by M. Giantomassi  D.4 As a follow-up of the Achievement B3 in the release notes of ABINITv8.0 (DMFT + TRIQS),\n    new input variables have been defined for DMFT : dmft_tolfreq and dmftctqmc_triqs_nleg.\n    Automatic tests have been set-up, tests v8#01 and paral#99.\n    Work by B. Amadon and V. Planes  D.5 More systematic tests of the IO in parallel (different files) have been set up,\n    in the norm-conserving, PAW and PAW + spin-orbit cases.\n    See tests mpiio#26, 27 and 28.\n    Also, the case paral_kgb=0 is now tested with idle processors. See test paral#62.\n    Work by M. Giantomassi  D.6 The load balancing for the repartition of the plane waves among procs is now monitored,\n    and a dynamical equilibration is made possible thanks to the new input variable pw_unbal_thresh.\n    See test mpiio#26.\n    Work by M. Torrent  D.7 The capability to output spin-resolved DOS in case of spin-orbit NC pseudopotential\n    calculations has been checked, and a test has been set-up (test v7#17).\n    Work by M. Giantomassi  D.8 Files generated by ABINIT, and used by BOLTZTRAP are now tested.\n    See v6#11.\n    Work by M. Giantomassi  D.9 Unit tests (fftprof) have been set up for the use of the MKL-DFTI routines : \n    unitary#tfftmkl_03 and 04.\n    Work by M. Giantomassi  D.10 Ongoing work : Raman intensities, in the PAW case, using DFPT. \n     By L. Baguet and M. Torrent  D.11 prtvcbm working with all parallelizations.\n     Tests mpiio 26:28 have been reactivated on 4 processors.\n     By M. Torrent  D.12 On going work related to non-collinear DFPT.\n     By F. Ricci, S. Prokhorenko, and E. Bousquet  D.13 MBPT : support for the commutator [Vnl r] in the case of NC pseudos \n     with more than one projector per l-channel has been added. \n     Tests in v67mbpt[40] (GW run with psp8 files).\n     SOC is not yet available, though.\n     The KSS file continues to use the old implementation to maintain backward compatibility \n     hence outkss won\u2019t produce the file if multiple-projectors are detected\n     inclvkb 1 has been removed. Now the possible values are either 0 or 2\n     By M Giantomassi  D.14 For Hirshfeld and Bader : doc and warning.\n     For Hirshfeld charges the output was unclear: the density integral (electrons only) \n     was called the hirshfeld charge, as opposed to the net one. \n     For Bader there was no check that the core charge file \n     corresponded to the pseudopotential used. \n     Now checks at least that it integrates to znucl-zion, which is a first step. \n     Important as the default fc files on the web do not have semicore electrons, \n     whereas many of the psp8 will.\n     Contribution by M. Verstraete.  D.15 Updated acknowledgments, including the 2016 paper.\n     By X. Gonze  D.16 Ongoing work on forces and stresses for hybrid functionals.\n     By F. Jollet   D.17 Ongoing work concerning weights for the Fourier interpolation inside ANADDB.\n     By G. Petretto  D.18 Numerous miscellaneous additional bug fixes \n     (to the sources, as well as to the build system, including patches for the fallbacks), \n     and improvements of documentation by :\n     G. Antonius, L. Baguet, J. Bieder, F. Bruneval,\n     M. Giantomassi, Y. Gillet, G. Petretto, Y. Pouillon,\n     M. Verstraete, M. Torrent (in particular, for DFPT+PAW).",
            "title": "v8.2"
        },
        {
            "location": "/about/contributing/",
            "text": "How to contribute to ABINIT\n\u00b6\n\n\nThis page provides a description of the procedures followed for development of\nthe ABINIT package through collaboration of different groups of persons, based\nin different places in the world. Its content was formerly found in the\nInfos/Notes_for_coding/contributing.html text file.\n\n\nAny comment or suggestion to improve these procedures will be welcome!\n\n\n\n\n\n\nHow to contribute to ABINIT\n\n\nIntroduction\n\n\nCode repositories\n\n\nBasic philosophy\n\n\nDetailed protocol for the developer\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction\n\u00b6\n\n\nThe ABINIT package is aimed at being used by different groups of people,\nwithout mandatory control by the main contributors of the ABINIT group. In the\nsame way, the ABINIT development project is fundamentally open to the\ncontributions of different persons, not located in Louvain-la-neuve or\nCorning. These contributing persons are members \nde facto\n of the ABINIT\ngroup.\n\n\nPeople using the code might consider adding their personal subroutines,\nwithout trying to make them part of the official ABINIT package. However, this\nhas two drawbacks for them: in subsequent versions, their modifications will\nnot be incorporated, so that they might have to check and modify the interface\nfor each new version ; moreover, their contribution is not tested by other\nusers of the code, so that bugs might remain unnoticed. It is also nicer to\nshare the result of their coding efforts with other users of the code.\n\n\nOf course, a collaborative effort has also some drawbacks. In particular, the\ncollaboration between distant developers should be carefully planned, since\northogonal modifications of the same piece of code by two different people at\nthe same time is very likely to happen, generating \u201cnegative progress\u201d, i.e. a\nlarge waste of time when synchronization is to be done. Also, it is required\nto use a well-defined coding style, to provide test case files, and to comment\nthe modifications and additions as much as possible, in order to facilitate\nthe maintenance and the future modifications.\n\n\nThis document aims at defining the protocol to be followed to avoid \u201cnegative\nprogress\u201d due to lack of synchronization. The analogy with the procedures to\nbe used for the parallelization of a code is obvious. The aim is that each\nexternal \u2018node\u2019 does not waste its time, that communications are kept at the\nlowest level possible, and that the final result is correct ! We will need\nbarriers for synchronization, and so on \u2026\n\n\nThe ability to incorporate the contributions of different groups in a\nharmonious way might become a noticeable strength of the ABINIT project.\n\n\nCode repositories\n\u00b6\n\n\nManaging different versions of ABINIT is done thanks to a utility called\n\nBazaar\n. For an introduction to this powerful\nand versatile tool, you can have a look at our dedicated pages in the\nDevelopers\u2019 corner of the ABINIT web site.\n\n\nThanks to Bazaar, the development of a project becomes completely transparent,\nsince all the changes in the files are registered: the latest version is of\ncourse available, but one can come backwards in time to track bugs easily or\nto know what anybody did. The development of different branches is also\nmanaged, as well as the subsequent merging procedure. This feature is\nimportant to allow development by many different people. The place where all\nthe files are stored, including their history, is called a \nrepository\n.\n\n\nFor developers, using the repository is a privileged way of managing their\ncontributions, since the coordinator is automatically and instantly informed\nof their progresses. They also benefit from regular backups of all the\ncontributions.\n\n\nThe ABINIT repository is divided into several \nmain categories\n:\n\n\n\n\nabinit-release\n, where go all contributions for the official release packages, these contributions consisting mainly in fixes and documentation;\n\n\nabinit-devel\n, where all new and ongoing developments are managed;\n\n\nabinit-doc\n, containing new and incomplete documentation, until it is consistent enough to be moved to the source code.\n\n\n\n\nEach category is divided into \nversions\n, 3 digits for \nabinit-release\n and\n2 digits for \nabinit-devel\n. Then, in each category and for each version,\nthere is one \nreference branch\n, codename \nmerge\n, which is the backbone of\nthe development effort. All concerned developers are supposed to use this\nbranch as a starting point for their tasks and to keep permanently in sync\nwith it. They may have at least one branch of their own.\n\n\nBasic philosophy\n\u00b6\n\n\nIn the following, we will distinguish between \n\u201cdebugging\u201d contributions\n\nand \n\u201cdevelopment\u201d contributions\n.\n\n\nDebugging contributions\n are typically modifications of a few lines in one or\nrelatively few routines, needed for the code to work properly or to be\nproperly documented. Sometimes they are related to comments within routines or\ncorrections to documents. Usually, such modifications do not need any\nsynchronization and can be sent directly to the coordinator via email, in the\nform of a patch. It is however possible to have them synchronized by recording\nthem inside the \nabinit-release\n category of the repository.\n\n\nFor the time being, Xavier\n\n<gonze@pcpm.ucl.ac.be>\n should be\ncontacted.\n\n\nDevelopment contributions\n usually involve the addition of new capabilities\nto the code. Despite the use of Bazaar, synchronization with the coordinator\nis \nALWAYS\n needed: one has to make sure that nobody else is already in\ncharge of a similar project! The development contributions might be quite\nlocal (basically adding one routine, called by a few lines from an existing\nroutine), or, on the contrary, involve modifications of many existing\nroutines. Even for the local type of modifications, discussion with the\ncoordinator is mandatory. Though Bazaar now deals nicely with conflicts at the\nfile level, it is of great importance to avoid semantic conflicts from the\nvery beginning.\n\n\nThe developer will be allocated a \ndevelopment task\n. Related to this task,\nthey will be free to code, experiment, debug, and check the result of their\nwork without any communication with the rest of the ABINIT group. The\nallocation of the task has obviously to be done in coordination with the rest\nof the group prior to the work, while the result of the development has to be\nincorporated into a new official version. The task is thus also limited in\ntime.\n\n\nThe prior allocation and subsequent incorporation, taking into account the\npossibility that many different developers work independently, must be done\ncentrally by one or more coordinators (at present Xavier but this might change\nin the future), in order to guarantee the harmony, relevancy and consistency\nof all contributions.\n\n\nIt will be the responsibility of the developer to make enough checks of the\ncorrectness of their modifications or additions. The developer should provide\nadequate documentation: basically the description of the input variables and\noutput data in the \nabinit_help\n file, as well as a possible update of the\nbibliography. They should also provide one or more tests to be added to the\nstandard suite of tests. This is needed to ensure that the transfer to the\nofficial version of the code has been done properly, and also that the new\ncapabilities will be preserved by the subsequent modifications of the code.\nFinally, they have to show that their modifications have not suppressed\nexisting capabilities of the codes, by running the set of already existing\nautomatic tests.\n\n\nIt will be the responsibility of the coordinator to transfer the result of the\ndevelopment effort of each developer to an official version, in such a way\nthat the test is reproduced in a satisfactory way. The subsequent maintenance\nwill be automatically done by checking that the corresponding test is still\nworking despite modifications.\n\n\nDetailed protocol for the developer\n\u00b6\n\n\na.\n The developer proposes a modification or addition to the code to the coordinator. In most cases, such a proposal will be warmly welcome! There might be some discussions possibly involving other scientists to improve the original proposal. The developers mailing list has been set-up for that purpose (see the \u201cCommunity section\u201d on the ABINIT web site). \n\n\nb.\n With respect to the latest official version, the developers define their task and make a list of routines they wish to heavily modify (and those they would like to add, but this is not really needed at that time). Following the current coding practice, adding new input variables would need rather small modifications of a very large number of routines (invars, abinit, gstate, brdmin, move, scfcv, vtorho \u2026). In order to avoid the allocation of too large an area of development within the source code, which would make other development efforts impossible, it is assumed that the developer will make appropriate use of the different \u2018user\u2019 input variables. This appropriate use means that none of the aforementioned routines will be modified for that purpose. The easiest case to handle is when a routine or a set of routines are added to the package, and the interface to the rest of the code involves only a set of called subroutines the interface (list of arguments) should not change, and just one (modified) calling routine. Many development projects of this type can coexist. By contrast, if one of the development efforts involves major changes to major routines, it will prohibit the execution of another development project of the same type, taking into account the current structure of the code. \n\n\nc.\n Having gathered the different suggestions made on the basis of the current official version, the coordinator releases the next version, adequately prepared to allow the proposed developments by different developer groups, with a list of routines allocated to each group, the number of the test cases allocated, and, for information, the tasks that will be done. \n\n\nd.\n After installation on the development machine, and prior to any modification, the developer runs the internal tests, as well as the tests series \nv1\n to \nv5\n and the \nparal\n (sequential cases) suite of tests. The \u201c\nmake tests_dev\n\u201d command is perfectly suited for that purpose. Checking against previous reference files that the results are OK is always nice enough. The developer can replace the reference files provided with the official version by those produced on their machines, to ease further checking of the results. Then the development effort can begin. It is expected \na priori\n that the following files will be modified in any case: \n\n\n\n\nabinit.src\n files in some \nsrc/*\n directories, because the new routines must be listed there;\n\n\nthe \nallvariables.html\n and some of the \nvar*.html\n files, because the new input variables must be listed and documented there (the \u2018user\u2019 variables are now used, but a final, aesthetic, name should be proposed);\n\n\nthe \nREADME\n and \ntests.cnf\n files in the subdirectory \nv5\n, as well as an additional input file (at least).\n\n\n\n\nIMPORTANT\n  \n\n\nDuring the development, only the allocated routines should be modified. This\nis very important. Many others can be created.\n\n\nIn both cases, the developers \nMUST\n follow the current ABINIT coding style,\npresented in the latest version of the document \nrules_coding\n, in the\n\n~abinit/doc/developers\n subdirectory. In particular, they should mention\ntheir initials in the header of the new or modified routines. This will be\nuseful if somebody needs information about this routine some time later.\n\n\nAt the end of the development effort, it is mandatory that the developer runs\nagain the \ntests_dev\n series, to be sure that the developments have not\nspoiled some other feature of the code. This is easily done by issuing \nmake\ntests_dev\n. This command will run automatically the required tests, and\nproduce a file \nsummary_tests.tar.gz\n that should be send with the updated\nroutines and separate new tests. This is important, since the coordinator will\nhave to run the suite of tests as well, but at that time, having trouble with\na modification done by some developer would mean an important delay in the\ndelivery of the new official version, and thus a large waste of time. It is\ndesirable that the tests of the new feature do not last more than 1 minute on\nPentium III 1GHz, or about 20 seconds on other (faster) processors.\n\n\ne.\n After the development has occurred, the developer prepares a gzipped (compressed) tar file with all the needed files (additional routines, modified routines, makemake, abinit_help, README, tests.cnf, \u2026), the \nsummary_tests.tar.gz\n file, and makes it available to the coordinator (by email, FTP or SSH). \n\n\nExample\n\u00b6\n\n\na. David proposes a nice addition to the ABINIT package. Doug and Xavier are\nenthusiastic about it.\n\n\nb. On the basis of version 5.3.4, David proposes a list of routines that\nshould be allocated to him.\n\n\nc. Xavier delivers a 5.4.x version that has been adequately prepared for the\nindependent development that David wants to do.\n\n\nd. David implements his addition and modifications on the basis of version\n5.4.x, checks whether the suite of tests is still OK, and makes the files\navailable to Xavier.\n\n\ne. Xavier thanks David very much, transfers the work to the official version\n5.5.y and performs the final modification of the names of the (new) input\nvariables, including the propagation through the routines that were not\nallocated to the developper.",
            "title": "Contributing"
        },
        {
            "location": "/about/contributing/#how-to-contribute-to-abinit",
            "text": "This page provides a description of the procedures followed for development of\nthe ABINIT package through collaboration of different groups of persons, based\nin different places in the world. Its content was formerly found in the\nInfos/Notes_for_coding/contributing.html text file.  Any comment or suggestion to improve these procedures will be welcome!    How to contribute to ABINIT  Introduction  Code repositories  Basic philosophy  Detailed protocol for the developer  Example",
            "title": "How to contribute to ABINIT"
        },
        {
            "location": "/about/contributing/#introduction",
            "text": "The ABINIT package is aimed at being used by different groups of people,\nwithout mandatory control by the main contributors of the ABINIT group. In the\nsame way, the ABINIT development project is fundamentally open to the\ncontributions of different persons, not located in Louvain-la-neuve or\nCorning. These contributing persons are members  de facto  of the ABINIT\ngroup.  People using the code might consider adding their personal subroutines,\nwithout trying to make them part of the official ABINIT package. However, this\nhas two drawbacks for them: in subsequent versions, their modifications will\nnot be incorporated, so that they might have to check and modify the interface\nfor each new version ; moreover, their contribution is not tested by other\nusers of the code, so that bugs might remain unnoticed. It is also nicer to\nshare the result of their coding efforts with other users of the code.  Of course, a collaborative effort has also some drawbacks. In particular, the\ncollaboration between distant developers should be carefully planned, since\northogonal modifications of the same piece of code by two different people at\nthe same time is very likely to happen, generating \u201cnegative progress\u201d, i.e. a\nlarge waste of time when synchronization is to be done. Also, it is required\nto use a well-defined coding style, to provide test case files, and to comment\nthe modifications and additions as much as possible, in order to facilitate\nthe maintenance and the future modifications.  This document aims at defining the protocol to be followed to avoid \u201cnegative\nprogress\u201d due to lack of synchronization. The analogy with the procedures to\nbe used for the parallelization of a code is obvious. The aim is that each\nexternal \u2018node\u2019 does not waste its time, that communications are kept at the\nlowest level possible, and that the final result is correct ! We will need\nbarriers for synchronization, and so on \u2026  The ability to incorporate the contributions of different groups in a\nharmonious way might become a noticeable strength of the ABINIT project.",
            "title": "Introduction"
        },
        {
            "location": "/about/contributing/#code-repositories",
            "text": "Managing different versions of ABINIT is done thanks to a utility called Bazaar . For an introduction to this powerful\nand versatile tool, you can have a look at our dedicated pages in the\nDevelopers\u2019 corner of the ABINIT web site.  Thanks to Bazaar, the development of a project becomes completely transparent,\nsince all the changes in the files are registered: the latest version is of\ncourse available, but one can come backwards in time to track bugs easily or\nto know what anybody did. The development of different branches is also\nmanaged, as well as the subsequent merging procedure. This feature is\nimportant to allow development by many different people. The place where all\nthe files are stored, including their history, is called a  repository .  For developers, using the repository is a privileged way of managing their\ncontributions, since the coordinator is automatically and instantly informed\nof their progresses. They also benefit from regular backups of all the\ncontributions.  The ABINIT repository is divided into several  main categories :   abinit-release , where go all contributions for the official release packages, these contributions consisting mainly in fixes and documentation;  abinit-devel , where all new and ongoing developments are managed;  abinit-doc , containing new and incomplete documentation, until it is consistent enough to be moved to the source code.   Each category is divided into  versions , 3 digits for  abinit-release  and\n2 digits for  abinit-devel . Then, in each category and for each version,\nthere is one  reference branch , codename  merge , which is the backbone of\nthe development effort. All concerned developers are supposed to use this\nbranch as a starting point for their tasks and to keep permanently in sync\nwith it. They may have at least one branch of their own.",
            "title": "Code repositories"
        },
        {
            "location": "/about/contributing/#basic-philosophy",
            "text": "In the following, we will distinguish between  \u201cdebugging\u201d contributions \nand  \u201cdevelopment\u201d contributions .  Debugging contributions  are typically modifications of a few lines in one or\nrelatively few routines, needed for the code to work properly or to be\nproperly documented. Sometimes they are related to comments within routines or\ncorrections to documents. Usually, such modifications do not need any\nsynchronization and can be sent directly to the coordinator via email, in the\nform of a patch. It is however possible to have them synchronized by recording\nthem inside the  abinit-release  category of the repository.  For the time being, Xavier <gonze@pcpm.ucl.ac.be>  should be\ncontacted.  Development contributions  usually involve the addition of new capabilities\nto the code. Despite the use of Bazaar, synchronization with the coordinator\nis  ALWAYS  needed: one has to make sure that nobody else is already in\ncharge of a similar project! The development contributions might be quite\nlocal (basically adding one routine, called by a few lines from an existing\nroutine), or, on the contrary, involve modifications of many existing\nroutines. Even for the local type of modifications, discussion with the\ncoordinator is mandatory. Though Bazaar now deals nicely with conflicts at the\nfile level, it is of great importance to avoid semantic conflicts from the\nvery beginning.  The developer will be allocated a  development task . Related to this task,\nthey will be free to code, experiment, debug, and check the result of their\nwork without any communication with the rest of the ABINIT group. The\nallocation of the task has obviously to be done in coordination with the rest\nof the group prior to the work, while the result of the development has to be\nincorporated into a new official version. The task is thus also limited in\ntime.  The prior allocation and subsequent incorporation, taking into account the\npossibility that many different developers work independently, must be done\ncentrally by one or more coordinators (at present Xavier but this might change\nin the future), in order to guarantee the harmony, relevancy and consistency\nof all contributions.  It will be the responsibility of the developer to make enough checks of the\ncorrectness of their modifications or additions. The developer should provide\nadequate documentation: basically the description of the input variables and\noutput data in the  abinit_help  file, as well as a possible update of the\nbibliography. They should also provide one or more tests to be added to the\nstandard suite of tests. This is needed to ensure that the transfer to the\nofficial version of the code has been done properly, and also that the new\ncapabilities will be preserved by the subsequent modifications of the code.\nFinally, they have to show that their modifications have not suppressed\nexisting capabilities of the codes, by running the set of already existing\nautomatic tests.  It will be the responsibility of the coordinator to transfer the result of the\ndevelopment effort of each developer to an official version, in such a way\nthat the test is reproduced in a satisfactory way. The subsequent maintenance\nwill be automatically done by checking that the corresponding test is still\nworking despite modifications.",
            "title": "Basic philosophy"
        },
        {
            "location": "/about/contributing/#detailed-protocol-for-the-developer",
            "text": "a.  The developer proposes a modification or addition to the code to the coordinator. In most cases, such a proposal will be warmly welcome! There might be some discussions possibly involving other scientists to improve the original proposal. The developers mailing list has been set-up for that purpose (see the \u201cCommunity section\u201d on the ABINIT web site).   b.  With respect to the latest official version, the developers define their task and make a list of routines they wish to heavily modify (and those they would like to add, but this is not really needed at that time). Following the current coding practice, adding new input variables would need rather small modifications of a very large number of routines (invars, abinit, gstate, brdmin, move, scfcv, vtorho \u2026). In order to avoid the allocation of too large an area of development within the source code, which would make other development efforts impossible, it is assumed that the developer will make appropriate use of the different \u2018user\u2019 input variables. This appropriate use means that none of the aforementioned routines will be modified for that purpose. The easiest case to handle is when a routine or a set of routines are added to the package, and the interface to the rest of the code involves only a set of called subroutines the interface (list of arguments) should not change, and just one (modified) calling routine. Many development projects of this type can coexist. By contrast, if one of the development efforts involves major changes to major routines, it will prohibit the execution of another development project of the same type, taking into account the current structure of the code.   c.  Having gathered the different suggestions made on the basis of the current official version, the coordinator releases the next version, adequately prepared to allow the proposed developments by different developer groups, with a list of routines allocated to each group, the number of the test cases allocated, and, for information, the tasks that will be done.   d.  After installation on the development machine, and prior to any modification, the developer runs the internal tests, as well as the tests series  v1  to  v5  and the  paral  (sequential cases) suite of tests. The \u201c make tests_dev \u201d command is perfectly suited for that purpose. Checking against previous reference files that the results are OK is always nice enough. The developer can replace the reference files provided with the official version by those produced on their machines, to ease further checking of the results. Then the development effort can begin. It is expected  a priori  that the following files will be modified in any case:    abinit.src  files in some  src/*  directories, because the new routines must be listed there;  the  allvariables.html  and some of the  var*.html  files, because the new input variables must be listed and documented there (the \u2018user\u2019 variables are now used, but a final, aesthetic, name should be proposed);  the  README  and  tests.cnf  files in the subdirectory  v5 , as well as an additional input file (at least).   IMPORTANT     During the development, only the allocated routines should be modified. This\nis very important. Many others can be created.  In both cases, the developers  MUST  follow the current ABINIT coding style,\npresented in the latest version of the document  rules_coding , in the ~abinit/doc/developers  subdirectory. In particular, they should mention\ntheir initials in the header of the new or modified routines. This will be\nuseful if somebody needs information about this routine some time later.  At the end of the development effort, it is mandatory that the developer runs\nagain the  tests_dev  series, to be sure that the developments have not\nspoiled some other feature of the code. This is easily done by issuing  make\ntests_dev . This command will run automatically the required tests, and\nproduce a file  summary_tests.tar.gz  that should be send with the updated\nroutines and separate new tests. This is important, since the coordinator will\nhave to run the suite of tests as well, but at that time, having trouble with\na modification done by some developer would mean an important delay in the\ndelivery of the new official version, and thus a large waste of time. It is\ndesirable that the tests of the new feature do not last more than 1 minute on\nPentium III 1GHz, or about 20 seconds on other (faster) processors.  e.  After the development has occurred, the developer prepares a gzipped (compressed) tar file with all the needed files (additional routines, modified routines, makemake, abinit_help, README, tests.cnf, \u2026), the  summary_tests.tar.gz  file, and makes it available to the coordinator (by email, FTP or SSH).",
            "title": "Detailed protocol for the developer"
        },
        {
            "location": "/about/contributing/#example",
            "text": "a. David proposes a nice addition to the ABINIT package. Doug and Xavier are\nenthusiastic about it.  b. On the basis of version 5.3.4, David proposes a list of routines that\nshould be allocated to him.  c. Xavier delivers a 5.4.x version that has been adequately prepared for the\nindependent development that David wants to do.  d. David implements his addition and modifications on the basis of version\n5.4.x, checks whether the suite of tests is still OK, and makes the files\navailable to Xavier.  e. Xavier thanks David very much, transfers the work to the official version\n5.5.y and performs the final modification of the names of the (new) input\nvariables, including the propagation through the routines that were not\nallocated to the developper.",
            "title": "Example"
        },
        {
            "location": "/about/license/",
            "text": "GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. \n\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    \n\n    Copyright (C) \n  \n\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see \n.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    \n  Copyright (C) \n  \n\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n\n.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n\n.",
            "title": "License"
        }
    ]
}